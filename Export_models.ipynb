{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af563537",
   "metadata": {},
   "source": [
    "%%latex\n",
    "\\tableofcontents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bb9f224",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "import random\n",
    "import csv\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcceeebc",
   "metadata": {},
   "source": [
    "# Export the NNC2P model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d04d5a",
   "metadata": {},
   "source": [
    "This is the model architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40ee3cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters of the model here. Will first of all put two hidden layers\n",
    "# total of 800 neurons for the one in the paper\n",
    "device = \"cpu\"\n",
    "size_HL_1 = 600\n",
    "size_HL_2 = 200\n",
    "\n",
    "# Implement neural network\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        #self.flatten = nn.Flatten()\n",
    "        self.stack = nn.Sequential(\n",
    "            nn.Linear(3, size_HL_1),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(size_HL_1, size_HL_2),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(size_HL_2, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # No flatten needed, as our input and output are 1D?\n",
    "        #x = self.flatten(x) \n",
    "        logits = self.stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9071780a",
   "metadata": {},
   "source": [
    "We import NNC2Pv0, which was on par with the models in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e1c29f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "NNC2P = torch.load('Models/NNC2Pv0.pth')\n",
    "model = NNC2P"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561328c5",
   "metadata": {},
   "source": [
    "Look at the parameter values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb013c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.3637,  0.4540, -0.4355],\n",
      "        [ 0.0066,  0.6949,  0.4879],\n",
      "        [ 0.1112, -0.0925,  0.1091],\n",
      "        ...,\n",
      "        [ 0.5306, -0.4535, -0.3026],\n",
      "        [-0.4308, -0.1415,  0.2810],\n",
      "        [ 0.6349, -0.2947,  0.0561]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.5675,  0.2904, -0.7667, -0.3078, -0.1945,  0.0523,  0.0514, -0.4138,\n",
      "         0.2312, -0.5222,  0.2495, -0.3197, -0.4844, -0.5024, -0.3668, -0.2699,\n",
      "         0.7860,  0.7489,  0.1024,  0.8798,  0.1536, -0.4353, -0.3389, -0.5969,\n",
      "        -0.4334, -0.7355, -0.4756, -0.4140, -0.1220, -0.1788, -0.7250, -0.0075,\n",
      "         0.2842,  0.1193,  0.5405, -0.1805, -0.0228, -0.3408, -0.1134, -0.2822,\n",
      "         0.5498, -0.1406,  0.3311, -0.5858,  0.0567, -0.2661,  0.3879,  0.8417,\n",
      "        -0.2426,  0.5311,  0.0035,  0.1361, -0.3355,  0.2191, -0.3657,  0.0739,\n",
      "        -0.7668, -0.7611, -0.4528,  0.7155,  0.4711,  0.1546, -0.7966, -0.6006,\n",
      "         0.5338, -0.4438, -0.5507,  0.2647, -0.5531, -0.1843,  0.6857, -0.1058,\n",
      "        -0.2366,  0.5566, -0.2539, -0.0841, -0.2701,  0.1520, -0.3656, -0.0887,\n",
      "        -0.3681, -0.4994,  0.1562,  0.0979, -0.1539, -0.2539, -0.3159,  0.2476,\n",
      "         0.1437,  0.1037, -0.6092, -0.4861,  0.6079, -0.1717,  0.3969, -0.8278,\n",
      "        -0.7750,  0.4500,  0.1029,  0.0236,  0.3942, -0.0011, -0.5502, -0.6392,\n",
      "        -0.1455, -0.5056, -0.4315, -0.6536, -0.8086,  0.8507, -0.4151, -0.7212,\n",
      "        -0.0891,  0.1468, -0.0913,  0.1593, -0.3147, -0.7297,  0.2530, -0.1589,\n",
      "        -0.1999,  0.4665, -0.5153, -0.6170, -0.3868,  0.0854,  0.5496,  0.1570,\n",
      "        -0.5972,  0.1290, -0.2804, -0.1617, -0.4747, -0.1994,  0.1695, -0.2299,\n",
      "         0.5255, -0.7798,  0.7290, -0.1372, -0.0409,  0.4159,  0.2687, -0.6314,\n",
      "         0.1840, -0.6343, -0.7727,  0.0432,  0.1978,  0.0018, -0.2912,  0.5889,\n",
      "         0.1239, -0.5980, -0.3289, -0.4699,  0.1432,  0.6450, -0.4566,  0.6617,\n",
      "        -0.5549, -0.7374,  0.2306,  0.9800,  0.1920,  0.5020,  0.2284,  0.2587,\n",
      "         0.6900,  0.2306,  0.7923, -0.1113,  0.2198,  0.6304,  0.3187,  0.0511,\n",
      "        -0.5725, -0.6510, -0.7051, -0.3080, -0.2263, -0.5543, -0.2684, -0.2800,\n",
      "        -0.5838,  0.6659, -0.0447, -0.3244, -0.2777,  0.1524,  0.8192, -0.0718,\n",
      "        -0.1331,  0.0362, -0.3517,  0.2572,  0.0893, -0.3430, -0.6010, -0.2209,\n",
      "         0.4120, -0.5042,  0.1973,  0.0020,  0.2477,  0.2700, -0.6794, -0.2675,\n",
      "        -0.3750,  0.3425, -0.0609, -0.0658,  0.3587, -0.2422,  0.3080, -0.7774,\n",
      "        -0.0425, -0.1093, -0.6006, -0.4135,  0.0222,  0.0549,  0.4497,  0.2517,\n",
      "        -0.0629,  0.4377,  0.3117,  0.3804, -0.8146, -0.1727, -0.0757, -0.4479,\n",
      "        -0.3724,  0.2646,  0.2722,  0.2111, -0.4963, -0.7829, -0.1263,  0.1045,\n",
      "        -0.4437, -0.4764,  0.0316, -0.6644,  0.0834,  0.5011,  0.3411,  0.3595,\n",
      "        -0.5658, -0.4027, -0.5273,  0.2064, -0.2696,  0.1704, -0.7847, -0.4299,\n",
      "        -0.5457, -0.2170,  0.5040,  0.1638, -0.2259, -0.1841,  0.3940, -0.1587,\n",
      "        -0.0681, -0.5532,  0.0486, -0.0708, -0.0685, -0.1967, -0.6578, -0.0085,\n",
      "        -0.5584,  0.3869, -0.3360,  0.0781, -0.4732, -0.4988,  0.5257, -0.0463,\n",
      "        -0.5861,  0.0443,  0.3502, -0.3827, -0.0767, -0.4918, -0.0975,  0.0335,\n",
      "         0.0242, -0.1530,  0.2708,  0.3870, -0.0407, -0.7733, -0.3965,  0.7103,\n",
      "        -0.5266, -0.8473, -0.2814,  0.0634, -0.0469,  0.2093, -0.5929,  0.3147,\n",
      "         0.7441, -0.2883, -0.4244, -0.4688,  0.7391, -0.2475, -0.2986, -0.7846,\n",
      "        -0.5749,  0.6449,  0.5729,  0.0330, -0.7806, -0.3968, -0.1973,  0.8683,\n",
      "         0.2063,  0.0795, -0.2172, -0.3743, -0.1792,  0.0273, -0.2719, -0.1724,\n",
      "         0.5487, -0.2173, -0.5166, -0.8283, -0.5187, -0.2308,  0.0458, -0.0205,\n",
      "        -0.0467, -0.6538, -0.0829,  0.0589,  0.0573,  0.3710,  0.1821, -0.6651,\n",
      "         0.0139,  0.1801, -0.3490, -0.5684,  0.5960,  0.6916, -0.5211, -0.0705,\n",
      "        -0.0245,  0.5548, -0.4998,  0.1310,  0.0123,  0.1382,  0.5340, -0.1300,\n",
      "         0.0042,  0.0777, -0.8929, -0.2648,  0.1318,  0.1760,  0.0599, -0.4066,\n",
      "         0.3279,  0.2792, -0.3842,  0.1425, -0.0647, -0.6798, -0.9598,  0.3412,\n",
      "        -0.4429, -0.3725,  0.2720,  0.5411,  0.0429, -0.7045,  0.4488,  0.2515,\n",
      "         0.4915, -0.2986, -0.0725,  0.8208,  0.0345, -0.4975,  0.2115, -0.3730,\n",
      "        -0.1543,  0.4633, -0.7425,  0.3975, -0.1460, -0.0902,  0.5782, -0.5746,\n",
      "        -0.0736, -0.8905, -0.1959,  0.3797,  0.6835,  0.4984, -0.0769,  0.2039,\n",
      "         0.5143, -0.4893, -0.5451, -0.5868,  0.8137,  0.5941,  0.1640,  0.2265,\n",
      "        -0.6311,  0.3958, -0.2065, -0.4971, -0.0210, -0.3891, -0.2294, -0.3468,\n",
      "         0.7438, -0.1030,  0.7179, -0.7436, -0.5150,  0.0701, -0.2541,  0.5022,\n",
      "        -0.7572,  0.0990,  0.1417,  0.1436,  0.0180,  0.0168, -0.4819,  0.8244,\n",
      "        -0.0125, -0.1109, -0.6625,  0.7918, -0.4478, -0.2006,  0.1864, -0.3666,\n",
      "         0.2405,  0.2242, -0.0725, -0.1479, -0.2050,  0.4549,  0.2757, -0.2656,\n",
      "         0.5447,  0.2885,  0.0163, -0.5062, -0.3655, -0.4252, -0.2810, -0.6262,\n",
      "         0.4720, -0.5443, -0.2816,  0.7436,  0.7959, -0.2127,  0.6045,  0.2159,\n",
      "         0.0723,  0.8628,  0.0749,  0.1937, -0.5478, -0.1131,  0.3797,  0.4071,\n",
      "        -0.5809, -0.6407, -0.6400, -0.3935, -0.7474, -0.2790,  0.1554,  0.1401,\n",
      "         0.4752, -0.2307, -0.5861,  0.6426, -0.3433, -0.5701,  0.1752,  0.4724,\n",
      "        -0.3654,  0.4743,  0.5474,  0.2260, -0.3306, -0.1384,  0.3962, -0.3417,\n",
      "        -1.0276, -0.4299,  0.2657,  0.1818,  0.3824,  0.1642, -0.1071, -0.1129,\n",
      "         0.1338,  0.3750, -0.0246,  0.2682,  0.6734, -0.4917, -0.8268,  0.1484,\n",
      "        -0.6909, -0.3862,  0.1191,  0.2251,  0.4636, -0.0899,  0.5847, -0.5227,\n",
      "         0.0309, -0.1919, -0.4084,  0.0564,  0.2178,  0.1525, -0.4559, -0.0342,\n",
      "        -0.1900, -0.2373, -0.0560,  0.3202, -0.2350, -0.1091, -0.2436, -0.0595,\n",
      "        -0.0075,  0.0434,  0.4786,  0.4589, -0.7814, -0.4575, -0.1438,  0.7816,\n",
      "         0.6213, -0.3059, -0.0335,  0.5486, -0.8782, -0.7016,  0.6680, -0.4792,\n",
      "         0.2301,  0.0706, -0.1901, -0.2882, -0.1218,  0.3371, -0.1424, -0.5664,\n",
      "        -0.3493,  0.2683, -0.4209, -0.1263,  0.1663,  0.3661,  0.0221, -0.0802,\n",
      "         0.8377, -0.8028,  0.1312,  0.5930,  0.0925,  0.5772, -0.3172, -0.2318,\n",
      "         0.3839, -0.3587, -0.1506, -0.2225, -0.3813,  0.3004,  0.5387, -0.0993,\n",
      "         0.1397, -0.2269, -0.4488,  0.6487, -0.3429,  0.7323, -0.6757, -0.1690],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.2088,  0.0383,  0.0544,  ..., -0.1030,  0.0783, -0.0014],\n",
      "        [ 0.0470, -0.0564, -0.0553,  ...,  0.0203, -0.1165, -0.0557],\n",
      "        [-0.0048, -0.0284, -0.0800,  ..., -0.0789, -0.0413, -0.0859],\n",
      "        ...,\n",
      "        [ 0.0504, -0.0565, -0.0705,  ...,  0.0052, -0.0812, -0.0857],\n",
      "        [ 0.0676, -0.0898, -0.0730,  ...,  0.0324, -0.0613, -0.0054],\n",
      "        [-0.1756,  0.0118,  0.0710,  ..., -0.0210,  0.0434,  0.0014]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0270, -0.0241, -0.0302, -0.0111, -0.0253,  0.0092, -0.0516, -0.0816,\n",
      "         0.0336, -0.0337, -0.0481,  0.0434, -0.0189,  0.0027, -0.0539, -0.0060,\n",
      "        -0.0646, -0.0440, -0.0354, -0.0596, -0.0734, -0.0540, -0.0820, -0.0217,\n",
      "        -0.0141, -0.0055, -0.0674,  0.0044, -0.0344, -0.0741,  0.0176, -0.0616,\n",
      "        -0.0446, -0.0020, -0.0306, -0.0233, -0.0305, -0.0373, -0.0475, -0.0744,\n",
      "         0.0541, -0.0632, -0.0144, -0.0232, -0.0255,  0.0226, -0.0348, -0.0434,\n",
      "        -0.0581,  0.0095, -0.0401, -0.0386, -0.0368,  0.0169,  0.0336, -0.0220,\n",
      "         0.0518, -0.0205,  0.0081, -0.0749, -0.0333, -0.0069, -0.0173,  0.0392,\n",
      "         0.0175, -0.0278,  0.0328,  0.0343, -0.0011, -0.0501, -0.0517, -0.0325,\n",
      "        -0.0284, -0.0531,  0.0279, -0.0292,  0.0079, -0.0678, -0.0238, -0.0258,\n",
      "        -0.0790,  0.0158, -0.0643,  0.0079, -0.0183,  0.0297,  0.0061,  0.0364,\n",
      "        -0.0228, -0.0035,  0.0068, -0.0856, -0.0804,  0.0039, -0.0382, -0.0563,\n",
      "        -0.0724,  0.0061, -0.0240, -0.0852, -0.0255, -0.0267,  0.0112, -0.0661,\n",
      "        -0.0289, -0.0278, -0.0946,  0.0428, -0.0398, -0.0250, -0.0035,  0.0147,\n",
      "        -0.0032, -0.0094, -0.0720, -0.0195, -0.0702, -0.0429,  0.0336, -0.0590,\n",
      "         0.0109,  0.0078, -0.0717, -0.0769, -0.0308, -0.0152,  0.0234,  0.0287,\n",
      "        -0.0626, -0.0299,  0.0259,  0.0166, -0.0485, -0.0169, -0.0319,  0.0128,\n",
      "         0.0126,  0.0150, -0.0164,  0.0116, -0.0582,  0.0241, -0.0376,  0.0374,\n",
      "        -0.0056, -0.0238, -0.0540,  0.0336, -0.0016, -0.0473, -0.0338, -0.0415,\n",
      "        -0.0025, -0.0549,  0.0414, -0.0718, -0.0048, -0.0709,  0.0092, -0.0428,\n",
      "        -0.0446, -0.0539,  0.0246, -0.0199, -0.0679, -0.0330, -0.0509, -0.0346,\n",
      "        -0.0404,  0.0587,  0.0257,  0.0199,  0.0176,  0.0247, -0.0360,  0.0113,\n",
      "        -0.0526,  0.0746, -0.0126,  0.0148, -0.0180,  0.0308, -0.0730,  0.0025,\n",
      "        -0.0178, -0.0758,  0.0204, -0.0438,  0.0013,  0.0851, -0.0482, -0.0559,\n",
      "        -0.0076, -0.0415,  0.0245,  0.0066,  0.0124, -0.0645, -0.0227, -0.0411],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1627, -0.0709,  0.0123,  0.3133, -0.0664,  0.1463,  0.1598, -0.0656,\n",
      "          0.1418,  0.1590, -0.0636,  0.1596, -0.0613,  0.1870,  0.2146,  0.1589,\n",
      "         -0.0531,  0.1655,  0.2035, -0.0812,  0.2130, -0.0660, -0.0634,  0.1614,\n",
      "         -0.0514,  0.1856, -0.0662, -0.0870, -0.0564, -0.0592, -0.0726,  0.2121,\n",
      "         -0.0452, -0.0451, -0.0661,  0.1536, -0.0549, -0.0531, -0.0767, -0.0604,\n",
      "          0.0218,  0.1820, -0.0688, -0.0404,  0.1659,  0.1630,  0.1711,  0.1666,\n",
      "         -0.0629,  0.1867,  0.1757, -0.0653, -0.0009, -0.0835,  0.1746,  0.1658,\n",
      "          0.1263,  0.1652,  0.1826,  0.2197, -0.0461, -0.0854,  0.1609,  0.1759,\n",
      "          0.1829,  0.1776,  0.1510,  0.1660,  0.1700,  0.2523, -0.0616,  0.1798,\n",
      "          0.2320,  0.1671,  0.1840, -0.0574,  0.1818,  0.1700, -0.0544, -0.0604,\n",
      "         -0.0597,  0.1765,  0.1576,  0.1636,  0.1670,  0.1743,  0.1496,  0.1805,\n",
      "         -0.0265, -0.0614,  0.1608, -0.0620, -0.0661, -0.0646, -0.0664, -0.0510,\n",
      "         -0.0638,  0.1882,  0.1827, -0.0636,  0.1784,  0.1607,  0.1750, -0.0586,\n",
      "          0.2005,  0.1738, -0.0557,  0.1631, -0.0659, -0.0593,  0.1661,  0.2004,\n",
      "          0.1617, -0.0612, -0.0625, -0.0604, -0.0643,  0.1516,  0.1590, -0.0466,\n",
      "          0.1747, -0.0753,  0.2033, -0.0531, -0.0683, -0.0731,  0.1523,  0.1447,\n",
      "          0.1618, -0.0730,  0.1459,  0.1990, -0.0332, -0.0622, -0.0709,  0.1701,\n",
      "          0.1877, -0.0721, -0.0712,  0.1784,  0.1617, -0.0757,  0.1658,  0.1736,\n",
      "          0.1609, -0.0745,  0.0118,  0.1497,  0.2044,  0.1691,  0.1669,  0.1960,\n",
      "         -0.0650,  0.1632,  0.1851, -0.0569,  0.1556,  0.1992,  0.1768, -0.0513,\n",
      "         -0.0658,  0.1782,  0.2142,  0.1588, -0.0646,  0.1558,  0.1586, -0.0601,\n",
      "         -0.0669,  0.0652,  0.1553, -0.0779,  0.1668,  0.1606, -0.0585,  0.1972,\n",
      "         -0.0570,  0.2067,  0.1678,  0.1546, -0.0296,  0.1642, -0.0804, -0.0662,\n",
      "         -0.0473, -0.0452,  0.1472, -0.0654,  0.1412,  0.1047, -0.0688, -0.0658,\n",
      "         -0.0858,  0.2038,  0.1444,  0.1963,  0.1914, -0.0606, -0.0622,  0.1813]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.1309], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for param in NNC2P.parameters():\n",
    "        print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc75802c",
   "metadata": {},
   "source": [
    "We follow [this guide from the PyTorch documentation](https://pytorch.org/tutorials/advanced/cpp_export.html). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abf305d-ffc5-469e-a032-0d84be9c2d71",
   "metadata": {},
   "source": [
    "## Get the parameters as matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1b30a37-e4a1-4ba7-ab7d-9b4dfb524c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(NNC2P.state_dict(), \"NNC2Pv0_params.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05d1fee6-36b8-4ef9-a84d-cec0dcc9456c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('stack.0.weight',\n",
       "              tensor([[-0.3637,  0.4540, -0.4355],\n",
       "                      [ 0.0066,  0.6949,  0.4879],\n",
       "                      [ 0.1112, -0.0925,  0.1091],\n",
       "                      ...,\n",
       "                      [ 0.5306, -0.4535, -0.3026],\n",
       "                      [-0.4308, -0.1415,  0.2810],\n",
       "                      [ 0.6349, -0.2947,  0.0561]])),\n",
       "             ('stack.0.bias',\n",
       "              tensor([ 0.5675,  0.2904, -0.7667, -0.3078, -0.1945,  0.0523,  0.0514, -0.4138,\n",
       "                       0.2312, -0.5222,  0.2495, -0.3197, -0.4844, -0.5024, -0.3668, -0.2699,\n",
       "                       0.7860,  0.7489,  0.1024,  0.8798,  0.1536, -0.4353, -0.3389, -0.5969,\n",
       "                      -0.4334, -0.7355, -0.4756, -0.4140, -0.1220, -0.1788, -0.7250, -0.0075,\n",
       "                       0.2842,  0.1193,  0.5405, -0.1805, -0.0228, -0.3408, -0.1134, -0.2822,\n",
       "                       0.5498, -0.1406,  0.3311, -0.5858,  0.0567, -0.2661,  0.3879,  0.8417,\n",
       "                      -0.2426,  0.5311,  0.0035,  0.1361, -0.3355,  0.2191, -0.3657,  0.0739,\n",
       "                      -0.7668, -0.7611, -0.4528,  0.7155,  0.4711,  0.1546, -0.7966, -0.6006,\n",
       "                       0.5338, -0.4438, -0.5507,  0.2647, -0.5531, -0.1843,  0.6857, -0.1058,\n",
       "                      -0.2366,  0.5566, -0.2539, -0.0841, -0.2701,  0.1520, -0.3656, -0.0887,\n",
       "                      -0.3681, -0.4994,  0.1562,  0.0979, -0.1539, -0.2539, -0.3159,  0.2476,\n",
       "                       0.1437,  0.1037, -0.6092, -0.4861,  0.6079, -0.1717,  0.3969, -0.8278,\n",
       "                      -0.7750,  0.4500,  0.1029,  0.0236,  0.3942, -0.0011, -0.5502, -0.6392,\n",
       "                      -0.1455, -0.5056, -0.4315, -0.6536, -0.8086,  0.8507, -0.4151, -0.7212,\n",
       "                      -0.0891,  0.1468, -0.0913,  0.1593, -0.3147, -0.7297,  0.2530, -0.1589,\n",
       "                      -0.1999,  0.4665, -0.5153, -0.6170, -0.3868,  0.0854,  0.5496,  0.1570,\n",
       "                      -0.5972,  0.1290, -0.2804, -0.1617, -0.4747, -0.1994,  0.1695, -0.2299,\n",
       "                       0.5255, -0.7798,  0.7290, -0.1372, -0.0409,  0.4159,  0.2687, -0.6314,\n",
       "                       0.1840, -0.6343, -0.7727,  0.0432,  0.1978,  0.0018, -0.2912,  0.5889,\n",
       "                       0.1239, -0.5980, -0.3289, -0.4699,  0.1432,  0.6450, -0.4566,  0.6617,\n",
       "                      -0.5549, -0.7374,  0.2306,  0.9800,  0.1920,  0.5020,  0.2284,  0.2587,\n",
       "                       0.6900,  0.2306,  0.7923, -0.1113,  0.2198,  0.6304,  0.3187,  0.0511,\n",
       "                      -0.5725, -0.6510, -0.7051, -0.3080, -0.2263, -0.5543, -0.2684, -0.2800,\n",
       "                      -0.5838,  0.6659, -0.0447, -0.3244, -0.2777,  0.1524,  0.8192, -0.0718,\n",
       "                      -0.1331,  0.0362, -0.3517,  0.2572,  0.0893, -0.3430, -0.6010, -0.2209,\n",
       "                       0.4120, -0.5042,  0.1973,  0.0020,  0.2477,  0.2700, -0.6794, -0.2675,\n",
       "                      -0.3750,  0.3425, -0.0609, -0.0658,  0.3587, -0.2422,  0.3080, -0.7774,\n",
       "                      -0.0425, -0.1093, -0.6006, -0.4135,  0.0222,  0.0549,  0.4497,  0.2517,\n",
       "                      -0.0629,  0.4377,  0.3117,  0.3804, -0.8146, -0.1727, -0.0757, -0.4479,\n",
       "                      -0.3724,  0.2646,  0.2722,  0.2111, -0.4963, -0.7829, -0.1263,  0.1045,\n",
       "                      -0.4437, -0.4764,  0.0316, -0.6644,  0.0834,  0.5011,  0.3411,  0.3595,\n",
       "                      -0.5658, -0.4027, -0.5273,  0.2064, -0.2696,  0.1704, -0.7847, -0.4299,\n",
       "                      -0.5457, -0.2170,  0.5040,  0.1638, -0.2259, -0.1841,  0.3940, -0.1587,\n",
       "                      -0.0681, -0.5532,  0.0486, -0.0708, -0.0685, -0.1967, -0.6578, -0.0085,\n",
       "                      -0.5584,  0.3869, -0.3360,  0.0781, -0.4732, -0.4988,  0.5257, -0.0463,\n",
       "                      -0.5861,  0.0443,  0.3502, -0.3827, -0.0767, -0.4918, -0.0975,  0.0335,\n",
       "                       0.0242, -0.1530,  0.2708,  0.3870, -0.0407, -0.7733, -0.3965,  0.7103,\n",
       "                      -0.5266, -0.8473, -0.2814,  0.0634, -0.0469,  0.2093, -0.5929,  0.3147,\n",
       "                       0.7441, -0.2883, -0.4244, -0.4688,  0.7391, -0.2475, -0.2986, -0.7846,\n",
       "                      -0.5749,  0.6449,  0.5729,  0.0330, -0.7806, -0.3968, -0.1973,  0.8683,\n",
       "                       0.2063,  0.0795, -0.2172, -0.3743, -0.1792,  0.0273, -0.2719, -0.1724,\n",
       "                       0.5487, -0.2173, -0.5166, -0.8283, -0.5187, -0.2308,  0.0458, -0.0205,\n",
       "                      -0.0467, -0.6538, -0.0829,  0.0589,  0.0573,  0.3710,  0.1821, -0.6651,\n",
       "                       0.0139,  0.1801, -0.3490, -0.5684,  0.5960,  0.6916, -0.5211, -0.0705,\n",
       "                      -0.0245,  0.5548, -0.4998,  0.1310,  0.0123,  0.1382,  0.5340, -0.1300,\n",
       "                       0.0042,  0.0777, -0.8929, -0.2648,  0.1318,  0.1760,  0.0599, -0.4066,\n",
       "                       0.3279,  0.2792, -0.3842,  0.1425, -0.0647, -0.6798, -0.9598,  0.3412,\n",
       "                      -0.4429, -0.3725,  0.2720,  0.5411,  0.0429, -0.7045,  0.4488,  0.2515,\n",
       "                       0.4915, -0.2986, -0.0725,  0.8208,  0.0345, -0.4975,  0.2115, -0.3730,\n",
       "                      -0.1543,  0.4633, -0.7425,  0.3975, -0.1460, -0.0902,  0.5782, -0.5746,\n",
       "                      -0.0736, -0.8905, -0.1959,  0.3797,  0.6835,  0.4984, -0.0769,  0.2039,\n",
       "                       0.5143, -0.4893, -0.5451, -0.5868,  0.8137,  0.5941,  0.1640,  0.2265,\n",
       "                      -0.6311,  0.3958, -0.2065, -0.4971, -0.0210, -0.3891, -0.2294, -0.3468,\n",
       "                       0.7438, -0.1030,  0.7179, -0.7436, -0.5150,  0.0701, -0.2541,  0.5022,\n",
       "                      -0.7572,  0.0990,  0.1417,  0.1436,  0.0180,  0.0168, -0.4819,  0.8244,\n",
       "                      -0.0125, -0.1109, -0.6625,  0.7918, -0.4478, -0.2006,  0.1864, -0.3666,\n",
       "                       0.2405,  0.2242, -0.0725, -0.1479, -0.2050,  0.4549,  0.2757, -0.2656,\n",
       "                       0.5447,  0.2885,  0.0163, -0.5062, -0.3655, -0.4252, -0.2810, -0.6262,\n",
       "                       0.4720, -0.5443, -0.2816,  0.7436,  0.7959, -0.2127,  0.6045,  0.2159,\n",
       "                       0.0723,  0.8628,  0.0749,  0.1937, -0.5478, -0.1131,  0.3797,  0.4071,\n",
       "                      -0.5809, -0.6407, -0.6400, -0.3935, -0.7474, -0.2790,  0.1554,  0.1401,\n",
       "                       0.4752, -0.2307, -0.5861,  0.6426, -0.3433, -0.5701,  0.1752,  0.4724,\n",
       "                      -0.3654,  0.4743,  0.5474,  0.2260, -0.3306, -0.1384,  0.3962, -0.3417,\n",
       "                      -1.0276, -0.4299,  0.2657,  0.1818,  0.3824,  0.1642, -0.1071, -0.1129,\n",
       "                       0.1338,  0.3750, -0.0246,  0.2682,  0.6734, -0.4917, -0.8268,  0.1484,\n",
       "                      -0.6909, -0.3862,  0.1191,  0.2251,  0.4636, -0.0899,  0.5847, -0.5227,\n",
       "                       0.0309, -0.1919, -0.4084,  0.0564,  0.2178,  0.1525, -0.4559, -0.0342,\n",
       "                      -0.1900, -0.2373, -0.0560,  0.3202, -0.2350, -0.1091, -0.2436, -0.0595,\n",
       "                      -0.0075,  0.0434,  0.4786,  0.4589, -0.7814, -0.4575, -0.1438,  0.7816,\n",
       "                       0.6213, -0.3059, -0.0335,  0.5486, -0.8782, -0.7016,  0.6680, -0.4792,\n",
       "                       0.2301,  0.0706, -0.1901, -0.2882, -0.1218,  0.3371, -0.1424, -0.5664,\n",
       "                      -0.3493,  0.2683, -0.4209, -0.1263,  0.1663,  0.3661,  0.0221, -0.0802,\n",
       "                       0.8377, -0.8028,  0.1312,  0.5930,  0.0925,  0.5772, -0.3172, -0.2318,\n",
       "                       0.3839, -0.3587, -0.1506, -0.2225, -0.3813,  0.3004,  0.5387, -0.0993,\n",
       "                       0.1397, -0.2269, -0.4488,  0.6487, -0.3429,  0.7323, -0.6757, -0.1690])),\n",
       "             ('stack.2.weight',\n",
       "              tensor([[-0.2088,  0.0383,  0.0544,  ..., -0.1030,  0.0783, -0.0014],\n",
       "                      [ 0.0470, -0.0564, -0.0553,  ...,  0.0203, -0.1165, -0.0557],\n",
       "                      [-0.0048, -0.0284, -0.0800,  ..., -0.0789, -0.0413, -0.0859],\n",
       "                      ...,\n",
       "                      [ 0.0504, -0.0565, -0.0705,  ...,  0.0052, -0.0812, -0.0857],\n",
       "                      [ 0.0676, -0.0898, -0.0730,  ...,  0.0324, -0.0613, -0.0054],\n",
       "                      [-0.1756,  0.0118,  0.0710,  ..., -0.0210,  0.0434,  0.0014]])),\n",
       "             ('stack.2.bias',\n",
       "              tensor([-0.0270, -0.0241, -0.0302, -0.0111, -0.0253,  0.0092, -0.0516, -0.0816,\n",
       "                       0.0336, -0.0337, -0.0481,  0.0434, -0.0189,  0.0027, -0.0539, -0.0060,\n",
       "                      -0.0646, -0.0440, -0.0354, -0.0596, -0.0734, -0.0540, -0.0820, -0.0217,\n",
       "                      -0.0141, -0.0055, -0.0674,  0.0044, -0.0344, -0.0741,  0.0176, -0.0616,\n",
       "                      -0.0446, -0.0020, -0.0306, -0.0233, -0.0305, -0.0373, -0.0475, -0.0744,\n",
       "                       0.0541, -0.0632, -0.0144, -0.0232, -0.0255,  0.0226, -0.0348, -0.0434,\n",
       "                      -0.0581,  0.0095, -0.0401, -0.0386, -0.0368,  0.0169,  0.0336, -0.0220,\n",
       "                       0.0518, -0.0205,  0.0081, -0.0749, -0.0333, -0.0069, -0.0173,  0.0392,\n",
       "                       0.0175, -0.0278,  0.0328,  0.0343, -0.0011, -0.0501, -0.0517, -0.0325,\n",
       "                      -0.0284, -0.0531,  0.0279, -0.0292,  0.0079, -0.0678, -0.0238, -0.0258,\n",
       "                      -0.0790,  0.0158, -0.0643,  0.0079, -0.0183,  0.0297,  0.0061,  0.0364,\n",
       "                      -0.0228, -0.0035,  0.0068, -0.0856, -0.0804,  0.0039, -0.0382, -0.0563,\n",
       "                      -0.0724,  0.0061, -0.0240, -0.0852, -0.0255, -0.0267,  0.0112, -0.0661,\n",
       "                      -0.0289, -0.0278, -0.0946,  0.0428, -0.0398, -0.0250, -0.0035,  0.0147,\n",
       "                      -0.0032, -0.0094, -0.0720, -0.0195, -0.0702, -0.0429,  0.0336, -0.0590,\n",
       "                       0.0109,  0.0078, -0.0717, -0.0769, -0.0308, -0.0152,  0.0234,  0.0287,\n",
       "                      -0.0626, -0.0299,  0.0259,  0.0166, -0.0485, -0.0169, -0.0319,  0.0128,\n",
       "                       0.0126,  0.0150, -0.0164,  0.0116, -0.0582,  0.0241, -0.0376,  0.0374,\n",
       "                      -0.0056, -0.0238, -0.0540,  0.0336, -0.0016, -0.0473, -0.0338, -0.0415,\n",
       "                      -0.0025, -0.0549,  0.0414, -0.0718, -0.0048, -0.0709,  0.0092, -0.0428,\n",
       "                      -0.0446, -0.0539,  0.0246, -0.0199, -0.0679, -0.0330, -0.0509, -0.0346,\n",
       "                      -0.0404,  0.0587,  0.0257,  0.0199,  0.0176,  0.0247, -0.0360,  0.0113,\n",
       "                      -0.0526,  0.0746, -0.0126,  0.0148, -0.0180,  0.0308, -0.0730,  0.0025,\n",
       "                      -0.0178, -0.0758,  0.0204, -0.0438,  0.0013,  0.0851, -0.0482, -0.0559,\n",
       "                      -0.0076, -0.0415,  0.0245,  0.0066,  0.0124, -0.0645, -0.0227, -0.0411])),\n",
       "             ('stack.4.weight',\n",
       "              tensor([[ 0.1627, -0.0709,  0.0123,  0.3133, -0.0664,  0.1463,  0.1598, -0.0656,\n",
       "                        0.1418,  0.1590, -0.0636,  0.1596, -0.0613,  0.1870,  0.2146,  0.1589,\n",
       "                       -0.0531,  0.1655,  0.2035, -0.0812,  0.2130, -0.0660, -0.0634,  0.1614,\n",
       "                       -0.0514,  0.1856, -0.0662, -0.0870, -0.0564, -0.0592, -0.0726,  0.2121,\n",
       "                       -0.0452, -0.0451, -0.0661,  0.1536, -0.0549, -0.0531, -0.0767, -0.0604,\n",
       "                        0.0218,  0.1820, -0.0688, -0.0404,  0.1659,  0.1630,  0.1711,  0.1666,\n",
       "                       -0.0629,  0.1867,  0.1757, -0.0653, -0.0009, -0.0835,  0.1746,  0.1658,\n",
       "                        0.1263,  0.1652,  0.1826,  0.2197, -0.0461, -0.0854,  0.1609,  0.1759,\n",
       "                        0.1829,  0.1776,  0.1510,  0.1660,  0.1700,  0.2523, -0.0616,  0.1798,\n",
       "                        0.2320,  0.1671,  0.1840, -0.0574,  0.1818,  0.1700, -0.0544, -0.0604,\n",
       "                       -0.0597,  0.1765,  0.1576,  0.1636,  0.1670,  0.1743,  0.1496,  0.1805,\n",
       "                       -0.0265, -0.0614,  0.1608, -0.0620, -0.0661, -0.0646, -0.0664, -0.0510,\n",
       "                       -0.0638,  0.1882,  0.1827, -0.0636,  0.1784,  0.1607,  0.1750, -0.0586,\n",
       "                        0.2005,  0.1738, -0.0557,  0.1631, -0.0659, -0.0593,  0.1661,  0.2004,\n",
       "                        0.1617, -0.0612, -0.0625, -0.0604, -0.0643,  0.1516,  0.1590, -0.0466,\n",
       "                        0.1747, -0.0753,  0.2033, -0.0531, -0.0683, -0.0731,  0.1523,  0.1447,\n",
       "                        0.1618, -0.0730,  0.1459,  0.1990, -0.0332, -0.0622, -0.0709,  0.1701,\n",
       "                        0.1877, -0.0721, -0.0712,  0.1784,  0.1617, -0.0757,  0.1658,  0.1736,\n",
       "                        0.1609, -0.0745,  0.0118,  0.1497,  0.2044,  0.1691,  0.1669,  0.1960,\n",
       "                       -0.0650,  0.1632,  0.1851, -0.0569,  0.1556,  0.1992,  0.1768, -0.0513,\n",
       "                       -0.0658,  0.1782,  0.2142,  0.1588, -0.0646,  0.1558,  0.1586, -0.0601,\n",
       "                       -0.0669,  0.0652,  0.1553, -0.0779,  0.1668,  0.1606, -0.0585,  0.1972,\n",
       "                       -0.0570,  0.2067,  0.1678,  0.1546, -0.0296,  0.1642, -0.0804, -0.0662,\n",
       "                       -0.0473, -0.0452,  0.1472, -0.0654,  0.1412,  0.1047, -0.0688, -0.0658,\n",
       "                       -0.0858,  0.2038,  0.1444,  0.1963,  0.1914, -0.0606, -0.0622,  0.1813]])),\n",
       "             ('stack.4.bias', tensor([0.1309]))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NNC2P.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fcb86b-ad79-4733-8911-d26de50082b3",
   "metadata": {},
   "source": [
    "### First, make it easy: save the matrices as a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f210e996-8996-4aef-a7e4-e759f410fcbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models/NNC2Pv0_params_stack.0.weight.csv\n",
      "Models/NNC2Pv0_params_stack.0.bias.csv\n",
      "Models/NNC2Pv0_params_stack.2.weight.csv\n",
      "Models/NNC2Pv0_params_stack.2.bias.csv\n",
      "Models/NNC2Pv0_params_stack.4.weight.csv\n",
      "Models/NNC2Pv0_params_stack.4.bias.csv\n"
     ]
    }
   ],
   "source": [
    "param_names = NNC2P.state_dict().keys()\n",
    "file_names = [\"Models/NNC2Pv0_params_\" + key + \".csv\" for key in param_names]\n",
    "\n",
    "\n",
    "for i, key in enumerate(param_names):\n",
    "    # Get the key and name of the current parameter matrix that we are saving\n",
    "    # key = param_names[i]\n",
    "    name = file_names[i]\n",
    "    print(name)\n",
    "    # Get the value of these parameters:\n",
    "    matrix = NNC2P.state_dict()[key]\n",
    "    # Convert to Numpy array\n",
    "    matrix_np = matrix.numpy() \n",
    "    # Convert to a dataframe\n",
    "    df = pd.DataFrame(matrix_np)\n",
    "    # Save to file\n",
    "    df.to_csv(name,index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88386f6f-a165-4d9a-9c2d-4c14fccbfe72",
   "metadata": {},
   "source": [
    "Read the files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "788d1c48-f316-4c85-b069-e7d62cd6c9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight0 = pd.read_csv(\"Models/NNC2Pv0_params_stack.0.weight.csv\", header=None).values\n",
    "bias0   = pd.read_csv(\"Models/NNC2Pv0_params_stack.0.bias.csv\", header=None).values\n",
    "weight2 = pd.read_csv(\"Models/NNC2Pv0_params_stack.2.weight.csv\", header=None).values\n",
    "bias2   = pd.read_csv(\"Models/NNC2Pv0_params_stack.2.bias.csv\", header=None).values\n",
    "weight4 = pd.read_csv(\"Models/NNC2Pv0_params_stack.4.weight.csv\", header=None).values\n",
    "bias4   = pd.read_csv(\"Models/NNC2Pv0_params_stack.4.bias.csv\", header=None).values\n",
    "\n",
    "weights_and_biases = [weight0, bias0, weight2, bias2, weight4, bias4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85e7dfa7-7137-4a5f-9c90-b79ab3516a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the file:  Models/NNC2Pv0_params_stack.0.weight.csv\n",
      "The shape is equal to  (600, 3)\n",
      "For the file:  Models/NNC2Pv0_params_stack.0.bias.csv\n",
      "The shape is equal to  (600, 1)\n",
      "For the file:  Models/NNC2Pv0_params_stack.2.weight.csv\n",
      "The shape is equal to  (200, 600)\n",
      "For the file:  Models/NNC2Pv0_params_stack.2.bias.csv\n",
      "The shape is equal to  (200, 1)\n",
      "For the file:  Models/NNC2Pv0_params_stack.4.weight.csv\n",
      "The shape is equal to  (1, 200)\n",
      "For the file:  Models/NNC2Pv0_params_stack.4.bias.csv\n",
      "The shape is equal to  (1, 1)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape for each parameter:\n",
    "for i in range(len(weights_and_biases)):\n",
    "    print(\"For the file: \", file_names[i])\n",
    "    # Read the values\n",
    "    shape = np.shape(weights_and_biases[i])\n",
    "    print(\"The shape is equal to \", shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8c6a77e-6221-4158-8dc5-2de8cdddbce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.36373898  0.45402282 -0.4355268 ]\n",
      " [ 0.00657238  0.69492054  0.4879491 ]\n",
      " [ 0.11119203 -0.09253014  0.10905483]\n",
      " ...\n",
      " [ 0.5305801  -0.45353398 -0.3026449 ]\n",
      " [-0.4308225  -0.14152803  0.28101048]\n",
      " [ 0.63488334 -0.29469463  0.05608372]]\n",
      "(600, 3)\n"
     ]
    }
   ],
   "source": [
    "# Read the example file\n",
    "example = pd.read_csv(\"Models/NNC2Pv0_params_stack.0.weight.csv\", header=None).values\n",
    "print(example)\n",
    "print(np.shape(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2b702c",
   "metadata": {},
   "source": [
    "### Now, also export their 'flattened versions', as we are struggling with arrays in Fortran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0218eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight0_flat = weight0.flatten()\n",
    "bias0_flat      = bias0.flatten()\n",
    "weight2_flat = weight2.flatten()\n",
    "bias2_flat      = bias2.flatten()\n",
    "weight4_flat = weight4.flatten()\n",
    "bias4_flat      = bias4.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99d5d556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.36373898  0.45402282 -0.4355268  ...  0.63488334 -0.29469463\n",
      "  0.05608372]\n"
     ]
    }
   ],
   "source": [
    "print(weight0_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "faed9cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "head_bool = True\n",
    "# Now to csv files:\n",
    "df = pd.DataFrame(weight0_flat)\n",
    "df.to_csv(\"weight0_flat.csv\", index=False, header=head_bool)\n",
    "df = pd.DataFrame(bias0_flat)\n",
    "df.to_csv(\"bias0_flat.csv\",      index=False, header=head_bool)\n",
    "df = pd.DataFrame(weight2_flat)\n",
    "df.to_csv(\"weight2_flat.csv\", index=False, header=head_bool)\n",
    "df = pd.DataFrame(bias2_flat)\n",
    "df.to_csv(\"bias2_flat.csv\",      index=False, header=head_bool)\n",
    "df = pd.DataFrame(weight4_flat)\n",
    "df.to_csv(\"weight4_flat.csv\", index=False, header=head_bool)\n",
    "df = pd.DataFrame(bias4_flat)\n",
    "df.to_csv(\"bias4_flat.csv\",      index=False, header=head_bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a77502-f96b-4221-9878-4e50854bcfe2",
   "metadata": {},
   "source": [
    "### How to use the parameters to make a prediction without any Pytorch tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9709a2-c540-4130-ac6b-3ada2552bc0b",
   "metadata": {},
   "source": [
    "When we are going to implement this in the Gmunu code, we can no longer use any of the built-in tools of PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1e65ebe8-1c4f-4c4f-aced-77fadcd57267",
   "metadata": {},
   "outputs": [],
   "source": [
    "## One specific test case for the data\n",
    "rho,eps,v,p,D,S,tau = 9.83632270803203,1.962038705851822,0.2660655147967911,12.866163917605371,10.204131145455385,12.026584842282125,22.131296926293793"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acabd1c-7014-4bae-9615-389bd9c251d5",
   "metadata": {},
   "source": [
    "This is how the PyTorch implementation works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1ffbcdea-ab47-41ce-a968-d53be5534c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.866163917605371\n",
      "tensor([10.2041, 12.0266, 22.1313])\n",
      "12.86711311340332\n"
     ]
    }
   ],
   "source": [
    "input_test = torch.tensor([D, S, tau])\n",
    "exact_result = p\n",
    "print(exact_result)\n",
    "print(input_test)\n",
    "with torch.no_grad():\n",
    "    pred = model(input_test).item()\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28e00da-5bd8-419c-806b-4b6ecf3f2dbf",
   "metadata": {},
   "source": [
    "Now, we have to try and get the same output, but by defining all intermediate steps ourselves!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "194e0737-14b7-49b7-b3af-89221678facc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def compute_prediction(x):\n",
    "    \"\"\"Input is a np. array of size 1x3\"\"\"\n",
    "    print(np.shape(x))\n",
    "    x = np.matmul(weight0, x.T) + bias0\n",
    "    print(np.shape(x))\n",
    "    x = sigmoid(x)\n",
    "    x = np.matmul(weight2, x) + bias2\n",
    "    print(np.shape(x))\n",
    "    x = sigmoid(x)\n",
    "    x = np.matmul(weight4, x) + bias4\n",
    "    print(np.shape(x))\n",
    "    return x[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5745fb74-6f68-4556-a8e0-c80628e93b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3)\n"
     ]
    }
   ],
   "source": [
    "input_test = np.array([[D, S, tau]])\n",
    "print(np.shape(input_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c422a5de-4b83-4f5f-b1e0-c6023c8cd65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3)\n",
      "(600, 1)\n",
      "(200, 1)\n",
      "(1, 1)\n",
      "12.867113930614748\n",
      "12.86711311340332\n"
     ]
    }
   ],
   "source": [
    "our_prediction = compute_prediction(input_test)\n",
    "print(our_prediction)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fbe512-19ff-4157-9a33-68899241991d",
   "metadata": {},
   "source": [
    "Now we compute rho and eps from this (see appendix A of central paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "aee97e55-2be0-4bc1-8c31-62ad7b4db25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our calculations:\n",
      "9.836338457223192 1.9620408002397969\n",
      "Exact results:\n",
      "9.83632270803203 1.962038705851822\n"
     ]
    }
   ],
   "source": [
    "v_star = S/(tau + D + our_prediction)\n",
    "W_star = 1/np.sqrt(1-v_star**2)\n",
    "\n",
    "rho_star = D/W_star\n",
    "eps_star = (tau + D*(1 - W_star) + our_prediction*(1 - W_star**2))/(D*W_star)\n",
    "print(\"Our calculations:\")\n",
    "print(rho_star, eps_star)\n",
    "print(\"Exact results:\")\n",
    "print(rho, eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aff9646-60ef-402e-a56c-3eccee7478e2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Now save it into an hdf5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba57a7f2-8af2-4ba6-a242-d19fbfbe034b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object dtype dtype('O') has no native HDF5 equivalent",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Open an HDF5 file for writing\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m h5py\u001b[38;5;241m.\u001b[39mFile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNNC2Pv0_params.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# Save the weights and biases of the network to the HDF5 file\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNNC2Pv0_params\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNNC2P\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\h5py\\_hl\\group.py:149\u001b[0m, in \u001b[0;36mGroup.create_dataset\u001b[1;34m(self, name, shape, dtype, data, **kwds)\u001b[0m\n\u001b[0;32m    146\u001b[0m         parent_path, name \u001b[38;5;241m=\u001b[39m name\u001b[38;5;241m.\u001b[39mrsplit(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    147\u001b[0m         group \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequire_group(parent_path)\n\u001b[1;32m--> 149\u001b[0m dsid \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mmake_new_dset(group, shape, dtype, data, name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    150\u001b[0m dset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mDataset(dsid)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dset\n",
      "File \u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\h5py\\_hl\\dataset.py:91\u001b[0m, in \u001b[0;36mmake_new_dset\u001b[1;34m(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, allow_unknown_filter)\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     90\u001b[0m         dtype \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mdtype(dtype)\n\u001b[1;32m---> 91\u001b[0m     tid \u001b[38;5;241m=\u001b[39m \u001b[43mh5t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpy_create\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogical\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# Legacy\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m((compression, shuffle, fletcher32, maxshape, scaleoffset)) \u001b[38;5;129;01mand\u001b[39;00m chunks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
      "File \u001b[1;32mh5py\\h5t.pyx:1663\u001b[0m, in \u001b[0;36mh5py.h5t.py_create\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\h5t.pyx:1687\u001b[0m, in \u001b[0;36mh5py.h5t.py_create\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\h5t.pyx:1747\u001b[0m, in \u001b[0;36mh5py.h5t.py_create\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Object dtype dtype('O') has no native HDF5 equivalent"
     ]
    }
   ],
   "source": [
    "# # Open an HDF5 file for writing\n",
    "# with h5py.File(\"NNC2Pv0_params.h5\", \"w\") as f:\n",
    "#     # Save the weights and biases of the network to the HDF5 file\n",
    "#     f.create_dataset(\"NNC2Pv0_params\", data=NNC2P.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929bc14b",
   "metadata": {},
   "source": [
    "## More advanced: using Torch script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a983a5e9",
   "metadata": {},
   "source": [
    "There exist two ways of converting a PyTorch model to Torch Script. The first is known as tracing, a mechanism in which the structure of the model is captured by evaluating it once using example inputs, and recording the flow of those inputs through the model. This is suitable for models that make limited use of control flow. The second approach is to add explicit annotations to your model that inform the Torch Script compiler that it may directly parse and compile your model code, subject to the constraints imposed by the Torch Script language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa4c899e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 0.5000])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = torch.tensor([1, 1, 0.5])\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71837a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  original_name=NeuralNetwork\n",
       "  (stack): Sequential(\n",
       "    original_name=Sequential\n",
       "    (0): Linear(original_name=Linear)\n",
       "    (1): Sigmoid(original_name=Sigmoid)\n",
       "    (2): Linear(original_name=Linear)\n",
       "    (3): Sigmoid(original_name=Sigmoid)\n",
       "    (4): Linear(original_name=Linear)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traced_script_module = torch.jit.trace(model, example)\n",
    "traced_script_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28fafa57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0595], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = traced_script_module(torch.tensor([1,1,0.5]))\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8866ef33",
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_script_module.save(\"traced_NNC2P_model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7817ec-e463-4ed5-baf0-1b887b960d0b",
   "metadata": {},
   "source": [
    "__To do: finish it__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498cc2eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "author": "Thibeau Wouters",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
