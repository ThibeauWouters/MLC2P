{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af563537",
   "metadata": {},
   "source": [
    "%%latex\n",
    "\\tableofcontents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bb9f224",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "import random\n",
    "import csv\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import time\n",
    "# import torch\n",
    "# from torch import nn\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# from torchvision.transforms import ToTensor \n",
    "# import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fb3c8c",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2175a87",
   "metadata": {},
   "source": [
    "In this notebook, we are going to investigate different methods to do the C2P transformation. We'll look at Random Forest Regression and LSSVMs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca72213",
   "metadata": {},
   "source": [
    "# Data and methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ebd9592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the three functions determining the output\n",
    "def eos(rho, eps, Gamma = 5/3):\n",
    "    \"\"\"Computes the analytical gamma law EOS from rho and epsilon\"\"\"\n",
    "    return (Gamma - 1) * rho * eps\n",
    "\n",
    "def h(rho, eps, v):\n",
    "    \"\"\"Enthalpy\"\"\"\n",
    "    p = eos(rho, eps)\n",
    "    return 1 + eps + p/rho\n",
    "\n",
    "def W(rho, eps, v):\n",
    "    \"\"\"Lorentz factor. Here, in 1D so v = v_x\"\"\"\n",
    "    return (1-v**2)**(-1/2)\n",
    "\n",
    "def D(rho, eps, v):\n",
    "    \"\"\"See eq 2 paper\"\"\"\n",
    "    return rho*W(rho, eps, v)\n",
    "\n",
    "def S(rho, eps, v):\n",
    "    \"\"\"See eq2 paper. Note: 1D only for now.\"\"\"\n",
    "    return rho*h(rho, eps, v)*((W(rho, eps, v))**2)*v\n",
    "\n",
    "def tau(rho, eps, v):\n",
    "    \"\"\"See eq2 paper.\"\"\"\n",
    "    return rho*(h(rho, eps, v))*((W(rho, eps, v))**2) - eos(rho, eps) - D(rho, eps, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ab74eb",
   "metadata": {},
   "source": [
    "We generate data as follows. We create a training set by randomly sampling as follows:\n",
    "- $\\rho \\in (0, 10.1)$,\n",
    "- $\\epsilon \\in (0, 2.02)$, \n",
    "- $v_x \\in (0, 0.721)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40409d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ranges of parameters to be sampled (see paper Section 2.1)\n",
    "rho_min = 0\n",
    "rho_max = 10.1\n",
    "eps_min = 0\n",
    "eps_max = 2.02\n",
    "v_min = 0\n",
    "v_max = 0.721"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1751eb",
   "metadata": {},
   "source": [
    "Note: the code in comment below was used to generate the data. It has now been saved separately in a folder called \"data\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af4df2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number_of_datapoints = 10000\n",
    "# data = []\n",
    "\n",
    "# for i in range(number_of_datapoints):\n",
    "#     rho = random.uniform(rho_min, rho_max)\n",
    "#     eps = random.uniform(eps_min, eps_max)\n",
    "#     v     = random.uniform(v_min, v_max)\n",
    "    \n",
    "#     p               = eos(rho, eps)\n",
    "#     Dvalue    = D(rho, eps, v)\n",
    "#     Svalue     = S(rho, eps, v)\n",
    "#     tauvalue = tau(rho, eps, v)\n",
    "    \n",
    "#     new_row = [rho, eps, v, p, Dvalue, Svalue, tauvalue]\n",
    "    \n",
    "#     data.append(new_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b204d50d",
   "metadata": {},
   "source": [
    "Save the data in a csv file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "663bea84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# header = ['rho', 'eps', 'v', 'p', 'D', 'S', 'tau']\n",
    "\n",
    "# with open('data/NNC2P_data_test.csv', 'w', newline = '') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     # write header\n",
    "#     writer.writerow(header)\n",
    "#     # write data\n",
    "#     writer.writerows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ea690aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training data has 80000 instances\n",
      "The test data has 10000 instances\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rho</th>\n",
       "      <th>eps</th>\n",
       "      <th>v</th>\n",
       "      <th>p</th>\n",
       "      <th>D</th>\n",
       "      <th>S</th>\n",
       "      <th>tau</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.662984</td>\n",
       "      <td>0.084146</td>\n",
       "      <td>0.218802</td>\n",
       "      <td>0.037192</td>\n",
       "      <td>0.679448</td>\n",
       "      <td>0.173724</td>\n",
       "      <td>0.077335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.565808</td>\n",
       "      <td>0.205945</td>\n",
       "      <td>0.657351</td>\n",
       "      <td>1.176059</td>\n",
       "      <td>11.366755</td>\n",
       "      <td>13.318537</td>\n",
       "      <td>7.718100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.387112</td>\n",
       "      <td>1.598809</td>\n",
       "      <td>0.021593</td>\n",
       "      <td>4.676103</td>\n",
       "      <td>4.388135</td>\n",
       "      <td>0.347321</td>\n",
       "      <td>7.020631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.337054</td>\n",
       "      <td>0.530803</td>\n",
       "      <td>0.351307</td>\n",
       "      <td>1.888615</td>\n",
       "      <td>5.700396</td>\n",
       "      <td>4.031171</td>\n",
       "      <td>3.885760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.133895</td>\n",
       "      <td>0.786717</td>\n",
       "      <td>0.079475</td>\n",
       "      <td>0.594703</td>\n",
       "      <td>1.137493</td>\n",
       "      <td>0.209600</td>\n",
       "      <td>0.905115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79995</th>\n",
       "      <td>8.101834</td>\n",
       "      <td>0.428605</td>\n",
       "      <td>0.616897</td>\n",
       "      <td>2.314990</td>\n",
       "      <td>10.294002</td>\n",
       "      <td>13.832316</td>\n",
       "      <td>9.813427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79996</th>\n",
       "      <td>7.841014</td>\n",
       "      <td>1.125480</td>\n",
       "      <td>0.209087</td>\n",
       "      <td>5.883268</td>\n",
       "      <td>8.018242</td>\n",
       "      <td>4.930289</td>\n",
       "      <td>9.678536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79997</th>\n",
       "      <td>4.628822</td>\n",
       "      <td>0.194190</td>\n",
       "      <td>0.237759</td>\n",
       "      <td>0.599248</td>\n",
       "      <td>4.765476</td>\n",
       "      <td>1.544018</td>\n",
       "      <td>1.129323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79998</th>\n",
       "      <td>9.913117</td>\n",
       "      <td>1.152242</td>\n",
       "      <td>0.477216</td>\n",
       "      <td>7.614874</td>\n",
       "      <td>11.280468</td>\n",
       "      <td>17.889657</td>\n",
       "      <td>18.592193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79999</th>\n",
       "      <td>9.717025</td>\n",
       "      <td>0.001552</td>\n",
       "      <td>0.163383</td>\n",
       "      <td>0.010052</td>\n",
       "      <td>9.849373</td>\n",
       "      <td>1.635352</td>\n",
       "      <td>0.149919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80000 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            rho       eps         v         p          D          S        tau\n",
       "0      0.662984  0.084146  0.218802  0.037192   0.679448   0.173724   0.077335\n",
       "1      8.565808  0.205945  0.657351  1.176059  11.366755  13.318537   7.718100\n",
       "2      4.387112  1.598809  0.021593  4.676103   4.388135   0.347321   7.020631\n",
       "3      5.337054  0.530803  0.351307  1.888615   5.700396   4.031171   3.885760\n",
       "4      1.133895  0.786717  0.079475  0.594703   1.137493   0.209600   0.905115\n",
       "...         ...       ...       ...       ...        ...        ...        ...\n",
       "79995  8.101834  0.428605  0.616897  2.314990  10.294002  13.832316   9.813427\n",
       "79996  7.841014  1.125480  0.209087  5.883268   8.018242   4.930289   9.678536\n",
       "79997  4.628822  0.194190  0.237759  0.599248   4.765476   1.544018   1.129323\n",
       "79998  9.913117  1.152242  0.477216  7.614874  11.280468  17.889657  18.592193\n",
       "79999  9.717025  0.001552  0.163383  0.010052   9.849373   1.635352   0.149919\n",
       "\n",
       "[80000 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data\n",
    "data_train = pd.read_csv(\"data/NNC2P_data_train.csv\")\n",
    "data_test = pd.read_csv(\"data/NNC2P_data_test.csv\")\n",
    "print(\"The training data has \" + str(len(data_train)) + \" instances\")\n",
    "print(\"The test data has \" + str(len(data_test)) + \" instances\")\n",
    "data_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190e037a",
   "metadata": {},
   "source": [
    "## Rework data into appropriate format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55e49cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = list(data_train[\"p\"].values)\n",
    "\n",
    "D_values = data_train[\"D\"].values\n",
    "S_values = data_train[\"S\"].values\n",
    "tau_values = data_train[\"tau\"].values\n",
    "\n",
    "for i in range(len(data_train[\"D\"])):\n",
    "    D_val, S_val, tau_val = D_values[i], S_values[i], tau_values[i]\n",
    "    \n",
    "    X_train.append([D_val, S_val, tau_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d95ab9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "y_test = list(data_test[\"p\"].values)\n",
    "\n",
    "D_values = data_test[\"D\"].values\n",
    "S_values = data_test[\"S\"].values\n",
    "tau_values = data_test[\"tau\"].values\n",
    "\n",
    "for i in range(len(data_test[\"D\"])):\n",
    "    D_val, S_val, tau_val = D_values[i], S_values[i], tau_values[i]\n",
    "    \n",
    "    X_test.append([D_val, S_val, tau_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c388d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.6794479873399221, 0.1737236543879239, 0.0773353397338715],\n",
       " [11.366754576378616, 13.318537432696782, 7.718099642903207],\n",
       " [4.388134954254378, 0.3473214062039617, 7.020631287593812]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a84fcb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0371918424194553, 1.1760592057471289, 4.676103122386751]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e900a05",
   "metadata": {},
   "source": [
    "# Random forest regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d06cb66",
   "metadata": {},
   "source": [
    "__NOTE:__ bad predictions. Need to read about this method in order to understand how to tune certain hyperparameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa772c8",
   "metadata": {},
   "source": [
    "Taken from [this documentation page](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6ee12f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e011f53f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = RandomForestRegressor()\n",
    "regr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9a83a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005007216202530824\n"
     ]
    }
   ],
   "source": [
    "y_pred = regr.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831867a7",
   "metadata": {},
   "source": [
    "# LSSVMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2308ef4",
   "metadata": {},
   "source": [
    "Can use [this repo](https://github.com/DannyVanpoucke/LSSVMlib/blob/master/examples/LSSVMlib-example_sklearn.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd2f8b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from LSSVMlib.LSSVMRegression import LSSVMRegression\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f384ef2a",
   "metadata": {},
   "source": [
    "In order to start working with the module, it can be useful to read [this example](https://github.com/DannyVanpoucke/LSSVMlib/blob/master/examples/LSSVMlib-example_sklearn.ipynb). \n",
    "\n",
    "Note: SVMs are $\\mathcal{O}(N^2)$, so limit the amount of training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d1d47ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsize_data = 500\n",
    "# --- Limit train data\n",
    "sub_data_train = data_train[:subsize_data]\n",
    "sub_data_train\n",
    "\n",
    "# Also limit the data presented in the other format:\n",
    "sub_X_train, sub_y_train = X_train[:subsize_data], y_train[:subsize_data]\n",
    "\n",
    "# --- Limit test data\n",
    "sub_data_test = data_test[:subsize_data]\n",
    "sub_data_test\n",
    "\n",
    "# Also limit the data presented in the other format:\n",
    "sub_X_test, sub_y_test = X_test[:subsize_data], y_test[:subsize_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a1a8acba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:\n",
      "[[ 0.67944799  0.17372365  0.07733534]\n",
      " [11.36675458 13.31853743  7.71809964]\n",
      " [ 4.38813495  0.34732141  7.02063129]]\n",
      "Labels:\n",
      "[0.03719184 1.17605921 4.67610312]\n"
     ]
    }
   ],
   "source": [
    "train_features = np.array(sub_X_train)\n",
    "train_labels = np.array(sub_y_train)\n",
    "test_features = np.array(sub_X_test)\n",
    "test_labels = np.array(sub_y_test)\n",
    "print(\"Features:\")\n",
    "print(train_features[:3])\n",
    "print(\"Labels:\")\n",
    "print(train_labels[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9282bc",
   "metadata": {},
   "source": [
    "## RBF kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fb24b047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b =  5.024197009415371\n",
      "Trained on 500 instances and took 0.10 seconds\n"
     ]
    }
   ],
   "source": [
    "ndata = train_features.shape[0] \n",
    "start = time.time()\n",
    "clf = LSSVMRegression(\n",
    "        gamma=100,       #set the gamma-hyper parameter equal to 1\n",
    "        kernel='rbf', #use the linear kernel\n",
    "        sigma=1.0,\n",
    "        c=0.01,\n",
    "        d=2)\n",
    "\n",
    "clf.fit(train_features, train_labels) # train our model, aka solve the set of linear equations\n",
    "print(\"b = \", clf.intercept_)\n",
    "end = time.time()\n",
    "elapsed = end-start\n",
    "print(\"Trained on %d instances and took %0.2f seconds\" % (ndata, elapsed))\n",
    "# print(\"a_i = \", clf.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6dd3e6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 1.15\n",
      "Coefficient of determination: 0.87\n"
     ]
    }
   ],
   "source": [
    "# Predict for test set\n",
    "predictions  =clf.predict(test_features)\n",
    "\n",
    "# The mean squared error\n",
    "print('Mean squared error: %.2f' % mean_squared_error(test_labels, predictions))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Coefficient of determination: %.2f' % r2_score(test_labels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7741d55",
   "metadata": {},
   "source": [
    "## Poly kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0275bfdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b =  0.007781134495329835\n",
      "Trained on 500 instances and took 0.07 seconds\n"
     ]
    }
   ],
   "source": [
    "ndata = train_features.shape[0] \n",
    "start = time.time()\n",
    "clf = LSSVMRegression(\n",
    "        gamma=100,       #set the gamma-hyper parameter equal to 1\n",
    "        kernel='poly', #use the linear kernel\n",
    "        sigma=1.0,\n",
    "        c=0.01,\n",
    "        d=2)\n",
    "\n",
    "clf.fit(train_features, train_labels) # train our model, aka solve the set of linear equations\n",
    "print(\"b = \", clf.intercept_)\n",
    "end = time.time()\n",
    "elapsed = end-start\n",
    "print(\"Trained on %d instances and took %0.2f seconds\" % (ndata, elapsed))\n",
    "# print(\"a_i = \", clf.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d997997d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 0.03\n",
      "Coefficient of determination: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Predict for test set\n",
    "predictions  =clf.predict(test_features)\n",
    "\n",
    "# The mean squared error\n",
    "print('Mean squared error: %.2f' % mean_squared_error(test_labels, predictions))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Coefficient of determination: %.2f' % r2_score(test_labels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f75d5f1",
   "metadata": {},
   "source": [
    "## Grid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f210b2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "009b835b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LSSVMRegression(kernel='rbf'),\n",
       "             param_grid={'gamma': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0],\n",
       "                         'kernel': ['rbf'],\n",
       "                         'sigma': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'kernel':['rbf'], \n",
    "    'gamma':[0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0],\n",
    "    'sigma':[0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]}\n",
    "\n",
    "lssvm = LSSVMRegression() \n",
    "clf = GridSearchCV(lssvm, parameters) \n",
    "clf.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f21e80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "author": "Thibeau Wouters",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
