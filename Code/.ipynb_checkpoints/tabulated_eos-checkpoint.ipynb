{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bb9f224",
   "metadata": {
    "executionInfo": {
     "elapsed": 8764,
     "status": "ok",
     "timestamp": 1681398656896,
     "user": {
      "displayName": "Thibeau Wouters",
      "userId": "14702334917940433667"
     },
     "user_tz": -120
    },
    "id": "0bb9f224"
   },
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "import random\n",
    "import csv\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import gc  # garbage collection\n",
    "# Scikit learn libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# PyTorch libraries\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import ToTensor, Normalize \n",
    "# Get dirs\n",
    "import os\n",
    "cwd = os.getcwd()# \"Code\" folder\n",
    "master_dir = os.path.abspath(os.path.join(cwd, \"..\"))\n",
    "# ONNX\n",
    "# import onnx\n",
    "# import onnxruntime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c465f7c",
   "metadata": {
    "id": "4c465f7c"
   },
   "source": [
    "When using __Google Colab__, run the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75bacf53",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19202,
     "status": "ok",
     "timestamp": 1681398681220,
     "user": {
      "displayName": "Thibeau Wouters",
      "userId": "14702334917940433667"
     },
     "user_tz": -120
    },
    "id": "bbeb496d",
    "outputId": "30fa916e-e8c0-4fbe-de12-cd51790fc6a3"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# code_dir = \"/content/drive/MyDrive/KUL/MAI thesis/Code\"\n",
    "# master_dir = os.path.join(code_dir, \"..\")\n",
    "# os.chdir(code_dir)\n",
    "# print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36bbffc0",
   "metadata": {
    "executionInfo": {
     "elapsed": 1462,
     "status": "ok",
     "timestamp": 1681398682653,
     "user": {
      "displayName": "Thibeau Wouters",
      "userId": "14702334917940433667"
     },
     "user_tz": -120
    },
    "id": "36bbffc0"
   },
   "outputs": [],
   "source": [
    "# Load own scripts:\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import physics\n",
    "import data\n",
    "import nnc2p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3393c80",
   "metadata": {
    "id": "c3393c80"
   },
   "source": [
    "Point towards the folder where we store the EOS tables (__Note:__ they are not in the Github as these are very large files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efbc8d2b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1681398682653,
     "user": {
      "displayName": "Thibeau Wouters",
      "userId": "14702334917940433667"
     },
     "user_tz": -120
    },
    "id": "efbc8d2b",
    "outputId": "49af00ba-c706-4dd9-fd2c-ee828683afe1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to look for EOS tables at D:/Coding/Datasets/eos_tables\n"
     ]
    }
   ],
   "source": [
    "eos_tables_dir = os.path.join(\"D:/Coding/Datasets/eos_tables\")  # offline\n",
    "# eos_tables_dir = os.path.join(master_dir, \"Data\")  # in Google Colab\n",
    "print(f\"Going to look for EOS tables at {eos_tables_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vqCsP2sKAeCm",
   "metadata": {
    "id": "vqCsP2sKAeCm"
   },
   "source": [
    "For the training, check if GPU is available (Google Colab):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "P8YoVE15AhRC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1681398682654,
     "user": {
      "displayName": "Thibeau Wouters",
      "userId": "14702334917940433667"
     },
     "user_tz": -120
    },
    "id": "P8YoVE15AhRC",
    "outputId": "4f6e373c-7e27-4461-f5cf-51b91d99d440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device for training: cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available(): \n",
    "    DEVICE = \"cuda:0\" \n",
    "    torch.set_default_device('cuda')\n",
    "else: \n",
    "    DEVICE = \"cpu\" \n",
    "print(f\"Device for training: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fb3c8c",
   "metadata": {
    "id": "02fb3c8c"
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ab265e",
   "metadata": {
    "id": "96ab265e"
   },
   "source": [
    "Here, we try to find a way to generalize the NN approach from the first semester to the situation of tabular EOS. \n",
    "\n",
    "*Note*: We use HDF5 files, but you have to close them manually. Forgot to close one? Check if there is still an open HDF5 file with garbage collect in the memory, and close it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "17ceb9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Closed HDF5 file>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Browse through objects\n",
    "for obj in gc.get_objects():\n",
    "    # see if is an HDF5 file\n",
    "    if isinstance(obj, h5py.File):\n",
    "        print(obj)\n",
    "        try:\n",
    "            obj.close()\n",
    "            del obj\n",
    "        except:\n",
    "            pass\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf08ad4a",
   "metadata": {
    "id": "cf08ad4a"
   },
   "source": [
    "# Exploring EOS tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d5e6fdb",
   "metadata": {
    "executionInfo": {
     "elapsed": 380,
     "status": "ok",
     "timestamp": 1681398683009,
     "user": {
      "displayName": "Thibeau Wouters",
      "userId": "14702334917940433667"
     },
     "user_tz": -120
    },
    "id": "4d5e6fdb"
   },
   "outputs": [],
   "source": [
    "# Put the downloaded EOS tables here\n",
    "# first_table_filename       = \"LS180_234r_136t_50y_analmu_20091212_SVNr26.h5\"\n",
    "# second_table_filename = \"GShen_NL3EOS_rho280_temp180_ye52_version_1.1_20120817.h5\"\n",
    "third_table_filename      = \"SLy4_0000_rho391_temp163_ye66.h5\"\n",
    "# Then specify which we are going to use here\n",
    "eos_table_filename = third_table_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d8f465",
   "metadata": {
    "id": "78d8f465"
   },
   "source": [
    "Read in the SLy4 EOS table using our py script: (make sure to close HDF5 files!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "913d9582",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 660,
     "status": "ok",
     "timestamp": 1681398683667,
     "user": {
      "displayName": "Thibeau Wouters",
      "userId": "14702334917940433667"
     },
     "user_tz": -120
    },
    "id": "913d9582",
    "outputId": "677bba7a-6c4a-4190-a9fa-8f0bbca82bfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This EOS table has dimensions 66 x 163 x 391\n",
      "Example: (3.0239960056064277, -3.0, 0.005) we have (log eps, log p): (19.2791052025363, 17.99956975587081).\n"
     ]
    }
   ],
   "source": [
    "# Open EOS table\n",
    "eos_table = physics.read_eos_table(os.path.join(eos_tables_dir, eos_table_filename))\n",
    "# Read in the most important variables and convert them to np arrays\n",
    "dim_ye, dim_temp, dim_rho = eos_table[\"pointsye\"][()][0], eos_table[\"pointstemp\"][()][0], eos_table[\"pointsrho\"][()][0]\n",
    "logrho = eos_table[\"logrho\"][()]\n",
    "logtemp = eos_table[\"logtemp\"][()]\n",
    "ye = eos_table[\"ye\"][()]\n",
    "logpress = eos_table[\"logpress\"][()]\n",
    "logenergy = eos_table[\"logenergy\"][()]\n",
    "energy_shift = eos_table[\"energy_shift\"][()][0]\n",
    "cs2 = eos_table[\"cs2\"][()]\n",
    "print(f\"This EOS table has dimensions {dim_ye} x {dim_temp} x {dim_rho}\")\n",
    "# Small test to see the output of the EOS table\n",
    "test_ye = eos_table[\"ye\"][()][0]\n",
    "test_temp = eos_table[\"logtemp\"][()][0]\n",
    "test_rho = eos_table[\"logrho\"][()][0]\n",
    "test_press, test_eps = eos_table[\"logpress\"][()][0, 0, 0], eos_table[\"logenergy\"][()][0, 0, 0]\n",
    "print(f\"Example: ({test_rho}, {test_temp}, {test_ye}) we have (log eps, log p): ({test_eps}, {test_press}).\")\n",
    "eos_table.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8dd7c23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt(\"energy_shift.txt\", [energy_shift])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0167f31",
   "metadata": {
    "id": "f0167f31"
   },
   "source": [
    "See what is inside this EOS table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "316b6963",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 517,
     "status": "ok",
     "timestamp": 1681398689771,
     "user": {
      "displayName": "Thibeau Wouters",
      "userId": "14702334917940433667"
     },
     "user_tz": -120
    },
    "id": "316b6963",
    "outputId": "77b6ecac-15ea-461d-f76a-b641a290fd63"
   },
   "outputs": [],
   "source": [
    "# # Iterate over keys and save them to list for simplified viewing\n",
    "# keys = []\n",
    "# for key in eos_table:\n",
    "#     keys.append(key)\n",
    "# print(keys)\n",
    "# print(len(keys))\n",
    "\n",
    "## Output\n",
    "# ['Abar', 'Albar', 'MERGE-space.in', 'MERGE-src.tar.gz', 'MERGE-tables.in', 'MERGE-transition.in', 'SNA-skyrme.in', 'SNA-space.in', 'SNA-src.tar.gz', 'Xa', 'Xh', 'Xl', 'Xn', 'Xp', 'Zbar', 'Zlbar', 'cs2', 'dedt', 'dpderho', 'dpdrhoe', 'energy_shift', 'entropy', 'gamma', 'have_rel_cs2', 'logenergy', 'logpress', 'logrho', 'logtemp', 'meffn', 'meffp', 'mu_e', 'mu_n', 'mu_p', 'muhat', 'munu', 'pointsrho', 'pointstemp', 'pointsye', 'r', 'u', 'ye']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc15e58b",
   "metadata": {
    "id": "cc15e58b"
   },
   "source": [
    "# Generating training data by sampling from EOS table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8fc6d3",
   "metadata": {
    "id": "bc8fc6d3"
   },
   "source": [
    "To generate new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "511ae7db",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1681398695231,
     "user": {
      "displayName": "Thibeau Wouters",
      "userId": "14702334917940433667"
     },
     "user_tz": -120
    },
    "id": "511ae7db"
   },
   "outputs": [],
   "source": [
    "# dat = physics.generate_tabular_data(eos_table, number_of_points = 100000, save_name = \"SLy4_training_data\")\n",
    "# dat = physics.generate_tabular_data(eos_table, number_of_points = 20000, save_name = \"SLy4_test_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a121af",
   "metadata": {
    "id": "a0a121af"
   },
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f929937d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "executionInfo": {
     "elapsed": 557,
     "status": "ok",
     "timestamp": 1681398695783,
     "user": {
      "displayName": "Thibeau Wouters",
      "userId": "14702334917940433667"
     },
     "user_tz": -120
    },
    "id": "f929937d",
    "outputId": "304adfcc-4c0a-40fa-e2eb-452997407dc9"
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv(os.path.join(master_dir, \"Data/SLy4_training_data.csv\"))\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2fce3d",
   "metadata": {
    "id": "5f2fce3d"
   },
   "source": [
    "The network architecture we will use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "270fd513",
   "metadata": {
    "executionInfo": {
     "elapsed": 215,
     "status": "ok",
     "timestamp": 1681398697956,
     "user": {
      "displayName": "Thibeau Wouters",
      "userId": "14702334917940433667"
     },
     "user_tz": -120
    },
    "id": "270fd513"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements a simple feedforward neural network.\n",
    "    \"\"\"\n",
    "    def __init__(self, nb_of_inputs: int = 3, nb_of_outputs: int = 1, h: list = [600, 200], reg: bool = False, \n",
    "                 activation_function = torch.nn.Sigmoid) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the neural network class.\n",
    "        \"\"\"\n",
    "        # Call the super constructor first\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # For convenience, save the sizes of the hidden layers as fields as well\n",
    "        self.h = h\n",
    "        # Add visible layers as well: input is 3D and output is 1D\n",
    "        self.h_augmented = [nb_of_inputs] + h + [nb_of_outputs]\n",
    "\n",
    "        # Add field to specify whether or not we do regularization\n",
    "        self.regularization = reg\n",
    "\n",
    "        # Define the layers:\n",
    "        for i in range(len(self.h_augmented)-1):\n",
    "            if i == len(self.h_augmented)-2:\n",
    "                setattr(self, f\"linear{i+1}\", nn.Linear(self.h_augmented[i], self.h_augmented[i+1], bias=False))\n",
    "            else:\n",
    "                setattr(self, f\"linear{i+1}\", nn.Linear(self.h_augmented[i], self.h_augmented[i+1]))\n",
    "                setattr(self, f\"activation{i+1}\", activation_function())\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Computes a forward step given the input x.\n",
    "        :param x: Input for the neural network.\n",
    "        :return: x: Output neural network\n",
    "        \"\"\"\n",
    "        \n",
    "        for i, module in enumerate(self.modules()):\n",
    "            # The first module is the whole NNC2P object, continue\n",
    "            if i == 0:\n",
    "                continue\n",
    "            x = module(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd2f127",
   "metadata": {
    "id": "8fd2f127"
   },
   "source": [
    "# First goal: NNEOS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5850152",
   "metadata": {
    "id": "e5850152"
   },
   "source": [
    "__NNEOS__: try to replicate the EOS table (at least the core variables we are interested in) using the \"input\" variables rho, temp, ye."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12089f53",
   "metadata": {
    "id": "12089f53"
   },
   "source": [
    "## Convert EOS table to table of training examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7a92994d",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1681398700618,
     "user": {
      "displayName": "Thibeau Wouters",
      "userId": "14702334917940433667"
     },
     "user_tz": -120
    },
    "id": "7a92994d"
   },
   "outputs": [],
   "source": [
    "# Get the filename of converted training data\n",
    "filename = os.path.join(eos_tables_dir, \"train_eos_table.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "051199cf",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1681398701905,
     "user": {
      "displayName": "Thibeau Wouters",
      "userId": "14702334917940433667"
     },
     "user_tz": -120
    },
    "id": "051199cf"
   },
   "outputs": [],
   "source": [
    "# # Create new dataset (if desired)\n",
    "# # Specify output vars as \"var_names\" argument in this function - see physics.py\n",
    "# eos_table = physics.read_eos_table(os.path.join(eos_tables_dir, eos_table_filename))\n",
    "# physics.convert_eos_table(eos_table, save_name=filename)\n",
    "# eos_table.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ccbc983b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2035,
     "status": "ok",
     "timestamp": 1681398704133,
     "user": {
      "displayName": "Thibeau Wouters",
      "userId": "14702334917940433667"
     },
     "user_tz": -120
    },
    "id": "ccbc983b",
    "outputId": "a345b306-1aba-427e-874c-daa97b43cdca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output variables are [b'logenergy' b'logpress' b'cs2']. Number of examples: 4206378\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "train_eos_table = h5py.File(filename, 'r')\n",
    "# Get the data saved in the HDF5 file\n",
    "features  = train_eos_table[\"features\"][:]\n",
    "labels    = train_eos_table[\"labels\"][:]\n",
    "var_names = train_eos_table[\"var_names\"][:]\n",
    "size_eos_table = len(features)\n",
    "print(f\"The output variables are {var_names}. Number of examples: {size_eos_table}\")\n",
    "# Close the file\n",
    "train_eos_table.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805525b8",
   "metadata": {},
   "source": [
    "## Preprocess the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370870df",
   "metadata": {},
   "source": [
    "An example of a features/labels pair:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "0d8a4d14",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1681398706075,
     "user": {
      "displayName": "Thibeau Wouters",
      "userId": "14702334917940433667"
     },
     "user_tz": -120
    },
    "id": "0d8a4d14",
    "outputId": "0f2e12a5-cd17-4dcb-ac27-f09ecee5e38a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.02399601 -3.          0.005     ]\n",
      "[19.2791052  17.99956976 34.99350003]\n"
     ]
    }
   ],
   "source": [
    "print(features[0])\n",
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ffe6ce",
   "metadata": {},
   "source": [
    "### Delete negative $c_s^2$ values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ff9a72",
   "metadata": {},
   "source": [
    "There are apparently a few negative values for the speed of sound... They are likely a bug in the code? We'll remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4dd3f488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.57573784e+15, 1.53801127e+15, 1.49992954e+15, ...,\n",
       "       1.34334539e+21, 1.34446322e+21, 1.34570741e+21])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs_values = labels[:, 2]\n",
    "cs_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "afe39d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3629826],\n",
       "       [3629892],\n",
       "       [3629958],\n",
       "       [3630024],\n",
       "       [3630090],\n",
       "       [3630156],\n",
       "       [3630222],\n",
       "       [3630288],\n",
       "       [3630354]], dtype=int64)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_indices = np.argwhere(cs_values < 0)\n",
    "negative_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "318b7b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.delete(features, negative_indices, axis=0)\n",
    "labels = np.delete(labels, negative_indices, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae7707a",
   "metadata": {},
   "source": [
    "### Use log values for $c_s^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c4f2e6",
   "metadata": {},
   "source": [
    "If we are using cs2 in the output, you see that its values are huge -- we will also output log cs2 values to improve training the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c822a63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: binary text!\n",
    "if b\"cs2\" in var_names:\n",
    "    cs_index = np.where(var_names == b\"cs2\")[0][0]\n",
    "    labels[:, cs_index] = np.log(labels[:, cs_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7e8b787d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.02399601 -3.          0.005     ]\n",
      "[19.2791052  17.99956976 34.99350003]\n"
     ]
    }
   ],
   "source": [
    "print(features[0])\n",
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "eb2c3936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19.02463658 17.42022108 33.74498022]\n",
      "[33.15270695 38.1640256  48.77010732]\n"
     ]
    }
   ],
   "source": [
    "min_values = np.min(labels, axis=0)\n",
    "print(min_values)\n",
    "max_values = np.max(labels, axis=0)\n",
    "print(max_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95206a4e",
   "metadata": {},
   "source": [
    "### Convert to Torch datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6d6047",
   "metadata": {
    "id": "ec6d6047"
   },
   "source": [
    "Get the training data as DataSet and DataLoader objects. Note on normalization: we fit transform on the training data, then use the fitted scaler object to transform (i.e. using same transformation as the training data) the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ec910284",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1126,
     "status": "ok",
     "timestamp": 1681398709169,
     "user": {
      "displayName": "Thibeau Wouters",
      "userId": "14702334917940433667"
     },
     "user_tz": -120
    },
    "id": "ec910284",
    "outputId": "4f15e095-7252-40dc-c90d-2bafae1c6cb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3154776\n",
      "78869\n"
     ]
    }
   ],
   "source": [
    "# For normalization, use sklearn's StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# Do train test split here\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, random_state=42)\n",
    "# \"Cutoff\": only use certain portion of the data for training and testing, to speed up training when tuning architecture \n",
    "cutoff = 0.025\n",
    "print(len(train_features))\n",
    "end = int(cutoff*len(train_features))\n",
    "train_features = train_features[:end]\n",
    "train_labels = train_labels[:end]\n",
    "end = int(cutoff*len(test_features))\n",
    "test_features = test_features[:end]\n",
    "test_labels = test_labels[:end]\n",
    "print(len(train_features))\n",
    "# Convert to PyTorch Datasets as we defined them\n",
    "train_dataset = data.HDF5Dataset(train_features, train_labels, normalization_function = scaler.fit_transform) \n",
    "test_dataset  = data.HDF5Dataset(test_features, test_labels, normalization_function = scaler.transform)\n",
    "# Then create dataloaders, with batch size 32, from datasets\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = 32)\n",
    "test_dataloader  = DataLoader(test_dataset, batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12e532a",
   "metadata": {
    "id": "f12e532a"
   },
   "source": [
    "Create a new instance of the Net:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "be7a388c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1681398714800,
     "user": {
      "displayName": "Thibeau Wouters",
      "userId": "14702334917940433667"
     },
     "user_tz": -120
    },
    "id": "be7a388c",
    "outputId": "c92948dd-975b-4e2f-81a0-ee0661b400ff"
   },
   "outputs": [],
   "source": [
    "model = Net(nb_of_inputs=3, nb_of_outputs=3, h=[50, 50]).double()\n",
    "# print(next(model.parameters()).is_cuda )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5a0e1f63",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1681398716642,
     "user": {
      "displayName": "Thibeau Wouters",
      "userId": "14702334917940433667"
     },
     "user_tz": -120
    },
    "id": "5a0e1f63",
    "outputId": "474f33c1-c8a7-4433-9f4d-9738b0a08141"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2900"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnc2p.count_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1e3745",
   "metadata": {
    "id": "1e1e3745"
   },
   "source": [
    "Create a trainer object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "df92e917",
   "metadata": {
    "executionInfo": {
     "elapsed": 705,
     "status": "ok",
     "timestamp": 1681398719638,
     "user": {
      "displayName": "Thibeau Wouters",
      "userId": "14702334917940433667"
     },
     "user_tz": -120
    },
    "id": "df92e917"
   },
   "outputs": [],
   "source": [
    "trainer = nnc2p.Trainer(model, 1e-2, train_dataloader=train_dataloader, test_dataloader=test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227207f2",
   "metadata": {},
   "source": [
    "Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "53ce8669",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 171807,
     "status": "ok",
     "timestamp": 1681398892786,
     "user": {
      "displayName": "Thibeau Wouters",
      "userId": "14702334917940433667"
     },
     "user_tz": -120
    },
    "id": "53ce8669",
    "outputId": "711c53ca-cf46-43e3-8d63-6625ebdf0880"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model for 500 epochs.\n",
      "\n",
      " Epoch 0 \n",
      " --------------\n",
      "Train loss: 1.95E-01\n",
      "Test  loss: 1.93E-01\n",
      "\n",
      " Epoch 1 \n",
      " --------------\n",
      "Train loss: 1.98E-02\n",
      "Test  loss: 1.97E-02\n",
      "\n",
      " Epoch 2 \n",
      " --------------\n",
      "Train loss: 1.02E-02\n",
      "Test  loss: 1.03E-02\n",
      "\n",
      " Epoch 3 \n",
      " --------------\n",
      "Train loss: 8.71E-03\n",
      "Test  loss: 8.84E-03\n",
      "\n",
      " Epoch 4 \n",
      " --------------\n",
      "Train loss: 8.40E-03\n",
      "Test  loss: 8.52E-03\n",
      "\n",
      " Epoch 5 \n",
      " --------------\n",
      "Train loss: 7.04E-03\n",
      "Test  loss: 7.18E-03\n",
      "\n",
      " Epoch 6 \n",
      " --------------\n",
      "Train loss: 6.35E-03\n",
      "Test  loss: 6.51E-03\n",
      "\n",
      " Epoch 7 \n",
      " --------------\n",
      "Train loss: 5.96E-03\n",
      "Test  loss: 6.13E-03\n",
      "\n",
      " Epoch 8 \n",
      " --------------\n",
      "Train loss: 5.32E-03\n",
      "Test  loss: 5.49E-03\n",
      "\n",
      " Epoch 9 \n",
      " --------------\n",
      "Train loss: 5.02E-03\n",
      "Test  loss: 5.17E-03\n",
      "\n",
      " Epoch 10 \n",
      " --------------\n",
      "Train loss: 4.97E-03\n",
      "Test  loss: 5.11E-03\n",
      "\n",
      " Epoch 11 \n",
      " --------------\n",
      "Train loss: 4.69E-03\n",
      "Test  loss: 4.82E-03\n",
      "\n",
      " Epoch 12 \n",
      " --------------\n",
      "Train loss: 4.54E-03\n",
      "Test  loss: 4.67E-03\n",
      "\n",
      " Epoch 13 \n",
      " --------------\n",
      "Train loss: 4.28E-03\n",
      "Test  loss: 4.40E-03\n",
      "\n",
      " Epoch 14 \n",
      " --------------\n",
      "Train loss: 4.04E-03\n",
      "Test  loss: 4.16E-03\n",
      "\n",
      " Epoch 15 \n",
      " --------------\n",
      "Train loss: 3.79E-03\n",
      "Test  loss: 3.90E-03\n",
      "\n",
      " Epoch 16 \n",
      " --------------\n",
      "Train loss: 3.40E-03\n",
      "Test  loss: 3.52E-03\n",
      "\n",
      " Epoch 17 \n",
      " --------------\n",
      "Train loss: 3.05E-03\n",
      "Test  loss: 3.16E-03\n",
      "\n",
      " Epoch 18 \n",
      " --------------\n",
      "Train loss: 2.80E-03\n",
      "Test  loss: 2.90E-03\n",
      "\n",
      " Epoch 19 \n",
      " --------------\n",
      "Train loss: 2.65E-03\n",
      "Test  loss: 2.76E-03\n",
      "\n",
      " Epoch 20 \n",
      " --------------\n",
      "Train loss: 2.57E-03\n",
      "Test  loss: 2.68E-03\n",
      "\n",
      " Epoch 21 \n",
      " --------------\n",
      "Train loss: 2.52E-03\n",
      "Test  loss: 2.62E-03\n",
      "\n",
      " Epoch 22 \n",
      " --------------\n",
      "Train loss: 2.49E-03\n",
      "Test  loss: 2.59E-03\n",
      "\n",
      " Epoch 23 \n",
      " --------------\n",
      "Train loss: 2.48E-03\n",
      "Test  loss: 2.57E-03\n",
      "\n",
      " Epoch 24 \n",
      " --------------\n",
      "Train loss: 2.46E-03\n",
      "Test  loss: 2.56E-03\n",
      "\n",
      " Epoch 25 \n",
      " --------------\n",
      "Train loss: 2.45E-03\n",
      "Test  loss: 2.55E-03\n",
      "\n",
      " Epoch 26 \n",
      " --------------\n",
      "Train loss: 2.45E-03\n",
      "Test  loss: 2.54E-03\n",
      "\n",
      " Epoch 27 \n",
      " --------------\n",
      "Train loss: 2.44E-03\n",
      "Test  loss: 2.53E-03\n",
      "\n",
      " Epoch 28 \n",
      " --------------\n",
      "Train loss: 2.43E-03\n",
      "Test  loss: 2.52E-03\n",
      "\n",
      " Epoch 29 \n",
      " --------------\n",
      "Train loss: 2.40E-03\n",
      "Test  loss: 2.49E-03\n",
      "\n",
      " Epoch 30 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.40E-03\n",
      "\n",
      " Epoch 31 \n",
      " --------------\n",
      "Train loss: 2.24E-03\n",
      "Test  loss: 2.33E-03\n",
      "\n",
      " Epoch 32 \n",
      " --------------\n",
      "Train loss: 2.18E-03\n",
      "Test  loss: 2.26E-03\n",
      "\n",
      " Epoch 33 \n",
      " --------------\n",
      "Train loss: 2.15E-03\n",
      "Test  loss: 2.23E-03\n",
      "\n",
      " Epoch 34 \n",
      " --------------\n",
      "Train loss: 2.15E-03\n",
      "Test  loss: 2.24E-03\n",
      "\n",
      " Epoch 35 \n",
      " --------------\n",
      "Train loss: 2.18E-03\n",
      "Test  loss: 2.26E-03\n",
      "\n",
      " Epoch 36 \n",
      " --------------\n",
      "Train loss: 2.21E-03\n",
      "Test  loss: 2.29E-03\n",
      "\n",
      " Epoch 37 \n",
      " --------------\n",
      "Train loss: 2.23E-03\n",
      "Test  loss: 2.31E-03\n",
      "\n",
      " Epoch 38 \n",
      " --------------\n",
      "Adapting learning rate to 0.005\n",
      "Train loss: 2.22E-03\n",
      "Test  loss: 2.30E-03\n",
      "\n",
      " Epoch 39 \n",
      " --------------\n",
      "Train loss: 1.01E-03\n",
      "Test  loss: 1.08E-03\n",
      "\n",
      " Epoch 40 \n",
      " --------------\n",
      "Train loss: 9.76E-04\n",
      "Test  loss: 1.05E-03\n",
      "\n",
      " Epoch 41 \n",
      " --------------\n",
      "Train loss: 9.57E-04\n",
      "Test  loss: 1.03E-03\n",
      "\n",
      " Epoch 42 \n",
      " --------------\n",
      "Train loss: 9.41E-04\n",
      "Test  loss: 1.02E-03\n",
      "\n",
      " Epoch 43 \n",
      " --------------\n",
      "Train loss: 9.27E-04\n",
      "Test  loss: 1.00E-03\n",
      "\n",
      " Epoch 44 \n",
      " --------------\n",
      "Train loss: 9.15E-04\n",
      "Test  loss: 9.91E-04\n",
      "\n",
      " Epoch 45 \n",
      " --------------\n",
      "Train loss: 9.05E-04\n",
      "Test  loss: 9.80E-04\n",
      "\n",
      " Epoch 46 \n",
      " --------------\n",
      "Train loss: 8.96E-04\n",
      "Test  loss: 9.70E-04\n",
      "\n",
      " Epoch 47 \n",
      " --------------\n",
      "Train loss: 8.88E-04\n",
      "Test  loss: 9.62E-04\n",
      "\n",
      " Epoch 48 \n",
      " --------------\n",
      "Train loss: 8.82E-04\n",
      "Test  loss: 9.55E-04\n",
      "\n",
      " Epoch 49 \n",
      " --------------\n",
      "Train loss: 8.77E-04\n",
      "Test  loss: 9.49E-04\n",
      "\n",
      " Epoch 50 \n",
      " --------------\n",
      "Train loss: 8.73E-04\n",
      "Test  loss: 9.45E-04\n",
      "\n",
      " Epoch 51 \n",
      " --------------\n",
      "Train loss: 8.70E-04\n",
      "Test  loss: 9.42E-04\n",
      "\n",
      " Epoch 52 \n",
      " --------------\n",
      "Train loss: 8.68E-04\n",
      "Test  loss: 9.39E-04\n",
      "\n",
      " Epoch 53 \n",
      " --------------\n",
      "Train loss: 8.67E-04\n",
      "Test  loss: 9.37E-04\n",
      "\n",
      " Epoch 54 \n",
      " --------------\n",
      "Train loss: 8.65E-04\n",
      "Test  loss: 9.35E-04\n",
      "\n",
      " Epoch 55 \n",
      " --------------\n",
      "Train loss: 8.64E-04\n",
      "Test  loss: 9.33E-04\n",
      "\n",
      " Epoch 56 \n",
      " --------------\n",
      "Train loss: 8.63E-04\n",
      "Test  loss: 9.31E-04\n",
      "\n",
      " Epoch 57 \n",
      " --------------\n",
      "Train loss: 8.61E-04\n",
      "Test  loss: 9.29E-04\n",
      "\n",
      " Epoch 58 \n",
      " --------------\n",
      "Train loss: 8.60E-04\n",
      "Test  loss: 9.27E-04\n",
      "\n",
      " Epoch 59 \n",
      " --------------\n",
      "Train loss: 8.58E-04\n",
      "Test  loss: 9.25E-04\n",
      "\n",
      " Epoch 60 \n",
      " --------------\n",
      "Train loss: 8.55E-04\n",
      "Test  loss: 9.22E-04\n",
      "\n",
      " Epoch 61 \n",
      " --------------\n",
      "Train loss: 8.53E-04\n",
      "Test  loss: 9.19E-04\n",
      "\n",
      " Epoch 62 \n",
      " --------------\n",
      "Train loss: 8.50E-04\n",
      "Test  loss: 9.16E-04\n",
      "\n",
      " Epoch 63 \n",
      " --------------\n",
      "Train loss: 8.47E-04\n",
      "Test  loss: 9.13E-04\n",
      "\n",
      " Epoch 64 \n",
      " --------------\n",
      "Train loss: 8.44E-04\n",
      "Test  loss: 9.09E-04\n",
      "\n",
      " Epoch 65 \n",
      " --------------\n",
      "Train loss: 8.41E-04\n",
      "Test  loss: 9.06E-04\n",
      "\n",
      " Epoch 66 \n",
      " --------------\n",
      "Train loss: 8.38E-04\n",
      "Test  loss: 9.02E-04\n",
      "\n",
      " Epoch 67 \n",
      " --------------\n",
      "Train loss: 8.34E-04\n",
      "Test  loss: 8.99E-04\n",
      "\n",
      " Epoch 68 \n",
      " --------------\n",
      "Train loss: 8.31E-04\n",
      "Test  loss: 8.95E-04\n",
      "\n",
      " Epoch 69 \n",
      " --------------\n",
      "Train loss: 8.28E-04\n",
      "Test  loss: 8.92E-04\n",
      "\n",
      " Epoch 70 \n",
      " --------------\n",
      "Train loss: 8.25E-04\n",
      "Test  loss: 8.89E-04\n",
      "\n",
      " Epoch 71 \n",
      " --------------\n",
      "Train loss: 8.23E-04\n",
      "Test  loss: 8.86E-04\n",
      "\n",
      " Epoch 72 \n",
      " --------------\n",
      "Train loss: 8.20E-04\n",
      "Test  loss: 8.84E-04\n",
      "\n",
      " Epoch 73 \n",
      " --------------\n",
      "Train loss: 8.18E-04\n",
      "Test  loss: 8.81E-04\n",
      "\n",
      " Epoch 74 \n",
      " --------------\n",
      "Train loss: 8.16E-04\n",
      "Test  loss: 8.79E-04\n",
      "\n",
      " Epoch 75 \n",
      " --------------\n",
      "Train loss: 8.14E-04\n",
      "Test  loss: 8.77E-04\n",
      "\n",
      " Epoch 76 \n",
      " --------------\n",
      "Train loss: 8.12E-04\n",
      "Test  loss: 8.75E-04\n",
      "\n",
      " Epoch 77 \n",
      " --------------\n",
      "Train loss: 8.10E-04\n",
      "Test  loss: 8.73E-04\n",
      "\n",
      " Epoch 78 \n",
      " --------------\n",
      "Train loss: 8.08E-04\n",
      "Test  loss: 8.71E-04\n",
      "\n",
      " Epoch 79 \n",
      " --------------\n",
      "Train loss: 8.06E-04\n",
      "Test  loss: 8.69E-04\n",
      "\n",
      " Epoch 80 \n",
      " --------------\n",
      "Train loss: 8.04E-04\n",
      "Test  loss: 8.67E-04\n",
      "\n",
      " Epoch 81 \n",
      " --------------\n",
      "Train loss: 8.11E-04\n",
      "Test  loss: 8.74E-04\n",
      "\n",
      " Epoch 82 \n",
      " --------------\n",
      "Train loss: 8.22E-04\n",
      "Test  loss: 8.85E-04\n",
      "\n",
      " Epoch 83 \n",
      " --------------\n",
      "Train loss: 8.31E-04\n",
      "Test  loss: 8.93E-04\n",
      "\n",
      " Epoch 84 \n",
      " --------------\n",
      "Train loss: 8.28E-04\n",
      "Test  loss: 8.91E-04\n",
      "\n",
      " Epoch 85 \n",
      " --------------\n",
      "Adapting learning rate to 0.0025\n",
      "Train loss: 8.24E-04\n",
      "Test  loss: 8.87E-04\n",
      "\n",
      " Epoch 86 \n",
      " --------------\n",
      "Train loss: 7.13E-04\n",
      "Test  loss: 7.80E-04\n",
      "\n",
      " Epoch 87 \n",
      " --------------\n",
      "Train loss: 7.08E-04\n",
      "Test  loss: 7.75E-04\n",
      "\n",
      " Epoch 88 \n",
      " --------------\n",
      "Train loss: 7.06E-04\n",
      "Test  loss: 7.73E-04\n",
      "\n",
      " Epoch 89 \n",
      " --------------\n",
      "Train loss: 7.04E-04\n",
      "Test  loss: 7.71E-04\n",
      "\n",
      " Epoch 90 \n",
      " --------------\n",
      "Train loss: 7.02E-04\n",
      "Test  loss: 7.69E-04\n",
      "\n",
      " Epoch 91 \n",
      " --------------\n",
      "Train loss: 7.01E-04\n",
      "Test  loss: 7.68E-04\n",
      "\n",
      " Epoch 92 \n",
      " --------------\n",
      "Train loss: 7.00E-04\n",
      "Test  loss: 7.66E-04\n",
      "\n",
      " Epoch 93 \n",
      " --------------\n",
      "Train loss: 6.98E-04\n",
      "Test  loss: 7.65E-04\n",
      "\n",
      " Epoch 94 \n",
      " --------------\n",
      "Train loss: 6.96E-04\n",
      "Test  loss: 7.62E-04\n",
      "\n",
      " Epoch 95 \n",
      " --------------\n",
      "Train loss: 6.93E-04\n",
      "Test  loss: 7.60E-04\n",
      "\n",
      " Epoch 96 \n",
      " --------------\n",
      "Train loss: 6.91E-04\n",
      "Test  loss: 7.57E-04\n",
      "\n",
      " Epoch 97 \n",
      " --------------\n",
      "Train loss: 6.89E-04\n",
      "Test  loss: 7.55E-04\n",
      "\n",
      " Epoch 98 \n",
      " --------------\n",
      "Train loss: 6.87E-04\n",
      "Test  loss: 7.53E-04\n",
      "\n",
      " Epoch 99 \n",
      " --------------\n",
      "Train loss: 6.85E-04\n",
      "Test  loss: 7.51E-04\n",
      "\n",
      " Epoch 100 \n",
      " --------------\n",
      "Train loss: 6.83E-04\n",
      "Test  loss: 7.50E-04\n",
      "\n",
      " Epoch 101 \n",
      " --------------\n",
      "Train loss: 6.82E-04\n",
      "Test  loss: 7.48E-04\n",
      "\n",
      " Epoch 102 \n",
      " --------------\n",
      "Train loss: 6.81E-04\n",
      "Test  loss: 7.47E-04\n",
      "\n",
      " Epoch 103 \n",
      " --------------\n",
      "Train loss: 6.80E-04\n",
      "Test  loss: 7.46E-04\n",
      "\n",
      " Epoch 104 \n",
      " --------------\n",
      "Train loss: 6.79E-04\n",
      "Test  loss: 7.45E-04\n",
      "\n",
      " Epoch 105 \n",
      " --------------\n",
      "Train loss: 6.78E-04\n",
      "Test  loss: 7.45E-04\n",
      "\n",
      " Epoch 106 \n",
      " --------------\n",
      "Train loss: 6.78E-04\n",
      "Test  loss: 7.44E-04\n",
      "\n",
      " Epoch 107 \n",
      " --------------\n",
      "Train loss: 6.77E-04\n",
      "Test  loss: 7.43E-04\n",
      "\n",
      " Epoch 108 \n",
      " --------------\n",
      "Train loss: 6.77E-04\n",
      "Test  loss: 7.43E-04\n",
      "\n",
      " Epoch 109 \n",
      " --------------\n",
      "Train loss: 6.77E-04\n",
      "Test  loss: 7.43E-04\n",
      "\n",
      " Epoch 110 \n",
      " --------------\n",
      "Train loss: 6.76E-04\n",
      "Test  loss: 7.42E-04\n",
      "\n",
      " Epoch 111 \n",
      " --------------\n",
      "Train loss: 6.76E-04\n",
      "Test  loss: 7.42E-04\n",
      "\n",
      " Epoch 112 \n",
      " --------------\n",
      "Train loss: 6.76E-04\n",
      "Test  loss: 7.42E-04\n",
      "\n",
      " Epoch 113 \n",
      " --------------\n",
      "Train loss: 6.76E-04\n",
      "Test  loss: 7.41E-04\n",
      "\n",
      " Epoch 114 \n",
      " --------------\n",
      "Train loss: 6.76E-04\n",
      "Test  loss: 7.41E-04\n",
      "\n",
      " Epoch 115 \n",
      " --------------\n",
      "Train loss: 6.75E-04\n",
      "Test  loss: 7.41E-04\n",
      "\n",
      " Epoch 116 \n",
      " --------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 6.75E-04\n",
      "Test  loss: 7.41E-04\n",
      "\n",
      " Epoch 117 \n",
      " --------------\n",
      "Train loss: 6.75E-04\n",
      "Test  loss: 7.41E-04\n",
      "\n",
      " Epoch 118 \n",
      " --------------\n",
      "Train loss: 6.75E-04\n",
      "Test  loss: 7.40E-04\n",
      "\n",
      " Epoch 119 \n",
      " --------------\n",
      "Train loss: 6.75E-04\n",
      "Test  loss: 7.40E-04\n",
      "\n",
      " Epoch 120 \n",
      " --------------\n",
      "Train loss: 6.75E-04\n",
      "Test  loss: 7.40E-04\n",
      "\n",
      " Epoch 121 \n",
      " --------------\n",
      "Train loss: 6.75E-04\n",
      "Test  loss: 7.40E-04\n",
      "\n",
      " Epoch 122 \n",
      " --------------\n",
      "Train loss: 6.75E-04\n",
      "Test  loss: 7.40E-04\n",
      "\n",
      " Epoch 123 \n",
      " --------------\n",
      "Train loss: 6.74E-04\n",
      "Test  loss: 7.40E-04\n",
      "\n",
      " Epoch 124 \n",
      " --------------\n",
      "Train loss: 6.74E-04\n",
      "Test  loss: 7.39E-04\n",
      "\n",
      " Epoch 125 \n",
      " --------------\n",
      "Train loss: 6.74E-04\n",
      "Test  loss: 7.39E-04\n",
      "\n",
      " Epoch 126 \n",
      " --------------\n",
      "Train loss: 6.74E-04\n",
      "Test  loss: 7.39E-04\n",
      "\n",
      " Epoch 127 \n",
      " --------------\n",
      "Train loss: 6.73E-04\n",
      "Test  loss: 7.38E-04\n",
      "\n",
      " Epoch 128 \n",
      " --------------\n",
      "Train loss: 6.73E-04\n",
      "Test  loss: 7.38E-04\n",
      "\n",
      " Epoch 129 \n",
      " --------------\n",
      "Train loss: 6.73E-04\n",
      "Test  loss: 7.37E-04\n",
      "\n",
      " Epoch 130 \n",
      " --------------\n",
      "Train loss: 6.72E-04\n",
      "Test  loss: 7.37E-04\n",
      "\n",
      " Epoch 131 \n",
      " --------------\n",
      "Train loss: 6.71E-04\n",
      "Test  loss: 7.36E-04\n",
      "\n",
      " Epoch 132 \n",
      " --------------\n",
      "Train loss: 6.71E-04\n",
      "Test  loss: 7.35E-04\n",
      "\n",
      " Epoch 133 \n",
      " --------------\n",
      "Train loss: 6.70E-04\n",
      "Test  loss: 7.35E-04\n",
      "\n",
      " Epoch 134 \n",
      " --------------\n",
      "Train loss: 6.70E-04\n",
      "Test  loss: 7.34E-04\n",
      "\n",
      " Epoch 135 \n",
      " --------------\n",
      "Train loss: 6.69E-04\n",
      "Test  loss: 7.33E-04\n",
      "\n",
      " Epoch 136 \n",
      " --------------\n",
      "Train loss: 6.68E-04\n",
      "Test  loss: 7.33E-04\n",
      "\n",
      " Epoch 137 \n",
      " --------------\n",
      "Train loss: 6.67E-04\n",
      "Test  loss: 7.32E-04\n",
      "\n",
      " Epoch 138 \n",
      " --------------\n",
      "Train loss: 6.67E-04\n",
      "Test  loss: 7.31E-04\n",
      "\n",
      " Epoch 139 \n",
      " --------------\n",
      "Train loss: 6.66E-04\n",
      "Test  loss: 7.30E-04\n",
      "\n",
      " Epoch 140 \n",
      " --------------\n",
      "Train loss: 6.65E-04\n",
      "Test  loss: 7.29E-04\n",
      "\n",
      " Epoch 141 \n",
      " --------------\n",
      "Train loss: 6.64E-04\n",
      "Test  loss: 7.29E-04\n",
      "\n",
      " Epoch 142 \n",
      " --------------\n",
      "Train loss: 6.63E-04\n",
      "Test  loss: 7.28E-04\n",
      "\n",
      " Epoch 143 \n",
      " --------------\n",
      "Train loss: 6.63E-04\n",
      "Test  loss: 7.27E-04\n",
      "\n",
      " Epoch 144 \n",
      " --------------\n",
      "Train loss: 6.62E-04\n",
      "Test  loss: 7.26E-04\n",
      "\n",
      " Epoch 145 \n",
      " --------------\n",
      "Train loss: 6.61E-04\n",
      "Test  loss: 7.25E-04\n",
      "\n",
      " Epoch 146 \n",
      " --------------\n",
      "Train loss: 6.60E-04\n",
      "Test  loss: 7.25E-04\n",
      "\n",
      " Epoch 147 \n",
      " --------------\n",
      "Train loss: 6.60E-04\n",
      "Test  loss: 7.24E-04\n",
      "\n",
      " Epoch 148 \n",
      " --------------\n",
      "Train loss: 6.59E-04\n",
      "Test  loss: 7.23E-04\n",
      "\n",
      " Epoch 149 \n",
      " --------------\n",
      "Train loss: 6.58E-04\n",
      "Test  loss: 7.22E-04\n",
      "\n",
      " Epoch 150 \n",
      " --------------\n",
      "Train loss: 6.57E-04\n",
      "Test  loss: 7.21E-04\n",
      "\n",
      " Epoch 151 \n",
      " --------------\n",
      "Train loss: 6.57E-04\n",
      "Test  loss: 7.21E-04\n",
      "\n",
      " Epoch 152 \n",
      " --------------\n",
      "Train loss: 6.56E-04\n",
      "Test  loss: 7.20E-04\n",
      "\n",
      " Epoch 153 \n",
      " --------------\n",
      "Train loss: 6.55E-04\n",
      "Test  loss: 7.19E-04\n",
      "\n",
      " Epoch 154 \n",
      " --------------\n",
      "Train loss: 6.54E-04\n",
      "Test  loss: 7.18E-04\n",
      "\n",
      " Epoch 155 \n",
      " --------------\n",
      "Train loss: 6.53E-04\n",
      "Test  loss: 7.18E-04\n",
      "\n",
      " Epoch 156 \n",
      " --------------\n",
      "Train loss: 6.53E-04\n",
      "Test  loss: 7.17E-04\n",
      "\n",
      " Epoch 157 \n",
      " --------------\n",
      "Train loss: 6.52E-04\n",
      "Test  loss: 7.16E-04\n",
      "\n",
      " Epoch 158 \n",
      " --------------\n",
      "Train loss: 6.51E-04\n",
      "Test  loss: 7.15E-04\n",
      "\n",
      " Epoch 159 \n",
      " --------------\n",
      "Train loss: 6.51E-04\n",
      "Test  loss: 7.15E-04\n",
      "\n",
      " Epoch 160 \n",
      " --------------\n",
      "Train loss: 6.50E-04\n",
      "Test  loss: 7.14E-04\n",
      "\n",
      " Epoch 161 \n",
      " --------------\n",
      "Train loss: 6.49E-04\n",
      "Test  loss: 7.13E-04\n",
      "\n",
      " Epoch 162 \n",
      " --------------\n",
      "Train loss: 6.48E-04\n",
      "Test  loss: 7.13E-04\n",
      "\n",
      " Epoch 163 \n",
      " --------------\n",
      "Train loss: 6.48E-04\n",
      "Test  loss: 7.12E-04\n",
      "\n",
      " Epoch 164 \n",
      " --------------\n",
      "Train loss: 6.47E-04\n",
      "Test  loss: 7.11E-04\n",
      "\n",
      " Epoch 165 \n",
      " --------------\n",
      "Train loss: 6.47E-04\n",
      "Test  loss: 7.11E-04\n",
      "\n",
      " Epoch 166 \n",
      " --------------\n",
      "Train loss: 6.46E-04\n",
      "Test  loss: 7.10E-04\n",
      "\n",
      " Epoch 167 \n",
      " --------------\n",
      "Train loss: 6.45E-04\n",
      "Test  loss: 7.09E-04\n",
      "\n",
      " Epoch 168 \n",
      " --------------\n",
      "Train loss: 6.45E-04\n",
      "Test  loss: 7.09E-04\n",
      "\n",
      " Epoch 169 \n",
      " --------------\n",
      "Train loss: 6.44E-04\n",
      "Test  loss: 7.08E-04\n",
      "\n",
      " Epoch 170 \n",
      " --------------\n",
      "Train loss: 6.44E-04\n",
      "Test  loss: 7.08E-04\n",
      "\n",
      " Epoch 171 \n",
      " --------------\n",
      "Train loss: 6.43E-04\n",
      "Test  loss: 7.08E-04\n",
      "\n",
      " Epoch 172 \n",
      " --------------\n",
      "Train loss: 6.43E-04\n",
      "Test  loss: 7.07E-04\n",
      "\n",
      " Epoch 173 \n",
      " --------------\n",
      "Train loss: 6.43E-04\n",
      "Test  loss: 7.07E-04\n",
      "\n",
      " Epoch 174 \n",
      " --------------\n",
      "Train loss: 6.42E-04\n",
      "Test  loss: 7.07E-04\n",
      "\n",
      " Epoch 175 \n",
      " --------------\n",
      "Train loss: 6.42E-04\n",
      "Test  loss: 7.07E-04\n",
      "\n",
      " Epoch 176 \n",
      " --------------\n",
      "Train loss: 6.42E-04\n",
      "Test  loss: 7.06E-04\n",
      "\n",
      " Epoch 177 \n",
      " --------------\n",
      "Train loss: 6.42E-04\n",
      "Test  loss: 7.06E-04\n",
      "\n",
      " Epoch 178 \n",
      " --------------\n",
      "Train loss: 6.42E-04\n",
      "Test  loss: 7.06E-04\n",
      "\n",
      " Epoch 179 \n",
      " --------------\n",
      "Train loss: 6.41E-04\n",
      "Test  loss: 7.06E-04\n",
      "\n",
      " Epoch 180 \n",
      " --------------\n",
      "Train loss: 6.41E-04\n",
      "Test  loss: 7.06E-04\n",
      "\n",
      " Epoch 181 \n",
      " --------------\n",
      "Train loss: 6.41E-04\n",
      "Test  loss: 7.06E-04\n",
      "\n",
      " Epoch 182 \n",
      " --------------\n",
      "Train loss: 6.41E-04\n",
      "Test  loss: 7.05E-04\n",
      "\n",
      " Epoch 183 \n",
      " --------------\n",
      "Train loss: 6.41E-04\n",
      "Test  loss: 7.05E-04\n",
      "\n",
      " Epoch 184 \n",
      " --------------\n",
      "Train loss: 6.41E-04\n",
      "Test  loss: 7.05E-04\n",
      "\n",
      " Epoch 185 \n",
      " --------------\n",
      "Train loss: 6.40E-04\n",
      "Test  loss: 7.05E-04\n",
      "\n",
      " Epoch 186 \n",
      " --------------\n",
      "Train loss: 6.40E-04\n",
      "Test  loss: 7.04E-04\n",
      "\n",
      " Epoch 187 \n",
      " --------------\n",
      "Train loss: 6.40E-04\n",
      "Test  loss: 7.04E-04\n",
      "\n",
      " Epoch 188 \n",
      " --------------\n",
      "Train loss: 6.39E-04\n",
      "Test  loss: 7.03E-04\n",
      "\n",
      " Epoch 189 \n",
      " --------------\n",
      "Train loss: 6.39E-04\n",
      "Test  loss: 7.03E-04\n",
      "\n",
      " Epoch 190 \n",
      " --------------\n",
      "Train loss: 6.38E-04\n",
      "Test  loss: 7.02E-04\n",
      "\n",
      " Epoch 191 \n",
      " --------------\n",
      "Train loss: 6.38E-04\n",
      "Test  loss: 7.02E-04\n",
      "\n",
      " Epoch 192 \n",
      " --------------\n",
      "Train loss: 6.37E-04\n",
      "Test  loss: 7.01E-04\n",
      "\n",
      " Epoch 193 \n",
      " --------------\n",
      "Train loss: 6.36E-04\n",
      "Test  loss: 7.00E-04\n",
      "\n",
      " Epoch 194 \n",
      " --------------\n",
      "Train loss: 6.35E-04\n",
      "Test  loss: 6.99E-04\n",
      "\n",
      " Epoch 195 \n",
      " --------------\n",
      "Train loss: 6.34E-04\n",
      "Test  loss: 6.98E-04\n",
      "\n",
      " Epoch 196 \n",
      " --------------\n",
      "Train loss: 6.33E-04\n",
      "Test  loss: 6.97E-04\n",
      "\n",
      " Epoch 197 \n",
      " --------------\n",
      "Train loss: 6.32E-04\n",
      "Test  loss: 6.96E-04\n",
      "\n",
      " Epoch 198 \n",
      " --------------\n",
      "Train loss: 6.31E-04\n",
      "Test  loss: 6.94E-04\n",
      "\n",
      " Epoch 199 \n",
      " --------------\n",
      "Train loss: 6.30E-04\n",
      "Test  loss: 6.93E-04\n",
      "\n",
      " Epoch 200 \n",
      " --------------\n",
      "Train loss: 6.28E-04\n",
      "Test  loss: 6.92E-04\n",
      "\n",
      " Epoch 201 \n",
      " --------------\n",
      "Train loss: 6.27E-04\n",
      "Test  loss: 6.90E-04\n",
      "\n",
      " Epoch 202 \n",
      " --------------\n",
      "Train loss: 6.26E-04\n",
      "Test  loss: 6.89E-04\n",
      "\n",
      " Epoch 203 \n",
      " --------------\n",
      "Train loss: 6.24E-04\n",
      "Test  loss: 6.88E-04\n",
      "\n",
      " Epoch 204 \n",
      " --------------\n",
      "Train loss: 6.23E-04\n",
      "Test  loss: 6.86E-04\n",
      "\n",
      " Epoch 205 \n",
      " --------------\n",
      "Train loss: 6.22E-04\n",
      "Test  loss: 6.85E-04\n",
      "\n",
      " Epoch 206 \n",
      " --------------\n",
      "Train loss: 6.20E-04\n",
      "Test  loss: 6.83E-04\n",
      "\n",
      " Epoch 207 \n",
      " --------------\n",
      "Train loss: 6.19E-04\n",
      "Test  loss: 6.82E-04\n",
      "\n",
      " Epoch 208 \n",
      " --------------\n",
      "Train loss: 6.17E-04\n",
      "Test  loss: 6.80E-04\n",
      "\n",
      " Epoch 209 \n",
      " --------------\n",
      "Train loss: 6.15E-04\n",
      "Test  loss: 6.78E-04\n",
      "\n",
      " Epoch 210 \n",
      " --------------\n",
      "Train loss: 6.14E-04\n",
      "Test  loss: 6.77E-04\n",
      "\n",
      " Epoch 211 \n",
      " --------------\n",
      "Train loss: 6.12E-04\n",
      "Test  loss: 6.75E-04\n",
      "\n",
      " Epoch 212 \n",
      " --------------\n",
      "Train loss: 6.11E-04\n",
      "Test  loss: 6.74E-04\n",
      "\n",
      " Epoch 213 \n",
      " --------------\n",
      "Train loss: 6.09E-04\n",
      "Test  loss: 6.72E-04\n",
      "\n",
      " Epoch 214 \n",
      " --------------\n",
      "Train loss: 6.08E-04\n",
      "Test  loss: 6.70E-04\n",
      "\n",
      " Epoch 215 \n",
      " --------------\n",
      "Train loss: 6.06E-04\n",
      "Test  loss: 6.69E-04\n",
      "\n",
      " Epoch 216 \n",
      " --------------\n",
      "Train loss: 6.05E-04\n",
      "Test  loss: 6.67E-04\n",
      "\n",
      " Epoch 217 \n",
      " --------------\n",
      "Train loss: 6.03E-04\n",
      "Test  loss: 6.66E-04\n",
      "\n",
      " Epoch 218 \n",
      " --------------\n",
      "Train loss: 6.02E-04\n",
      "Test  loss: 6.64E-04\n",
      "\n",
      " Epoch 219 \n",
      " --------------\n",
      "Train loss: 6.00E-04\n",
      "Test  loss: 6.62E-04\n",
      "\n",
      " Epoch 220 \n",
      " --------------\n",
      "Train loss: 5.98E-04\n",
      "Test  loss: 6.61E-04\n",
      "\n",
      " Epoch 221 \n",
      " --------------\n",
      "Train loss: 5.97E-04\n",
      "Test  loss: 6.59E-04\n",
      "\n",
      " Epoch 222 \n",
      " --------------\n",
      "Train loss: 5.95E-04\n",
      "Test  loss: 6.58E-04\n",
      "\n",
      " Epoch 223 \n",
      " --------------\n",
      "Train loss: 5.94E-04\n",
      "Test  loss: 6.56E-04\n",
      "\n",
      " Epoch 224 \n",
      " --------------\n",
      "Train loss: 5.93E-04\n",
      "Test  loss: 6.55E-04\n",
      "\n",
      " Epoch 225 \n",
      " --------------\n",
      "Train loss: 5.91E-04\n",
      "Test  loss: 6.53E-04\n",
      "\n",
      " Epoch 226 \n",
      " --------------\n",
      "Train loss: 5.90E-04\n",
      "Test  loss: 6.52E-04\n",
      "\n",
      " Epoch 227 \n",
      " --------------\n",
      "Train loss: 5.88E-04\n",
      "Test  loss: 6.50E-04\n",
      "\n",
      " Epoch 228 \n",
      " --------------\n",
      "Train loss: 5.87E-04\n",
      "Test  loss: 6.49E-04\n",
      "\n",
      " Epoch 229 \n",
      " --------------\n",
      "Train loss: 5.85E-04\n",
      "Test  loss: 6.47E-04\n",
      "\n",
      " Epoch 230 \n",
      " --------------\n",
      "Train loss: 5.84E-04\n",
      "Test  loss: 6.46E-04\n",
      "\n",
      " Epoch 231 \n",
      " --------------\n",
      "Train loss: 5.83E-04\n",
      "Test  loss: 6.45E-04\n",
      "\n",
      " Epoch 232 \n",
      " --------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 5.81E-04\n",
      "Test  loss: 6.43E-04\n",
      "\n",
      " Epoch 233 \n",
      " --------------\n",
      "Train loss: 5.80E-04\n",
      "Test  loss: 6.42E-04\n",
      "\n",
      " Epoch 234 \n",
      " --------------\n",
      "Train loss: 5.79E-04\n",
      "Test  loss: 6.41E-04\n",
      "\n",
      " Epoch 235 \n",
      " --------------\n",
      "Train loss: 5.77E-04\n",
      "Test  loss: 6.39E-04\n",
      "\n",
      " Epoch 236 \n",
      " --------------\n",
      "Train loss: 5.76E-04\n",
      "Test  loss: 6.38E-04\n",
      "\n",
      " Epoch 237 \n",
      " --------------\n",
      "Train loss: 5.75E-04\n",
      "Test  loss: 6.37E-04\n",
      "\n",
      " Epoch 238 \n",
      " --------------\n",
      "Train loss: 5.74E-04\n",
      "Test  loss: 6.35E-04\n",
      "\n",
      " Epoch 239 \n",
      " --------------\n",
      "Train loss: 5.73E-04\n",
      "Test  loss: 6.34E-04\n",
      "\n",
      " Epoch 240 \n",
      " --------------\n",
      "Train loss: 5.71E-04\n",
      "Test  loss: 6.33E-04\n",
      "\n",
      " Epoch 241 \n",
      " --------------\n",
      "Train loss: 5.70E-04\n",
      "Test  loss: 6.32E-04\n",
      "\n",
      " Epoch 242 \n",
      " --------------\n",
      "Train loss: 5.69E-04\n",
      "Test  loss: 6.31E-04\n",
      "\n",
      " Epoch 243 \n",
      " --------------\n",
      "Train loss: 5.68E-04\n",
      "Test  loss: 6.29E-04\n",
      "\n",
      " Epoch 244 \n",
      " --------------\n",
      "Train loss: 5.67E-04\n",
      "Test  loss: 6.28E-04\n",
      "\n",
      " Epoch 245 \n",
      " --------------\n",
      "Train loss: 5.66E-04\n",
      "Test  loss: 6.27E-04\n",
      "\n",
      " Epoch 246 \n",
      " --------------\n",
      "Train loss: 5.65E-04\n",
      "Test  loss: 6.26E-04\n",
      "\n",
      " Epoch 247 \n",
      " --------------\n",
      "Train loss: 5.64E-04\n",
      "Test  loss: 6.25E-04\n",
      "\n",
      " Epoch 248 \n",
      " --------------\n",
      "Train loss: 5.63E-04\n",
      "Test  loss: 6.24E-04\n",
      "\n",
      " Epoch 249 \n",
      " --------------\n",
      "Train loss: 5.62E-04\n",
      "Test  loss: 6.23E-04\n",
      "\n",
      " Epoch 250 \n",
      " --------------\n",
      "Train loss: 5.61E-04\n",
      "Test  loss: 6.22E-04\n",
      "\n",
      " Epoch 251 \n",
      " --------------\n",
      "Train loss: 5.60E-04\n",
      "Test  loss: 6.21E-04\n",
      "\n",
      " Epoch 252 \n",
      " --------------\n",
      "Train loss: 5.59E-04\n",
      "Test  loss: 6.20E-04\n",
      "\n",
      " Epoch 253 \n",
      " --------------\n",
      "Train loss: 5.58E-04\n",
      "Test  loss: 6.19E-04\n",
      "\n",
      " Epoch 254 \n",
      " --------------\n",
      "Train loss: 5.57E-04\n",
      "Test  loss: 6.18E-04\n",
      "\n",
      " Epoch 255 \n",
      " --------------\n",
      "Train loss: 5.56E-04\n",
      "Test  loss: 6.17E-04\n",
      "\n",
      " Epoch 256 \n",
      " --------------\n",
      "Train loss: 5.55E-04\n",
      "Test  loss: 6.16E-04\n",
      "\n",
      " Epoch 257 \n",
      " --------------\n",
      "Train loss: 5.54E-04\n",
      "Test  loss: 6.15E-04\n",
      "\n",
      " Epoch 258 \n",
      " --------------\n",
      "Train loss: 5.53E-04\n",
      "Test  loss: 6.14E-04\n",
      "\n",
      " Epoch 259 \n",
      " --------------\n",
      "Train loss: 5.52E-04\n",
      "Test  loss: 6.13E-04\n",
      "\n",
      " Epoch 260 \n",
      " --------------\n",
      "Train loss: 5.51E-04\n",
      "Test  loss: 6.12E-04\n",
      "\n",
      " Epoch 261 \n",
      " --------------\n",
      "Train loss: 5.51E-04\n",
      "Test  loss: 6.11E-04\n",
      "\n",
      " Epoch 262 \n",
      " --------------\n",
      "Train loss: 5.50E-04\n",
      "Test  loss: 6.10E-04\n",
      "\n",
      " Epoch 263 \n",
      " --------------\n",
      "Train loss: 5.49E-04\n",
      "Test  loss: 6.10E-04\n",
      "\n",
      " Epoch 264 \n",
      " --------------\n",
      "Train loss: 5.48E-04\n",
      "Test  loss: 6.09E-04\n",
      "\n",
      " Epoch 265 \n",
      " --------------\n",
      "Train loss: 5.47E-04\n",
      "Test  loss: 6.08E-04\n",
      "\n",
      " Epoch 266 \n",
      " --------------\n",
      "Train loss: 5.46E-04\n",
      "Test  loss: 6.07E-04\n",
      "\n",
      " Epoch 267 \n",
      " --------------\n",
      "Train loss: 5.45E-04\n",
      "Test  loss: 6.06E-04\n",
      "\n",
      " Epoch 268 \n",
      " --------------\n",
      "Train loss: 5.45E-04\n",
      "Test  loss: 6.05E-04\n",
      "\n",
      " Epoch 269 \n",
      " --------------\n",
      "Train loss: 5.44E-04\n",
      "Test  loss: 6.04E-04\n",
      "\n",
      " Epoch 270 \n",
      " --------------\n",
      "Train loss: 5.43E-04\n",
      "Test  loss: 6.04E-04\n",
      "\n",
      " Epoch 271 \n",
      " --------------\n",
      "Train loss: 5.42E-04\n",
      "Test  loss: 6.03E-04\n",
      "\n",
      " Epoch 272 \n",
      " --------------\n",
      "Train loss: 5.41E-04\n",
      "Test  loss: 6.02E-04\n",
      "\n",
      " Epoch 273 \n",
      " --------------\n",
      "Train loss: 5.41E-04\n",
      "Test  loss: 6.01E-04\n",
      "\n",
      " Epoch 274 \n",
      " --------------\n",
      "Train loss: 5.40E-04\n",
      "Test  loss: 6.00E-04\n",
      "\n",
      " Epoch 275 \n",
      " --------------\n",
      "Train loss: 5.39E-04\n",
      "Test  loss: 6.00E-04\n",
      "\n",
      " Epoch 276 \n",
      " --------------\n",
      "Train loss: 5.39E-04\n",
      "Test  loss: 5.99E-04\n",
      "\n",
      " Epoch 277 \n",
      " --------------\n",
      "Train loss: 5.38E-04\n",
      "Test  loss: 5.98E-04\n",
      "\n",
      " Epoch 278 \n",
      " --------------\n",
      "Train loss: 5.37E-04\n",
      "Test  loss: 5.97E-04\n",
      "\n",
      " Epoch 279 \n",
      " --------------\n",
      "Train loss: 5.36E-04\n",
      "Test  loss: 5.97E-04\n",
      "\n",
      " Epoch 280 \n",
      " --------------\n",
      "Train loss: 5.36E-04\n",
      "Test  loss: 5.96E-04\n",
      "\n",
      " Epoch 281 \n",
      " --------------\n",
      "Train loss: 5.35E-04\n",
      "Test  loss: 5.95E-04\n",
      "\n",
      " Epoch 282 \n",
      " --------------\n",
      "Train loss: 5.34E-04\n",
      "Test  loss: 5.95E-04\n",
      "\n",
      " Epoch 283 \n",
      " --------------\n",
      "Train loss: 5.34E-04\n",
      "Test  loss: 5.94E-04\n",
      "\n",
      " Epoch 284 \n",
      " --------------\n",
      "Train loss: 5.33E-04\n",
      "Test  loss: 5.93E-04\n",
      "\n",
      " Epoch 285 \n",
      " --------------\n",
      "Train loss: 5.32E-04\n",
      "Test  loss: 5.93E-04\n",
      "\n",
      " Epoch 286 \n",
      " --------------\n",
      "Train loss: 5.32E-04\n",
      "Test  loss: 5.92E-04\n",
      "\n",
      " Epoch 287 \n",
      " --------------\n",
      "Train loss: 5.31E-04\n",
      "Test  loss: 5.91E-04\n",
      "\n",
      " Epoch 288 \n",
      " --------------\n",
      "Train loss: 5.30E-04\n",
      "Test  loss: 5.91E-04\n",
      "\n",
      " Epoch 289 \n",
      " --------------\n",
      "Train loss: 5.30E-04\n",
      "Test  loss: 5.90E-04\n",
      "\n",
      " Epoch 290 \n",
      " --------------\n",
      "Train loss: 5.29E-04\n",
      "Test  loss: 5.89E-04\n",
      "\n",
      " Epoch 291 \n",
      " --------------\n",
      "Train loss: 5.29E-04\n",
      "Test  loss: 5.89E-04\n",
      "\n",
      " Epoch 292 \n",
      " --------------\n",
      "Train loss: 5.28E-04\n",
      "Test  loss: 5.88E-04\n",
      "\n",
      " Epoch 293 \n",
      " --------------\n",
      "Train loss: 5.27E-04\n",
      "Test  loss: 5.87E-04\n",
      "\n",
      " Epoch 294 \n",
      " --------------\n",
      "Train loss: 5.27E-04\n",
      "Test  loss: 5.87E-04\n",
      "\n",
      " Epoch 295 \n",
      " --------------\n",
      "Train loss: 5.26E-04\n",
      "Test  loss: 5.86E-04\n",
      "\n",
      " Epoch 296 \n",
      " --------------\n",
      "Train loss: 5.26E-04\n",
      "Test  loss: 5.86E-04\n",
      "\n",
      " Epoch 297 \n",
      " --------------\n",
      "Train loss: 5.25E-04\n",
      "Test  loss: 5.85E-04\n",
      "\n",
      " Epoch 298 \n",
      " --------------\n",
      "Train loss: 5.24E-04\n",
      "Test  loss: 5.84E-04\n",
      "\n",
      " Epoch 299 \n",
      " --------------\n",
      "Train loss: 5.24E-04\n",
      "Test  loss: 5.84E-04\n",
      "\n",
      " Epoch 300 \n",
      " --------------\n",
      "Train loss: 5.23E-04\n",
      "Test  loss: 5.83E-04\n",
      "\n",
      " Epoch 301 \n",
      " --------------\n",
      "Train loss: 5.23E-04\n",
      "Test  loss: 5.83E-04\n",
      "\n",
      " Epoch 302 \n",
      " --------------\n",
      "Train loss: 5.22E-04\n",
      "Test  loss: 5.82E-04\n",
      "\n",
      " Epoch 303 \n",
      " --------------\n",
      "Train loss: 5.22E-04\n",
      "Test  loss: 5.81E-04\n",
      "\n",
      " Epoch 304 \n",
      " --------------\n",
      "Train loss: 5.21E-04\n",
      "Test  loss: 5.81E-04\n",
      "\n",
      " Epoch 305 \n",
      " --------------\n",
      "Train loss: 5.21E-04\n",
      "Test  loss: 5.80E-04\n",
      "\n",
      " Epoch 306 \n",
      " --------------\n",
      "Train loss: 5.20E-04\n",
      "Test  loss: 5.80E-04\n",
      "\n",
      " Epoch 307 \n",
      " --------------\n",
      "Train loss: 5.19E-04\n",
      "Test  loss: 5.79E-04\n",
      "\n",
      " Epoch 308 \n",
      " --------------\n",
      "Train loss: 5.19E-04\n",
      "Test  loss: 5.79E-04\n",
      "\n",
      " Epoch 309 \n",
      " --------------\n",
      "Train loss: 5.18E-04\n",
      "Test  loss: 5.78E-04\n",
      "\n",
      " Epoch 310 \n",
      " --------------\n",
      "Train loss: 5.18E-04\n",
      "Test  loss: 5.78E-04\n",
      "\n",
      " Epoch 311 \n",
      " --------------\n",
      "Train loss: 5.17E-04\n",
      "Test  loss: 5.77E-04\n",
      "\n",
      " Epoch 312 \n",
      " --------------\n",
      "Train loss: 5.17E-04\n",
      "Test  loss: 5.77E-04\n",
      "\n",
      " Epoch 313 \n",
      " --------------\n",
      "Train loss: 5.17E-04\n",
      "Test  loss: 5.76E-04\n",
      "\n",
      " Epoch 314 \n",
      " --------------\n",
      "Train loss: 5.16E-04\n",
      "Test  loss: 5.76E-04\n",
      "\n",
      " Epoch 315 \n",
      " --------------\n",
      "Train loss: 5.16E-04\n",
      "Test  loss: 5.75E-04\n",
      "\n",
      " Epoch 316 \n",
      " --------------\n",
      "Train loss: 5.15E-04\n",
      "Test  loss: 5.75E-04\n",
      "\n",
      " Epoch 317 \n",
      " --------------\n",
      "Train loss: 5.15E-04\n",
      "Test  loss: 5.74E-04\n",
      "\n",
      " Epoch 318 \n",
      " --------------\n",
      "Train loss: 5.14E-04\n",
      "Test  loss: 5.74E-04\n",
      "\n",
      " Epoch 319 \n",
      " --------------\n",
      "Train loss: 5.14E-04\n",
      "Test  loss: 5.73E-04\n",
      "\n",
      " Epoch 320 \n",
      " --------------\n",
      "Train loss: 5.13E-04\n",
      "Test  loss: 5.73E-04\n",
      "\n",
      " Epoch 321 \n",
      " --------------\n",
      "Train loss: 5.13E-04\n",
      "Test  loss: 5.72E-04\n",
      "\n",
      " Epoch 322 \n",
      " --------------\n",
      "Train loss: 5.12E-04\n",
      "Test  loss: 5.72E-04\n",
      "\n",
      " Epoch 323 \n",
      " --------------\n",
      "Train loss: 5.12E-04\n",
      "Test  loss: 5.71E-04\n",
      "\n",
      " Epoch 324 \n",
      " --------------\n",
      "Train loss: 5.11E-04\n",
      "Test  loss: 5.71E-04\n",
      "\n",
      " Epoch 325 \n",
      " --------------\n",
      "Train loss: 5.11E-04\n",
      "Test  loss: 5.70E-04\n",
      "\n",
      " Epoch 326 \n",
      " --------------\n",
      "Train loss: 5.10E-04\n",
      "Test  loss: 5.70E-04\n",
      "\n",
      " Epoch 327 \n",
      " --------------\n",
      "Train loss: 5.10E-04\n",
      "Test  loss: 5.69E-04\n",
      "\n",
      " Epoch 328 \n",
      " --------------\n",
      "Train loss: 5.09E-04\n",
      "Test  loss: 5.69E-04\n",
      "\n",
      " Epoch 329 \n",
      " --------------\n",
      "Train loss: 5.09E-04\n",
      "Test  loss: 5.68E-04\n",
      "\n",
      " Epoch 330 \n",
      " --------------\n",
      "Train loss: 5.08E-04\n",
      "Test  loss: 5.68E-04\n",
      "\n",
      " Epoch 331 \n",
      " --------------\n",
      "Train loss: 5.08E-04\n",
      "Test  loss: 5.67E-04\n",
      "\n",
      " Epoch 332 \n",
      " --------------\n",
      "Train loss: 5.07E-04\n",
      "Test  loss: 5.67E-04\n",
      "\n",
      " Epoch 333 \n",
      " --------------\n",
      "Train loss: 5.07E-04\n",
      "Test  loss: 5.66E-04\n",
      "\n",
      " Epoch 334 \n",
      " --------------\n",
      "Train loss: 5.06E-04\n",
      "Test  loss: 5.66E-04\n",
      "\n",
      " Epoch 335 \n",
      " --------------\n",
      "Train loss: 5.06E-04\n",
      "Test  loss: 5.65E-04\n",
      "\n",
      " Epoch 336 \n",
      " --------------\n",
      "Train loss: 5.05E-04\n",
      "Test  loss: 5.65E-04\n",
      "\n",
      " Epoch 337 \n",
      " --------------\n",
      "Train loss: 5.05E-04\n",
      "Test  loss: 5.64E-04\n",
      "\n",
      " Epoch 338 \n",
      " --------------\n",
      "Train loss: 5.04E-04\n",
      "Test  loss: 5.64E-04\n",
      "\n",
      " Epoch 339 \n",
      " --------------\n",
      "Train loss: 5.04E-04\n",
      "Test  loss: 5.63E-04\n",
      "\n",
      " Epoch 340 \n",
      " --------------\n",
      "Train loss: 5.04E-04\n",
      "Test  loss: 5.63E-04\n",
      "\n",
      " Epoch 341 \n",
      " --------------\n",
      "Train loss: 5.03E-04\n",
      "Test  loss: 5.62E-04\n",
      "\n",
      " Epoch 342 \n",
      " --------------\n",
      "Train loss: 5.03E-04\n",
      "Test  loss: 5.62E-04\n",
      "\n",
      " Epoch 343 \n",
      " --------------\n",
      "Train loss: 5.02E-04\n",
      "Test  loss: 5.62E-04\n",
      "\n",
      " Epoch 344 \n",
      " --------------\n",
      "Train loss: 5.02E-04\n",
      "Test  loss: 5.61E-04\n",
      "\n",
      " Epoch 345 \n",
      " --------------\n",
      "Train loss: 5.02E-04\n",
      "Test  loss: 5.61E-04\n",
      "\n",
      " Epoch 346 \n",
      " --------------\n",
      "Train loss: 5.01E-04\n",
      "Test  loss: 5.60E-04\n",
      "\n",
      " Epoch 347 \n",
      " --------------\n",
      "Train loss: 5.01E-04\n",
      "Test  loss: 5.60E-04\n",
      "\n",
      " Epoch 348 \n",
      " --------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 5.00E-04\n",
      "Test  loss: 5.60E-04\n",
      "\n",
      " Epoch 349 \n",
      " --------------\n",
      "Train loss: 5.00E-04\n",
      "Test  loss: 5.59E-04\n",
      "\n",
      " Epoch 350 \n",
      " --------------\n",
      "Train loss: 5.00E-04\n",
      "Test  loss: 5.59E-04\n",
      "\n",
      " Epoch 351 \n",
      " --------------\n",
      "Train loss: 4.99E-04\n",
      "Test  loss: 5.58E-04\n",
      "\n",
      " Epoch 352 \n",
      " --------------\n",
      "Train loss: 4.99E-04\n",
      "Test  loss: 5.58E-04\n",
      "\n",
      " Epoch 353 \n",
      " --------------\n",
      "Train loss: 4.99E-04\n",
      "Test  loss: 5.58E-04\n",
      "\n",
      " Epoch 354 \n",
      " --------------\n",
      "Train loss: 4.98E-04\n",
      "Test  loss: 5.57E-04\n",
      "\n",
      " Epoch 355 \n",
      " --------------\n",
      "Train loss: 4.98E-04\n",
      "Test  loss: 5.57E-04\n",
      "\n",
      " Epoch 356 \n",
      " --------------\n",
      "Train loss: 4.98E-04\n",
      "Test  loss: 5.57E-04\n",
      "\n",
      " Epoch 357 \n",
      " --------------\n",
      "Train loss: 4.97E-04\n",
      "Test  loss: 5.56E-04\n",
      "\n",
      " Epoch 358 \n",
      " --------------\n",
      "Train loss: 4.97E-04\n",
      "Test  loss: 5.56E-04\n",
      "\n",
      " Epoch 359 \n",
      " --------------\n",
      "Train loss: 4.97E-04\n",
      "Test  loss: 5.56E-04\n",
      "\n",
      " Epoch 360 \n",
      " --------------\n",
      "Train loss: 4.96E-04\n",
      "Test  loss: 5.55E-04\n",
      "\n",
      " Epoch 361 \n",
      " --------------\n",
      "Train loss: 4.96E-04\n",
      "Test  loss: 5.55E-04\n",
      "\n",
      " Epoch 362 \n",
      " --------------\n",
      "Train loss: 4.96E-04\n",
      "Test  loss: 5.55E-04\n",
      "\n",
      " Epoch 363 \n",
      " --------------\n",
      "Train loss: 4.95E-04\n",
      "Test  loss: 5.54E-04\n",
      "\n",
      " Epoch 364 \n",
      " --------------\n",
      "Train loss: 4.95E-04\n",
      "Test  loss: 5.54E-04\n",
      "\n",
      " Epoch 365 \n",
      " --------------\n",
      "Train loss: 4.95E-04\n",
      "Test  loss: 5.53E-04\n",
      "\n",
      " Epoch 366 \n",
      " --------------\n",
      "Train loss: 4.94E-04\n",
      "Test  loss: 5.53E-04\n",
      "\n",
      " Epoch 367 \n",
      " --------------\n",
      "Train loss: 4.94E-04\n",
      "Test  loss: 5.53E-04\n",
      "\n",
      " Epoch 368 \n",
      " --------------\n",
      "Train loss: 4.94E-04\n",
      "Test  loss: 5.52E-04\n",
      "\n",
      " Epoch 369 \n",
      " --------------\n",
      "Train loss: 4.93E-04\n",
      "Test  loss: 5.52E-04\n",
      "\n",
      " Epoch 370 \n",
      " --------------\n",
      "Train loss: 4.93E-04\n",
      "Test  loss: 5.52E-04\n",
      "\n",
      " Epoch 371 \n",
      " --------------\n",
      "Train loss: 4.92E-04\n",
      "Test  loss: 5.51E-04\n",
      "\n",
      " Epoch 372 \n",
      " --------------\n",
      "Train loss: 4.92E-04\n",
      "Test  loss: 5.51E-04\n",
      "\n",
      " Epoch 373 \n",
      " --------------\n",
      "Train loss: 4.92E-04\n",
      "Test  loss: 5.50E-04\n",
      "\n",
      " Epoch 374 \n",
      " --------------\n",
      "Train loss: 4.91E-04\n",
      "Test  loss: 5.50E-04\n",
      "\n",
      " Epoch 375 \n",
      " --------------\n",
      "Train loss: 4.91E-04\n",
      "Test  loss: 5.50E-04\n",
      "\n",
      " Epoch 376 \n",
      " --------------\n",
      "Train loss: 4.91E-04\n",
      "Test  loss: 5.49E-04\n",
      "\n",
      " Epoch 377 \n",
      " --------------\n",
      "Train loss: 4.90E-04\n",
      "Test  loss: 5.49E-04\n",
      "\n",
      " Epoch 378 \n",
      " --------------\n",
      "Train loss: 4.90E-04\n",
      "Test  loss: 5.49E-04\n",
      "\n",
      " Epoch 379 \n",
      " --------------\n",
      "Train loss: 4.90E-04\n",
      "Test  loss: 5.48E-04\n",
      "\n",
      " Epoch 380 \n",
      " --------------\n",
      "Train loss: 4.89E-04\n",
      "Test  loss: 5.48E-04\n",
      "\n",
      " Epoch 381 \n",
      " --------------\n",
      "Train loss: 4.89E-04\n",
      "Test  loss: 5.47E-04\n",
      "\n",
      " Epoch 382 \n",
      " --------------\n",
      "Train loss: 4.88E-04\n",
      "Test  loss: 5.47E-04\n",
      "\n",
      " Epoch 383 \n",
      " --------------\n",
      "Train loss: 4.88E-04\n",
      "Test  loss: 5.47E-04\n",
      "\n",
      " Epoch 384 \n",
      " --------------\n",
      "Train loss: 4.88E-04\n",
      "Test  loss: 5.46E-04\n",
      "\n",
      " Epoch 385 \n",
      " --------------\n",
      "Train loss: 4.87E-04\n",
      "Test  loss: 5.46E-04\n",
      "\n",
      " Epoch 386 \n",
      " --------------\n",
      "Train loss: 4.87E-04\n",
      "Test  loss: 5.46E-04\n",
      "\n",
      " Epoch 387 \n",
      " --------------\n",
      "Train loss: 4.87E-04\n",
      "Test  loss: 5.45E-04\n",
      "\n",
      " Epoch 388 \n",
      " --------------\n",
      "Train loss: 4.86E-04\n",
      "Test  loss: 5.45E-04\n",
      "\n",
      " Epoch 389 \n",
      " --------------\n",
      "Train loss: 4.86E-04\n",
      "Test  loss: 5.44E-04\n",
      "\n",
      " Epoch 390 \n",
      " --------------\n",
      "Train loss: 4.86E-04\n",
      "Test  loss: 5.44E-04\n",
      "\n",
      " Epoch 391 \n",
      " --------------\n",
      "Train loss: 4.85E-04\n",
      "Test  loss: 5.44E-04\n",
      "\n",
      " Epoch 392 \n",
      " --------------\n",
      "Train loss: 4.85E-04\n",
      "Test  loss: 5.43E-04\n",
      "\n",
      " Epoch 393 \n",
      " --------------\n",
      "Train loss: 4.85E-04\n",
      "Test  loss: 5.43E-04\n",
      "\n",
      " Epoch 394 \n",
      " --------------\n",
      "Train loss: 4.84E-04\n",
      "Test  loss: 5.43E-04\n",
      "\n",
      " Epoch 395 \n",
      " --------------\n",
      "Train loss: 4.84E-04\n",
      "Test  loss: 5.43E-04\n",
      "\n",
      " Epoch 396 \n",
      " --------------\n",
      "Train loss: 4.84E-04\n",
      "Test  loss: 5.42E-04\n",
      "\n",
      " Epoch 397 \n",
      " --------------\n",
      "Train loss: 4.84E-04\n",
      "Test  loss: 5.42E-04\n",
      "\n",
      " Epoch 398 \n",
      " --------------\n",
      "Train loss: 4.83E-04\n",
      "Test  loss: 5.42E-04\n",
      "\n",
      " Epoch 399 \n",
      " --------------\n",
      "Train loss: 4.83E-04\n",
      "Test  loss: 5.41E-04\n",
      "\n",
      " Epoch 400 \n",
      " --------------\n",
      "Train loss: 4.83E-04\n",
      "Test  loss: 5.41E-04\n",
      "\n",
      " Epoch 401 \n",
      " --------------\n",
      "Train loss: 4.82E-04\n",
      "Test  loss: 5.41E-04\n",
      "\n",
      " Epoch 402 \n",
      " --------------\n",
      "Train loss: 4.82E-04\n",
      "Test  loss: 5.40E-04\n",
      "\n",
      " Epoch 403 \n",
      " --------------\n",
      "Train loss: 4.82E-04\n",
      "Test  loss: 5.40E-04\n",
      "\n",
      " Epoch 404 \n",
      " --------------\n",
      "Train loss: 4.82E-04\n",
      "Test  loss: 5.40E-04\n",
      "\n",
      " Epoch 405 \n",
      " --------------\n",
      "Train loss: 4.81E-04\n",
      "Test  loss: 5.40E-04\n",
      "\n",
      " Epoch 406 \n",
      " --------------\n",
      "Train loss: 4.81E-04\n",
      "Test  loss: 5.39E-04\n",
      "\n",
      " Epoch 407 \n",
      " --------------\n",
      "Train loss: 4.81E-04\n",
      "Test  loss: 5.39E-04\n",
      "\n",
      " Epoch 408 \n",
      " --------------\n",
      "Train loss: 4.81E-04\n",
      "Test  loss: 5.39E-04\n",
      "\n",
      " Epoch 409 \n",
      " --------------\n",
      "Train loss: 4.80E-04\n",
      "Test  loss: 5.39E-04\n",
      "\n",
      " Epoch 410 \n",
      " --------------\n",
      "Train loss: 4.80E-04\n",
      "Test  loss: 5.38E-04\n",
      "\n",
      " Epoch 411 \n",
      " --------------\n",
      "Train loss: 4.80E-04\n",
      "Test  loss: 5.38E-04\n",
      "\n",
      " Epoch 412 \n",
      " --------------\n",
      "Train loss: 4.79E-04\n",
      "Test  loss: 5.38E-04\n",
      "\n",
      " Epoch 413 \n",
      " --------------\n",
      "Train loss: 4.79E-04\n",
      "Test  loss: 5.37E-04\n",
      "\n",
      " Epoch 414 \n",
      " --------------\n",
      "Train loss: 4.79E-04\n",
      "Test  loss: 5.37E-04\n",
      "\n",
      " Epoch 415 \n",
      " --------------\n",
      "Train loss: 4.79E-04\n",
      "Test  loss: 5.37E-04\n",
      "\n",
      " Epoch 416 \n",
      " --------------\n",
      "Train loss: 4.78E-04\n",
      "Test  loss: 5.37E-04\n",
      "\n",
      " Epoch 417 \n",
      " --------------\n",
      "Train loss: 4.78E-04\n",
      "Test  loss: 5.36E-04\n",
      "\n",
      " Epoch 418 \n",
      " --------------\n",
      "Train loss: 4.78E-04\n",
      "Test  loss: 5.36E-04\n",
      "\n",
      " Epoch 419 \n",
      " --------------\n",
      "Train loss: 4.78E-04\n",
      "Test  loss: 5.36E-04\n",
      "\n",
      " Epoch 420 \n",
      " --------------\n",
      "Train loss: 4.77E-04\n",
      "Test  loss: 5.35E-04\n",
      "\n",
      " Epoch 421 \n",
      " --------------\n",
      "Train loss: 4.77E-04\n",
      "Test  loss: 5.35E-04\n",
      "\n",
      " Epoch 422 \n",
      " --------------\n",
      "Train loss: 4.77E-04\n",
      "Test  loss: 5.35E-04\n",
      "\n",
      " Epoch 423 \n",
      " --------------\n",
      "Train loss: 4.77E-04\n",
      "Test  loss: 5.35E-04\n",
      "\n",
      " Epoch 424 \n",
      " --------------\n",
      "Train loss: 4.76E-04\n",
      "Test  loss: 5.34E-04\n",
      "\n",
      " Epoch 425 \n",
      " --------------\n",
      "Train loss: 4.76E-04\n",
      "Test  loss: 5.34E-04\n",
      "\n",
      " Epoch 426 \n",
      " --------------\n",
      "Train loss: 4.76E-04\n",
      "Test  loss: 5.34E-04\n",
      "\n",
      " Epoch 427 \n",
      " --------------\n",
      "Train loss: 4.76E-04\n",
      "Test  loss: 5.34E-04\n",
      "\n",
      " Epoch 428 \n",
      " --------------\n",
      "Train loss: 4.75E-04\n",
      "Test  loss: 5.33E-04\n",
      "\n",
      " Epoch 429 \n",
      " --------------\n",
      "Train loss: 4.75E-04\n",
      "Test  loss: 5.33E-04\n",
      "\n",
      " Epoch 430 \n",
      " --------------\n",
      "Train loss: 4.75E-04\n",
      "Test  loss: 5.33E-04\n",
      "\n",
      " Epoch 431 \n",
      " --------------\n",
      "Train loss: 4.75E-04\n",
      "Test  loss: 5.33E-04\n",
      "\n",
      " Epoch 432 \n",
      " --------------\n",
      "Train loss: 4.74E-04\n",
      "Test  loss: 5.32E-04\n",
      "\n",
      " Epoch 433 \n",
      " --------------\n",
      "Train loss: 4.74E-04\n",
      "Test  loss: 5.32E-04\n",
      "\n",
      " Epoch 434 \n",
      " --------------\n",
      "Train loss: 4.74E-04\n",
      "Test  loss: 5.32E-04\n",
      "\n",
      " Epoch 435 \n",
      " --------------\n",
      "Train loss: 4.74E-04\n",
      "Test  loss: 5.32E-04\n",
      "\n",
      " Epoch 436 \n",
      " --------------\n",
      "Train loss: 4.73E-04\n",
      "Test  loss: 5.31E-04\n",
      "\n",
      " Epoch 437 \n",
      " --------------\n",
      "Train loss: 4.73E-04\n",
      "Test  loss: 5.31E-04\n",
      "\n",
      " Epoch 438 \n",
      " --------------\n",
      "Train loss: 4.73E-04\n",
      "Test  loss: 5.31E-04\n",
      "\n",
      " Epoch 439 \n",
      " --------------\n",
      "Train loss: 4.73E-04\n",
      "Test  loss: 5.31E-04\n",
      "\n",
      " Epoch 440 \n",
      " --------------\n",
      "Train loss: 4.72E-04\n",
      "Test  loss: 5.30E-04\n",
      "\n",
      " Epoch 441 \n",
      " --------------\n",
      "Train loss: 4.72E-04\n",
      "Test  loss: 5.30E-04\n",
      "\n",
      " Epoch 442 \n",
      " --------------\n",
      "Train loss: 4.72E-04\n",
      "Test  loss: 5.30E-04\n",
      "\n",
      " Epoch 443 \n",
      " --------------\n",
      "Train loss: 4.72E-04\n",
      "Test  loss: 5.30E-04\n",
      "\n",
      " Epoch 444 \n",
      " --------------\n",
      "Train loss: 4.71E-04\n",
      "Test  loss: 5.29E-04\n",
      "\n",
      " Epoch 445 \n",
      " --------------\n",
      "Train loss: 4.71E-04\n",
      "Test  loss: 5.29E-04\n",
      "\n",
      " Epoch 446 \n",
      " --------------\n",
      "Train loss: 4.71E-04\n",
      "Test  loss: 5.29E-04\n",
      "\n",
      " Epoch 447 \n",
      " --------------\n",
      "Train loss: 4.71E-04\n",
      "Test  loss: 5.29E-04\n",
      "\n",
      " Epoch 448 \n",
      " --------------\n",
      "Train loss: 4.71E-04\n",
      "Test  loss: 5.29E-04\n",
      "\n",
      " Epoch 449 \n",
      " --------------\n",
      "Train loss: 4.71E-04\n",
      "Test  loss: 5.28E-04\n",
      "\n",
      " Epoch 450 \n",
      " --------------\n",
      "Train loss: 4.70E-04\n",
      "Test  loss: 5.28E-04\n",
      "\n",
      " Epoch 451 \n",
      " --------------\n",
      "Train loss: 4.70E-04\n",
      "Test  loss: 5.28E-04\n",
      "\n",
      " Epoch 452 \n",
      " --------------\n",
      "Train loss: 4.70E-04\n",
      "Test  loss: 5.28E-04\n",
      "\n",
      " Epoch 453 \n",
      " --------------\n",
      "Train loss: 4.70E-04\n",
      "Test  loss: 5.28E-04\n",
      "\n",
      " Epoch 454 \n",
      " --------------\n",
      "Train loss: 4.70E-04\n",
      "Test  loss: 5.28E-04\n",
      "\n",
      " Epoch 455 \n",
      " --------------\n",
      "Train loss: 4.70E-04\n",
      "Test  loss: 5.28E-04\n",
      "\n",
      " Epoch 456 \n",
      " --------------\n",
      "Adapting learning rate to 0.00125\n",
      "Train loss: 4.70E-04\n",
      "Test  loss: 5.28E-04\n",
      "\n",
      " Epoch 457 \n",
      " --------------\n",
      "Train loss: 3.67E-04\n",
      "Test  loss: 4.23E-04\n",
      "\n",
      " Epoch 458 \n",
      " --------------\n",
      "Train loss: 3.67E-04\n",
      "Test  loss: 4.22E-04\n",
      "\n",
      " Epoch 459 \n",
      " --------------\n",
      "Train loss: 3.67E-04\n",
      "Test  loss: 4.22E-04\n",
      "\n",
      " Epoch 460 \n",
      " --------------\n",
      "Train loss: 3.67E-04\n",
      "Test  loss: 4.22E-04\n",
      "\n",
      " Epoch 461 \n",
      " --------------\n",
      "Train loss: 3.66E-04\n",
      "Test  loss: 4.22E-04\n",
      "\n",
      " Epoch 462 \n",
      " --------------\n",
      "Train loss: 3.66E-04\n",
      "Test  loss: 4.22E-04\n",
      "\n",
      " Epoch 463 \n",
      " --------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.66E-04\n",
      "Test  loss: 4.22E-04\n",
      "\n",
      " Epoch 464 \n",
      " --------------\n",
      "Train loss: 3.66E-04\n",
      "Test  loss: 4.22E-04\n",
      "\n",
      " Epoch 465 \n",
      " --------------\n",
      "Train loss: 3.66E-04\n",
      "Test  loss: 4.21E-04\n",
      "\n",
      " Epoch 466 \n",
      " --------------\n",
      "Train loss: 3.66E-04\n",
      "Test  loss: 4.21E-04\n",
      "\n",
      " Epoch 467 \n",
      " --------------\n",
      "Train loss: 3.66E-04\n",
      "Test  loss: 4.21E-04\n",
      "\n",
      " Epoch 468 \n",
      " --------------\n",
      "Train loss: 3.66E-04\n",
      "Test  loss: 4.21E-04\n",
      "\n",
      " Epoch 469 \n",
      " --------------\n",
      "Train loss: 3.65E-04\n",
      "Test  loss: 4.21E-04\n",
      "\n",
      " Epoch 470 \n",
      " --------------\n",
      "Train loss: 3.65E-04\n",
      "Test  loss: 4.21E-04\n",
      "\n",
      " Epoch 471 \n",
      " --------------\n",
      "Train loss: 3.65E-04\n",
      "Test  loss: 4.20E-04\n",
      "\n",
      " Epoch 472 \n",
      " --------------\n",
      "Train loss: 3.65E-04\n",
      "Test  loss: 4.20E-04\n",
      "\n",
      " Epoch 473 \n",
      " --------------\n",
      "Train loss: 3.65E-04\n",
      "Test  loss: 4.20E-04\n",
      "\n",
      " Epoch 474 \n",
      " --------------\n",
      "Train loss: 3.65E-04\n",
      "Test  loss: 4.20E-04\n",
      "\n",
      " Epoch 475 \n",
      " --------------\n",
      "Train loss: 3.65E-04\n",
      "Test  loss: 4.20E-04\n",
      "\n",
      " Epoch 476 \n",
      " --------------\n",
      "Train loss: 3.65E-04\n",
      "Test  loss: 4.20E-04\n",
      "\n",
      " Epoch 477 \n",
      " --------------\n",
      "Train loss: 3.65E-04\n",
      "Test  loss: 4.19E-04\n",
      "\n",
      " Epoch 478 \n",
      " --------------\n",
      "Train loss: 3.64E-04\n",
      "Test  loss: 4.19E-04\n",
      "\n",
      " Epoch 479 \n",
      " --------------\n",
      "Train loss: 3.64E-04\n",
      "Test  loss: 4.19E-04\n",
      "\n",
      " Epoch 480 \n",
      " --------------\n",
      "Train loss: 3.64E-04\n",
      "Test  loss: 4.19E-04\n",
      "\n",
      " Epoch 481 \n",
      " --------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[87], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Thibeau\\master-thesis-AI\\Code\\nnc2p.py:412\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, adaptation_threshold, adaptation_multiplier, number_of_epochs, log_file, csv_file)\u001b[0m\n\u001b[0;32m    410\u001b[0m write_to_txt(log_file, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_counter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m --------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    411\u001b[0m \u001b[38;5;66;03m# Train the network\u001b[39;00m\n\u001b[1;32m--> 412\u001b[0m \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_c2p_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse_c2p_loss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[38;5;66;03m# Test on the training data\u001b[39;00m\n\u001b[0;32m    414\u001b[0m average_train_loss \u001b[38;5;241m=\u001b[39m test_loop(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_dataloader, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn)\n",
      "File \u001b[1;32mD:\\Thibeau\\master-thesis-AI\\Code\\nnc2p.py:292\u001b[0m, in \u001b[0;36mtrain_loop\u001b[1;34m(dataloader, model, loss_fn, optimizer, report_progress, use_c2p_loss)\u001b[0m\n\u001b[0;32m    290\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m    291\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m--> 292\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;66;03m# If we want to report progress during training (not recommended - obstructs view)\u001b[39;00m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m report_progress:\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\thesis\\Lib\\site-packages\\torch\\optim\\optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    277\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m                                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 280\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    283\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\thesis\\Lib\\site-packages\\torch\\optim\\optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 33\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     35\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\thesis\\Lib\\site-packages\\torch\\optim\\adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    130\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    133\u001b[0m         group,\n\u001b[0;32m    134\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    138\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    139\u001b[0m         state_steps)\n\u001b[1;32m--> 141\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\thesis\\Lib\\site-packages\\torch\\optim\\adam.py:281\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    279\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 281\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\thesis\\Lib\\site-packages\\torch\\optim\\adam.py:337\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weight_decay \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    335\u001b[0m     grad \u001b[38;5;241m=\u001b[39m grad\u001b[38;5;241m.\u001b[39madd(param, alpha\u001b[38;5;241m=\u001b[39mweight_decay)\n\u001b[1;32m--> 337\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    338\u001b[0m     grad \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mview_as_real(grad)\n\u001b[0;32m    339\u001b[0m     exp_avg \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mview_as_real(exp_avg)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c550e901",
   "metadata": {},
   "source": [
    "Report architecture (this saves info to a CSV, such as hidden layer set-up, nb of epochs trained, loss after training,... in order to compare performances across different architecture details)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2f3a92f7",
   "metadata": {
    "id": "2f3a92f7"
   },
   "outputs": [],
   "source": [
    "# trainer.report_training(\"NNEOS_tab_experiments.csv\", comment = \"logeps, logpress and log cs2.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296ab01e",
   "metadata": {
    "id": "296ab01e"
   },
   "source": [
    "Create a quick sketch of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f8056faf",
   "metadata": {
    "id": "f8056faf"
   },
   "outputs": [],
   "source": [
    "# plt.plot(trainer.train_losses, color='red', label=\"Train loss\")\n",
    "# plt.plot(trainer.test_losses, color='blue', label=\"Test loss\")\n",
    "\n",
    "# plt.grid()\n",
    "# plt.legend()\n",
    "# for ind in trainer.adaptation_indices:\n",
    "#     plt.axvline(ind, ls = '--', color='grey')\n",
    "# plt.yscale('log')\n",
    "# plt.xlabel(\"Epochs\")\n",
    "# plt.ylabel(\"MSE Loss\")\n",
    "# plt.title(\"Training (50, 50) network tabular EOS for p and eps\")\n",
    "# plt.savefig(\"testing_training_tab_eos_network_50_50.pdf\", bbox_inches = 'tight')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd574d7f",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70c0189",
   "metadata": {},
   "source": [
    "Predictions on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6616e477",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # Get the input we wish to use\n",
    "    test_input = test_features.copy()\n",
    "    # Normalize it\n",
    "    test_input = scaler.transform(test_input)\n",
    "    # Conver to Torch tensor\n",
    "    test_input = torch.from_numpy(test_input)\n",
    "    # Do predictions\n",
    "    predictions = model(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "125a2965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00571584, 0.00829841, 0.0132747 ])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnc2p.l1_norm(test_labels, predictions.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a12dfa",
   "metadata": {},
   "source": [
    "## Save, load and export model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e9ef41",
   "metadata": {},
   "source": [
    "If desired, save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7f5344f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, \"nn_tabeos_3_50_50_3.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbaefc43",
   "metadata": {},
   "source": [
    "If desired, load the original architecture (`tabular_eos_14_04.pth` contains for h = 50, 100, 20). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "84a8d614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net(nb_of_inputs=3, nb_of_outputs=3, h=[50, 50]).float()\n",
    "# Load the state dict\n",
    "state_dict = torch.load(\"nn_tabeos_3_50_50_3.pth\") \n",
    "# Convert everything to floats rather than doubles\n",
    "for key in state_dict:\n",
    "    state_dict[key] = state_dict[key].float()\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f64a42c",
   "metadata": {},
   "source": [
    "If desired, creat jit and onnx of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1ab9eba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example\n",
      "-1.728142261505127\n",
      "-1.4035654067993164\n",
      "-1.1849615573883057\n",
      "Output\n",
      "19.214147567749023\n",
      "18.384708404541016\n"
     ]
    }
   ],
   "source": [
    "x = scaler.transform(features[1000].reshape(1,-1))\n",
    "x = torch.from_numpy(x).float()\n",
    "print(\"Example\")\n",
    "print(x[0][0].item())\n",
    "print(x[0][1].item())\n",
    "print(x[0][2].item())\n",
    "torch_out = model(x)\n",
    "print(\"Output\")\n",
    "print(torch_out[0][0].item())\n",
    "print(torch_out[0][1].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c952dd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## ONNX\n",
    "# # Export the model\n",
    "# torch.onnx.export(model,               # model being run\n",
    "#                   x,                         # model input (or a tuple for multiple inputs)\n",
    "#                   \"tab_eos.onnx\",   # where to save the model (can be a file or file-like object)\n",
    "#                   export_params=True,        # store the trained parameter weights inside the model file\n",
    "#                   opset_version=10,          # the ONNX version to export the model to\n",
    "#                   do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "#                   input_names = ['input'],   # the model's input names\n",
    "#                   output_names = ['output'], # the model's output names\n",
    "#                   dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
    "#                                 'output' : {0 : 'batch_size'}})\n",
    "# ## Torchscript\n",
    "# # Use torch.jit.trace to generate a torch.jit.ScriptModule via tracing.\n",
    "# traced_script_module = torch.jit.trace(model, x)\n",
    "\n",
    "# # Save the TorchScript model\n",
    "# traced_script_module.save(\"tab_eos.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fbece1",
   "metadata": {},
   "source": [
    "Testing ONNX here!!! See [this PyTorch docs page for info.](https://pytorch.org/tutorials/advanced/super_resolution_with_onnxruntime.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "33c3d4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# onnx_model = onnx.load(\"tab_eos.onnx\")\n",
    "# onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "33a31b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported model has been tested with ONNXRuntime, and the result looks good!\n"
     ]
    }
   ],
   "source": [
    "# ort_session = onnxruntime.InferenceSession(\"tab_eos.onnx\")\n",
    "\n",
    "# def to_numpy(tensor):\n",
    "#     return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "# # compute ONNX Runtime output prediction\n",
    "# ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(x)}\n",
    "# ort_outs = ort_session.run(None, ort_inputs)\n",
    "\n",
    "# # compare ONNX Runtime and PyTorch results\n",
    "# np.testing.assert_allclose(to_numpy(torch_out), ort_outs[0], rtol=1e-03, atol=1e-05)\n",
    "\n",
    "# print(\"Exported model has been tested with ONNXRuntime, and the result looks good!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751ad8d9",
   "metadata": {},
   "source": [
    "## Compare performance against trilinear interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170faab4",
   "metadata": {},
   "source": [
    "We see (by running the cell below several times) that network is quite robust in generalization, althought the $\\ell_\\infty$ norm can sometimes suddenly get quite high, so further investigation into training on the full table is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "be6b1508",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eline\\AppData\\Local\\Temp\\ipykernel_740\\2540522382.py:1: RuntimeWarning: invalid value encountered in log\n",
      "  logcs2 = np.log(cs2)\n"
     ]
    }
   ],
   "source": [
    "logcs2 = np.log(cs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "8a8b5739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2       difference on sample:  [5.76892252e-05 1.27363625e-04 7.22979913e-04]\n",
      "Linfty difference on sample:  [0.04742512 0.09362586 0.86427861]\n"
     ]
    }
   ],
   "source": [
    "# Sample features and their labels\n",
    "n_samples = 10000\n",
    "sample_ind = np.random.choice(len(features), size=min(len(features), n_samples), replace=False)\n",
    "sample_features = features[sample_ind]\n",
    "sample_labels = labels[sample_ind]\n",
    "# Get predictions\n",
    "with torch.no_grad():\n",
    "    # Don't forget to apply normalization!!! We fixed the random seed for reproducibility\n",
    "    sample_features = scaler.transform(sample_features)\n",
    "    predictions = model(torch.from_numpy(sample_features).float())\n",
    "    predictions = predictions.numpy()\n",
    "    \n",
    "# print(sample_labels[0])\n",
    "# print(predictions[0])\n",
    "print(\"L2       difference on sample: \", nnc2p.l2_norm(sample_labels, predictions))\n",
    "# print(nnc2p.l1_norm(sample_labels, predictions))\n",
    "print(\"Linfty difference on sample: \",nnc2p.linfty_norm(sample_labels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617ca2f7",
   "metadata": {},
   "source": [
    "Don't forget normalization (note: we can export the normalization procedure later on by saving the mean and std)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1f1060b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: [ 9.51608373 -0.30081866  0.32936217], std: [3.76043372 1.56992791 0.19028245]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean: {scaler.mean_}, std: {scaler.scale_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3438e32b",
   "metadata": {},
   "source": [
    "## Compare network with trilinear interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040e1408",
   "metadata": {},
   "source": [
    "We use scipy for the interpolation: see [this docs page](https://docs.scipy.org/doc/scipy/reference/generated/scipy.interpolate.interpn.html#scipy.interpolate.interpn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4eaa66fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interpn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "c7d3e7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomn(a, b):\n",
    "    \"\"\"Generate a random number in the range [a, b]\"\"\"\n",
    "    \n",
    "    return a + (b-a)*np.random.rand()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c041a544",
   "metadata": {},
   "source": [
    "We define our own trilinear interpolation routine based on scipy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f009fd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trilinear_interpolation(points, values_list, test_points):\n",
    "    \"\"\"\n",
    "    Does a single prediction using trilinear interpolation.\n",
    "    \"\"\"\n",
    "    # Make the predictions\n",
    "    predictions = [interpn(points, values, test_points) for values in values_list]            \n",
    "    # Return transpose: shape is (n_samples, n_vars) similar to neural network\n",
    "    return np.transpose(np.array(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0805f55e",
   "metadata": {},
   "source": [
    "For the grid points, we reverse the order compared to the EOS table. That is, the EOS table uses (ye, logtemp, logrho), but we will use (logrho, logtemp, ye)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "b22ff32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(391, 163, 66)\n"
     ]
    }
   ],
   "source": [
    "logpress_reversed = np.swapaxes(logpress, 0, 2)\n",
    "logenergy_reversed = np.swapaxes(logenergy, 0, 2)\n",
    "logcs2_reversed = np.swapaxes(logcs2, 0, 2)\n",
    "print(logpress_reversed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "24facc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_eos(logrho, logtemp, ye, n_examples = 1):\n",
    "    \"\"\"\n",
    "    Simple auxiliary function that returns a random input data point for an EOS table, based on its (logrho, logtemp, ye) values.\n",
    "    \"\"\"\n",
    "    \n",
    "    return np.stack([[randomn(min(logrho), max(logrho)), randomn(min(logtemp), max(logtemp)), randomn(min(ye), max(ye))] for _ in range(n_examples)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "0b48f682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get an array of test cases:\n",
    "n_examples = 10000\n",
    "test_points = sample_eos(logrho, logtemp, ye, n_examples=n_examples)\n",
    "# Grid of tables\n",
    "points = (logrho, logtemp, ye)\n",
    "# Variables we wish to get\n",
    "values_list = [logenergy_reversed, logpress_reversed, logcs2_reversed]\n",
    "# Interpolation\n",
    "interpolated = trilinear_interpolation(points, values_list, test_points)\n",
    "# print(interpolated)  # print in case n_examples is low\n",
    "# Compare with neural net\n",
    "with torch.no_grad():\n",
    "    # Don't forget normalization!!!\n",
    "    test_points_n = scaler.transform(test_points)\n",
    "    predictions = model(torch.from_numpy(test_points_n).float())\n",
    "    predictions = predictions.numpy()\n",
    "#     print(predictions)  # print in case n_examples is low"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6165a0d3",
   "metadata": {},
   "source": [
    "Now get error rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "51b66e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_error, l2_error, linfty_error = nnc2p.l1_norm(interpolated, predictions), nnc2p.l2_norm(interpolated, predictions), nnc2p.linfty_norm(interpolated, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "48ee6869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00565407 0.0081235  0.01305064]\n",
      "[5.65448465e-05 1.19128211e-04 7.66002332e-04]\n",
      "[0.05040054 0.08126448 0.99801589]\n"
     ]
    }
   ],
   "source": [
    "print(l1_error)\n",
    "print(l2_error)\n",
    "print(linfty_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ccc391",
   "metadata": {},
   "source": [
    "## Compare performance of methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e72317",
   "metadata": {},
   "source": [
    "Here, we will try to compare the performance of the methods, by measuring the time they take (CPU time) through `timeit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "1d6f2327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a single point that has to be predicted\n",
    "test_point = sample_eos(logrho, logtemp, ye)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02146ac",
   "metadata": {},
   "source": [
    "Choose the number of runs and number of loops within each run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "dba98145",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 10\n",
    "n_loops = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "96877c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_execution(func, n_runs=10, n_loops=10000, verbose=True):\n",
    "    # Save all the runtimes\n",
    "    runtimes = []\n",
    "    for _ in range(n_runs):\n",
    "        # Start timer each run\n",
    "        start = time.process_time_ns()\n",
    "        for _ in range(n_loops):\n",
    "            func()\n",
    "        end = time.process_time_ns()\n",
    "        # Convert to micro seconds and get average for one loop\n",
    "        time_run = (end-start)/1000\n",
    "        time_loop = time_run/n_loops\n",
    "        runtimes.append(time_loop)\n",
    "    \n",
    "    # Convert to mean adn std\n",
    "    mu, sigma = np.mean(runtimes), np.std(runtimes)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"{mu} \\pm {sigma} per loop ({n_runs} runs, {n_loops} each)\")\n",
    "    \n",
    "    return mu, sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3266a43e",
   "metadata": {},
   "source": [
    "### Trilinear interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77be19ac",
   "metadata": {},
   "source": [
    "Performance of trilinear interpolation with Scipy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "6da37954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which values to predict?\n",
    "values_list = [logenergy_reversed, logpress_reversed]\n",
    "# single value:\n",
    "val = logenergy_reversed\n",
    "def function1():\n",
    "    [interpn(points, val, test_point) for val in values_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "2210bea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %timeit -r10 -n10000 interpn(points, logenergy_reversed, test_point)  # measure Scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57960034",
   "metadata": {},
   "source": [
    "### Neural network (using PyTorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa6d74c",
   "metadata": {},
   "source": [
    "Performance of running the network with PyTorch built-ins: first convert point to right format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "53c473f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_point_n = scaler.transform(test_point)\n",
    "test_point_torch = torch.from_numpy(test_point_n).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "f700b984",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function2():\n",
    "    model(test_point_torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d903553",
   "metadata": {},
   "source": [
    "### Neural network (using PyTorch, no grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f7dc09",
   "metadata": {},
   "source": [
    "It might be that saving the gradients etc in PyTorch can slow down the inference: check performance with grads disabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "69bb21dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function3():\n",
    "    with torch.no_grad():\n",
    "        model(test_point_torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7320f22f",
   "metadata": {},
   "source": [
    "### Neural network (using ONNX Runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "eab43d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function4():\n",
    "    ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(x)}\n",
    "    ort_outs = ort_session.run(None, ort_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7dbd218",
   "metadata": {},
   "source": [
    "### Neural network (using Numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7476d3d2",
   "metadata": {},
   "source": [
    "Other comparison: the neural network but just the matrices and using Numpy! Save everything externally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "b42da0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = model.state_dict()[\"linear1.weight\"].numpy()\n",
    "b1 = model.state_dict()[\"linear1.bias\"].numpy()\n",
    "w2 = model.state_dict()[\"linear2.weight\"].numpy()\n",
    "b2 = model.state_dict()[\"linear2.bias\"].numpy()\n",
    "w3 = model.state_dict()[\"linear3.weight\"].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "5552111b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_point_np = test_point_n[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "e39a3e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "dd1d0e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_nn(x):\n",
    "    x = np.matmul(w1, x) + b1\n",
    "    x = sigmoid(x)\n",
    "    x = np.matmul(w2, x) + b2\n",
    "    x = sigmoid(x)\n",
    "    x = np.matmul(w3, x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "814df05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11.57061122 -0.15633412  0.08561414]]\n",
      "[21.82010524 38.72651337 47.77346631]\n",
      "[21.820105 38.726513 47.773468]\n"
     ]
    }
   ],
   "source": [
    "# Check if we get the same results -- OK\n",
    "print(test_point)\n",
    "test1 = run_nn(test_point[0])\n",
    "print(test1)\n",
    "with torch.no_grad():\n",
    "    test2 = model(torch.from_numpy(test_point[0]).float())\n",
    "    test2 = test2.numpy()\n",
    "print(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "c87285fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function5():\n",
    "    run_nn(test_point_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e70883",
   "metadata": {},
   "source": [
    "### Python (no packages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c826585c",
   "metadata": {},
   "source": [
    "Convert everything to lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "916ba2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5463538641652405], [0.09203259199418481], [-1.280980106027008]]\n"
     ]
    }
   ],
   "source": [
    "test_point_list = test_point_np.tolist()\n",
    "test_point_list = [[val] for val in test_point_list]\n",
    "print(test_point_list)\n",
    "w1_list = w1.tolist()\n",
    "# b1_list = b1.tolist()\n",
    "b1_list = [[b1[i]] for i in range(len(b1))]\n",
    "# b1_list = [b1_list]\n",
    "w2_list = w2.tolist()\n",
    "b2_list = [[b2[i]] for i in range(len(b2))]\n",
    "w3_list = w3.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4f1ef8",
   "metadata": {},
   "source": [
    "Get sigmoid function without numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "ff76dfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_list(x):\n",
    "    return [[1/(1+2.71828182845904523536028747135266249**(-x[i][0]))] for i in range(len(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "4d6b49e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mm(A, B):\n",
    "    \"\"\"Matrix multiplication, pure Python\"\"\"\n",
    "    return [[sum(a*b for a,b in zip(A_row, B_col)) for B_col in zip(*B)] for A_row in A]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "0daf7f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2], [4], [6]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[2.731058578630005], [4.880797077977882], [6.952574126822433]]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [[2, 0, 0], [0, 2, 0], [0, 0, 2]]\n",
    "b = [[1],[2],[3]]\n",
    "first = mm(a,b)\n",
    "print(first)\n",
    "second = sigmoid_list(b)\n",
    "[[first[i][0] + second[i][0]] for i in range(len(first))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "46596592",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_nn_list(x):\n",
    "    x = mm(w1_list, x)\n",
    "    x = [[x[i][0] + b1_list[i][0]] for i in range(len(x))]\n",
    "    x = sigmoid_list(x)\n",
    "    x = mm(w2_list, x)\n",
    "    x = [[x[i][0] + b2_list[i][0]] for i in range(len(x))]\n",
    "    x = sigmoid_list(x)\n",
    "    x = mm(w3_list, x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f01dc3",
   "metadata": {},
   "source": [
    "The shape is slightly different, but this is good enough!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "bfee6f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19.28380190064578], [29.502848125783046], [41.66890742358023]]\n",
      "[[19.283802 29.50285  41.668907]]\n"
     ]
    }
   ],
   "source": [
    "# Check if we get the same results -- OK\n",
    "test1 = run_nn_list(test_point_list)\n",
    "print(test1)\n",
    "with torch.no_grad():\n",
    "    test2 = model(test_point_torch)\n",
    "    test2 = test2.numpy()\n",
    "print(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "432f3553",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function6():\n",
    "    run_nn_list(test_point_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dea986",
   "metadata": {},
   "source": [
    "__Do the runtime analysis__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "643e25e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Interpolation ---\n",
      "513.125 \\pm 5.284854539152426 per loop (10 runs, 10000 each)\n",
      "--- PyTorch ---\n",
      "101.40625 \\pm 0.8414320011147662 per loop (10 runs, 10000 each)\n",
      "--- PyTorch (no grad) ---\n",
      "73.125 \\pm 0.625 per loop (10 runs, 10000 each)\n",
      "--- Numpy ---\n",
      "20.15625 \\pm 1.09375 per loop (10 runs, 10000 each)\n"
     ]
    }
   ],
   "source": [
    "# Empty lists\n",
    "mu_list, sigma_list = [], []\n",
    "# Functions & names for runtime analysis\n",
    "funcs = [function1, function2, function3, function5]\n",
    "method_names = [\"Interpolation\", \"PyTorch\", \"PyTorch (no grad)\", \"Numpy\"]  # , \"Pure Python\"\n",
    "for i, func in enumerate(funcs):\n",
    "    print(f\"--- {method_names[i]} ---\")\n",
    "    mu, sigma = time_execution(func)\n",
    "    mu_list.append(mu)\n",
    "    sigma_list.append(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "ffc19f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best neural net implementation is around 25x faster.\n"
     ]
    }
   ],
   "source": [
    "speedup = round(mu_list[0]/mu_list[-1])\n",
    "print(f\"Best neural net implementation is around {speedup}x faster.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0903ef",
   "metadata": {},
   "source": [
    "\n",
    "### Plot to combine analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dac9bf",
   "metadata": {},
   "source": [
    "Prepare the plot, sort values etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "f6b6644a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xticks = [i+1 for i in range(len(method_names))]\n",
    "yvals = mu_list\n",
    "yerrs = sigma_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "b3ef8205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cutoff = 5\n",
    "\n",
    "# # Get vals more clearly, do cutoff\n",
    "# xvals = xticks[:cutoff]\n",
    "# yvals = mu_list[:cutoff]\n",
    "# yerrs = sigma_list[:cutoff]\n",
    "# # Swap based on performance  ## NOT WORKING FOR SOME REASON\n",
    "# # sort_ind = np.argsort(yvals)[::-1]\n",
    "# # # Sort\n",
    "# # xvals = my_sort(xvals, sort_ind)\n",
    "# # yvals = my_sort(yvals, sort_ind)\n",
    "# # yerrs = my_sort(yerrs, sort_ind)\n",
    "# # method_names = my_sort(method_names, sort_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "8036f717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1920x1440 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preparation\n",
    "plt.errorbar(xticks, yvals, yerrs, fmt=\"o\", color=\"blue\", capsize=5)\n",
    "plt.xticks(ticks=xticks, labels = method_names, rotation=30)\n",
    "plt.ylabel(\"CPU time/prediction (s)\")\n",
    "plt.grid()\n",
    "plt.savefig(\"Time comparison single prediction\")\n",
    "# plt.savefig(\"interpolation_neuralnet_speed_comparison.pdf\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377b0cbf",
   "metadata": {
    "id": "377b0cbf"
   },
   "source": [
    "# Second goal: NNC2P"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf95fa58",
   "metadata": {
    "id": "bf95fa58"
   },
   "source": [
    "__TO DO__ think about design of architecture AND fix the conserved variable values -- I think they were not computed correctly before! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b454181",
   "metadata": {
    "id": "2b454181"
   },
   "source": [
    "__NNC2P__: try to replicate the full C2P conversion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c10571f",
   "metadata": {
    "id": "9c10571f"
   },
   "source": [
    "Get the training data as DataSet and DataLoader objects. Note on normalization: we fit transform on the training data, then use the fitted scaler object to transform (i.e. using same transformation as the training data) the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852d22c5",
   "metadata": {
    "id": "852d22c5"
   },
   "outputs": [],
   "source": [
    "# Give the names of the input vars (features) and output vars (labels)\n",
    "in_vars = [\"rho\", \"eps\", \"ye\"]\n",
    "out_vars = [\"temp\"]\n",
    "# For normalization, use sklearn's StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# Read the sampled data as pandas dataframes\n",
    "train_df = pd.read_csv(os.path.join(master_dir, \"Data/SLy4_training_data.csv\"))\n",
    "test_df  = pd.read_csv(os.path.join(master_dir, \"Data/SLy4_test_data.csv\"))\n",
    "# Convert to PyTorch Datasets as we defined them\n",
    "train_dataset = data.CustomDataset(train_df, feature_names = in_vars, label_names = out_vars, normalization_function = scaler.fit_transform) \n",
    "test_dataset  = data.CustomDataset(test_df, feature_names = in_vars, label_names = out_vars, normalization_function = scaler.transform)\n",
    "# Then create dataloaders, with batch size 32, from datasets\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32)\n",
    "test_dataloader  = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e96de6",
   "metadata": {
    "id": "24e96de6"
   },
   "source": [
    "Create a new instance of the Net:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08aa592",
   "metadata": {
    "id": "d08aa592",
    "outputId": "1a3ec4f4-f574-496b-d3a8-25cfc9c30361"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (linear1): Linear(in_features=3, out_features=50, bias=True)\n",
       "  (activation1): Sigmoid()\n",
       "  (linear2): Linear(in_features=50, out_features=50, bias=True)\n",
       "  (activation2): Sigmoid()\n",
       "  (linear3): Linear(in_features=50, out_features=1, bias=False)\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Net(nb_of_inputs = 3, nb_of_outputs = 1, h=[50, 50])\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504399cb",
   "metadata": {
    "id": "504399cb",
    "outputId": "aa1b5560-9e9b-461b-a9e5-3eb90573d2c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2800"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nnc2p.count_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da83cead",
   "metadata": {
    "id": "da83cead"
   },
   "source": [
    "Create a trainer object from it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fffc1e4",
   "metadata": {
    "id": "7fffc1e4"
   },
   "outputs": [],
   "source": [
    "trainer = nnc2p.Trainer(model, 1e-1, train_dataloader=train_dataloader, test_dataloader=test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0369872",
   "metadata": {
    "id": "e0369872",
    "outputId": "324b4965-3166-4d96-dac7-ff9fa27aae78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model for 500 epochs.\n",
      "\n",
      " Epoch 0 \n",
      " --------------\n",
      "Train loss: 7.59E-01\n",
      "Test  loss: 7.62E-01\n",
      "\n",
      " Epoch 1 \n",
      " --------------\n",
      "Train loss: 9.92E-01\n",
      "Test  loss: 9.98E-01\n",
      "\n",
      " Epoch 2 \n",
      " --------------\n",
      "Train loss: 9.45E-01\n",
      "Test  loss: 9.61E-01\n",
      "\n",
      " Epoch 3 \n",
      " --------------\n",
      "Train loss: 8.24E-01\n",
      "Test  loss: 8.29E-01\n",
      "\n",
      " Epoch 4 \n",
      " --------------\n",
      "Train loss: 9.10E-01\n",
      "Test  loss: 9.16E-01\n",
      "\n",
      " Epoch 5 \n",
      " --------------\n",
      "Train loss: 8.80E-01\n",
      "Test  loss: 8.91E-01\n",
      "\n",
      " Epoch 6 \n",
      " --------------\n",
      "Train loss: 8.62E-01\n",
      "Test  loss: 8.67E-01\n",
      "\n",
      " Epoch 7 \n",
      " --------------\n",
      "Train loss: 8.20E-01\n",
      "Test  loss: 8.27E-01\n",
      "\n",
      " Epoch 8 \n",
      " --------------\n",
      "Train loss: 8.80E-01\n",
      "Test  loss: 8.94E-01\n",
      "\n",
      " Epoch 9 \n",
      " --------------\n",
      "Train loss: 9.20E-01\n",
      "Test  loss: 9.26E-01\n",
      "\n",
      " Epoch 10 \n",
      " --------------\n",
      "Train loss: 7.34E-01\n",
      "Test  loss: 7.39E-01\n",
      "\n",
      " Epoch 11 \n",
      " --------------\n",
      "Train loss: 7.48E-01\n",
      "Test  loss: 7.56E-01\n",
      "\n",
      " Epoch 12 \n",
      " --------------\n",
      "Train loss: 7.28E-01\n",
      "Test  loss: 7.31E-01\n",
      "\n",
      " Epoch 13 \n",
      " --------------\n",
      "Train loss: 8.87E-01\n",
      "Test  loss: 8.99E-01\n",
      "\n",
      " Epoch 14 \n",
      " --------------\n",
      "Train loss: 8.02E-01\n",
      "Test  loss: 8.09E-01\n",
      "\n",
      " Epoch 15 \n",
      " --------------\n",
      "Train loss: 8.11E-01\n",
      "Test  loss: 8.20E-01\n",
      "\n",
      " Epoch 16 \n",
      " --------------\n",
      "Train loss: 8.02E-01\n",
      "Test  loss: 8.08E-01\n",
      "\n",
      " Epoch 17 \n",
      " --------------\n",
      "Adapting learning rate to 0.05\n",
      "Train loss: 8.70E-01\n",
      "Test  loss: 8.79E-01\n",
      "\n",
      " Epoch 18 \n",
      " --------------\n",
      "Train loss: 6.88E-01\n",
      "Test  loss: 6.92E-01\n",
      "\n",
      " Epoch 19 \n",
      " --------------\n",
      "Train loss: 6.24E-01\n",
      "Test  loss: 6.25E-01\n",
      "\n",
      " Epoch 20 \n",
      " --------------\n",
      "Train loss: 6.42E-01\n",
      "Test  loss: 6.46E-01\n",
      "\n",
      " Epoch 21 \n",
      " --------------\n",
      "Train loss: 6.21E-01\n",
      "Test  loss: 6.25E-01\n",
      "\n",
      " Epoch 22 \n",
      " --------------\n",
      "Train loss: 6.29E-01\n",
      "Test  loss: 6.32E-01\n",
      "\n",
      " Epoch 23 \n",
      " --------------\n",
      "Train loss: 6.30E-01\n",
      "Test  loss: 6.33E-01\n",
      "\n",
      " Epoch 24 \n",
      " --------------\n",
      "Train loss: 6.13E-01\n",
      "Test  loss: 6.16E-01\n",
      "\n",
      " Epoch 25 \n",
      " --------------\n",
      "Train loss: 6.25E-01\n",
      "Test  loss: 6.27E-01\n",
      "\n",
      " Epoch 26 \n",
      " --------------\n",
      "Train loss: 6.75E-01\n",
      "Test  loss: 6.81E-01\n",
      "\n",
      " Epoch 27 \n",
      " --------------\n",
      "Train loss: 6.22E-01\n",
      "Test  loss: 6.23E-01\n",
      "\n",
      " Epoch 28 \n",
      " --------------\n",
      "Train loss: 6.77E-01\n",
      "Test  loss: 6.81E-01\n",
      "\n",
      " Epoch 29 \n",
      " --------------\n",
      "Adapting learning rate to 0.025\n",
      "Train loss: 6.98E-01\n",
      "Test  loss: 6.99E-01\n",
      "\n",
      " Epoch 30 \n",
      " --------------\n",
      "Train loss: 5.71E-01\n",
      "Test  loss: 5.74E-01\n",
      "\n",
      " Epoch 31 \n",
      " --------------\n",
      "Train loss: 5.77E-01\n",
      "Test  loss: 5.81E-01\n",
      "\n",
      " Epoch 32 \n",
      " --------------\n",
      "Train loss: 5.69E-01\n",
      "Test  loss: 5.74E-01\n",
      "\n",
      " Epoch 33 \n",
      " --------------\n",
      "Train loss: 5.65E-01\n",
      "Test  loss: 5.69E-01\n",
      "\n",
      " Epoch 34 \n",
      " --------------\n",
      "Train loss: 5.63E-01\n",
      "Test  loss: 5.67E-01\n",
      "\n",
      " Epoch 35 \n",
      " --------------\n",
      "Train loss: 5.60E-01\n",
      "Test  loss: 5.65E-01\n",
      "\n",
      " Epoch 36 \n",
      " --------------\n",
      "Train loss: 5.67E-01\n",
      "Test  loss: 5.70E-01\n",
      "\n",
      " Epoch 37 \n",
      " --------------\n",
      "Train loss: 5.58E-01\n",
      "Test  loss: 5.60E-01\n",
      "\n",
      " Epoch 38 \n",
      " --------------\n",
      "Train loss: 5.62E-01\n",
      "Test  loss: 5.66E-01\n",
      "\n",
      " Epoch 39 \n",
      " --------------\n",
      "Train loss: 5.62E-01\n",
      "Test  loss: 5.66E-01\n",
      "\n",
      " Epoch 40 \n",
      " --------------\n",
      "Train loss: 5.62E-01\n",
      "Test  loss: 5.64E-01\n",
      "\n",
      " Epoch 41 \n",
      " --------------\n",
      "Train loss: 5.73E-01\n",
      "Test  loss: 5.75E-01\n",
      "\n",
      " Epoch 42 \n",
      " --------------\n",
      "Adapting learning rate to 0.0125\n",
      "Train loss: 5.69E-01\n",
      "Test  loss: 5.73E-01\n",
      "\n",
      " Epoch 43 \n",
      " --------------\n",
      "Train loss: 4.89E-01\n",
      "Test  loss: 4.92E-01\n",
      "\n",
      " Epoch 44 \n",
      " --------------\n",
      "Train loss: 4.87E-01\n",
      "Test  loss: 4.91E-01\n",
      "\n",
      " Epoch 45 \n",
      " --------------\n",
      "Train loss: 4.86E-01\n",
      "Test  loss: 4.91E-01\n",
      "\n",
      " Epoch 46 \n",
      " --------------\n",
      "Train loss: 4.83E-01\n",
      "Test  loss: 4.88E-01\n",
      "\n",
      " Epoch 47 \n",
      " --------------\n",
      "Train loss: 4.80E-01\n",
      "Test  loss: 4.85E-01\n",
      "\n",
      " Epoch 48 \n",
      " --------------\n",
      "Train loss: 4.78E-01\n",
      "Test  loss: 4.83E-01\n",
      "\n",
      " Epoch 49 \n",
      " --------------\n",
      "Train loss: 4.77E-01\n",
      "Test  loss: 4.81E-01\n",
      "\n",
      " Epoch 50 \n",
      " --------------\n",
      "Train loss: 4.75E-01\n",
      "Test  loss: 4.79E-01\n",
      "\n",
      " Epoch 51 \n",
      " --------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[118], line 1\u001b[0m\n",
      "\u001b[1;32m----> 1\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "\n",
      "File \u001b[1;32md:\\Coding\\master-thesis-AI\\Code\\nnc2p.py:407\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, adaptation_threshold, adaptation_multiplier, number_of_epochs, log_file, csv_file)\u001b[0m\n",
      "\u001b[0;32m    405\u001b[0m write_to_txt(log_file, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m Epoch \u001b[39m\u001b[39m{\u001b[39;00mepoch_counter\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m --------------\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;32m    406\u001b[0m \u001b[39m# Train the network\u001b[39;00m\n",
      "\u001b[1;32m--> 407\u001b[0m train_loop(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_dataloader, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss_fn, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer, use_c2p_loss\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49muse_c2p_loss)\n",
      "\u001b[0;32m    408\u001b[0m \u001b[39m# Test on the training data\u001b[39;00m\n",
      "\u001b[0;32m    409\u001b[0m average_train_loss \u001b[39m=\u001b[39m test_loop(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_dataloader, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_fn)\n",
      "\n",
      "File \u001b[1;32md:\\Coding\\master-thesis-AI\\Code\\nnc2p.py:277\u001b[0m, in \u001b[0;36mtrain_loop\u001b[1;34m(dataloader, model, loss_fn, optimizer, report_progress, use_c2p_loss)\u001b[0m\n",
      "\u001b[0;32m    274\u001b[0m size \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(dataloader\u001b[39m.\u001b[39mdataset)\n",
      "\u001b[0;32m    275\u001b[0m \u001b[39mfor\u001b[39;00m batch, (X, y) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataloader):\n",
      "\u001b[0;32m    276\u001b[0m     \u001b[39m# Compute prediction \u001b[39;00m\n",
      "\u001b[1;32m--> 277\u001b[0m     prediction \u001b[39m=\u001b[39m model(X)\n",
      "\u001b[0;32m    278\u001b[0m     \u001b[39m# In case we use C2P loss function, have to provide conserved variables for the loss computation\u001b[39;00m\n",
      "\u001b[0;32m    279\u001b[0m     \u001b[39mif\u001b[39;00m use_c2p_loss:\n",
      "\n",
      "File \u001b[1;32md:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n",
      "\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n",
      "\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n",
      "\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n",
      "\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\n",
      "Cell \u001b[1;32mIn[25], line 39\u001b[0m, in \u001b[0;36mNet.forward\u001b[1;34m(self, x)\u001b[0m\n",
      "\u001b[0;32m     37\u001b[0m     \u001b[39mif\u001b[39;00m i \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[0;32m     38\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n",
      "\u001b[1;32m---> 39\u001b[0m     x \u001b[39m=\u001b[39m module(x)\n",
      "\u001b[0;32m     41\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "\n",
      "File \u001b[1;32md:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n",
      "\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n",
      "\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n",
      "\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n",
      "\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\n",
      "File \u001b[1;32md:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n",
      "\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n",
      "\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8a5288",
   "metadata": {
    "id": "1b8a5288"
   },
   "source": [
    "Create a quick sketch of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07eb521",
   "metadata": {
    "id": "f07eb521"
   },
   "outputs": [],
   "source": [
    "# plt.plot(trainer.train_losses, color='red', label=\"Train loss\")\n",
    "# plt.plot(trainer.test_losses, color='blue', label=\"Test loss\")\n",
    "\n",
    "# plt.grid()\n",
    "# plt.legend()\n",
    "# for ind in trainer.adaptation_indices:\n",
    "#     plt.axvline(ind, ls = '--', color='grey')\n",
    "# plt.yscale('log')\n",
    "# plt.xlabel(\"Epochs\")\n",
    "# plt.xlabel(\"MSE Loss\")\n",
    "# plt.title(\"Training (100, 100) network tabular EOS for p and eps\")\n",
    "# plt.savefig(\"testing_training_tab_eos_network_100_100.pdf\", bbox_inches = 'tight')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad41d2a",
   "metadata": {
    "id": "8ad41d2a"
   },
   "source": [
    "# Archive: NNE2T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391a25b5",
   "metadata": {
    "id": "391a25b5"
   },
   "source": [
    "__NNE2T__: try to replicate the conversion from energy to temperature, which is currently done by rootfinding approximations & lookups in the EOS table (see Gmunu code). It seemed harder than I initially thought to model and train this; and in the end, I'm not sure how useful it'll be, so I'm archiving this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f48e387",
   "metadata": {
    "id": "7f48e387"
   },
   "source": [
    "Get the training data as DataSet and DataLoader objects. Note on normalization: we fit transform on the training data, then use the fitted scaler object to transform (i.e. using same transformation as the training data) the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88f2675",
   "metadata": {
    "id": "b88f2675"
   },
   "outputs": [],
   "source": [
    "# Give the names of the input vars (features) and output vars (labels)\n",
    "in_vars = [\"rho\", \"eps\", \"ye\"]\n",
    "out_vars = [\"temp\"]\n",
    "# For normalization, use sklearn's StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# Read the sampled data as pandas dataframes\n",
    "train_df = pd.read_csv(os.path.join(master_dir, \"Data/SLy4_training_data.csv\"))\n",
    "test_df  = pd.read_csv(os.path.join(master_dir, \"Data/SLy4_test_data.csv\"))\n",
    "# Convert to PyTorch Datasets as we defined them\n",
    "train_dataset = data.CustomDataset(train_df, feature_names = in_vars, label_names = out_vars, normalization_function = scaler.fit_transform) \n",
    "test_dataset  = data.CustomDataset(test_df, feature_names = in_vars, label_names = out_vars, normalization_function = scaler.transform)\n",
    "# Then create dataloaders, with batch size 32, from datasets\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32)\n",
    "test_dataloader  = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abee61f0",
   "metadata": {
    "id": "abee61f0"
   },
   "source": [
    "Create a new instance of the Net:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b990a7ff",
   "metadata": {
    "id": "b990a7ff",
    "outputId": "76d4c28e-ca6a-423d-e905-27d55d54b42e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (linear1): Linear(in_features=3, out_features=50, bias=True)\n",
       "  (activation1): Sigmoid()\n",
       "  (linear2): Linear(in_features=50, out_features=50, bias=True)\n",
       "  (activation2): Sigmoid()\n",
       "  (linear3): Linear(in_features=50, out_features=1, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net(nb_of_inputs = 3, nb_of_outputs = 1, h=[50, 50])\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312052a9",
   "metadata": {
    "id": "312052a9",
    "outputId": "18d37e9e-a86e-48e2-87bd-c82646596aeb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2800"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnc2p.count_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f23d022",
   "metadata": {
    "id": "1f23d022"
   },
   "source": [
    "Create a trainer object from it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06becda4",
   "metadata": {
    "id": "06becda4"
   },
   "outputs": [],
   "source": [
    "trainer = nnc2p.Trainer(model, 1e-1, train_dataloader=train_dataloader, test_dataloader=test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ce3bda",
   "metadata": {
    "id": "93ce3bda",
    "outputId": "f4a25ecd-bfdf-4140-b06d-6c414eaf8736"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model for 500 epochs.\n",
      "\n",
      " Epoch 0 \n",
      " --------------\n",
      "Train loss: 7.59E-01\n",
      "Test  loss: 7.62E-01\n",
      "\n",
      " Epoch 1 \n",
      " --------------\n",
      "Train loss: 9.92E-01\n",
      "Test  loss: 9.98E-01\n",
      "\n",
      " Epoch 2 \n",
      " --------------\n",
      "Train loss: 9.45E-01\n",
      "Test  loss: 9.61E-01\n",
      "\n",
      " Epoch 3 \n",
      " --------------\n",
      "Train loss: 8.24E-01\n",
      "Test  loss: 8.29E-01\n",
      "\n",
      " Epoch 4 \n",
      " --------------\n",
      "Train loss: 9.10E-01\n",
      "Test  loss: 9.16E-01\n",
      "\n",
      " Epoch 5 \n",
      " --------------\n",
      "Train loss: 8.80E-01\n",
      "Test  loss: 8.91E-01\n",
      "\n",
      " Epoch 6 \n",
      " --------------\n",
      "Train loss: 8.62E-01\n",
      "Test  loss: 8.67E-01\n",
      "\n",
      " Epoch 7 \n",
      " --------------\n",
      "Train loss: 8.20E-01\n",
      "Test  loss: 8.27E-01\n",
      "\n",
      " Epoch 8 \n",
      " --------------\n",
      "Train loss: 8.80E-01\n",
      "Test  loss: 8.94E-01\n",
      "\n",
      " Epoch 9 \n",
      " --------------\n",
      "Train loss: 9.20E-01\n",
      "Test  loss: 9.26E-01\n",
      "\n",
      " Epoch 10 \n",
      " --------------\n",
      "Train loss: 7.34E-01\n",
      "Test  loss: 7.39E-01\n",
      "\n",
      " Epoch 11 \n",
      " --------------\n",
      "Train loss: 7.48E-01\n",
      "Test  loss: 7.56E-01\n",
      "\n",
      " Epoch 12 \n",
      " --------------\n",
      "Train loss: 7.28E-01\n",
      "Test  loss: 7.31E-01\n",
      "\n",
      " Epoch 13 \n",
      " --------------\n",
      "Train loss: 8.87E-01\n",
      "Test  loss: 8.99E-01\n",
      "\n",
      " Epoch 14 \n",
      " --------------\n",
      "Train loss: 8.02E-01\n",
      "Test  loss: 8.09E-01\n",
      "\n",
      " Epoch 15 \n",
      " --------------\n",
      "Train loss: 8.11E-01\n",
      "Test  loss: 8.20E-01\n",
      "\n",
      " Epoch 16 \n",
      " --------------\n",
      "Train loss: 8.02E-01\n",
      "Test  loss: 8.08E-01\n",
      "\n",
      " Epoch 17 \n",
      " --------------\n",
      "Adapting learning rate to 0.05\n",
      "Train loss: 8.70E-01\n",
      "Test  loss: 8.79E-01\n",
      "\n",
      " Epoch 18 \n",
      " --------------\n",
      "Train loss: 6.88E-01\n",
      "Test  loss: 6.92E-01\n",
      "\n",
      " Epoch 19 \n",
      " --------------\n",
      "Train loss: 6.24E-01\n",
      "Test  loss: 6.25E-01\n",
      "\n",
      " Epoch 20 \n",
      " --------------\n",
      "Train loss: 6.42E-01\n",
      "Test  loss: 6.46E-01\n",
      "\n",
      " Epoch 21 \n",
      " --------------\n",
      "Train loss: 6.21E-01\n",
      "Test  loss: 6.25E-01\n",
      "\n",
      " Epoch 22 \n",
      " --------------\n",
      "Train loss: 6.29E-01\n",
      "Test  loss: 6.32E-01\n",
      "\n",
      " Epoch 23 \n",
      " --------------\n",
      "Train loss: 6.30E-01\n",
      "Test  loss: 6.33E-01\n",
      "\n",
      " Epoch 24 \n",
      " --------------\n",
      "Train loss: 6.13E-01\n",
      "Test  loss: 6.16E-01\n",
      "\n",
      " Epoch 25 \n",
      " --------------\n",
      "Train loss: 6.25E-01\n",
      "Test  loss: 6.27E-01\n",
      "\n",
      " Epoch 26 \n",
      " --------------\n",
      "Train loss: 6.75E-01\n",
      "Test  loss: 6.81E-01\n",
      "\n",
      " Epoch 27 \n",
      " --------------\n",
      "Train loss: 6.22E-01\n",
      "Test  loss: 6.23E-01\n",
      "\n",
      " Epoch 28 \n",
      " --------------\n",
      "Train loss: 6.77E-01\n",
      "Test  loss: 6.81E-01\n",
      "\n",
      " Epoch 29 \n",
      " --------------\n",
      "Adapting learning rate to 0.025\n",
      "Train loss: 6.98E-01\n",
      "Test  loss: 6.99E-01\n",
      "\n",
      " Epoch 30 \n",
      " --------------\n",
      "Train loss: 5.71E-01\n",
      "Test  loss: 5.74E-01\n",
      "\n",
      " Epoch 31 \n",
      " --------------\n",
      "Train loss: 5.77E-01\n",
      "Test  loss: 5.81E-01\n",
      "\n",
      " Epoch 32 \n",
      " --------------\n",
      "Train loss: 5.69E-01\n",
      "Test  loss: 5.74E-01\n",
      "\n",
      " Epoch 33 \n",
      " --------------\n",
      "Train loss: 5.65E-01\n",
      "Test  loss: 5.69E-01\n",
      "\n",
      " Epoch 34 \n",
      " --------------\n",
      "Train loss: 5.63E-01\n",
      "Test  loss: 5.67E-01\n",
      "\n",
      " Epoch 35 \n",
      " --------------\n",
      "Train loss: 5.60E-01\n",
      "Test  loss: 5.65E-01\n",
      "\n",
      " Epoch 36 \n",
      " --------------\n",
      "Train loss: 5.67E-01\n",
      "Test  loss: 5.70E-01\n",
      "\n",
      " Epoch 37 \n",
      " --------------\n",
      "Train loss: 5.58E-01\n",
      "Test  loss: 5.60E-01\n",
      "\n",
      " Epoch 38 \n",
      " --------------\n",
      "Train loss: 5.62E-01\n",
      "Test  loss: 5.66E-01\n",
      "\n",
      " Epoch 39 \n",
      " --------------\n",
      "Train loss: 5.62E-01\n",
      "Test  loss: 5.66E-01\n",
      "\n",
      " Epoch 40 \n",
      " --------------\n",
      "Train loss: 5.62E-01\n",
      "Test  loss: 5.64E-01\n",
      "\n",
      " Epoch 41 \n",
      " --------------\n",
      "Train loss: 5.73E-01\n",
      "Test  loss: 5.75E-01\n",
      "\n",
      " Epoch 42 \n",
      " --------------\n",
      "Adapting learning rate to 0.0125\n",
      "Train loss: 5.69E-01\n",
      "Test  loss: 5.73E-01\n",
      "\n",
      " Epoch 43 \n",
      " --------------\n",
      "Train loss: 4.89E-01\n",
      "Test  loss: 4.92E-01\n",
      "\n",
      " Epoch 44 \n",
      " --------------\n",
      "Train loss: 4.87E-01\n",
      "Test  loss: 4.91E-01\n",
      "\n",
      " Epoch 45 \n",
      " --------------\n",
      "Train loss: 4.86E-01\n",
      "Test  loss: 4.91E-01\n",
      "\n",
      " Epoch 46 \n",
      " --------------\n",
      "Train loss: 4.83E-01\n",
      "Test  loss: 4.88E-01\n",
      "\n",
      " Epoch 47 \n",
      " --------------\n",
      "Train loss: 4.80E-01\n",
      "Test  loss: 4.85E-01\n",
      "\n",
      " Epoch 48 \n",
      " --------------\n",
      "Train loss: 4.78E-01\n",
      "Test  loss: 4.83E-01\n",
      "\n",
      " Epoch 49 \n",
      " --------------\n",
      "Train loss: 4.77E-01\n",
      "Test  loss: 4.81E-01\n",
      "\n",
      " Epoch 50 \n",
      " --------------\n",
      "Train loss: 4.75E-01\n",
      "Test  loss: 4.79E-01\n",
      "\n",
      " Epoch 51 \n",
      " --------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[118], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[1;32md:\\Coding\\master-thesis-AI\\Code\\nnc2p.py:407\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, adaptation_threshold, adaptation_multiplier, number_of_epochs, log_file, csv_file)\u001b[0m\n\u001b[0;32m    405\u001b[0m write_to_txt(log_file, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m Epoch \u001b[39m\u001b[39m{\u001b[39;00mepoch_counter\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m --------------\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    406\u001b[0m \u001b[39m# Train the network\u001b[39;00m\n\u001b[1;32m--> 407\u001b[0m train_loop(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_dataloader, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss_fn, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer, use_c2p_loss\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49muse_c2p_loss)\n\u001b[0;32m    408\u001b[0m \u001b[39m# Test on the training data\u001b[39;00m\n\u001b[0;32m    409\u001b[0m average_train_loss \u001b[39m=\u001b[39m test_loop(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_dataloader, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_fn)\n",
      "File \u001b[1;32md:\\Coding\\master-thesis-AI\\Code\\nnc2p.py:277\u001b[0m, in \u001b[0;36mtrain_loop\u001b[1;34m(dataloader, model, loss_fn, optimizer, report_progress, use_c2p_loss)\u001b[0m\n\u001b[0;32m    274\u001b[0m size \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(dataloader\u001b[39m.\u001b[39mdataset)\n\u001b[0;32m    275\u001b[0m \u001b[39mfor\u001b[39;00m batch, (X, y) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataloader):\n\u001b[0;32m    276\u001b[0m     \u001b[39m# Compute prediction \u001b[39;00m\n\u001b[1;32m--> 277\u001b[0m     prediction \u001b[39m=\u001b[39m model(X)\n\u001b[0;32m    278\u001b[0m     \u001b[39m# In case we use C2P loss function, have to provide conserved variables for the loss computation\u001b[39;00m\n\u001b[0;32m    279\u001b[0m     \u001b[39mif\u001b[39;00m use_c2p_loss:\n",
      "File \u001b[1;32md:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[25], line 39\u001b[0m, in \u001b[0;36mNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[39mif\u001b[39;00m i \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     38\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m     x \u001b[39m=\u001b[39m module(x)\n\u001b[0;32m     41\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32md:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc2a130",
   "metadata": {
    "id": "8cc2a130"
   },
   "source": [
    "Create a quick sketch of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5338413",
   "metadata": {
    "id": "c5338413"
   },
   "outputs": [],
   "source": [
    "# plt.plot(trainer.train_losses, color='red', label=\"Train loss\")\n",
    "# plt.plot(trainer.test_losses, color='blue', label=\"Test loss\")\n",
    "\n",
    "# plt.grid()\n",
    "# plt.legend()\n",
    "# for ind in trainer.adaptation_indices:\n",
    "#     plt.axvline(ind, ls = '--', color='grey')\n",
    "# plt.yscale('log')\n",
    "# plt.xlabel(\"Epochs\")\n",
    "# plt.xlabel(\"MSE Loss\")\n",
    "# plt.title(\"Training (100, 100) network tabular EOS for p and eps\")\n",
    "# plt.savefig(\"testing_training_tab_eos_network_100_100.pdf\", bbox_inches = 'tight')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "author": "Thibeau Wouters",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
