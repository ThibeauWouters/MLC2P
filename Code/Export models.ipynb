{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af563537",
   "metadata": {},
   "source": [
    "%%latex\n",
    "\\tableofcontents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bb9f224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Thibeau\\master-thesis-AI\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "import random\n",
    "import csv\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "# import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.cm as cm\n",
    "import pickle\n",
    "import os\n",
    "# Own modules:\n",
    "import physics\n",
    "import data\n",
    "from data import CustomDataset\n",
    "import nnc2p\n",
    "# Get master directory\n",
    "master_dir = os.path.normpath(os.path.join(os.getcwd(), '..'))\n",
    "print(master_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4687804",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3b2e02",
   "metadata": {},
   "source": [
    "This notebook is a complete mess, so please don't look at it, this is just my playground to quickly test a few nets, and export hem etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dff221f",
   "metadata": {},
   "source": [
    "# Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "374edfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements a simple feedforward neural network.\n",
    "    \"\"\"\n",
    "    def __init__(self, h: list = [3, 600, 200, 1], activation_function = nn.Sigmoid, output_bias=True) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the neural network class.\n",
    "        \"\"\"\n",
    "        # Call the super constructor first\n",
    "        super(FeedForwardNetwork, self).__init__()\n",
    "\n",
    "        # For convenience, save the sizes of the hidden layers as fields as well\n",
    "        self.h = h\n",
    "\n",
    "        # Define the layers:\n",
    "        for i in range(len(self.h)-1):\n",
    "            if i == len(self.h)-2:\n",
    "                setattr(self, f\"linear{i+1}\", nn.Linear(self.h[i], self.h[i+1], bias=output_bias))\n",
    "            else:\n",
    "                setattr(self, f\"linear{i+1}\", nn.Linear(self.h[i], self.h[i+1]))\n",
    "                setattr(self, f\"activation{i+1}\", activation_function())\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Computes a forward step given the input x.\n",
    "        :param x: Input for the neural network.\n",
    "        :return: x: Output neural network\n",
    "        \"\"\"\n",
    "\n",
    "        for i, module in enumerate(self.modules()):\n",
    "            # The first module is the whole NNC2P object, continue\n",
    "            if i == 0:\n",
    "                continue\n",
    "            x = module(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1bfa94c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements a simple feedforward neural network.\n",
    "    \"\"\"\n",
    "    def __init__(self, h: list = [3, 600, 200, 1], activation_function = nn.Sigmoid, output_bias=True) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the neural network class.\n",
    "        \"\"\"\n",
    "        # Call the super constructor first\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        # For convenience, save the sizes of the hidden layers as fields as well\n",
    "        self.h = h\n",
    "\n",
    "        # Define the layers:\n",
    "        for i in range(len(self.h)-1):\n",
    "            if i == len(self.h)-2:\n",
    "                setattr(self, f\"linear{i+1}\", nn.Linear(self.h[i], self.h[i+1], bias=output_bias))\n",
    "            else:\n",
    "                setattr(self, f\"linear{i+1}\", nn.Linear(self.h[i], self.h[i+1]))\n",
    "                setattr(self, f\"activation{i+1}\", activation_function())\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Computes a forward step given the input x.\n",
    "        :param x: Input for the neural network.\n",
    "        :return: x: Output neural network\n",
    "        \"\"\"\n",
    "\n",
    "        for i, module in enumerate(self.modules()):\n",
    "            # The first module is the whole NNC2P object, continue\n",
    "            if i == 0:\n",
    "                continue\n",
    "            x = module(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88888cdd",
   "metadata": {},
   "source": [
    "# Update: using the ONNX format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e57225",
   "metadata": {},
   "source": [
    "(Semester 2) I'm exporting a model again, now in ONNX format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd101c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (linear1): Linear(in_features=3, out_features=504, bias=True)\n",
       "  (linear2): Linear(in_features=504, out_features=127, bias=True)\n",
       "  (linear3): Linear(in_features=127, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a model\n",
    "state_dict = torch.load(\"finetuned_most_pruned.pth\")\n",
    "model = nnc2p.create_nn(state_dict)\n",
    "model = model.float()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cf5442b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(model, torch.randn(3).float(), \"pruned_model.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9164f66c",
   "metadata": {},
   "source": [
    "Testing the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5a4801a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rho</th>\n",
       "      <th>eps</th>\n",
       "      <th>v</th>\n",
       "      <th>p</th>\n",
       "      <th>D</th>\n",
       "      <th>S</th>\n",
       "      <th>tau</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.836323</td>\n",
       "      <td>1.962039</td>\n",
       "      <td>0.266066</td>\n",
       "      <td>12.866164</td>\n",
       "      <td>10.204131</td>\n",
       "      <td>12.026585</td>\n",
       "      <td>22.131297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        rho       eps         v          p          D          S        tau\n",
       "0  9.836323  1.962039  0.266066  12.866164  10.204131  12.026585  22.131297"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../Data/ideal_gas_c2p_test_data.csv\")\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28854fc9",
   "metadata": {},
   "source": [
    "Get a first input for the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "374dec08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.20413115, 12.02658484, 22.13129693])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([df[\"D\"][0], df[\"S\"][0], df[\"tau\"][0]])\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4770318",
   "metadata": {},
   "source": [
    "Check inference on model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07f48643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.866582\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    out = model(torch.from_numpy(x).float()).numpy()\n",
    "    print(out[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ad98f1ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear1.weight',\n",
       "              tensor([[-0.3666,  0.4540, -0.4352],\n",
       "                      [ 0.0356,  0.9699,  0.4002],\n",
       "                      [ 0.1087, -0.0912,  0.1072],\n",
       "                      ...,\n",
       "                      [ 0.5475, -0.5256, -0.2971],\n",
       "                      [-0.4310, -0.1393,  0.2783],\n",
       "                      [ 0.6337, -0.3134,  0.0312]])),\n",
       "             ('linear1.bias',\n",
       "              tensor([ 5.6061e-01,  2.4333e-01, -7.7467e-01, -3.2593e-01,  4.9073e-02,\n",
       "                       7.0926e-03,  2.2542e-01, -5.3934e-01,  2.5813e-01, -3.1620e-01,\n",
       "                      -4.9130e-01, -3.7876e-01, -2.5505e-01,  7.9304e-01,  7.3299e-01,\n",
       "                       1.0455e-01,  8.8842e-01,  1.4683e-01, -4.3929e-01, -3.4603e-01,\n",
       "                      -6.0459e-01, -7.6528e-01, -4.8161e-01, -4.2301e-01, -1.1967e-01,\n",
       "                      -7.1304e-01,  2.7122e-01,  1.1723e-01,  5.4620e-01, -1.7614e-01,\n",
       "                      -1.1986e-02, -3.2823e-01, -1.2451e-01, -2.4551e-01,  5.5276e-01,\n",
       "                      -1.3098e-01,  3.2348e-01, -5.8645e-01,  5.6136e-02, -2.5985e-01,\n",
       "                       3.8681e-01,  8.3229e-01, -2.3454e-01,  5.3122e-01,  4.7994e-03,\n",
       "                       1.4047e-01, -3.4001e-01,  2.0402e-01,  6.8717e-02, -7.6738e-01,\n",
       "                       7.2325e-01,  4.5350e-01,  1.4957e-01, -7.9855e-01, -6.0024e-01,\n",
       "                       5.3511e-01, -4.5407e-01, -5.5787e-01,  2.6786e-01, -5.6681e-01,\n",
       "                      -1.8479e-01,  6.8825e-01, -1.0905e-01, -2.3895e-01,  5.6507e-01,\n",
       "                      -2.4706e-01, -8.0426e-02, -2.7791e-01,  1.4884e-01, -3.7208e-01,\n",
       "                      -5.0654e-01,  1.5907e-01,  9.4968e-02, -2.5627e-01,  2.5145e-01,\n",
       "                       9.9624e-02,  6.1657e-01, -1.6875e-01,  4.0218e-01, -7.7376e-01,\n",
       "                       9.7056e-02,  7.6158e-03,  4.0075e-01,  3.5677e-04, -5.5413e-01,\n",
       "                      -6.7252e-01, -1.5020e-01, -5.0897e-01, -4.4934e-01, -6.6589e-01,\n",
       "                      -8.1114e-01,  8.5806e-01, -4.1454e-01, -9.7778e-02, -9.7389e-02,\n",
       "                       9.8068e-02, -3.0615e-01, -2.3949e-02, -1.6122e-01,  4.6998e-01,\n",
       "                      -5.5137e-01, -6.1980e-01, -3.9145e-01,  8.6247e-02,  5.5046e-01,\n",
       "                       1.5668e-01, -2.7502e-01, -1.8127e-01, -4.9198e-01, -2.0787e-01,\n",
       "                       1.6453e-01, -2.4607e-01,  5.3280e-01, -7.8030e-01,  7.3768e-01,\n",
       "                      -4.4428e-02,  4.1386e-01,  2.6073e-01, -5.3616e-01, -6.7525e-01,\n",
       "                      -6.2794e-01, -3.0024e-02,  1.9229e-01, -4.0597e-03,  5.8490e-01,\n",
       "                       1.2414e-01, -6.2282e-01, -3.3803e-01, -4.7853e-01,  1.5441e-01,\n",
       "                       6.4502e-01,  6.5766e-01, -5.5193e-01, -7.5390e-01,  1.3894e-01,\n",
       "                       9.8502e-01,  1.8964e-01,  5.1192e-01,  1.9887e-01,  2.5534e-01,\n",
       "                       6.9651e-01,  2.3346e-01,  7.9083e-01,  2.2313e-01,  6.2242e-01,\n",
       "                       3.0691e-01,  4.4167e-02, -5.8303e-01, -6.7877e-01, -3.1687e-01,\n",
       "                      -2.7313e-01, -5.5454e-01, -5.9223e-01,  6.7415e-01, -5.3458e-02,\n",
       "                      -3.2087e-01, -2.8056e-01,  1.4163e-01,  8.2622e-01, -6.9740e-02,\n",
       "                      -1.1789e-01, -3.5249e-01,  2.2896e-01,  8.9731e-02, -3.4253e-01,\n",
       "                      -5.8954e-01, -2.2534e-01,  3.8568e-01, -5.1930e-01,  1.9953e-01,\n",
       "                       6.1900e-03,  2.6773e-01, -6.8539e-01, -2.8038e-01, -3.7443e-01,\n",
       "                       3.5219e-01, -6.6597e-02, -7.2470e-02,  3.8389e-01, -2.4917e-01,\n",
       "                       2.9217e-01, -8.1484e-01, -4.2813e-02, -1.1196e-01, -6.4715e-01,\n",
       "                      -4.2079e-01,  5.5912e-02,  4.5545e-01,  2.4642e-01, -5.7082e-02,\n",
       "                       4.4132e-01,  3.0203e-01,  3.8295e-01, -8.3331e-01, -7.9781e-02,\n",
       "                      -3.6571e-01,  2.6059e-01,  2.8052e-01,  2.1758e-01, -7.8758e-01,\n",
       "                      -1.4521e-01,  1.0382e-01, -4.5079e-01, -4.8731e-01,  3.5570e-02,\n",
       "                      -6.6347e-01,  8.1051e-02,  4.9484e-01,  3.5027e-01, -3.8311e-01,\n",
       "                      -5.3328e-01, -3.4040e-01,  1.6403e-01, -7.8798e-01, -4.3605e-01,\n",
       "                      -2.1721e-01,  4.9041e-01, -2.2180e-01, -1.7955e-01,  3.9273e-01,\n",
       "                      -1.5853e-01, -7.3876e-02,  3.8864e-02, -6.2598e-02, -8.1087e-02,\n",
       "                      -1.9798e-01, -6.5552e-01, -5.6502e-01,  3.7701e-01, -3.4392e-01,\n",
       "                       8.2957e-02, -4.8004e-01, -4.6550e-02, -5.9087e-01,  3.6662e-02,\n",
       "                       3.4451e-01, -8.8631e-02, -5.3218e-01, -7.9140e-02,  3.0321e-02,\n",
       "                       1.8166e-02, -1.5071e-01,  2.6164e-01, -6.4562e-02, -7.7570e-01,\n",
       "                       7.2120e-01, -8.5811e-01,  6.0622e-02, -4.8881e-02,  2.1444e-01,\n",
       "                      -5.9472e-01,  3.2926e-01,  7.5049e-01, -2.9735e-01, -4.2053e-01,\n",
       "                      -4.7628e-01,  7.4014e-01, -2.4838e-01, -2.9999e-01, -7.9381e-01,\n",
       "                      -5.7938e-01,  6.5448e-01,  5.6605e-01, -1.5443e-02, -7.7997e-01,\n",
       "                      -4.0222e-01, -1.9633e-01,  8.7221e-01, -2.4332e-01, -3.8246e-01,\n",
       "                       2.6872e-02, -1.7040e-01, -1.9700e-01, -5.1869e-01, -8.3258e-01,\n",
       "                      -5.2976e-01, -2.3812e-01,  4.4821e-02, -2.0142e-02, -5.2488e-02,\n",
       "                      -6.7306e-01, -7.7793e-02,  8.1652e-03,  4.9168e-02,  3.8233e-01,\n",
       "                       1.7576e-01, -6.6489e-01, -6.6914e-02,  1.8089e-01, -3.5073e-01,\n",
       "                       6.0601e-01,  6.7418e-01, -5.1596e-01, -4.4838e-02, -1.4989e-02,\n",
       "                       5.6407e-01, -5.0503e-01,  1.0544e-01,  1.3190e-02,  5.4493e-01,\n",
       "                      -1.4568e-01, -1.6339e-04,  8.3324e-02, -2.6391e-01,  1.2711e-01,\n",
       "                       1.7127e-01,  5.0796e-02, -4.1261e-01,  3.2490e-01,  2.7839e-01,\n",
       "                      -3.8546e-01,  1.4934e-01,  3.3574e-01, -4.5479e-01, -3.8480e-01,\n",
       "                       2.7638e-01,  4.5449e-01,  4.5720e-01,  2.5101e-01,  4.7465e-01,\n",
       "                      -3.1147e-01, -6.8385e-02,  8.2914e-01,  2.4961e-02, -4.9627e-01,\n",
       "                       2.0639e-01, -1.5687e-01,  4.2896e-01, -7.5359e-01,  3.9584e-01,\n",
       "                      -1.3844e-01,  5.7653e-01, -6.2221e-01, -1.2231e-01, -8.9451e-01,\n",
       "                      -1.9282e-01,  4.3169e-01,  6.8659e-01,  5.0441e-01, -8.1701e-02,\n",
       "                       2.0244e-01,  5.0619e-01, -5.5520e-01, -5.9935e-01,  8.1521e-01,\n",
       "                       6.0223e-01,  1.6424e-01,  2.3404e-01, -6.3086e-01,  4.0273e-01,\n",
       "                      -1.1020e-01, -4.9546e-01, -3.3658e-02, -3.8937e-01, -2.1455e-01,\n",
       "                      -3.4698e-01,  7.5002e-01, -1.0651e-01,  7.2249e-01, -7.4550e-01,\n",
       "                      -5.1744e-01,  5.1015e-01, -7.6862e-01,  5.4379e-02,  1.4252e-01,\n",
       "                       1.5078e-01,  2.2445e-02, -4.9472e-01,  8.2544e-01, -1.2985e-02,\n",
       "                      -1.1099e-01, -6.5773e-01,  7.8922e-01, -4.5647e-01, -2.0565e-01,\n",
       "                       1.8342e-01, -3.6585e-01,  2.3095e-01,  2.2266e-01, -6.6948e-02,\n",
       "                      -1.4292e-01,  4.6304e-01,  2.7524e-01, -2.6237e-01,  5.2672e-01,\n",
       "                       2.7830e-01, -3.2785e-02, -2.4114e-01, -6.4739e-01,  4.9275e-01,\n",
       "                      -5.5368e-01, -2.8899e-01,  7.5072e-01,  8.0340e-01, -2.1609e-01,\n",
       "                       6.1026e-01,  6.6894e-02,  7.5997e-01,  5.9304e-02,  2.0161e-01,\n",
       "                      -5.3993e-01, -1.3188e-01,  3.8199e-01,  3.9901e-01, -5.9074e-01,\n",
       "                      -6.5068e-01, -6.8939e-01, -7.4917e-01, -2.7302e-01,  1.5330e-01,\n",
       "                       1.3607e-01,  4.7892e-01, -2.3037e-01, -5.8969e-01,  6.3816e-01,\n",
       "                      -3.4101e-01,  1.8069e-01,  4.8082e-01, -3.5878e-01,  4.6800e-01,\n",
       "                       5.3187e-01,  2.2503e-01, -3.7638e-01, -2.0842e-01,  3.8425e-01,\n",
       "                      -3.3656e-01, -4.2364e-01,  2.6078e-01,  1.8838e-01,  3.7220e-01,\n",
       "                       1.4417e-01, -1.0077e-01, -1.0681e-01,  1.2787e-01,  3.7760e-01,\n",
       "                      -2.5847e-02,  2.6523e-01,  6.8195e-01, -4.9772e-01,  1.4203e-01,\n",
       "                      -7.0256e-01, -3.8349e-01,  2.2317e-01,  4.7887e-01, -4.4954e-02,\n",
       "                       5.8802e-01, -5.2608e-01, -1.8691e-01, -3.9720e-01,  5.5767e-02,\n",
       "                       2.2479e-01,  1.5030e-01, -4.8814e-01, -1.8910e-01, -2.3814e-01,\n",
       "                      -5.6490e-02,  3.1868e-01, -1.0439e-01, -2.5642e-01, -5.2558e-02,\n",
       "                      -9.7838e-03,  5.0738e-02,  4.8262e-01,  4.6405e-01, -7.9877e-01,\n",
       "                      -1.6047e-01,  8.0333e-01,  6.2192e-01, -3.2752e-01, -2.9073e-02,\n",
       "                       5.5172e-01, -7.0825e-01,  6.4921e-01, -4.7262e-01,  2.3057e-01,\n",
       "                      -1.8620e-01, -2.9797e-01,  3.4108e-01,  2.6027e-01, -1.0116e-02,\n",
       "                       1.7032e-01,  3.6078e-01,  2.2924e-03,  8.2963e-01, -8.0770e-01,\n",
       "                       1.2874e-01,  5.9890e-01,  9.3857e-02,  5.7788e-01, -3.0665e-01,\n",
       "                      -2.2959e-01,  3.9055e-01, -3.5936e-01, -3.8635e-01,  2.9675e-01,\n",
       "                       5.4247e-01,  1.4175e-01, -2.3542e-01, -4.5953e-01,  6.5254e-01,\n",
       "                      -1.8286e-01,  7.3629e-01, -6.9211e-01, -1.7368e-01])),\n",
       "             ('linear2.weight',\n",
       "              tensor([[-0.1975,  0.0353,  0.0494,  ..., -0.1239,  0.0699, -0.0145],\n",
       "                      [-0.4241, -0.0561,  0.0716,  ..., -0.2802,  0.1693, -0.0044],\n",
       "                      [ 0.1471, -0.0358, -0.0640,  ...,  0.0976, -0.0556, -0.0480],\n",
       "                      ...,\n",
       "                      [-0.2535, -0.0136,  0.0662,  ..., -0.0097,  0.0494, -0.0094],\n",
       "                      [-0.2617, -0.0677,  0.0799,  ..., -0.0303,  0.0620,  0.0430],\n",
       "                      [-0.1746,  0.0117,  0.0723,  ..., -0.0221,  0.0402, -0.0008]])),\n",
       "             ('linear2.bias',\n",
       "              tensor([-0.0300, -0.0085, -0.0241,  0.0045, -0.0497,  0.0358, -0.0348,  0.0416,\n",
       "                       0.0006, -0.0533, -0.0059, -0.0452, -0.0490, -0.0718, -0.0193, -0.0061,\n",
       "                      -0.0623,  0.0067,  0.0112, -0.0616,  0.0002, -0.0232, -0.0453,  0.0438,\n",
       "                      -0.0642, -0.0277,  0.0230, -0.0351, -0.0443,  0.0093, -0.0409,  0.0191,\n",
       "                       0.0319, -0.0232,  0.0492, -0.0231,  0.0078, -0.0039, -0.0186,  0.0386,\n",
       "                       0.0195, -0.0284,  0.0273,  0.0323,  0.0024, -0.0493, -0.0524, -0.0335,\n",
       "                      -0.0273, -0.0532,  0.0267,  0.0069,  0.0181, -0.0636,  0.0055, -0.0193,\n",
       "                       0.0277,  0.0011,  0.0368, -0.0007,  0.0060,  0.0059,  0.0064, -0.0231,\n",
       "                      -0.0267, -0.0249,  0.0117, -0.0349,  0.0416, -0.0025,  0.0137, -0.0035,\n",
       "                      -0.0041, -0.0428,  0.0353,  0.0131,  0.0087, -0.0124,  0.0059,  0.0283,\n",
       "                      -0.0612,  0.0239,  0.0179,  0.0107,  0.0102,  0.0181,  0.0094,  0.0259,\n",
       "                      -0.0393,  0.0382, -0.0052,  0.0420, -0.0020, -0.0486, -0.0345, -0.0424,\n",
       "                       0.0024, -0.0560,  0.0400,  0.0057, -0.0556,  0.0243, -0.0183, -0.0325,\n",
       "                      -0.0495,  0.0488,  0.0240,  0.0243,  0.0174,  0.0286,  0.0159, -0.0456,\n",
       "                       0.0775, -0.0148,  0.0138,  0.0292,  0.0039, -0.0163,  0.0299, -0.0100,\n",
       "                       0.0749, -0.0488, -0.0056,  0.0238,  0.0060,  0.0120, -0.0412])),\n",
       "             ('linear3.weight',\n",
       "              tensor([[ 0.1659,  0.4207, -0.0723,  0.1485,  0.1768,  0.1228,  0.1697,  0.1643,\n",
       "                        0.1911,  0.2465,  0.1654,  0.1752, -0.1662,  0.2802,  0.1686,  0.1902,\n",
       "                       -0.0697, -0.0929, -0.0764,  0.2651, -0.0498,  0.1440, -0.0490,  0.0517,\n",
       "                        0.2108,  0.1801,  0.1701,  0.1790,  0.1938,  0.2001,  0.1823, -0.0895,\n",
       "                        0.1778,  0.1762,  0.1151,  0.1629,  0.1878, -0.0915,  0.1676,  0.1819,\n",
       "                        0.1876,  0.1844,  0.1468,  0.1705,  0.1832,  0.2991, -0.0671,  0.2047,\n",
       "                        0.3116,  0.1763,  0.1865,  0.2152,  0.1803,  0.1918,  0.1751,  0.1733,\n",
       "                        0.1802,  0.1476,  0.1857, -0.0661,  0.1681, -0.0706,  0.2169,  0.2045,\n",
       "                        0.1892,  0.1710,  0.1808,  0.2226,  0.1674,  0.1740,  0.2237,  0.1709,\n",
       "                       -0.0659,  0.1645,  0.1679,  0.1800, -0.0801, -0.0788,  0.1589,  0.1485,\n",
       "                        0.1957,  0.1487,  0.2049,  0.1854,  0.2007, -0.0776,  0.1780, -0.0816,\n",
       "                        0.1797,  0.1808,  0.1911,  0.1353,  0.2493,  0.1800,  0.1730,  0.2371,\n",
       "                       -0.0678,  0.1777,  0.1875,  0.1714,  0.2067,  0.2462,  0.1672,  0.1643,\n",
       "                        0.1753,  0.0615,  0.1566, -0.0823,  0.1724,  0.1716,  0.1895, -0.0603,\n",
       "                        0.2348,  0.1817,  0.1633,  0.1655, -0.0646, -0.0465,  0.1554,  0.1483,\n",
       "                        0.1100, -0.0740, -0.0917,  0.1508,  0.2362,  0.2279,  0.1881]])),\n",
       "             ('linear3.bias', tensor([0.1283]))])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdab96d",
   "metadata": {},
   "source": [
    "__NOTE__ The most recent architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83934a2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5fcb16a6",
   "metadata": {},
   "source": [
    "__NOTE__ the best & most pruned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "306b82e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for FeedForwardNetwork:\n\tMissing key(s) in state_dict: \"linear3.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m new_model \u001b[38;5;241m=\u001b[39m FeedForwardNetwork(h\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m3\u001b[39m])\n\u001b[1;32m----> 2\u001b[0m \u001b[43mnew_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnn_tabeos_3_50_50_3.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1671\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   1666\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   1667\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1668\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[0;32m   1670\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1671\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1672\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   1673\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for FeedForwardNetwork:\n\tMissing key(s) in state_dict: \"linear3.bias\". "
     ]
    }
   ],
   "source": [
    "new_model = FeedForwardNetwork(h=[3, 504, 127, 1])\n",
    "new_model.load_state_dict(torch.load(\"new_finetuned_most_pruned.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8efb4ddb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([df[\"D\"][0], df[\"S\"][0], df[\"tau\"][0]])\n",
    "x\n",
    "x = np.ones((1,3))\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74405938",
   "metadata": {},
   "source": [
    "Check inference on model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "282f617a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4520222]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    out = new_model(torch.from_numpy(x).float()).numpy()\n",
    "    print(out[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834c71b4",
   "metadata": {},
   "source": [
    "to save ENTIRE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a080ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(new_model, \"new_finetuned_most_pruned.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810ba7c5",
   "metadata": {},
   "source": [
    "Testing PyTorch load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49752c4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'FeedForwardNetwork' on <module '__main__'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m test \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnew_finetuned_most_pruned.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m test\n",
      "File \u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:789\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[0;32m    787\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    788\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m--> 789\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _load(opened_zipfile, map_location, pickle_module, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[0;32m    790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n\u001b[0;32m    791\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:1131\u001b[0m, in \u001b[0;36m_load\u001b[1;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1129\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[0;32m   1130\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[1;32m-> 1131\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1133\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[0;32m   1135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:1124\u001b[0m, in \u001b[0;36m_load.<locals>.UnpicklerWrapper.find_class\u001b[1;34m(self, mod_name, name)\u001b[0m\n\u001b[0;32m   1122\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1123\u001b[0m mod_name \u001b[38;5;241m=\u001b[39m load_module_mapping\u001b[38;5;241m.\u001b[39mget(mod_name, mod_name)\n\u001b[1;32m-> 1124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can't get attribute 'FeedForwardNetwork' on <module '__main__'>"
     ]
    }
   ],
   "source": [
    "test = torch.load(\"new_finetuned_most_pruned.pt\")\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f9e2da",
   "metadata": {},
   "source": [
    "# Use pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ec784f",
   "metadata": {},
   "source": [
    "We use pickle to save the whole neural net object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dd44c8",
   "metadata": {},
   "source": [
    "We redefine the architecture such that it can be used without nnc2p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f38b0204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"Our network architecture\"\"\"\n",
    "# class NeuralNetwork(nn.Module):\n",
    "#     \"\"\"\n",
    "#     Implements a two-layered neural network for the C2P conversion. Note that hence the number of layers is fixed\n",
    "#     for this NN subclass! The activation functions are sigmoids.\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, h1: int = 600, h2: int = 200) -> None:\n",
    "#         \"\"\"\n",
    "#         Initialize the neural network class.\n",
    "#         :param name: String that names this network, in order to recognize it later on.\n",
    "#         :param h1: Size (number of neurons) of the first hidden layer.\n",
    "#         :param h2: Size (number of neurons) of the second hidden layer.\n",
    "#         \"\"\"\n",
    "#         # Call the super constructor first\n",
    "#         super(NeuralNetwork, self).__init__()\n",
    "\n",
    "#         # For convenience, save the sizes of the hidden layers as fields as well\n",
    "#         self.h1 = h1\n",
    "#         self.h2 = h2\n",
    "\n",
    "#         # Define the weights:\n",
    "#         self.linear1 = nn.Linear(3, h1)\n",
    "#         self.linear2 = nn.Linear(h1, h2)\n",
    "#         self.linear3 = nn.Linear(h2, 1)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         \"\"\"\n",
    "#         Computes a forward step given the input x.\n",
    "#         :param x: Input for the neural network.\n",
    "#         :return: x: Output neural network\n",
    "#         \"\"\"\n",
    "\n",
    "#         x = self.linear1(x)\n",
    "#         x = torch.sigmoid(x)\n",
    "#         x = self.linear2(x)\n",
    "#         x = torch.sigmoid(x)\n",
    "#         x = self.linear3(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a880ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Two auxiliary functions are needed to load the weights from the state dict into a fresh network\n",
    "# def get_hidden_sizes_from_state_dict(state_dict):\n",
    "#     \"\"\"\n",
    "#     Finds the sizes of the two hidden layers of our 2-layer architecture given a state dict.\n",
    "#     :param state_dict: State dict of saved parameters\n",
    "#     :return: h1, size of first hidden layer, and h2, size of second hidden layer\n",
    "#     \"\"\"\n",
    "#     h1 = np.shape(state_dict['linear1.bias'])[0]\n",
    "#     h2 = np.shape(state_dict['linear2.bias'])[0]\n",
    "\n",
    "#     return h1, h2\n",
    "\n",
    "# def create_nn(state_dict):\n",
    "#     \"\"\"\n",
    "#     Create a NeuralNetwork object if given a dictionary of the weights, with correct sizes for hidden layers.\n",
    "#     :param state_dict: State dictionary containing the weights of the neural network\n",
    "#     :return:\n",
    "#     \"\"\"\n",
    "#     h1, h2 = get_hidden_sizes_from_state_dict(state_dict)\n",
    "#     model = NeuralNetwork(h1=h1, h2=h2)\n",
    "#     model.load_state_dict(state_dict)\n",
    "\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45bc63f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (linear1): Linear(in_features=3, out_features=504, bias=True)\n",
       "  (linear2): Linear(in_features=504, out_features=127, bias=True)\n",
       "  (linear3): Linear(in_features=127, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = torch.load(\"finetuned_most_pruned.pth\")\n",
    "model = create_nn(state_dict)\n",
    "model = model.float()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4aef531f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Open a file and use dump()\n",
    "# filename = \"model.pkl\"\n",
    "# with open(filename, 'wb') as file:\n",
    "      \n",
    "#     # A new file will be created\n",
    "#     pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4237279c",
   "metadata": {},
   "source": [
    "Check: to load again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f988d362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (linear1): Linear(in_features=3, out_features=504, bias=True)\n",
      "  (linear2): Linear(in_features=504, out_features=127, bias=True)\n",
      "  (linear3): Linear(in_features=127, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# # Open the file in binary mode\n",
    "# with open(filename, 'rb') as file:\n",
    "      \n",
    "#     # Call load method to deserialze\n",
    "#     test = pickle.load(file)\n",
    "  \n",
    "#     print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decbc7e7",
   "metadata": {},
   "source": [
    "# Most recent model for tabulated EOS/NN assist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014008fc",
   "metadata": {},
   "source": [
    "Load the tabulated EOS for (50, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6745d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = [3, 10, 10, 1]\n",
    "model = Net(h=h, output_bias=False).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e87d7d7",
   "metadata": {},
   "source": [
    "For neural nets assist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6418e813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(os.path.join(master_dir, \"Models/NNassist_10_10.pth\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43782dc4",
   "metadata": {},
   "source": [
    "Most recent architecture for NNEOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e81a17c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.load_state_dict(torch.load(\"nn_tabeos_3_50_50_3.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcceeebc",
   "metadata": {},
   "source": [
    "# (Archive) Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d04d5a",
   "metadata": {},
   "source": [
    "This is the model architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40ee3cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters of the model here. Will first of all put two hidden layers\n",
    "# total of 800 neurons for the one in the paper\n",
    "device = \"cpu\"\n",
    "size_HL_1 = 600\n",
    "size_HL_2 = 200\n",
    "\n",
    "# Implement neural network\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        #self.flatten = nn.Flatten()\n",
    "        self.stack = nn.Sequential(\n",
    "            nn.Linear(3, size_HL_1),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(size_HL_1, size_HL_2),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(size_HL_2, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # No flatten needed, as our input and output are 1D?\n",
    "        #x = self.flatten(x) \n",
    "        logits = self.stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9071780a",
   "metadata": {},
   "source": [
    "We import NNC2Pv0, which was on par with the models in the paper. The t2 version is trained a bit longer than the version of the paper. Use OS to locate the Models folder correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9341324c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models folder: D:\\Coding\\master-thesis-AI\\Models\n"
     ]
    }
   ],
   "source": [
    "# # Directory of current file:\n",
    "# dir_path = os.path.abspath(\"D:\\Coding\\master-thesis-AI\\Code\\Semester 1\")\n",
    "# # Models folder\n",
    "# models_folder =os.path.abspath(\"D:\\Coding\\master-thesis-AI\\Models\")\n",
    "# print(\"Models folder: \" + models_folder)\n",
    "# # Move to the models folder\n",
    "# os.chdir(models_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e1c29f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move to the correct folder\n",
    "file_location = os.chdir(\"D:\\Coding\\master-thesis-AI\\Models\")\n",
    "NNC2P = torch.load(\"NNC2Pv0t2.pth\")\n",
    "model = NNC2P"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2c9074",
   "metadata": {},
   "source": [
    "In case we want to view the variables, uncomment the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "05d1fee6-36b8-4ef9-a84d-cec0dcc9456c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NNC2P.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fcb86b-ad79-4733-8911-d26de50082b3",
   "metadata": {},
   "source": [
    "# Save the matrices as a CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad316e9b",
   "metadata": {},
   "source": [
    "Note that converting from Torch tensor to Numpy array does __not__ cause loss of information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b75e32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.3647063672542572021484375\n",
      "---\n",
      "-0.3647063672542572021484375\n"
     ]
    }
   ],
   "source": [
    "# test_exact = NNC2P.state_dict()[\"stack.0.weight\"]\n",
    "# test_exact_value = test_exact[0][0].item()\n",
    "# print('%.25f' % test_exact_value)\n",
    "# print(\"---\")\n",
    "# test_exact_np = test_exact.numpy()\n",
    "# test_exact_value_np = test_exact_np[0][0]\n",
    "# print('%.25f' % test_exact_value_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80676c3",
   "metadata": {},
   "source": [
    " ## Saving and loading as CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba9ed1f",
   "metadata": {},
   "source": [
    "Save the values: ([refresher on Pickle](https://tech.qvread.com/python/python-list-read-write-csv/))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b40bc299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model CSV files to ..\\Models\\paramvals_assist\n"
     ]
    }
   ],
   "source": [
    "dir_name = os.path.normpath(\"../Models/paramvals_assist//\")\n",
    "print(f\"Saving model CSV files to {dir_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f210e996-8996-4aef-a7e4-e759f410fcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# State dict contains all the variables\n",
    "state_dict = model.state_dict().items()\n",
    "# Names to save the files:\n",
    "file_names            = [\"weight0\", \"bias0\", \"weight2\", \"bias2\", \"weight4\", \"bias4\"]\n",
    "save_names         = [os.path.normpath(dir_name + \"/\" + name + \".csv\") for name in file_names]\n",
    "flat_save_names = [os.path.normpath(dir_name + \"/\" + name + \"_flat.csv\") for name in file_names]\n",
    "no_comma_flat_save_names = [os.path.normpath(dir_name + \"/\" + name + \"_flat_no_comma.csv\") for name in file_names]\n",
    "\n",
    "# Save each one:\n",
    "counter = 0\n",
    "for param_name, item in state_dict:\n",
    "    # Get appropriate names\n",
    "    name                   = file_names[counter]\n",
    "    save_name         = save_names[counter]\n",
    "    flat_save_name = flat_save_names[counter]\n",
    "    no_comma_flat_save_name = no_comma_flat_save_names[counter]\n",
    "    # Get the matrix and flatten it as well\n",
    "    matrix_np   = item.numpy() \n",
    "    flat_matrix_np   = matrix_np.flatten()\n",
    "    # The following save txt is only important for stuff done within this noteboo!\n",
    "    np.savetxt(no_comma_flat_save_name, flat_matrix_np, delimiter=\",\", fmt=\"%0.35f\")\n",
    "    \n",
    "    np.savetxt(save_name, matrix_np, delimiter=\",\", fmt=\"%0.35f\")\n",
    "    # Note: due to weird Fortran stuff, have to append a 0 at the start of the file\n",
    "    flat_matrix_np   = np.insert(flat_matrix_np, 0, 0)\n",
    "    np.savetxt(flat_save_name, flat_matrix_np, delimiter=\",\", newline=',\\n', fmt=\"%0.35f\")\n",
    "    \n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88386f6f-a165-4d9a-9c2d-4c14fccbfe72",
   "metadata": {},
   "source": [
    "Read the files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9180ced9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight0 = np.loadtxt('Models/paramvals/weight0.csv', delimiter=\",\")\n",
    "# bias0      = np.loadtxt('Models/paramvals/bias0.csv', delimiter=\",\")\n",
    "# s = np.shape(bias0)[0]\n",
    "# bias0 = np.reshape(bias0, (s, 1))\n",
    "# weight2 = np.loadtxt('Models/paramvals/weight2.csv', delimiter=\",\")\n",
    "# bias2      = np.loadtxt('Models/paramvals/bias2.csv', delimiter=\",\")\n",
    "# s = np.shape(bias2)[0]\n",
    "# bias2 = np.reshape(bias2, (s, 1))\n",
    "# weight4 = np.loadtxt('Models/paramvals/weight4.csv', delimiter=\",\")\n",
    "# s = np.shape(weight4)[0]\n",
    "# weight4 = np.reshape(weight4, (1, s))\n",
    "# bias4      = np.loadtxt('Models/paramvals/bias4.csv', delimiter=\",\")\n",
    "# bias4 = np.reshape(bias4, (1, 1))\n",
    "\n",
    "# weights_and_biases = [weight0, bias0, weight2, bias2, weight4, bias4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088e1425",
   "metadata": {},
   "source": [
    "Same for flat: __NOTE__ for numpy (here), we load \"no_comma\" files since otherwise there's an error. For Fortran, we use the files __WITHOUT__ \"no comma\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a79742bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight0_flat = np.loadtxt('Models/paramvals/weight0_flat_no_comma.csv', delimiter=\",\")\n",
    "# bias0_flat      = np.loadtxt('Models/paramvals/bias0_flat_no_comma.csv', delimiter=\",\")\n",
    "# weight2_flat = np.loadtxt('Models/paramvals/weight2_flat_no_comma.csv', delimiter=\",\")\n",
    "# bias2_flat      = np.loadtxt('Models/paramvals/bias2_flat_no_comma.csv', delimiter=\",\")\n",
    "# weight4_flat = np.loadtxt('Models/paramvals/weight4_flat_no_comma.csv', delimiter=\",\")\n",
    "# bias4_flat      = np.loadtxt('Models/paramvals/bias4_flat_no_comma.csv', delimiter=\",\")\n",
    "\n",
    "# weights_and_biases_flat = [weight0_flat, bias0_flat, weight2_flat, bias2_flat, weight4_flat, bias4_flat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a2157cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.3647063672542572021484375\n"
     ]
    }
   ],
   "source": [
    "print('%.25f' % weight0[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3e7a63e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1800,)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(weight0_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ad63b8",
   "metadata": {},
   "source": [
    "(Below: old pickle version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "60288975",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   reload pickled data from file\n",
    "# test_name = save_names[0]\n",
    "# with open(test_name, 'rb') as f:\n",
    "#     test_load = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "788d1c48-f316-4c85-b069-e7d62cd6c9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the loaded versions in the appropriate variables\n",
    "# with open('Models/paramvals/weight0.csv', 'rb') as f:\n",
    "#     weight0 = pickle.load(f)\n",
    "    \n",
    "# with open('Models/paramvals/bias0.csv', 'rb') as f:\n",
    "#     bias0 = pickle.load(f)\n",
    "#     s = np.shape(bias0)[0]\n",
    "#     bias0 = np.reshape(bias0, (s, 1))\n",
    "    \n",
    "# with open('Models/paramvals/weight2.csv', 'rb') as f:\n",
    "#     weight2 = pickle.load(f)\n",
    "    \n",
    "# with open('Models/paramvals/bias2.csv', 'rb') as f:\n",
    "#     bias2 = pickle.load(f)\n",
    "#     s = np.shape(bias2)[0]\n",
    "#     bias2 = np.reshape(bias2, (s, 1))\n",
    "    \n",
    "# with open('Models/paramvals/weight4.csv', 'rb') as f:\n",
    "#     weight4 = pickle.load(f)\n",
    "    \n",
    "# with open('Models/paramvals/bias4.csv', 'rb') as f:\n",
    "#     bias4 = pickle.load(f)\n",
    "#     s = np.shape(bias4)[0]\n",
    "#     bias4 = np.reshape(bias4, (s, 1))\n",
    "\n",
    "# # Gather together in a list of all variables\n",
    "# weights_and_biases = [weight0, bias0, weight2, bias2, weight4, bias4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5b9a2b",
   "metadata": {},
   "source": [
    "Same for flattened arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4abc8dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('Models/paramvals/bias0_flat.csv', 'r') as file:\n",
    "#     csvreader = csv.reader(file)\n",
    "# #     for row in csvreader:\n",
    "# #         print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5b4c157b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the loaded versions in the appropriate variables\n",
    "# with open('Models/paramvals/weight0_flat.csv', 'rb') as f:\n",
    "#     weight0_flat = pickle.load(f)\n",
    "    \n",
    "# # with open('Models/paramvals/bias0_flat.csv', 'rb') as f:\n",
    "# #     bias0_flat = pickle.load(f)\n",
    "\n",
    "    \n",
    "# with open('Models/paramvals/weight2_flat.csv', 'rb') as f:\n",
    "#     weight2_flat = pickle.load(f)\n",
    "    \n",
    "# with open('Models/paramvals/bias2_flat.csv', 'rb') as f:\n",
    "#     bias2_flat = pickle.load(f)\n",
    "    \n",
    "# with open('Models/paramvals/weight4_flat.csv', 'rb') as f:\n",
    "#     weight4_flat = pickle.load(f)\n",
    "    \n",
    "# with open('Models/paramvals/bias4_flat.csv', 'rb') as f:\n",
    "#     bias4_flat = pickle.load(f)\n",
    "\n",
    "# # Gather together in a list of all variables\n",
    "# weights_and_biases_flat = [weight0_flat, bias0_flat, weight2_flat, bias2_flat, weight4_flat, bias4_flat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "85e7dfa7-7137-4a5f-9c90-b79ab3516a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the file:  weight0\n",
      "The shape is equal to  (600, 3)\n",
      "For the file:  bias0\n",
      "The shape is equal to  (600, 1)\n",
      "For the file:  weight2\n",
      "The shape is equal to  (200, 600)\n",
      "For the file:  bias2\n",
      "The shape is equal to  (200, 1)\n",
      "For the file:  weight4\n",
      "The shape is equal to  (1, 200)\n",
      "For the file:  bias4\n",
      "The shape is equal to  (1, 1)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape for each parameter:\n",
    "for i in range(len(weights_and_biases)):\n",
    "    print(\"For the file: \", file_names[i])\n",
    "    # Read the values\n",
    "    shape = np.shape(weights_and_biases[i])\n",
    "    print(\"The shape is equal to \", shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b07bec3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the file:  Models/paramvals/weight0_flat.csv\n",
      "The shape is equal to  (1800,)\n",
      "For the file:  Models/paramvals/bias0_flat.csv\n",
      "The shape is equal to  (600,)\n",
      "For the file:  Models/paramvals/weight2_flat.csv\n",
      "The shape is equal to  (120000,)\n",
      "For the file:  Models/paramvals/bias2_flat.csv\n",
      "The shape is equal to  (200,)\n",
      "For the file:  Models/paramvals/weight4_flat.csv\n",
      "The shape is equal to  (200,)\n",
      "For the file:  Models/paramvals/bias4_flat.csv\n",
      "The shape is equal to  ()\n"
     ]
    }
   ],
   "source": [
    "# Same for their flattened versions:\n",
    "for i in range(len(weights_and_biases_flat)):\n",
    "    print(\"For the file: \", flat_save_names[i])\n",
    "    # Read the values\n",
    "    shape = np.shape(weights_and_biases_flat[i])\n",
    "    print(\"The shape is equal to \", shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afd58f4",
   "metadata": {},
   "source": [
    "##### Play around with some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b8c6a77e-6221-4158-8dc5-2de8cdddbce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read the example file\n",
    "# print(example)\n",
    "# print(np.shape(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8cf45633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_load_value = test_load[0][0]\n",
    "# print('%.25f' % test_load_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a77502-f96b-4221-9878-4e50854bcfe2",
   "metadata": {},
   "source": [
    "## Predicting using the values in the arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9709a2-c540-4130-ac6b-3ada2552bc0b",
   "metadata": {},
   "source": [
    "When we are going to implement this in the Gmunu code, we can no longer use any of the built-in tools of PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1e65ebe8-1c4f-4c4f-aced-77fadcd57267",
   "metadata": {},
   "outputs": [],
   "source": [
    "## One specific test case for the data\n",
    "rho,eps,v,p,D,S,tau = 9.83632270803203,1.962038705851822,0.2660655147967911,12.866163917605371,10.204131145455385,12.026584842282125,22.131296926293793"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acabd1c-7014-4bae-9615-389bd9c251d5",
   "metadata": {},
   "source": [
    "This is how the PyTorch implementation works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1ffbcdea-ab47-41ce-a968-d53be5534c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact:\n",
      "12.866163917605371\n",
      "Pytorch prediction:\n",
      "12.866371154785156\n"
     ]
    }
   ],
   "source": [
    "input_test = torch.tensor([D, S, tau])\n",
    "exact_result = p\n",
    "print(\"Exact:\")\n",
    "print(exact_result)\n",
    "# print(input_test)\n",
    "with torch.no_grad():\n",
    "    pred = model(input_test).item()\n",
    "\n",
    "print(\"Pytorch prediction:\")\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28e00da-5bd8-419c-806b-4b6ecf3f2dbf",
   "metadata": {},
   "source": [
    "Now, we have to try and get the same output, but by defining all intermediate steps ourselves!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "194e0737-14b7-49b7-b3af-89221678facc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def compute_prediction(x):\n",
    "    \"\"\"Input is a np. array of size 1x3\"\"\"\n",
    "    x = np.matmul(weight0, x) + bias0\n",
    "    x = sigmoid(x)\n",
    "    x = np.matmul(weight2, x) + bias2\n",
    "    x = sigmoid(x)\n",
    "    x = np.matmul(weight4, x) + bias4\n",
    "    return x[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5745fb74-6f68-4556-a8e0-c80628e93b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3)\n",
      "(3, 1)\n"
     ]
    }
   ],
   "source": [
    "input_test = np.array([[D, S, tau]])\n",
    "print(np.shape(input_test))\n",
    "input_test = np.transpose(input_test)\n",
    "print(np.shape(input_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c422a5de-4b83-4f5f-b1e0-c6023c8cd65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.866371869133928\n",
      "12.866371154785156\n"
     ]
    }
   ],
   "source": [
    "our_prediction = compute_prediction(input_test)\n",
    "print(our_prediction)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fbe512-19ff-4157-9a33-68899241991d",
   "metadata": {},
   "source": [
    "Now we compute rho and eps from this (see appendix A of central paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "aee97e55-2be0-4bc1-8c31-62ad7b4db25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our calculations:\n",
      "9.836326155512264 1.9620391642983483\n",
      "Exact results:\n",
      "9.83632270803203 1.962038705851822\n"
     ]
    }
   ],
   "source": [
    "v_star = S/(tau + D + our_prediction)\n",
    "W_star = 1/np.sqrt(1-v_star**2)\n",
    "\n",
    "rho_star = D/W_star\n",
    "eps_star = (tau + D*(1 - W_star) + our_prediction*(1 - W_star**2))/(D*W_star)\n",
    "print(\"Our calculations:\")\n",
    "print(rho_star, eps_star)\n",
    "print(\"Exact results:\")\n",
    "print(rho, eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aff9646-60ef-402e-a56c-3eccee7478e2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## (to do) Save as hdf5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ba57a7f2-8af2-4ba6-a242-d19fbfbe034b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Open an HDF5 file for writing\n",
    "# with h5py.File(\"NNC2Pv0_params.h5\", \"w\") as f:\n",
    "#     # Save the weights and biases of the network to the HDF5 file\n",
    "#     f.create_dataset(\"NNC2Pv0_params\", data=NNC2P.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929bc14b",
   "metadata": {},
   "source": [
    "# Using Torch script and tracing the network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a983a5e9",
   "metadata": {},
   "source": [
    "There exist two ways of converting a PyTorch model to Torch Script. The first is known as tracing, a mechanism in which the structure of the model is captured by evaluating it once using example inputs, and recording the flow of those inputs through the model. This is suitable for models that make limited use of control flow. The second approach is to add explicit annotations to your model that inform the Torch Script compiler that it may directly parse and compile your model code, subject to the constraints imposed by the Torch Script language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa4c899e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 0.5000])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = torch.tensor([1, 1, 0.5])\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "71837a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  original_name=NeuralNetwork\n",
       "  (stack): Sequential(\n",
       "    original_name=Sequential\n",
       "    (0): Linear(original_name=Linear)\n",
       "    (1): Sigmoid(original_name=Sigmoid)\n",
       "    (2): Linear(original_name=Linear)\n",
       "    (3): Sigmoid(original_name=Sigmoid)\n",
       "    (4): Linear(original_name=Linear)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traced_script_module = torch.jit.trace(model, example)\n",
    "traced_script_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28fafa57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0598], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = traced_script_module(torch.tensor([1,1,0.5]))\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8866ef33",
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_script_module.save(\"NNC2Pv0t2.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7817ec-e463-4ed5-baf0-1b887b960d0b",
   "metadata": {},
   "source": [
    "__To do: finish it__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498cc2eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "author": "Thibeau Wouters",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
