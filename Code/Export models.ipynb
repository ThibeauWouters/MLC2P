{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af563537",
   "metadata": {},
   "source": [
    "%%latex\n",
    "\\tableofcontents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bb9f224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Thibeau\\master-thesis-AI\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "import random\n",
    "import csv\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "# import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.cm as cm\n",
    "import pickle\n",
    "import os\n",
    "# Own modules:\n",
    "import physics\n",
    "import data\n",
    "from data import CustomDataset\n",
    "import nnc2p\n",
    "# Get master directory\n",
    "master_dir = os.path.normpath(os.path.join(os.getcwd(), '..'))\n",
    "print(master_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4687804",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3b2e02",
   "metadata": {},
   "source": [
    "This notebook is a complete mess, so please don't look at it, this is just my playground to quickly test a few nets, and export hem etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dff221f",
   "metadata": {},
   "source": [
    "## Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "374edfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements a simple feedforward neural network.\n",
    "    \"\"\"\n",
    "    def __init__(self, h: list = [3, 600, 200, 1], activation_function = nn.Sigmoid, output_bias=True) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the neural network class.\n",
    "        \"\"\"\n",
    "        # Call the super constructor first\n",
    "        super(FeedForwardNetwork, self).__init__()\n",
    "\n",
    "        # For convenience, save the sizes of the hidden layers as fields as well\n",
    "        self.h = h\n",
    "\n",
    "        # Define the layers:\n",
    "        for i in range(len(self.h)-1):\n",
    "            if i == len(self.h)-2:\n",
    "                setattr(self, f\"linear{i+1}\", nn.Linear(self.h[i], self.h[i+1], bias=output_bias))\n",
    "            else:\n",
    "                setattr(self, f\"linear{i+1}\", nn.Linear(self.h[i], self.h[i+1]))\n",
    "                setattr(self, f\"activation{i+1}\", activation_function())\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Computes a forward step given the input x.\n",
    "        :param x: Input for the neural network.\n",
    "        :return: x: Output neural network\n",
    "        \"\"\"\n",
    "\n",
    "        for i, module in enumerate(self.modules()):\n",
    "            # The first module is the whole NNC2P object, continue\n",
    "            if i == 0:\n",
    "                continue\n",
    "            x = module(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bfa94c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements a simple feedforward neural network.\n",
    "    \"\"\"\n",
    "    def __init__(self, h: list = [3, 600, 200, 1], activation_function = nn.Sigmoid, output_bias=True) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the neural network class.\n",
    "        \"\"\"\n",
    "        # Call the super constructor first\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        # For convenience, save the sizes of the hidden layers as fields as well\n",
    "        self.h = h\n",
    "\n",
    "        # Define the layers:\n",
    "        for i in range(len(self.h)-1):\n",
    "            if i == len(self.h)-2:\n",
    "                setattr(self, f\"linear{i+1}\", nn.Linear(self.h[i], self.h[i+1], bias=output_bias))\n",
    "            else:\n",
    "                setattr(self, f\"linear{i+1}\", nn.Linear(self.h[i], self.h[i+1]))\n",
    "                setattr(self, f\"activation{i+1}\", activation_function())\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Computes a forward step given the input x.\n",
    "        :param x: Input for the neural network.\n",
    "        :return: x: Output neural network\n",
    "        \"\"\"\n",
    "\n",
    "        for i, module in enumerate(self.modules()):\n",
    "            # The first module is the whole NNC2P object, continue\n",
    "            if i == 0:\n",
    "                continue\n",
    "            x = module(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decbc7e7",
   "metadata": {},
   "source": [
    "## Example: most recent model for tabulated EOS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014008fc",
   "metadata": {},
   "source": [
    "We take this as Load the tabulated EOS for (50, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6745d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# h = [3, 10, 10, 1]\n",
    "# model = Net(h=h, output_bias=False).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e87d7d7",
   "metadata": {},
   "source": [
    "Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6418e813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (linear1): Linear(in_features=3, out_features=10, bias=True)\n",
       "  (activation1): ReLU()\n",
       "  (linear2): Linear(in_features=10, out_features=10, bias=True)\n",
       "  (activation2): ReLU()\n",
       "  (linear3): Linear(in_features=10, out_features=3, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load(\"../Models/taboes_3_10_10_3_relu.pt\").float()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5995df0a",
   "metadata": {},
   "source": [
    "Look at the first entries of the first bias term (can check in Gmunu whether the files agree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58fed61c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.8957,  0.2801,  0.2953,  2.9228,  3.3674,  1.4406,  1.0542, -2.1192,\n",
       "         2.4787,  0.5717])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()[\"linear1.bias\"][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcceeebc",
   "metadata": {},
   "source": [
    "# Export as CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578ee0f0",
   "metadata": {},
   "source": [
    "This is currently in use for the thesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b949363c",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad316e9b",
   "metadata": {},
   "source": [
    "Note that converting from Torch tensor to Numpy array does __not__ cause loss of information: this was tested in the following code cell (see output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b75e32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_exact = NNC2P.state_dict()[\"stack.0.weight\"]\n",
    "# test_exact_value = test_exact[0][0].item()\n",
    "# print('%.25f' % test_exact_value)\n",
    "# print(\"---\")\n",
    "# test_exact_np = test_exact.numpy()\n",
    "# test_exact_value_np = test_exact_np[0][0]\n",
    "# print('%.25f' % test_exact_value_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beec8d40",
   "metadata": {},
   "source": [
    "How does the result looks like? We flatten the matrices and vectors, such that they are read in as a single column and we reshape them into the desired shape inside the Gmunu code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27d25e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example parameter\n",
    "# example_params = model.state_dict()[\"linear1.weight\"]\n",
    "# example_params_np = example_params.numpy()\n",
    "# np.shape(example_params_np.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cd3886",
   "metadata": {},
   "source": [
    "## Save parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea9eea1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model CSV files to D:\\Thibeau\\master-thesis-AI\\Models\\paramvals_tabeos_relu_small\n"
     ]
    }
   ],
   "source": [
    "# Specify where we want to save the parameter values:\n",
    "dir_name = os.path.normpath(\"../Models/paramvals_tabeos_relu_small//\")\n",
    "print(f\"Saving model CSV files to {os.path.abspath(dir_name)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029e0786",
   "metadata": {},
   "source": [
    "The weights are saved as \"flat\", so all in one column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f210e996-8996-4aef-a7e4-e759f410fcbb",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '..\\\\Models\\\\paramvals_tabeos_relu_small\\\\weight0.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 32\u001b[0m\n\u001b[0;32m     26\u001b[0m flat_zero_matrix_np   \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39minsert(flat_matrix_np, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m## The following save txt is only important for stuff done within this noteboo!\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m#np.savetxt(no_comma_flat_save_name, flat_matrix_np, delimiter=\",\", fmt=\"%0.35f\")\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Save all to txt\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavetxt\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatrix_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m%0.35f\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m np\u001b[38;5;241m.\u001b[39msavetxt(flat_save_name, flat_matrix_np, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m, newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m, fmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%0.35f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     34\u001b[0m np\u001b[38;5;241m.\u001b[39msavetxt(flat_zero_save_name, flat_zero_matrix_np, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m, newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m, fmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%0.35f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36msavetxt\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\numpy\\lib\\npyio.py:1523\u001b[0m, in \u001b[0;36msavetxt\u001b[1;34m(fname, X, fmt, delimiter, newline, header, footer, comments, encoding)\u001b[0m\n\u001b[0;32m   1520\u001b[0m     fname \u001b[38;5;241m=\u001b[39m os_fspath(fname)\n\u001b[0;32m   1521\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_string_like(fname):\n\u001b[0;32m   1522\u001b[0m     \u001b[38;5;66;03m# datasource doesn't support creating a new file ...\u001b[39;00m\n\u001b[1;32m-> 1523\u001b[0m     \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m   1524\u001b[0m     fh \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlib\u001b[38;5;241m.\u001b[39m_datasource\u001b[38;5;241m.\u001b[39mopen(fname, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwt\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39mencoding)\n\u001b[0;32m   1525\u001b[0m     own_fh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '..\\\\Models\\\\paramvals_tabeos_relu_small\\\\weight0.csv'"
     ]
    }
   ],
   "source": [
    "# State dict contains all the variables\n",
    "state_dict = model.state_dict().items()\n",
    "# Names to save the files:\n",
    "file_names                      = [\"weight0\", \"bias0\", \"weight2\", \"bias2\", \"weight4\", \"bias4\"]\n",
    "save_names                   = [os.path.normpath(dir_name + \"/\" + name + \".csv\") for name in file_names]\n",
    "flat_save_names           = [os.path.normpath(dir_name + \"/\" + name + \"_flat.csv\") for name in file_names]\n",
    "flat_zero_save_names = [os.path.normpath(dir_name + \"/\" + name + \"_flat_zero.csv\") for name in file_names]\n",
    "\n",
    "## Unused\n",
    "# no_comma_flat_save_names = [os.path.normpath(dir_name + \"/\" + name + \"_flat_no_comma.csv\") for name in file_names]\n",
    "\n",
    "# Save each one:\n",
    "counter = 0\n",
    "for param_name, item in state_dict:\n",
    "    # Get appropriate names\n",
    "    name                             = file_names[counter]\n",
    "    save_name                   = save_names[counter]\n",
    "    flat_save_name           = flat_save_names[counter]\n",
    "    flat_zero_save_name = flat_zero_save_names[counter]\n",
    "    #no_comma_flat_save_name = no_comma_flat_save_names[counter]\n",
    "    \n",
    "    # Get the matrix and flatten it as well\n",
    "    matrix_np                     = item.numpy() \n",
    "    flat_matrix_np             = matrix_np.flatten()\n",
    "    # Insert zero as first element (needed for how Fortran programs read in the CSV files)\n",
    "    flat_zero_matrix_np   = np.insert(flat_matrix_np, 0, 0)\n",
    "    \n",
    "    ## The following save txt is only important for stuff done within this noteboo!\n",
    "    #np.savetxt(no_comma_flat_save_name, flat_matrix_np, delimiter=\",\", fmt=\"%0.35f\")\n",
    "    \n",
    "    # Save all to txt\n",
    "    np.savetxt(save_name, matrix_np, delimiter=\",\", fmt=\"%0.35f\")\n",
    "    np.savetxt(flat_save_name, flat_matrix_np, delimiter=\",\", newline=',\\n', fmt=\"%0.35f\")\n",
    "    np.savetxt(flat_zero_save_name, flat_zero_matrix_np, delimiter=\",\", newline=',\\n', fmt=\"%0.35f\")\n",
    "    \n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3841f908",
   "metadata": {},
   "source": [
    "## Checking saved files (should be OK -- can ignore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88386f6f-a165-4d9a-9c2d-4c14fccbfe72",
   "metadata": {},
   "source": [
    "Read the files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9180ced9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight0 = np.loadtxt('Models/paramvals/weight0.csv', delimiter=\",\")\n",
    "# bias0      = np.loadtxt('Models/paramvals/bias0.csv', delimiter=\",\")\n",
    "# s = np.shape(bias0)[0]\n",
    "# bias0 = np.reshape(bias0, (s, 1))\n",
    "# weight2 = np.loadtxt('Models/paramvals/weight2.csv', delimiter=\",\")\n",
    "# bias2      = np.loadtxt('Models/paramvals/bias2.csv', delimiter=\",\")\n",
    "# s = np.shape(bias2)[0]\n",
    "# bias2 = np.reshape(bias2, (s, 1))\n",
    "# weight4 = np.loadtxt('Models/paramvals/weight4.csv', delimiter=\",\")\n",
    "# s = np.shape(weight4)[0]\n",
    "# weight4 = np.reshape(weight4, (1, s))\n",
    "# bias4      = np.loadtxt('Models/paramvals/bias4.csv', delimiter=\",\")\n",
    "# bias4 = np.reshape(bias4, (1, 1))\n",
    "\n",
    "# weights_and_biases = [weight0, bias0, weight2, bias2, weight4, bias4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088e1425",
   "metadata": {},
   "source": [
    "Same for flat: __NOTE__ for numpy (here), we load \"no_comma\" files since otherwise there's an error. For Fortran, we use the files __WITHOUT__ \"no comma\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a79742bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight0_flat = np.loadtxt('Models/paramvals/weight0_flat_no_comma.csv', delimiter=\",\")\n",
    "# bias0_flat      = np.loadtxt('Models/paramvals/bias0_flat_no_comma.csv', delimiter=\",\")\n",
    "# weight2_flat = np.loadtxt('Models/paramvals/weight2_flat_no_comma.csv', delimiter=\",\")\n",
    "# bias2_flat      = np.loadtxt('Models/paramvals/bias2_flat_no_comma.csv', delimiter=\",\")\n",
    "# weight4_flat = np.loadtxt('Models/paramvals/weight4_flat_no_comma.csv', delimiter=\",\")\n",
    "# bias4_flat      = np.loadtxt('Models/paramvals/bias4_flat_no_comma.csv', delimiter=\",\")\n",
    "\n",
    "# weights_and_biases_flat = [weight0_flat, bias0_flat, weight2_flat, bias2_flat, weight4_flat, bias4_flat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a2157cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.3647063672542572021484375\n"
     ]
    }
   ],
   "source": [
    "print('%.25f' % weight0[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3e7a63e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1800,)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(weight0_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ad63b8",
   "metadata": {},
   "source": [
    "(Below: old pickle version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "60288975",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   reload pickled data from file\n",
    "# test_name = save_names[0]\n",
    "# with open(test_name, 'rb') as f:\n",
    "#     test_load = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "788d1c48-f316-4c85-b069-e7d62cd6c9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the loaded versions in the appropriate variables\n",
    "# with open('Models/paramvals/weight0.csv', 'rb') as f:\n",
    "#     weight0 = pickle.load(f)\n",
    "    \n",
    "# with open('Models/paramvals/bias0.csv', 'rb') as f:\n",
    "#     bias0 = pickle.load(f)\n",
    "#     s = np.shape(bias0)[0]\n",
    "#     bias0 = np.reshape(bias0, (s, 1))\n",
    "    \n",
    "# with open('Models/paramvals/weight2.csv', 'rb') as f:\n",
    "#     weight2 = pickle.load(f)\n",
    "    \n",
    "# with open('Models/paramvals/bias2.csv', 'rb') as f:\n",
    "#     bias2 = pickle.load(f)\n",
    "#     s = np.shape(bias2)[0]\n",
    "#     bias2 = np.reshape(bias2, (s, 1))\n",
    "    \n",
    "# with open('Models/paramvals/weight4.csv', 'rb') as f:\n",
    "#     weight4 = pickle.load(f)\n",
    "    \n",
    "# with open('Models/paramvals/bias4.csv', 'rb') as f:\n",
    "#     bias4 = pickle.load(f)\n",
    "#     s = np.shape(bias4)[0]\n",
    "#     bias4 = np.reshape(bias4, (s, 1))\n",
    "\n",
    "# # Gather together in a list of all variables\n",
    "# weights_and_biases = [weight0, bias0, weight2, bias2, weight4, bias4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5b9a2b",
   "metadata": {},
   "source": [
    "Same for flattened arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4abc8dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('Models/paramvals/bias0_flat.csv', 'r') as file:\n",
    "#     csvreader = csv.reader(file)\n",
    "# #     for row in csvreader:\n",
    "# #         print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5b4c157b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the loaded versions in the appropriate variables\n",
    "# with open('Models/paramvals/weight0_flat.csv', 'rb') as f:\n",
    "#     weight0_flat = pickle.load(f)\n",
    "    \n",
    "# # with open('Models/paramvals/bias0_flat.csv', 'rb') as f:\n",
    "# #     bias0_flat = pickle.load(f)\n",
    "\n",
    "    \n",
    "# with open('Models/paramvals/weight2_flat.csv', 'rb') as f:\n",
    "#     weight2_flat = pickle.load(f)\n",
    "    \n",
    "# with open('Models/paramvals/bias2_flat.csv', 'rb') as f:\n",
    "#     bias2_flat = pickle.load(f)\n",
    "    \n",
    "# with open('Models/paramvals/weight4_flat.csv', 'rb') as f:\n",
    "#     weight4_flat = pickle.load(f)\n",
    "    \n",
    "# with open('Models/paramvals/bias4_flat.csv', 'rb') as f:\n",
    "#     bias4_flat = pickle.load(f)\n",
    "\n",
    "# # Gather together in a list of all variables\n",
    "# weights_and_biases_flat = [weight0_flat, bias0_flat, weight2_flat, bias2_flat, weight4_flat, bias4_flat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "85e7dfa7-7137-4a5f-9c90-b79ab3516a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the file:  weight0\n",
      "The shape is equal to  (600, 3)\n",
      "For the file:  bias0\n",
      "The shape is equal to  (600, 1)\n",
      "For the file:  weight2\n",
      "The shape is equal to  (200, 600)\n",
      "For the file:  bias2\n",
      "The shape is equal to  (200, 1)\n",
      "For the file:  weight4\n",
      "The shape is equal to  (1, 200)\n",
      "For the file:  bias4\n",
      "The shape is equal to  (1, 1)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape for each parameter:\n",
    "for i in range(len(weights_and_biases)):\n",
    "    print(\"For the file: \", file_names[i])\n",
    "    # Read the values\n",
    "    shape = np.shape(weights_and_biases[i])\n",
    "    print(\"The shape is equal to \", shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b07bec3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the file:  Models/paramvals/weight0_flat.csv\n",
      "The shape is equal to  (1800,)\n",
      "For the file:  Models/paramvals/bias0_flat.csv\n",
      "The shape is equal to  (600,)\n",
      "For the file:  Models/paramvals/weight2_flat.csv\n",
      "The shape is equal to  (120000,)\n",
      "For the file:  Models/paramvals/bias2_flat.csv\n",
      "The shape is equal to  (200,)\n",
      "For the file:  Models/paramvals/weight4_flat.csv\n",
      "The shape is equal to  (200,)\n",
      "For the file:  Models/paramvals/bias4_flat.csv\n",
      "The shape is equal to  ()\n"
     ]
    }
   ],
   "source": [
    "# Same for their flattened versions:\n",
    "for i in range(len(weights_and_biases_flat)):\n",
    "    print(\"For the file: \", flat_save_names[i])\n",
    "    # Read the values\n",
    "    shape = np.shape(weights_and_biases_flat[i])\n",
    "    print(\"The shape is equal to \", shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afd58f4",
   "metadata": {},
   "source": [
    "##### Play around with some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b8c6a77e-6221-4158-8dc5-2de8cdddbce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read the example file\n",
    "# print(example)\n",
    "# print(np.shape(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8cf45633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_load_value = test_load[0][0]\n",
    "# print('%.25f' % test_load_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a77502-f96b-4221-9878-4e50854bcfe2",
   "metadata": {},
   "source": [
    "## Predicting using the values in the arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9709a2-c540-4130-ac6b-3ada2552bc0b",
   "metadata": {},
   "source": [
    "When we are going to implement this in the Gmunu code, we can no longer use any of the built-in tools of PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1e65ebe8-1c4f-4c4f-aced-77fadcd57267",
   "metadata": {},
   "outputs": [],
   "source": [
    "## One specific test case for the data\n",
    "rho,eps,v,p,D,S,tau = 9.83632270803203,1.962038705851822,0.2660655147967911,12.866163917605371,10.204131145455385,12.026584842282125,22.131296926293793"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acabd1c-7014-4bae-9615-389bd9c251d5",
   "metadata": {},
   "source": [
    "This is how the PyTorch implementation works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1ffbcdea-ab47-41ce-a968-d53be5534c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact:\n",
      "12.866163917605371\n",
      "Pytorch prediction:\n",
      "12.866371154785156\n"
     ]
    }
   ],
   "source": [
    "input_test = torch.tensor([D, S, tau])\n",
    "exact_result = p\n",
    "print(\"Exact:\")\n",
    "print(exact_result)\n",
    "# print(input_test)\n",
    "with torch.no_grad():\n",
    "    pred = model(input_test).item()\n",
    "\n",
    "print(\"Pytorch prediction:\")\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28e00da-5bd8-419c-806b-4b6ecf3f2dbf",
   "metadata": {},
   "source": [
    "Now, we have to try and get the same output, but by defining all intermediate steps ourselves!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "194e0737-14b7-49b7-b3af-89221678facc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def compute_prediction(x):\n",
    "    \"\"\"Input is a np. array of size 1x3\"\"\"\n",
    "    x = np.matmul(weight0, x) + bias0\n",
    "    x = sigmoid(x)\n",
    "    x = np.matmul(weight2, x) + bias2\n",
    "    x = sigmoid(x)\n",
    "    x = np.matmul(weight4, x) + bias4\n",
    "    return x[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5745fb74-6f68-4556-a8e0-c80628e93b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3)\n",
      "(3, 1)\n"
     ]
    }
   ],
   "source": [
    "input_test = np.array([[D, S, tau]])\n",
    "print(np.shape(input_test))\n",
    "input_test = np.transpose(input_test)\n",
    "print(np.shape(input_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c422a5de-4b83-4f5f-b1e0-c6023c8cd65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.866371869133928\n",
      "12.866371154785156\n"
     ]
    }
   ],
   "source": [
    "our_prediction = compute_prediction(input_test)\n",
    "print(our_prediction)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fbe512-19ff-4157-9a33-68899241991d",
   "metadata": {},
   "source": [
    "Now we compute rho and eps from this (see appendix A of central paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "aee97e55-2be0-4bc1-8c31-62ad7b4db25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our calculations:\n",
      "9.836326155512264 1.9620391642983483\n",
      "Exact results:\n",
      "9.83632270803203 1.962038705851822\n"
     ]
    }
   ],
   "source": [
    "v_star = S/(tau + D + our_prediction)\n",
    "W_star = 1/np.sqrt(1-v_star**2)\n",
    "\n",
    "rho_star = D/W_star\n",
    "eps_star = (tau + D*(1 - W_star) + our_prediction*(1 - W_star**2))/(D*W_star)\n",
    "print(\"Our calculations:\")\n",
    "print(rho_star, eps_star)\n",
    "print(\"Exact results:\")\n",
    "print(rho, eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aff9646-60ef-402e-a56c-3eccee7478e2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## (to do) Save as hdf5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ba57a7f2-8af2-4ba6-a242-d19fbfbe034b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Open an HDF5 file for writing\n",
    "# with h5py.File(\"NNC2Pv0_params.h5\", \"w\") as f:\n",
    "#     # Save the weights and biases of the network to the HDF5 file\n",
    "#     f.create_dataset(\"NNC2Pv0_params\", data=NNC2P.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929bc14b",
   "metadata": {},
   "source": [
    "# Using Torch script and tracing the network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a983a5e9",
   "metadata": {},
   "source": [
    "There exist two ways of converting a PyTorch model to Torch Script. The first is known as tracing, a mechanism in which the structure of the model is captured by evaluating it once using example inputs, and recording the flow of those inputs through the model. This is suitable for models that make limited use of control flow. The second approach is to add explicit annotations to your model that inform the Torch Script compiler that it may directly parse and compile your model code, subject to the constraints imposed by the Torch Script language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa4c899e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 0.5000])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = torch.tensor([1, 1, 0.5])\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "71837a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  original_name=NeuralNetwork\n",
       "  (stack): Sequential(\n",
       "    original_name=Sequential\n",
       "    (0): Linear(original_name=Linear)\n",
       "    (1): Sigmoid(original_name=Sigmoid)\n",
       "    (2): Linear(original_name=Linear)\n",
       "    (3): Sigmoid(original_name=Sigmoid)\n",
       "    (4): Linear(original_name=Linear)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traced_script_module = torch.jit.trace(model, example)\n",
    "traced_script_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28fafa57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0598], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = traced_script_module(torch.tensor([1,1,0.5]))\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8866ef33",
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_script_module.save(\"NNC2Pv0t2.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7817ec-e463-4ed5-baf0-1b887b960d0b",
   "metadata": {},
   "source": [
    "__To do: finish it__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff298ca",
   "metadata": {},
   "source": [
    "# Archive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01e23b4",
   "metadata": {},
   "source": [
    "Earlier attempts which were not so useful"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f244585",
   "metadata": {},
   "source": [
    "## Using the ONNX format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b101d548",
   "metadata": {},
   "source": [
    "(Semester 2) I'm exporting a model again, now in ONNX format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74804f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (linear1): Linear(in_features=3, out_features=504, bias=True)\n",
       "  (linear2): Linear(in_features=504, out_features=127, bias=True)\n",
       "  (linear3): Linear(in_features=127, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a model\n",
    "state_dict = torch.load(\"finetuned_most_pruned.pth\")\n",
    "model = nnc2p.create_nn(state_dict)\n",
    "model = model.float()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdc27425",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(model, torch.randn(3).float(), \"pruned_model.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e788e9cd",
   "metadata": {},
   "source": [
    "Testing the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09e10681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rho</th>\n",
       "      <th>eps</th>\n",
       "      <th>v</th>\n",
       "      <th>p</th>\n",
       "      <th>D</th>\n",
       "      <th>S</th>\n",
       "      <th>tau</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.836323</td>\n",
       "      <td>1.962039</td>\n",
       "      <td>0.266066</td>\n",
       "      <td>12.866164</td>\n",
       "      <td>10.204131</td>\n",
       "      <td>12.026585</td>\n",
       "      <td>22.131297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        rho       eps         v          p          D          S        tau\n",
       "0  9.836323  1.962039  0.266066  12.866164  10.204131  12.026585  22.131297"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../Data/ideal_gas_c2p_test_data.csv\")\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f81c40",
   "metadata": {},
   "source": [
    "Get a first input for the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b4ca993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.20413115, 12.02658484, 22.13129693])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([df[\"D\"][0], df[\"S\"][0], df[\"tau\"][0]])\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5796ede",
   "metadata": {},
   "source": [
    "Check inference on model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3008bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.866582\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    out = model(torch.from_numpy(x).float()).numpy()\n",
    "    print(out[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7b1f4862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear1.weight',\n",
       "              tensor([[-0.3666,  0.4540, -0.4352],\n",
       "                      [ 0.0356,  0.9699,  0.4002],\n",
       "                      [ 0.1087, -0.0912,  0.1072],\n",
       "                      ...,\n",
       "                      [ 0.5475, -0.5256, -0.2971],\n",
       "                      [-0.4310, -0.1393,  0.2783],\n",
       "                      [ 0.6337, -0.3134,  0.0312]])),\n",
       "             ('linear1.bias',\n",
       "              tensor([ 5.6061e-01,  2.4333e-01, -7.7467e-01, -3.2593e-01,  4.9073e-02,\n",
       "                       7.0926e-03,  2.2542e-01, -5.3934e-01,  2.5813e-01, -3.1620e-01,\n",
       "                      -4.9130e-01, -3.7876e-01, -2.5505e-01,  7.9304e-01,  7.3299e-01,\n",
       "                       1.0455e-01,  8.8842e-01,  1.4683e-01, -4.3929e-01, -3.4603e-01,\n",
       "                      -6.0459e-01, -7.6528e-01, -4.8161e-01, -4.2301e-01, -1.1967e-01,\n",
       "                      -7.1304e-01,  2.7122e-01,  1.1723e-01,  5.4620e-01, -1.7614e-01,\n",
       "                      -1.1986e-02, -3.2823e-01, -1.2451e-01, -2.4551e-01,  5.5276e-01,\n",
       "                      -1.3098e-01,  3.2348e-01, -5.8645e-01,  5.6136e-02, -2.5985e-01,\n",
       "                       3.8681e-01,  8.3229e-01, -2.3454e-01,  5.3122e-01,  4.7994e-03,\n",
       "                       1.4047e-01, -3.4001e-01,  2.0402e-01,  6.8717e-02, -7.6738e-01,\n",
       "                       7.2325e-01,  4.5350e-01,  1.4957e-01, -7.9855e-01, -6.0024e-01,\n",
       "                       5.3511e-01, -4.5407e-01, -5.5787e-01,  2.6786e-01, -5.6681e-01,\n",
       "                      -1.8479e-01,  6.8825e-01, -1.0905e-01, -2.3895e-01,  5.6507e-01,\n",
       "                      -2.4706e-01, -8.0426e-02, -2.7791e-01,  1.4884e-01, -3.7208e-01,\n",
       "                      -5.0654e-01,  1.5907e-01,  9.4968e-02, -2.5627e-01,  2.5145e-01,\n",
       "                       9.9624e-02,  6.1657e-01, -1.6875e-01,  4.0218e-01, -7.7376e-01,\n",
       "                       9.7056e-02,  7.6158e-03,  4.0075e-01,  3.5677e-04, -5.5413e-01,\n",
       "                      -6.7252e-01, -1.5020e-01, -5.0897e-01, -4.4934e-01, -6.6589e-01,\n",
       "                      -8.1114e-01,  8.5806e-01, -4.1454e-01, -9.7778e-02, -9.7389e-02,\n",
       "                       9.8068e-02, -3.0615e-01, -2.3949e-02, -1.6122e-01,  4.6998e-01,\n",
       "                      -5.5137e-01, -6.1980e-01, -3.9145e-01,  8.6247e-02,  5.5046e-01,\n",
       "                       1.5668e-01, -2.7502e-01, -1.8127e-01, -4.9198e-01, -2.0787e-01,\n",
       "                       1.6453e-01, -2.4607e-01,  5.3280e-01, -7.8030e-01,  7.3768e-01,\n",
       "                      -4.4428e-02,  4.1386e-01,  2.6073e-01, -5.3616e-01, -6.7525e-01,\n",
       "                      -6.2794e-01, -3.0024e-02,  1.9229e-01, -4.0597e-03,  5.8490e-01,\n",
       "                       1.2414e-01, -6.2282e-01, -3.3803e-01, -4.7853e-01,  1.5441e-01,\n",
       "                       6.4502e-01,  6.5766e-01, -5.5193e-01, -7.5390e-01,  1.3894e-01,\n",
       "                       9.8502e-01,  1.8964e-01,  5.1192e-01,  1.9887e-01,  2.5534e-01,\n",
       "                       6.9651e-01,  2.3346e-01,  7.9083e-01,  2.2313e-01,  6.2242e-01,\n",
       "                       3.0691e-01,  4.4167e-02, -5.8303e-01, -6.7877e-01, -3.1687e-01,\n",
       "                      -2.7313e-01, -5.5454e-01, -5.9223e-01,  6.7415e-01, -5.3458e-02,\n",
       "                      -3.2087e-01, -2.8056e-01,  1.4163e-01,  8.2622e-01, -6.9740e-02,\n",
       "                      -1.1789e-01, -3.5249e-01,  2.2896e-01,  8.9731e-02, -3.4253e-01,\n",
       "                      -5.8954e-01, -2.2534e-01,  3.8568e-01, -5.1930e-01,  1.9953e-01,\n",
       "                       6.1900e-03,  2.6773e-01, -6.8539e-01, -2.8038e-01, -3.7443e-01,\n",
       "                       3.5219e-01, -6.6597e-02, -7.2470e-02,  3.8389e-01, -2.4917e-01,\n",
       "                       2.9217e-01, -8.1484e-01, -4.2813e-02, -1.1196e-01, -6.4715e-01,\n",
       "                      -4.2079e-01,  5.5912e-02,  4.5545e-01,  2.4642e-01, -5.7082e-02,\n",
       "                       4.4132e-01,  3.0203e-01,  3.8295e-01, -8.3331e-01, -7.9781e-02,\n",
       "                      -3.6571e-01,  2.6059e-01,  2.8052e-01,  2.1758e-01, -7.8758e-01,\n",
       "                      -1.4521e-01,  1.0382e-01, -4.5079e-01, -4.8731e-01,  3.5570e-02,\n",
       "                      -6.6347e-01,  8.1051e-02,  4.9484e-01,  3.5027e-01, -3.8311e-01,\n",
       "                      -5.3328e-01, -3.4040e-01,  1.6403e-01, -7.8798e-01, -4.3605e-01,\n",
       "                      -2.1721e-01,  4.9041e-01, -2.2180e-01, -1.7955e-01,  3.9273e-01,\n",
       "                      -1.5853e-01, -7.3876e-02,  3.8864e-02, -6.2598e-02, -8.1087e-02,\n",
       "                      -1.9798e-01, -6.5552e-01, -5.6502e-01,  3.7701e-01, -3.4392e-01,\n",
       "                       8.2957e-02, -4.8004e-01, -4.6550e-02, -5.9087e-01,  3.6662e-02,\n",
       "                       3.4451e-01, -8.8631e-02, -5.3218e-01, -7.9140e-02,  3.0321e-02,\n",
       "                       1.8166e-02, -1.5071e-01,  2.6164e-01, -6.4562e-02, -7.7570e-01,\n",
       "                       7.2120e-01, -8.5811e-01,  6.0622e-02, -4.8881e-02,  2.1444e-01,\n",
       "                      -5.9472e-01,  3.2926e-01,  7.5049e-01, -2.9735e-01, -4.2053e-01,\n",
       "                      -4.7628e-01,  7.4014e-01, -2.4838e-01, -2.9999e-01, -7.9381e-01,\n",
       "                      -5.7938e-01,  6.5448e-01,  5.6605e-01, -1.5443e-02, -7.7997e-01,\n",
       "                      -4.0222e-01, -1.9633e-01,  8.7221e-01, -2.4332e-01, -3.8246e-01,\n",
       "                       2.6872e-02, -1.7040e-01, -1.9700e-01, -5.1869e-01, -8.3258e-01,\n",
       "                      -5.2976e-01, -2.3812e-01,  4.4821e-02, -2.0142e-02, -5.2488e-02,\n",
       "                      -6.7306e-01, -7.7793e-02,  8.1652e-03,  4.9168e-02,  3.8233e-01,\n",
       "                       1.7576e-01, -6.6489e-01, -6.6914e-02,  1.8089e-01, -3.5073e-01,\n",
       "                       6.0601e-01,  6.7418e-01, -5.1596e-01, -4.4838e-02, -1.4989e-02,\n",
       "                       5.6407e-01, -5.0503e-01,  1.0544e-01,  1.3190e-02,  5.4493e-01,\n",
       "                      -1.4568e-01, -1.6339e-04,  8.3324e-02, -2.6391e-01,  1.2711e-01,\n",
       "                       1.7127e-01,  5.0796e-02, -4.1261e-01,  3.2490e-01,  2.7839e-01,\n",
       "                      -3.8546e-01,  1.4934e-01,  3.3574e-01, -4.5479e-01, -3.8480e-01,\n",
       "                       2.7638e-01,  4.5449e-01,  4.5720e-01,  2.5101e-01,  4.7465e-01,\n",
       "                      -3.1147e-01, -6.8385e-02,  8.2914e-01,  2.4961e-02, -4.9627e-01,\n",
       "                       2.0639e-01, -1.5687e-01,  4.2896e-01, -7.5359e-01,  3.9584e-01,\n",
       "                      -1.3844e-01,  5.7653e-01, -6.2221e-01, -1.2231e-01, -8.9451e-01,\n",
       "                      -1.9282e-01,  4.3169e-01,  6.8659e-01,  5.0441e-01, -8.1701e-02,\n",
       "                       2.0244e-01,  5.0619e-01, -5.5520e-01, -5.9935e-01,  8.1521e-01,\n",
       "                       6.0223e-01,  1.6424e-01,  2.3404e-01, -6.3086e-01,  4.0273e-01,\n",
       "                      -1.1020e-01, -4.9546e-01, -3.3658e-02, -3.8937e-01, -2.1455e-01,\n",
       "                      -3.4698e-01,  7.5002e-01, -1.0651e-01,  7.2249e-01, -7.4550e-01,\n",
       "                      -5.1744e-01,  5.1015e-01, -7.6862e-01,  5.4379e-02,  1.4252e-01,\n",
       "                       1.5078e-01,  2.2445e-02, -4.9472e-01,  8.2544e-01, -1.2985e-02,\n",
       "                      -1.1099e-01, -6.5773e-01,  7.8922e-01, -4.5647e-01, -2.0565e-01,\n",
       "                       1.8342e-01, -3.6585e-01,  2.3095e-01,  2.2266e-01, -6.6948e-02,\n",
       "                      -1.4292e-01,  4.6304e-01,  2.7524e-01, -2.6237e-01,  5.2672e-01,\n",
       "                       2.7830e-01, -3.2785e-02, -2.4114e-01, -6.4739e-01,  4.9275e-01,\n",
       "                      -5.5368e-01, -2.8899e-01,  7.5072e-01,  8.0340e-01, -2.1609e-01,\n",
       "                       6.1026e-01,  6.6894e-02,  7.5997e-01,  5.9304e-02,  2.0161e-01,\n",
       "                      -5.3993e-01, -1.3188e-01,  3.8199e-01,  3.9901e-01, -5.9074e-01,\n",
       "                      -6.5068e-01, -6.8939e-01, -7.4917e-01, -2.7302e-01,  1.5330e-01,\n",
       "                       1.3607e-01,  4.7892e-01, -2.3037e-01, -5.8969e-01,  6.3816e-01,\n",
       "                      -3.4101e-01,  1.8069e-01,  4.8082e-01, -3.5878e-01,  4.6800e-01,\n",
       "                       5.3187e-01,  2.2503e-01, -3.7638e-01, -2.0842e-01,  3.8425e-01,\n",
       "                      -3.3656e-01, -4.2364e-01,  2.6078e-01,  1.8838e-01,  3.7220e-01,\n",
       "                       1.4417e-01, -1.0077e-01, -1.0681e-01,  1.2787e-01,  3.7760e-01,\n",
       "                      -2.5847e-02,  2.6523e-01,  6.8195e-01, -4.9772e-01,  1.4203e-01,\n",
       "                      -7.0256e-01, -3.8349e-01,  2.2317e-01,  4.7887e-01, -4.4954e-02,\n",
       "                       5.8802e-01, -5.2608e-01, -1.8691e-01, -3.9720e-01,  5.5767e-02,\n",
       "                       2.2479e-01,  1.5030e-01, -4.8814e-01, -1.8910e-01, -2.3814e-01,\n",
       "                      -5.6490e-02,  3.1868e-01, -1.0439e-01, -2.5642e-01, -5.2558e-02,\n",
       "                      -9.7838e-03,  5.0738e-02,  4.8262e-01,  4.6405e-01, -7.9877e-01,\n",
       "                      -1.6047e-01,  8.0333e-01,  6.2192e-01, -3.2752e-01, -2.9073e-02,\n",
       "                       5.5172e-01, -7.0825e-01,  6.4921e-01, -4.7262e-01,  2.3057e-01,\n",
       "                      -1.8620e-01, -2.9797e-01,  3.4108e-01,  2.6027e-01, -1.0116e-02,\n",
       "                       1.7032e-01,  3.6078e-01,  2.2924e-03,  8.2963e-01, -8.0770e-01,\n",
       "                       1.2874e-01,  5.9890e-01,  9.3857e-02,  5.7788e-01, -3.0665e-01,\n",
       "                      -2.2959e-01,  3.9055e-01, -3.5936e-01, -3.8635e-01,  2.9675e-01,\n",
       "                       5.4247e-01,  1.4175e-01, -2.3542e-01, -4.5953e-01,  6.5254e-01,\n",
       "                      -1.8286e-01,  7.3629e-01, -6.9211e-01, -1.7368e-01])),\n",
       "             ('linear2.weight',\n",
       "              tensor([[-0.1975,  0.0353,  0.0494,  ..., -0.1239,  0.0699, -0.0145],\n",
       "                      [-0.4241, -0.0561,  0.0716,  ..., -0.2802,  0.1693, -0.0044],\n",
       "                      [ 0.1471, -0.0358, -0.0640,  ...,  0.0976, -0.0556, -0.0480],\n",
       "                      ...,\n",
       "                      [-0.2535, -0.0136,  0.0662,  ..., -0.0097,  0.0494, -0.0094],\n",
       "                      [-0.2617, -0.0677,  0.0799,  ..., -0.0303,  0.0620,  0.0430],\n",
       "                      [-0.1746,  0.0117,  0.0723,  ..., -0.0221,  0.0402, -0.0008]])),\n",
       "             ('linear2.bias',\n",
       "              tensor([-0.0300, -0.0085, -0.0241,  0.0045, -0.0497,  0.0358, -0.0348,  0.0416,\n",
       "                       0.0006, -0.0533, -0.0059, -0.0452, -0.0490, -0.0718, -0.0193, -0.0061,\n",
       "                      -0.0623,  0.0067,  0.0112, -0.0616,  0.0002, -0.0232, -0.0453,  0.0438,\n",
       "                      -0.0642, -0.0277,  0.0230, -0.0351, -0.0443,  0.0093, -0.0409,  0.0191,\n",
       "                       0.0319, -0.0232,  0.0492, -0.0231,  0.0078, -0.0039, -0.0186,  0.0386,\n",
       "                       0.0195, -0.0284,  0.0273,  0.0323,  0.0024, -0.0493, -0.0524, -0.0335,\n",
       "                      -0.0273, -0.0532,  0.0267,  0.0069,  0.0181, -0.0636,  0.0055, -0.0193,\n",
       "                       0.0277,  0.0011,  0.0368, -0.0007,  0.0060,  0.0059,  0.0064, -0.0231,\n",
       "                      -0.0267, -0.0249,  0.0117, -0.0349,  0.0416, -0.0025,  0.0137, -0.0035,\n",
       "                      -0.0041, -0.0428,  0.0353,  0.0131,  0.0087, -0.0124,  0.0059,  0.0283,\n",
       "                      -0.0612,  0.0239,  0.0179,  0.0107,  0.0102,  0.0181,  0.0094,  0.0259,\n",
       "                      -0.0393,  0.0382, -0.0052,  0.0420, -0.0020, -0.0486, -0.0345, -0.0424,\n",
       "                       0.0024, -0.0560,  0.0400,  0.0057, -0.0556,  0.0243, -0.0183, -0.0325,\n",
       "                      -0.0495,  0.0488,  0.0240,  0.0243,  0.0174,  0.0286,  0.0159, -0.0456,\n",
       "                       0.0775, -0.0148,  0.0138,  0.0292,  0.0039, -0.0163,  0.0299, -0.0100,\n",
       "                       0.0749, -0.0488, -0.0056,  0.0238,  0.0060,  0.0120, -0.0412])),\n",
       "             ('linear3.weight',\n",
       "              tensor([[ 0.1659,  0.4207, -0.0723,  0.1485,  0.1768,  0.1228,  0.1697,  0.1643,\n",
       "                        0.1911,  0.2465,  0.1654,  0.1752, -0.1662,  0.2802,  0.1686,  0.1902,\n",
       "                       -0.0697, -0.0929, -0.0764,  0.2651, -0.0498,  0.1440, -0.0490,  0.0517,\n",
       "                        0.2108,  0.1801,  0.1701,  0.1790,  0.1938,  0.2001,  0.1823, -0.0895,\n",
       "                        0.1778,  0.1762,  0.1151,  0.1629,  0.1878, -0.0915,  0.1676,  0.1819,\n",
       "                        0.1876,  0.1844,  0.1468,  0.1705,  0.1832,  0.2991, -0.0671,  0.2047,\n",
       "                        0.3116,  0.1763,  0.1865,  0.2152,  0.1803,  0.1918,  0.1751,  0.1733,\n",
       "                        0.1802,  0.1476,  0.1857, -0.0661,  0.1681, -0.0706,  0.2169,  0.2045,\n",
       "                        0.1892,  0.1710,  0.1808,  0.2226,  0.1674,  0.1740,  0.2237,  0.1709,\n",
       "                       -0.0659,  0.1645,  0.1679,  0.1800, -0.0801, -0.0788,  0.1589,  0.1485,\n",
       "                        0.1957,  0.1487,  0.2049,  0.1854,  0.2007, -0.0776,  0.1780, -0.0816,\n",
       "                        0.1797,  0.1808,  0.1911,  0.1353,  0.2493,  0.1800,  0.1730,  0.2371,\n",
       "                       -0.0678,  0.1777,  0.1875,  0.1714,  0.2067,  0.2462,  0.1672,  0.1643,\n",
       "                        0.1753,  0.0615,  0.1566, -0.0823,  0.1724,  0.1716,  0.1895, -0.0603,\n",
       "                        0.2348,  0.1817,  0.1633,  0.1655, -0.0646, -0.0465,  0.1554,  0.1483,\n",
       "                        0.1100, -0.0740, -0.0917,  0.1508,  0.2362,  0.2279,  0.1881]])),\n",
       "             ('linear3.bias', tensor([0.1283]))])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebec6deb",
   "metadata": {},
   "source": [
    "__NOTE__ The most recent architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cad2129c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb1d9230",
   "metadata": {},
   "source": [
    "__NOTE__ the best & most pruned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73e58633",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for FeedForwardNetwork:\n\tMissing key(s) in state_dict: \"linear3.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m new_model \u001b[38;5;241m=\u001b[39m FeedForwardNetwork(h\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m3\u001b[39m])\n\u001b[1;32m----> 2\u001b[0m \u001b[43mnew_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnn_tabeos_3_50_50_3.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1671\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   1666\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   1667\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1668\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[0;32m   1670\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1671\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1672\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   1673\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for FeedForwardNetwork:\n\tMissing key(s) in state_dict: \"linear3.bias\". "
     ]
    }
   ],
   "source": [
    "new_model = FeedForwardNetwork(h=[3, 504, 127, 1])\n",
    "new_model.load_state_dict(torch.load(\"new_finetuned_most_pruned.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05cc5248",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([df[\"D\"][0], df[\"S\"][0], df[\"tau\"][0]])\n",
    "x\n",
    "x = np.ones((1,3))\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b557872e",
   "metadata": {},
   "source": [
    "Check inference on model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "373bdc75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4520222]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    out = new_model(torch.from_numpy(x).float()).numpy()\n",
    "    print(out[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a24ce71",
   "metadata": {},
   "source": [
    "to save ENTIRE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbbffa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(new_model, \"new_finetuned_most_pruned.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e73b43",
   "metadata": {},
   "source": [
    "Testing PyTorch load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1125c19",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'FeedForwardNetwork' on <module '__main__'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m test \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnew_finetuned_most_pruned.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m test\n",
      "File \u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:789\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[0;32m    787\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    788\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m--> 789\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _load(opened_zipfile, map_location, pickle_module, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[0;32m    790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n\u001b[0;32m    791\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:1131\u001b[0m, in \u001b[0;36m_load\u001b[1;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1129\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[0;32m   1130\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[1;32m-> 1131\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1133\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[0;32m   1135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:1124\u001b[0m, in \u001b[0;36m_load.<locals>.UnpicklerWrapper.find_class\u001b[1;34m(self, mod_name, name)\u001b[0m\n\u001b[0;32m   1122\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1123\u001b[0m mod_name \u001b[38;5;241m=\u001b[39m load_module_mapping\u001b[38;5;241m.\u001b[39mget(mod_name, mod_name)\n\u001b[1;32m-> 1124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can't get attribute 'FeedForwardNetwork' on <module '__main__'>"
     ]
    }
   ],
   "source": [
    "test = torch.load(\"new_finetuned_most_pruned.pt\")\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3ed760",
   "metadata": {},
   "source": [
    "## Use pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e968336",
   "metadata": {},
   "source": [
    "We use pickle to save the whole neural net object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1865677",
   "metadata": {},
   "source": [
    "We redefine the architecture such that it can be used without nnc2p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dcd3838b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"Our network architecture\"\"\"\n",
    "# class NeuralNetwork(nn.Module):\n",
    "#     \"\"\"\n",
    "#     Implements a two-layered neural network for the C2P conversion. Note that hence the number of layers is fixed\n",
    "#     for this NN subclass! The activation functions are sigmoids.\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, h1: int = 600, h2: int = 200) -> None:\n",
    "#         \"\"\"\n",
    "#         Initialize the neural network class.\n",
    "#         :param name: String that names this network, in order to recognize it later on.\n",
    "#         :param h1: Size (number of neurons) of the first hidden layer.\n",
    "#         :param h2: Size (number of neurons) of the second hidden layer.\n",
    "#         \"\"\"\n",
    "#         # Call the super constructor first\n",
    "#         super(NeuralNetwork, self).__init__()\n",
    "\n",
    "#         # For convenience, save the sizes of the hidden layers as fields as well\n",
    "#         self.h1 = h1\n",
    "#         self.h2 = h2\n",
    "\n",
    "#         # Define the weights:\n",
    "#         self.linear1 = nn.Linear(3, h1)\n",
    "#         self.linear2 = nn.Linear(h1, h2)\n",
    "#         self.linear3 = nn.Linear(h2, 1)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         \"\"\"\n",
    "#         Computes a forward step given the input x.\n",
    "#         :param x: Input for the neural network.\n",
    "#         :return: x: Output neural network\n",
    "#         \"\"\"\n",
    "\n",
    "#         x = self.linear1(x)\n",
    "#         x = torch.sigmoid(x)\n",
    "#         x = self.linear2(x)\n",
    "#         x = torch.sigmoid(x)\n",
    "#         x = self.linear3(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0511eac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Two auxiliary functions are needed to load the weights from the state dict into a fresh network\n",
    "# def get_hidden_sizes_from_state_dict(state_dict):\n",
    "#     \"\"\"\n",
    "#     Finds the sizes of the two hidden layers of our 2-layer architecture given a state dict.\n",
    "#     :param state_dict: State dict of saved parameters\n",
    "#     :return: h1, size of first hidden layer, and h2, size of second hidden layer\n",
    "#     \"\"\"\n",
    "#     h1 = np.shape(state_dict['linear1.bias'])[0]\n",
    "#     h2 = np.shape(state_dict['linear2.bias'])[0]\n",
    "\n",
    "#     return h1, h2\n",
    "\n",
    "# def create_nn(state_dict):\n",
    "#     \"\"\"\n",
    "#     Create a NeuralNetwork object if given a dictionary of the weights, with correct sizes for hidden layers.\n",
    "#     :param state_dict: State dictionary containing the weights of the neural network\n",
    "#     :return:\n",
    "#     \"\"\"\n",
    "#     h1, h2 = get_hidden_sizes_from_state_dict(state_dict)\n",
    "#     model = NeuralNetwork(h1=h1, h2=h2)\n",
    "#     model.load_state_dict(state_dict)\n",
    "\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34b7566c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (linear1): Linear(in_features=3, out_features=504, bias=True)\n",
       "  (linear2): Linear(in_features=504, out_features=127, bias=True)\n",
       "  (linear3): Linear(in_features=127, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = torch.load(\"finetuned_most_pruned.pth\")\n",
    "model = create_nn(state_dict)\n",
    "model = model.float()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51856ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Open a file and use dump()\n",
    "# filename = \"model.pkl\"\n",
    "# with open(filename, 'wb') as file:\n",
    "      \n",
    "#     # A new file will be created\n",
    "#     pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996f12b7",
   "metadata": {},
   "source": [
    "Check: to load again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb904cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (linear1): Linear(in_features=3, out_features=504, bias=True)\n",
      "  (linear2): Linear(in_features=504, out_features=127, bias=True)\n",
      "  (linear3): Linear(in_features=127, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# # Open the file in binary mode\n",
    "# with open(filename, 'rb') as file:\n",
    "      \n",
    "#     # Call load method to deserialze\n",
    "#     test = pickle.load(file)\n",
    "  \n",
    "#     print(test)"
   ]
  }
 ],
 "metadata": {
  "author": "Thibeau Wouters",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
