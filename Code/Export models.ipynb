{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af563537",
   "metadata": {},
   "source": [
    "%%latex\n",
    "\\tableofcontents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bb9f224",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "import random\n",
    "import csv\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.cm as cm\n",
    "import pickle\n",
    "import os\n",
    "# Own modules:\n",
    "import physics\n",
    "import data\n",
    "from data import CustomDataset\n",
    "import nnc2p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88888cdd",
   "metadata": {},
   "source": [
    "# Update: using the ONNX format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e57225",
   "metadata": {},
   "source": [
    "(Semester 2) I'm exporting a model again, now in ONNX format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd101c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (linear1): Linear(in_features=3, out_features=504, bias=True)\n",
       "  (linear2): Linear(in_features=504, out_features=127, bias=True)\n",
       "  (linear3): Linear(in_features=127, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a model\n",
    "state_dict = torch.load(\"finetuned_most_pruned.pth\")\n",
    "model = nnc2p.create_nn(state_dict)\n",
    "model = model.float()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2cf5442b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(model, torch.randn(3).float(), \"pruned_model.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9164f66c",
   "metadata": {},
   "source": [
    "Testing the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5a4801a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rho</th>\n",
       "      <th>eps</th>\n",
       "      <th>v</th>\n",
       "      <th>p</th>\n",
       "      <th>D</th>\n",
       "      <th>S</th>\n",
       "      <th>tau</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.836323</td>\n",
       "      <td>1.962039</td>\n",
       "      <td>0.266066</td>\n",
       "      <td>12.866164</td>\n",
       "      <td>10.204131</td>\n",
       "      <td>12.026585</td>\n",
       "      <td>22.131297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        rho       eps         v          p          D          S        tau\n",
       "0  9.836323  1.962039  0.266066  12.866164  10.204131  12.026585  22.131297"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../Data/ideal_gas_c2p_test_data.csv\")\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28854fc9",
   "metadata": {},
   "source": [
    "Get a first input for the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "374dec08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.20413115, 12.02658484, 22.13129693])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([df[\"D\"][0], df[\"S\"][0], df[\"tau\"][0]])\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4770318",
   "metadata": {},
   "source": [
    "Check inference on model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07f48643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.866582\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    out = model(torch.from_numpy(x).float()).numpy()\n",
    "    print(out[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcceeebc",
   "metadata": {},
   "source": [
    "# (Archive) Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d04d5a",
   "metadata": {},
   "source": [
    "This is the model architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40ee3cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters of the model here. Will first of all put two hidden layers\n",
    "# total of 800 neurons for the one in the paper\n",
    "device = \"cpu\"\n",
    "size_HL_1 = 600\n",
    "size_HL_2 = 200\n",
    "\n",
    "# Implement neural network\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        #self.flatten = nn.Flatten()\n",
    "        self.stack = nn.Sequential(\n",
    "            nn.Linear(3, size_HL_1),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(size_HL_1, size_HL_2),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(size_HL_2, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # No flatten needed, as our input and output are 1D?\n",
    "        #x = self.flatten(x) \n",
    "        logits = self.stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9071780a",
   "metadata": {},
   "source": [
    "We import NNC2Pv0, which was on par with the models in the paper. The t2 version is trained a bit longer than the version of the paper. Use OS to locate the Models folder correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9341324c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models folder: D:\\Coding\\master-thesis-AI\\Models\n"
     ]
    }
   ],
   "source": [
    "# # Directory of current file:\n",
    "# dir_path = os.path.abspath(\"D:\\Coding\\master-thesis-AI\\Code\\Semester 1\")\n",
    "# # Models folder\n",
    "# models_folder =os.path.abspath(\"D:\\Coding\\master-thesis-AI\\Models\")\n",
    "# print(\"Models folder: \" + models_folder)\n",
    "# # Move to the models folder\n",
    "# os.chdir(models_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e1c29f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move to the correct folder\n",
    "file_location = os.chdir(\"D:\\Coding\\master-thesis-AI\\Models\")\n",
    "NNC2P = torch.load(\"NNC2Pv0t2.pth\")\n",
    "model = NNC2P"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2c9074",
   "metadata": {},
   "source": [
    "In case we want to view the variables, uncomment the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "05d1fee6-36b8-4ef9-a84d-cec0dcc9456c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NNC2P.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fcb86b-ad79-4733-8911-d26de50082b3",
   "metadata": {},
   "source": [
    "# Save the matrices as a CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad316e9b",
   "metadata": {},
   "source": [
    "Note that converting from Torch tensor to Numpy array does __not__ cause loss of information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b75e32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.3647063672542572021484375\n",
      "---\n",
      "-0.3647063672542572021484375\n"
     ]
    }
   ],
   "source": [
    "test_exact = NNC2P.state_dict()[\"stack.0.weight\"]\n",
    "test_exact_value = test_exact[0][0].item()\n",
    "print('%.25f' % test_exact_value)\n",
    "print(\"---\")\n",
    "test_exact_np = test_exact.numpy()\n",
    "test_exact_value_np = test_exact_np[0][0]\n",
    "print('%.25f' % test_exact_value_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80676c3",
   "metadata": {},
   "source": [
    " ## Saving and loading as CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba9ed1f",
   "metadata": {},
   "source": [
    "Save the values: ([refresher on Pickle](https://tech.qvread.com/python/python-list-read-write-csv/))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f210e996-8996-4aef-a7e4-e759f410fcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# State dict contains all the variables\n",
    "state_dict = NNC2P.state_dict().items()\n",
    "# Names to save the files:\n",
    "file_names            = [\"weight0\", \"bias0\", \"weight2\", \"bias2\", \"weight4\", \"bias4\"]\n",
    "save_names         = [\"Models/paramvals/\" + name + \".csv\" for name in file_names]\n",
    "flat_save_names = [\"Models/paramvals/\" + name + \"_flat.csv\" for name in file_names]\n",
    "no_comma_flat_save_names = [\"Models/paramvals/\" + name + \"_flat_no_comma.csv\" for name in file_names]\n",
    "\n",
    "# Save each one:\n",
    "counter = 0\n",
    "for param_name, item in state_dict:\n",
    "    # Get appropriate names\n",
    "    name                   = file_names[counter]\n",
    "    save_name         = save_names[counter]\n",
    "    flat_save_name = flat_save_names[counter]\n",
    "    no_comma_flat_save_name = no_comma_flat_save_names[counter]\n",
    "    # Get the matrix and flatten it as well\n",
    "    matrix_np   = item.numpy() \n",
    "    flat_matrix_np   = matrix_np.flatten()\n",
    "    # The following save txt is only important for stuff done within this noteboo!\n",
    "    np.savetxt(no_comma_flat_save_name, flat_matrix_np, delimiter=\",\", fmt=\"%0.35f\")\n",
    "    \n",
    "    np.savetxt(save_name, matrix_np, delimiter=\",\", fmt=\"%0.35f\")\n",
    "    # Note: due to weird Fortran stuff, have to append a 0 at the start of the file\n",
    "    flat_matrix_np   = np.insert(flat_matrix_np, 0, 0)\n",
    "    np.savetxt(flat_save_name, flat_matrix_np, delimiter=\",\", newline=',\\n', fmt=\"%0.35f\")\n",
    "    \n",
    "    \n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88386f6f-a165-4d9a-9c2d-4c14fccbfe72",
   "metadata": {},
   "source": [
    "Read the files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9180ced9",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight0 = np.loadtxt('Models/paramvals/weight0.csv', delimiter=\",\")\n",
    "bias0      = np.loadtxt('Models/paramvals/bias0.csv', delimiter=\",\")\n",
    "s = np.shape(bias0)[0]\n",
    "bias0 = np.reshape(bias0, (s, 1))\n",
    "weight2 = np.loadtxt('Models/paramvals/weight2.csv', delimiter=\",\")\n",
    "bias2      = np.loadtxt('Models/paramvals/bias2.csv', delimiter=\",\")\n",
    "s = np.shape(bias2)[0]\n",
    "bias2 = np.reshape(bias2, (s, 1))\n",
    "weight4 = np.loadtxt('Models/paramvals/weight4.csv', delimiter=\",\")\n",
    "s = np.shape(weight4)[0]\n",
    "weight4 = np.reshape(weight4, (1, s))\n",
    "bias4      = np.loadtxt('Models/paramvals/bias4.csv', delimiter=\",\")\n",
    "bias4 = np.reshape(bias4, (1, 1))\n",
    "\n",
    "weights_and_biases = [weight0, bias0, weight2, bias2, weight4, bias4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088e1425",
   "metadata": {},
   "source": [
    "Same for flat: __NOTE__ for numpy (here), we load \"no_comma\" files since otherwise there's an error. For Fortran, we use the files __WITHOUT__ \"no comma\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a79742bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight0_flat = np.loadtxt('Models/paramvals/weight0_flat_no_comma.csv', delimiter=\",\")\n",
    "# bias0_flat      = np.loadtxt('Models/paramvals/bias0_flat_no_comma.csv', delimiter=\",\")\n",
    "# weight2_flat = np.loadtxt('Models/paramvals/weight2_flat_no_comma.csv', delimiter=\",\")\n",
    "# bias2_flat      = np.loadtxt('Models/paramvals/bias2_flat_no_comma.csv', delimiter=\",\")\n",
    "# weight4_flat = np.loadtxt('Models/paramvals/weight4_flat_no_comma.csv', delimiter=\",\")\n",
    "# bias4_flat      = np.loadtxt('Models/paramvals/bias4_flat_no_comma.csv', delimiter=\",\")\n",
    "\n",
    "# weights_and_biases_flat = [weight0_flat, bias0_flat, weight2_flat, bias2_flat, weight4_flat, bias4_flat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a2157cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.3647063672542572021484375\n"
     ]
    }
   ],
   "source": [
    "print('%.25f' % weight0[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3e7a63e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1800,)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(weight0_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ad63b8",
   "metadata": {},
   "source": [
    "(Below: old pickle version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "60288975",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   reload pickled data from file\n",
    "# test_name = save_names[0]\n",
    "# with open(test_name, 'rb') as f:\n",
    "#     test_load = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "788d1c48-f316-4c85-b069-e7d62cd6c9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the loaded versions in the appropriate variables\n",
    "# with open('Models/paramvals/weight0.csv', 'rb') as f:\n",
    "#     weight0 = pickle.load(f)\n",
    "    \n",
    "# with open('Models/paramvals/bias0.csv', 'rb') as f:\n",
    "#     bias0 = pickle.load(f)\n",
    "#     s = np.shape(bias0)[0]\n",
    "#     bias0 = np.reshape(bias0, (s, 1))\n",
    "    \n",
    "# with open('Models/paramvals/weight2.csv', 'rb') as f:\n",
    "#     weight2 = pickle.load(f)\n",
    "    \n",
    "# with open('Models/paramvals/bias2.csv', 'rb') as f:\n",
    "#     bias2 = pickle.load(f)\n",
    "#     s = np.shape(bias2)[0]\n",
    "#     bias2 = np.reshape(bias2, (s, 1))\n",
    "    \n",
    "# with open('Models/paramvals/weight4.csv', 'rb') as f:\n",
    "#     weight4 = pickle.load(f)\n",
    "    \n",
    "# with open('Models/paramvals/bias4.csv', 'rb') as f:\n",
    "#     bias4 = pickle.load(f)\n",
    "#     s = np.shape(bias4)[0]\n",
    "#     bias4 = np.reshape(bias4, (s, 1))\n",
    "\n",
    "# # Gather together in a list of all variables\n",
    "# weights_and_biases = [weight0, bias0, weight2, bias2, weight4, bias4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5b9a2b",
   "metadata": {},
   "source": [
    "Same for flattened arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4abc8dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('Models/paramvals/bias0_flat.csv', 'r') as file:\n",
    "#     csvreader = csv.reader(file)\n",
    "# #     for row in csvreader:\n",
    "# #         print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5b4c157b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the loaded versions in the appropriate variables\n",
    "# with open('Models/paramvals/weight0_flat.csv', 'rb') as f:\n",
    "#     weight0_flat = pickle.load(f)\n",
    "    \n",
    "# # with open('Models/paramvals/bias0_flat.csv', 'rb') as f:\n",
    "# #     bias0_flat = pickle.load(f)\n",
    "\n",
    "    \n",
    "# with open('Models/paramvals/weight2_flat.csv', 'rb') as f:\n",
    "#     weight2_flat = pickle.load(f)\n",
    "    \n",
    "# with open('Models/paramvals/bias2_flat.csv', 'rb') as f:\n",
    "#     bias2_flat = pickle.load(f)\n",
    "    \n",
    "# with open('Models/paramvals/weight4_flat.csv', 'rb') as f:\n",
    "#     weight4_flat = pickle.load(f)\n",
    "    \n",
    "# with open('Models/paramvals/bias4_flat.csv', 'rb') as f:\n",
    "#     bias4_flat = pickle.load(f)\n",
    "\n",
    "# # Gather together in a list of all variables\n",
    "# weights_and_biases_flat = [weight0_flat, bias0_flat, weight2_flat, bias2_flat, weight4_flat, bias4_flat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "85e7dfa7-7137-4a5f-9c90-b79ab3516a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the file:  weight0\n",
      "The shape is equal to  (600, 3)\n",
      "For the file:  bias0\n",
      "The shape is equal to  (600, 1)\n",
      "For the file:  weight2\n",
      "The shape is equal to  (200, 600)\n",
      "For the file:  bias2\n",
      "The shape is equal to  (200, 1)\n",
      "For the file:  weight4\n",
      "The shape is equal to  (1, 200)\n",
      "For the file:  bias4\n",
      "The shape is equal to  (1, 1)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape for each parameter:\n",
    "for i in range(len(weights_and_biases)):\n",
    "    print(\"For the file: \", file_names[i])\n",
    "    # Read the values\n",
    "    shape = np.shape(weights_and_biases[i])\n",
    "    print(\"The shape is equal to \", shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b07bec3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the file:  Models/paramvals/weight0_flat.csv\n",
      "The shape is equal to  (1800,)\n",
      "For the file:  Models/paramvals/bias0_flat.csv\n",
      "The shape is equal to  (600,)\n",
      "For the file:  Models/paramvals/weight2_flat.csv\n",
      "The shape is equal to  (120000,)\n",
      "For the file:  Models/paramvals/bias2_flat.csv\n",
      "The shape is equal to  (200,)\n",
      "For the file:  Models/paramvals/weight4_flat.csv\n",
      "The shape is equal to  (200,)\n",
      "For the file:  Models/paramvals/bias4_flat.csv\n",
      "The shape is equal to  ()\n"
     ]
    }
   ],
   "source": [
    "# Same for their flattened versions:\n",
    "for i in range(len(weights_and_biases_flat)):\n",
    "    print(\"For the file: \", flat_save_names[i])\n",
    "    # Read the values\n",
    "    shape = np.shape(weights_and_biases_flat[i])\n",
    "    print(\"The shape is equal to \", shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afd58f4",
   "metadata": {},
   "source": [
    "##### Play around with some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b8c6a77e-6221-4158-8dc5-2de8cdddbce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read the example file\n",
    "# print(example)\n",
    "# print(np.shape(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8cf45633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_load_value = test_load[0][0]\n",
    "# print('%.25f' % test_load_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a77502-f96b-4221-9878-4e50854bcfe2",
   "metadata": {},
   "source": [
    "## Predicting using the values in the arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9709a2-c540-4130-ac6b-3ada2552bc0b",
   "metadata": {},
   "source": [
    "When we are going to implement this in the Gmunu code, we can no longer use any of the built-in tools of PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1e65ebe8-1c4f-4c4f-aced-77fadcd57267",
   "metadata": {},
   "outputs": [],
   "source": [
    "## One specific test case for the data\n",
    "rho,eps,v,p,D,S,tau = 9.83632270803203,1.962038705851822,0.2660655147967911,12.866163917605371,10.204131145455385,12.026584842282125,22.131296926293793"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acabd1c-7014-4bae-9615-389bd9c251d5",
   "metadata": {},
   "source": [
    "This is how the PyTorch implementation works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1ffbcdea-ab47-41ce-a968-d53be5534c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact:\n",
      "12.866163917605371\n",
      "Pytorch prediction:\n",
      "12.866371154785156\n"
     ]
    }
   ],
   "source": [
    "input_test = torch.tensor([D, S, tau])\n",
    "exact_result = p\n",
    "print(\"Exact:\")\n",
    "print(exact_result)\n",
    "# print(input_test)\n",
    "with torch.no_grad():\n",
    "    pred = model(input_test).item()\n",
    "\n",
    "print(\"Pytorch prediction:\")\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28e00da-5bd8-419c-806b-4b6ecf3f2dbf",
   "metadata": {},
   "source": [
    "Now, we have to try and get the same output, but by defining all intermediate steps ourselves!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "194e0737-14b7-49b7-b3af-89221678facc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def compute_prediction(x):\n",
    "    \"\"\"Input is a np. array of size 1x3\"\"\"\n",
    "    x = np.matmul(weight0, x) + bias0\n",
    "    x = sigmoid(x)\n",
    "    x = np.matmul(weight2, x) + bias2\n",
    "    x = sigmoid(x)\n",
    "    x = np.matmul(weight4, x) + bias4\n",
    "    return x[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5745fb74-6f68-4556-a8e0-c80628e93b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3)\n",
      "(3, 1)\n"
     ]
    }
   ],
   "source": [
    "input_test = np.array([[D, S, tau]])\n",
    "print(np.shape(input_test))\n",
    "input_test = np.transpose(input_test)\n",
    "print(np.shape(input_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c422a5de-4b83-4f5f-b1e0-c6023c8cd65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.866371869133928\n",
      "12.866371154785156\n"
     ]
    }
   ],
   "source": [
    "our_prediction = compute_prediction(input_test)\n",
    "print(our_prediction)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fbe512-19ff-4157-9a33-68899241991d",
   "metadata": {},
   "source": [
    "Now we compute rho and eps from this (see appendix A of central paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "aee97e55-2be0-4bc1-8c31-62ad7b4db25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our calculations:\n",
      "9.836326155512264 1.9620391642983483\n",
      "Exact results:\n",
      "9.83632270803203 1.962038705851822\n"
     ]
    }
   ],
   "source": [
    "v_star = S/(tau + D + our_prediction)\n",
    "W_star = 1/np.sqrt(1-v_star**2)\n",
    "\n",
    "rho_star = D/W_star\n",
    "eps_star = (tau + D*(1 - W_star) + our_prediction*(1 - W_star**2))/(D*W_star)\n",
    "print(\"Our calculations:\")\n",
    "print(rho_star, eps_star)\n",
    "print(\"Exact results:\")\n",
    "print(rho, eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aff9646-60ef-402e-a56c-3eccee7478e2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## (to do) Save as hdf5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ba57a7f2-8af2-4ba6-a242-d19fbfbe034b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Open an HDF5 file for writing\n",
    "# with h5py.File(\"NNC2Pv0_params.h5\", \"w\") as f:\n",
    "#     # Save the weights and biases of the network to the HDF5 file\n",
    "#     f.create_dataset(\"NNC2Pv0_params\", data=NNC2P.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929bc14b",
   "metadata": {},
   "source": [
    "# Using Torch script and tracing the network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a983a5e9",
   "metadata": {},
   "source": [
    "There exist two ways of converting a PyTorch model to Torch Script. The first is known as tracing, a mechanism in which the structure of the model is captured by evaluating it once using example inputs, and recording the flow of those inputs through the model. This is suitable for models that make limited use of control flow. The second approach is to add explicit annotations to your model that inform the Torch Script compiler that it may directly parse and compile your model code, subject to the constraints imposed by the Torch Script language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa4c899e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 0.5000])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = torch.tensor([1, 1, 0.5])\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "71837a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  original_name=NeuralNetwork\n",
       "  (stack): Sequential(\n",
       "    original_name=Sequential\n",
       "    (0): Linear(original_name=Linear)\n",
       "    (1): Sigmoid(original_name=Sigmoid)\n",
       "    (2): Linear(original_name=Linear)\n",
       "    (3): Sigmoid(original_name=Sigmoid)\n",
       "    (4): Linear(original_name=Linear)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traced_script_module = torch.jit.trace(model, example)\n",
    "traced_script_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28fafa57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0598], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = traced_script_module(torch.tensor([1,1,0.5]))\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8866ef33",
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_script_module.save(\"NNC2Pv0t2.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7817ec-e463-4ed5-baf0-1b887b960d0b",
   "metadata": {},
   "source": [
    "__To do: finish it__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498cc2eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "author": "Thibeau Wouters",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
