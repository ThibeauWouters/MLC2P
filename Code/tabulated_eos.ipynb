{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bb9f224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "import random\n",
    "import csv\n",
    "import pandas as pd\n",
    "import h5py\n",
    "# Scikit learn libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "# PyTorch libraries\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import ToTensor, Normalize \n",
    "# Own scripts:\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import physics\n",
    "import data\n",
    "import nnc2p\n",
    "# from nnc2p import NeuralNetwork # our own architecture\n",
    "# Get dirs\n",
    "import os\n",
    "cwd = os.getcwd()# \"Code\" folder\n",
    "master_dir = os.path.abspath(os.path.join(cwd, \"..\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c3393c80",
   "metadata": {},
   "source": [
    "Point towards the folder where we store the eos tables (__Note:__ they are not in the Github as these are very large files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efbc8d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eos_tables_folder = os.path.join(\"D:\\Coding\\eos_tables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fb3c8c",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "96ab265e",
   "metadata": {},
   "source": [
    "Here, we try to find a way to generalize the NN approach from the first semester to the situation of tabular EOS. More work coming soon!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf08ad4a",
   "metadata": {},
   "source": [
    "# Exploring EOS tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d5e6fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the downloaded EOS tables here\n",
    "first_table_filename       = \"LS180_234r_136t_50y_analmu_20091212_SVNr26.h5\"\n",
    "second_table_filename = \"GShen_NL3EOS_rho280_temp180_ye52_version_1.1_20120817.h5\"\n",
    "third_table_filename      = \"SLy4_0000_rho391_temp163_ye66.h5\"\n",
    "# Then specify which we are going to use here\n",
    "eos_table_filename = third_table_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d8f465",
   "metadata": {},
   "source": [
    "Read in the SLy4 EOS table using our py script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "913d9582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This EOS table has dimensions 66 x 163 x 391\n"
     ]
    }
   ],
   "source": [
    "eos_table = physics.read_eos_table(eos_table_filename)\n",
    "dim_ye, dim_temp, dim_rho = eos_table[\"pointsye\"][()][0], eos_table[\"pointstemp\"][()][0], eos_table[\"pointsrho\"][()][0]\n",
    "print(f\"This EOS table has dimensions {dim_ye} x {dim_temp} x {dim_rho}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2d38366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66, 163, 391)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(eos_table[\"logenergy\"][()])  # same dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d74b0643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For ye 0.005, log temp -3.0, log rho 3.0239960056064277, we have log p: 17.99956975587081.\n"
     ]
    }
   ],
   "source": [
    "# Small test to see the output of the EOS table\n",
    "test_ye = eos_table[\"ye\"][()][0]\n",
    "test_temp = eos_table[\"logtemp\"][()][0]\n",
    "test_rho = eos_table[\"logrho\"][()][0]\n",
    "test_press = eos_table[\"logpress\"][()][0, 0, 0]\n",
    "print(f\"For ye {test_ye}, log temp {test_temp}, log rho {test_rho}, we have log p: {test_press}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc15e58b",
   "metadata": {},
   "source": [
    "# Generating training data by sampling from EOS table"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bc8fc6d3",
   "metadata": {},
   "source": [
    "To generate new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "511ae7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dat = physics.generate_tabular_data(eos_table, number_of_points = 100000, save_name = \"SLy4_training_data\")\n",
    "# dat = physics.generate_tabular_data(eos_table, number_of_points = 20000, save_name = \"SLy4_test_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a121af",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f929937d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rho</th>\n",
       "      <th>eps</th>\n",
       "      <th>v</th>\n",
       "      <th>temp</th>\n",
       "      <th>ye</th>\n",
       "      <th>p</th>\n",
       "      <th>D</th>\n",
       "      <th>S</th>\n",
       "      <th>tau</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.590663</td>\n",
       "      <td>19.381445</td>\n",
       "      <td>0.683568</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.045</td>\n",
       "      <td>31.985334</td>\n",
       "      <td>18.620245</td>\n",
       "      <td>580.748110</td>\n",
       "      <td>655.358209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.457329</td>\n",
       "      <td>28.786040</td>\n",
       "      <td>0.041886</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>0.545</td>\n",
       "      <td>34.766248</td>\n",
       "      <td>6.463001</td>\n",
       "      <td>13.269992</td>\n",
       "      <td>186.431092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.323996</td>\n",
       "      <td>19.654200</td>\n",
       "      <td>0.558550</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.535</td>\n",
       "      <td>30.418591</td>\n",
       "      <td>13.652070</td>\n",
       "      <td>310.329455</td>\n",
       "      <td>393.570454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.723996</td>\n",
       "      <td>19.246855</td>\n",
       "      <td>0.009527</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>0.095</td>\n",
       "      <td>26.341137</td>\n",
       "      <td>8.724392</td>\n",
       "      <td>2.749496</td>\n",
       "      <td>167.935288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.523996</td>\n",
       "      <td>29.186040</td>\n",
       "      <td>0.334705</td>\n",
       "      <td>2.033333</td>\n",
       "      <td>0.095</td>\n",
       "      <td>34.232914</td>\n",
       "      <td>5.862105</td>\n",
       "      <td>103.365923</td>\n",
       "      <td>195.482542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>3.323996</td>\n",
       "      <td>25.652376</td>\n",
       "      <td>0.577186</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.435</td>\n",
       "      <td>28.498601</td>\n",
       "      <td>4.070468</td>\n",
       "      <td>125.881369</td>\n",
       "      <td>157.178893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>9.757329</td>\n",
       "      <td>19.124371</td>\n",
       "      <td>0.376611</td>\n",
       "      <td>-2.900000</td>\n",
       "      <td>0.295</td>\n",
       "      <td>27.371010</td>\n",
       "      <td>10.532847</td>\n",
       "      <td>140.768515</td>\n",
       "      <td>238.842241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>9.590663</td>\n",
       "      <td>19.114310</td>\n",
       "      <td>0.266570</td>\n",
       "      <td>-0.833333</td>\n",
       "      <td>0.305</td>\n",
       "      <td>27.176186</td>\n",
       "      <td>9.950723</td>\n",
       "      <td>90.427775</td>\n",
       "      <td>207.064143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>14.690663</td>\n",
       "      <td>20.976110</td>\n",
       "      <td>0.476948</td>\n",
       "      <td>2.233333</td>\n",
       "      <td>0.485</td>\n",
       "      <td>35.391058</td>\n",
       "      <td>16.714229</td>\n",
       "      <td>326.155098</td>\n",
       "      <td>461.688397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>7.590663</td>\n",
       "      <td>19.036140</td>\n",
       "      <td>0.589693</td>\n",
       "      <td>-2.133333</td>\n",
       "      <td>0.455</td>\n",
       "      <td>24.684220</td>\n",
       "      <td>9.398714</td>\n",
       "      <td>224.588620</td>\n",
       "      <td>275.127114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             rho        eps         v      temp     ye          p          D  \\\n",
       "0      13.590663  19.381445  0.683568 -0.333333  0.045  31.985334  18.620245   \n",
       "1       6.457329  28.786040  0.041886  2.166667  0.545  34.766248   6.463001   \n",
       "2      11.323996  19.654200  0.558550  0.866667  0.535  30.418591  13.652070   \n",
       "3       8.723996  19.246855  0.009527 -0.300000  0.095  26.341137   8.724392   \n",
       "4       5.523996  29.186040  0.334705  2.033333  0.095  34.232914   5.862105   \n",
       "...          ...        ...       ...       ...    ...        ...        ...   \n",
       "99995   3.323996  25.652376  0.577186  0.600000  0.435  28.498601   4.070468   \n",
       "99996   9.757329  19.124371  0.376611 -2.900000  0.295  27.371010  10.532847   \n",
       "99997   9.590663  19.114310  0.266570 -0.833333  0.305  27.176186   9.950723   \n",
       "99998  14.690663  20.976110  0.476948  2.233333  0.485  35.391058  16.714229   \n",
       "99999   7.590663  19.036140  0.589693 -2.133333  0.455  24.684220   9.398714   \n",
       "\n",
       "                S         tau  \n",
       "0      580.748110  655.358209  \n",
       "1       13.269992  186.431092  \n",
       "2      310.329455  393.570454  \n",
       "3        2.749496  167.935288  \n",
       "4      103.365923  195.482542  \n",
       "...           ...         ...  \n",
       "99995  125.881369  157.178893  \n",
       "99996  140.768515  238.842241  \n",
       "99997   90.427775  207.064143  \n",
       "99998  326.155098  461.688397  \n",
       "99999  224.588620  275.127114  \n",
       "\n",
       "[100000 rows x 9 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(master_dir, \"Data/SLy4_training_data.csv\"))\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cc8dda30",
   "metadata": {},
   "source": [
    "__TODO__ delete -- Get the mean for normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d6f69f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean is [ 10.61740893 171.68079015 283.8404585 ], std is [  4.38641801 155.12454904 147.9843713 ]\n"
     ]
    }
   ],
   "source": [
    "# input_channels = np.array([df[\"D\"], df[\"S\"], df[\"tau\"]]) \n",
    "# tabular_mean = np.mean(input_channels, axis=1)\n",
    "# tabular_std  = np.std(input_channels, axis=1)\n",
    "# print(f\"Mean is {tabular_mean}, std is {tabular_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c8457b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Normalize the input data, if not done already (check this by checking if mean is smaller than 1e-3)\n",
    "# if abs(np.mean(df[\"S\"])) > 1e-3:\n",
    "#     for i, var in enumerate([\"D\", \"S\", \"tau\"]):\n",
    "#         df[var] = (df[var] - tabular_mean[i])/tabular_std[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451d20ee",
   "metadata": {},
   "source": [
    "For comparison, this was the table we trained on for the ideal gas EOS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74c3ad69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rho</th>\n",
       "      <th>eps</th>\n",
       "      <th>v</th>\n",
       "      <th>p</th>\n",
       "      <th>D</th>\n",
       "      <th>S</th>\n",
       "      <th>tau</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.662984</td>\n",
       "      <td>0.084146</td>\n",
       "      <td>0.218802</td>\n",
       "      <td>0.037192</td>\n",
       "      <td>0.679448</td>\n",
       "      <td>0.173724</td>\n",
       "      <td>0.077335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.565808</td>\n",
       "      <td>0.205945</td>\n",
       "      <td>0.657351</td>\n",
       "      <td>1.176059</td>\n",
       "      <td>11.366755</td>\n",
       "      <td>13.318537</td>\n",
       "      <td>7.718100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.387112</td>\n",
       "      <td>1.598809</td>\n",
       "      <td>0.021593</td>\n",
       "      <td>4.676103</td>\n",
       "      <td>4.388135</td>\n",
       "      <td>0.347321</td>\n",
       "      <td>7.020631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.337054</td>\n",
       "      <td>0.530803</td>\n",
       "      <td>0.351307</td>\n",
       "      <td>1.888615</td>\n",
       "      <td>5.700396</td>\n",
       "      <td>4.031171</td>\n",
       "      <td>3.885760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.133895</td>\n",
       "      <td>0.786717</td>\n",
       "      <td>0.079475</td>\n",
       "      <td>0.594703</td>\n",
       "      <td>1.137493</td>\n",
       "      <td>0.209600</td>\n",
       "      <td>0.905115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79995</th>\n",
       "      <td>8.101834</td>\n",
       "      <td>0.428605</td>\n",
       "      <td>0.616897</td>\n",
       "      <td>2.314990</td>\n",
       "      <td>10.294002</td>\n",
       "      <td>13.832316</td>\n",
       "      <td>9.813427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79996</th>\n",
       "      <td>7.841014</td>\n",
       "      <td>1.125480</td>\n",
       "      <td>0.209087</td>\n",
       "      <td>5.883268</td>\n",
       "      <td>8.018242</td>\n",
       "      <td>4.930289</td>\n",
       "      <td>9.678536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79997</th>\n",
       "      <td>4.628822</td>\n",
       "      <td>0.194190</td>\n",
       "      <td>0.237759</td>\n",
       "      <td>0.599248</td>\n",
       "      <td>4.765476</td>\n",
       "      <td>1.544018</td>\n",
       "      <td>1.129323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79998</th>\n",
       "      <td>9.913117</td>\n",
       "      <td>1.152242</td>\n",
       "      <td>0.477216</td>\n",
       "      <td>7.614874</td>\n",
       "      <td>11.280468</td>\n",
       "      <td>17.889657</td>\n",
       "      <td>18.592193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79999</th>\n",
       "      <td>9.717025</td>\n",
       "      <td>0.001552</td>\n",
       "      <td>0.163383</td>\n",
       "      <td>0.010052</td>\n",
       "      <td>9.849373</td>\n",
       "      <td>1.635352</td>\n",
       "      <td>0.149919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            rho       eps         v         p          D          S        tau\n",
       "0      0.662984  0.084146  0.218802  0.037192   0.679448   0.173724   0.077335\n",
       "1      8.565808  0.205945  0.657351  1.176059  11.366755  13.318537   7.718100\n",
       "2      4.387112  1.598809  0.021593  4.676103   4.388135   0.347321   7.020631\n",
       "3      5.337054  0.530803  0.351307  1.888615   5.700396   4.031171   3.885760\n",
       "4      1.133895  0.786717  0.079475  0.594703   1.137493   0.209600   0.905115\n",
       "...         ...       ...       ...       ...        ...        ...        ...\n",
       "79995  8.101834  0.428605  0.616897  2.314990  10.294002  13.832316   9.813427\n",
       "79996  7.841014  1.125480  0.209087  5.883268   8.018242   4.930289   9.678536\n",
       "79997  4.628822  0.194190  0.237759  0.599248   4.765476   1.544018   1.129323\n",
       "79998  9.913117  1.152242  0.477216  7.614874  11.280468  17.889657  18.592193\n",
       "79999  9.717025  0.001552  0.163383  0.010052   9.849373   1.635352   0.149919\n",
       "\n",
       "[80000 rows x 7 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_df = pd.read_csv(os.path.join(master_dir, \"Data/ideal_gas_c2p_train_data.csv\"))\n",
    "old_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8fd2f127",
   "metadata": {},
   "source": [
    "# NNC2P"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714ed67a",
   "metadata": {},
   "source": [
    "## Define architecture and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "118ed574",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNC2P(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements a neural network for the C2P conversion, using tabulated SLy4 EOS.\n",
    "    \"\"\"\n",
    "    def __init__(self, h: list = [600, 200], reg: bool = False, activation_function = torch.nn.Sigmoid) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the neural network class.\n",
    "        \"\"\"\n",
    "        # Call the super constructor first\n",
    "        super(NNC2P, self).__init__()\n",
    "        \n",
    "        # For convenience, save the sizes of the hidden layers as fields as well\n",
    "        self.h = h\n",
    "        # Add visible layers as well: input is 3D and output is 1D\n",
    "        self.h_augmented = [3] + h + [1]\n",
    "\n",
    "        # Add field to specify whether or not we do regularization\n",
    "        self.regularization = reg\n",
    "\n",
    "        # Define the layers:\n",
    "        for i in range(len(self.h_augmented)-1):\n",
    "            if i == len(self.h_augmented)-2:\n",
    "                setattr(self, f\"linear{i+1}\", nn.Linear(self.h_augmented[i], self.h_augmented[i+1], bias=False))\n",
    "            else:\n",
    "                setattr(self, f\"linear{i+1}\", nn.Linear(self.h_augmented[i], self.h_augmented[i+1]))\n",
    "                setattr(self, f\"activation{i+1}\", activation_function())\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Computes a forward step given the input x.\n",
    "        :param x: Input for the neural network.\n",
    "        :return: x: Output neural network\n",
    "        \"\"\"\n",
    "\n",
    "        for i, module in enumerate(self.modules()):\n",
    "            # The first module is the whole NNC2P object, continue\n",
    "            if i == 0:\n",
    "                continue\n",
    "            x = module(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6d6047",
   "metadata": {},
   "source": [
    "Get the training data as DataSet and DataLoader objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "bf69d945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data as pandas dataframes\n",
    "train_df = pd.read_csv(os.path.join(master_dir, \"Data/SLy4_training_data.csv\"))\n",
    "test_df  = pd.read_csv(os.path.join(master_dir, \"Data/SLy4_test_data.csv\"))\n",
    "# Convert to PyTorch Datasets as we defined them\n",
    "train_dataset = data.CustomDataset(train_df)\n",
    "test_dataset  = data.CustomDataset(test_df, mean=train_dataset.mean, std=train_dataset.std)\n",
    "# Then create dataloaders, with batch size 32, from datasets\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32)\n",
    "test_dataloader  = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8cd89581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rho</th>\n",
       "      <th>eps</th>\n",
       "      <th>v</th>\n",
       "      <th>temp</th>\n",
       "      <th>ye</th>\n",
       "      <th>p</th>\n",
       "      <th>D</th>\n",
       "      <th>S</th>\n",
       "      <th>tau</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.590663</td>\n",
       "      <td>19.381445</td>\n",
       "      <td>0.683568</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.045</td>\n",
       "      <td>31.985334</td>\n",
       "      <td>18.620245</td>\n",
       "      <td>580.748110</td>\n",
       "      <td>655.358209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.457329</td>\n",
       "      <td>28.786040</td>\n",
       "      <td>0.041886</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>0.545</td>\n",
       "      <td>34.766248</td>\n",
       "      <td>6.463001</td>\n",
       "      <td>13.269992</td>\n",
       "      <td>186.431092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.323996</td>\n",
       "      <td>19.654200</td>\n",
       "      <td>0.558550</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.535</td>\n",
       "      <td>30.418591</td>\n",
       "      <td>13.652070</td>\n",
       "      <td>310.329455</td>\n",
       "      <td>393.570454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.723996</td>\n",
       "      <td>19.246855</td>\n",
       "      <td>0.009527</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>0.095</td>\n",
       "      <td>26.341137</td>\n",
       "      <td>8.724392</td>\n",
       "      <td>2.749496</td>\n",
       "      <td>167.935288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.523996</td>\n",
       "      <td>29.186040</td>\n",
       "      <td>0.334705</td>\n",
       "      <td>2.033333</td>\n",
       "      <td>0.095</td>\n",
       "      <td>34.232914</td>\n",
       "      <td>5.862105</td>\n",
       "      <td>103.365923</td>\n",
       "      <td>195.482542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>3.323996</td>\n",
       "      <td>25.652376</td>\n",
       "      <td>0.577186</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.435</td>\n",
       "      <td>28.498601</td>\n",
       "      <td>4.070468</td>\n",
       "      <td>125.881369</td>\n",
       "      <td>157.178893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>9.757329</td>\n",
       "      <td>19.124371</td>\n",
       "      <td>0.376611</td>\n",
       "      <td>-2.900000</td>\n",
       "      <td>0.295</td>\n",
       "      <td>27.371010</td>\n",
       "      <td>10.532847</td>\n",
       "      <td>140.768515</td>\n",
       "      <td>238.842241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>9.590663</td>\n",
       "      <td>19.114310</td>\n",
       "      <td>0.266570</td>\n",
       "      <td>-0.833333</td>\n",
       "      <td>0.305</td>\n",
       "      <td>27.176186</td>\n",
       "      <td>9.950723</td>\n",
       "      <td>90.427775</td>\n",
       "      <td>207.064143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>14.690663</td>\n",
       "      <td>20.976110</td>\n",
       "      <td>0.476948</td>\n",
       "      <td>2.233333</td>\n",
       "      <td>0.485</td>\n",
       "      <td>35.391058</td>\n",
       "      <td>16.714229</td>\n",
       "      <td>326.155098</td>\n",
       "      <td>461.688397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>7.590663</td>\n",
       "      <td>19.036140</td>\n",
       "      <td>0.589693</td>\n",
       "      <td>-2.133333</td>\n",
       "      <td>0.455</td>\n",
       "      <td>24.684220</td>\n",
       "      <td>9.398714</td>\n",
       "      <td>224.588620</td>\n",
       "      <td>275.127114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             rho        eps         v      temp     ye          p          D  \\\n",
       "0      13.590663  19.381445  0.683568 -0.333333  0.045  31.985334  18.620245   \n",
       "1       6.457329  28.786040  0.041886  2.166667  0.545  34.766248   6.463001   \n",
       "2      11.323996  19.654200  0.558550  0.866667  0.535  30.418591  13.652070   \n",
       "3       8.723996  19.246855  0.009527 -0.300000  0.095  26.341137   8.724392   \n",
       "4       5.523996  29.186040  0.334705  2.033333  0.095  34.232914   5.862105   \n",
       "...          ...        ...       ...       ...    ...        ...        ...   \n",
       "99995   3.323996  25.652376  0.577186  0.600000  0.435  28.498601   4.070468   \n",
       "99996   9.757329  19.124371  0.376611 -2.900000  0.295  27.371010  10.532847   \n",
       "99997   9.590663  19.114310  0.266570 -0.833333  0.305  27.176186   9.950723   \n",
       "99998  14.690663  20.976110  0.476948  2.233333  0.485  35.391058  16.714229   \n",
       "99999   7.590663  19.036140  0.589693 -2.133333  0.455  24.684220   9.398714   \n",
       "\n",
       "                S         tau  \n",
       "0      580.748110  655.358209  \n",
       "1       13.269992  186.431092  \n",
       "2      310.329455  393.570454  \n",
       "3        2.749496  167.935288  \n",
       "4      103.365923  195.482542  \n",
       "...           ...         ...  \n",
       "99995  125.881369  157.178893  \n",
       "99996  140.768515  238.842241  \n",
       "99997   90.427775  207.064143  \n",
       "99998  326.155098  461.688397  \n",
       "99999  224.588620  275.127114  \n",
       "\n",
       "[100000 rows x 9 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e620372b",
   "metadata": {},
   "source": [
    "Have a look at normalization procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3ae89a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 18.6202, 580.7481, 655.3582])\n",
      "[ 10.61740893 171.68079015 283.8404585 ] [  4.38641801 155.12454904 147.9843713 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([1.8245, 2.6370, 2.5105]), tensor([31.9853]))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = 0\n",
    "example = torch.from_numpy(np.array([train_df[\"D\"][index], train_df[\"S\"][index], train_df[\"tau\"][index]])).float()\n",
    "print(example)\n",
    "print(train_dataset.mean, train_dataset.std)\n",
    "train_dataset.__getitem__(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12e532a",
   "metadata": {},
   "source": [
    "Create a new instance of the NNC2P:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "be7a388c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NNC2P(\n",
       "  (linear1): Linear(in_features=3, out_features=600, bias=True)\n",
       "  (activation1): ReLU()\n",
       "  (linear2): Linear(in_features=600, out_features=200, bias=True)\n",
       "  (activation2): ReLU()\n",
       "  (linear3): Linear(in_features=200, out_features=1, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NNC2P(h=[600, 200], activation_function=nn.ReLU)\n",
    "model\n",
    "# for i, module in enumerate(model.modules()):\n",
    "#     print(i)\n",
    "#     print(module)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1e3745",
   "metadata": {},
   "source": [
    "Create a trainer object from it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "df92e917",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = nnc2p.Trainer(model, 1e-2, train_dataloader=train_dataloader, test_dataloader=test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0f90f8a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122800"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnc2p.count_parameters(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5a7e30e2",
   "metadata": {},
   "source": [
    "## Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "53ce8669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model for 500 epochs.\n",
      "\n",
      " Epoch 0 \n",
      " --------------\n",
      "Train loss: 3.31E-01\n",
      "Test  loss: 3.25E-01\n",
      "\n",
      " Epoch 1 \n",
      " --------------\n",
      "Train loss: 2.84E-01\n",
      "Test  loss: 2.79E-01\n",
      "\n",
      " Epoch 2 \n",
      " --------------\n",
      "Train loss: 3.48E-01\n",
      "Test  loss: 3.44E-01\n",
      "\n",
      " Epoch 3 \n",
      " --------------\n",
      "Train loss: 6.63E-01\n",
      "Test  loss: 6.63E-01\n",
      "\n",
      " Epoch 4 \n",
      " --------------\n",
      "Train loss: 4.68E-01\n",
      "Test  loss: 4.62E-01\n",
      "\n",
      " Epoch 5 \n",
      " --------------\n",
      "Train loss: 3.69E-01\n",
      "Test  loss: 3.65E-01\n",
      "\n",
      " Epoch 6 \n",
      " --------------\n",
      "Train loss: 4.30E-01\n",
      "Test  loss: 4.26E-01\n",
      "\n",
      " Epoch 7 \n",
      " --------------\n",
      "Train loss: 4.41E-01\n",
      "Test  loss: 4.35E-01\n",
      "\n",
      " Epoch 8 \n",
      " --------------\n",
      "Train loss: 4.13E-01\n",
      "Test  loss: 4.08E-01\n",
      "\n",
      " Epoch 9 \n",
      " --------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[118], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[1;32md:\\Coding\\master-thesis-AI\\Code\\nnc2p.py:407\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, adaptation_threshold, adaptation_multiplier, number_of_epochs, log_file, csv_file)\u001b[0m\n\u001b[0;32m    405\u001b[0m write_to_txt(log_file, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m Epoch \u001b[39m\u001b[39m{\u001b[39;00mepoch_counter\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m --------------\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    406\u001b[0m \u001b[39m# Train the network\u001b[39;00m\n\u001b[1;32m--> 407\u001b[0m train_loop(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_dataloader, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss_fn, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer, use_c2p_loss\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49muse_c2p_loss)\n\u001b[0;32m    408\u001b[0m \u001b[39m# Test on the training data\u001b[39;00m\n\u001b[0;32m    409\u001b[0m average_train_loss \u001b[39m=\u001b[39m test_loop(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_dataloader, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_fn)\n",
      "File \u001b[1;32md:\\Coding\\master-thesis-AI\\Code\\nnc2p.py:287\u001b[0m, in \u001b[0;36mtrain_loop\u001b[1;34m(dataloader, model, loss_fn, optimizer, report_progress, use_c2p_loss)\u001b[0m\n\u001b[0;32m    285\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m    286\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m--> 287\u001b[0m optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[0;32m    289\u001b[0m \u001b[39m# If we want to report progress during training (not recommended - obstructs view)\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39mif\u001b[39;00m report_progress:\n",
      "File \u001b[1;32md:\\Anaconda3\\lib\\site-packages\\torch\\optim\\optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[0;32m    139\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[1;32m--> 140\u001b[0m     out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     obj\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32md:\\Anaconda3\\lib\\site-packages\\torch\\optim\\optimizer.py:23\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     22\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m---> 23\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     24\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     25\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[1;32md:\\Anaconda3\\lib\\site-packages\\torch\\optim\\adam.py:234\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[0;32m    231\u001b[0m                 \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39m`requires_grad` is not supported for `step` in differentiable mode\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    232\u001b[0m             state_steps\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m--> 234\u001b[0m     adam(params_with_grad,\n\u001b[0;32m    235\u001b[0m          grads,\n\u001b[0;32m    236\u001b[0m          exp_avgs,\n\u001b[0;32m    237\u001b[0m          exp_avg_sqs,\n\u001b[0;32m    238\u001b[0m          max_exp_avg_sqs,\n\u001b[0;32m    239\u001b[0m          state_steps,\n\u001b[0;32m    240\u001b[0m          amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    241\u001b[0m          beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[0;32m    242\u001b[0m          beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[0;32m    243\u001b[0m          lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    244\u001b[0m          weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    245\u001b[0m          eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    246\u001b[0m          maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    247\u001b[0m          foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    248\u001b[0m          capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    249\u001b[0m          differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    250\u001b[0m          fused\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    251\u001b[0m          grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[0;32m    252\u001b[0m          found_inf\u001b[39m=\u001b[39;49mfound_inf)\n\u001b[0;32m    254\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32md:\\Anaconda3\\lib\\site-packages\\torch\\optim\\adam.py:300\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    298\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 300\u001b[0m func(params,\n\u001b[0;32m    301\u001b[0m      grads,\n\u001b[0;32m    302\u001b[0m      exp_avgs,\n\u001b[0;32m    303\u001b[0m      exp_avg_sqs,\n\u001b[0;32m    304\u001b[0m      max_exp_avg_sqs,\n\u001b[0;32m    305\u001b[0m      state_steps,\n\u001b[0;32m    306\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[0;32m    307\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[0;32m    308\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[0;32m    309\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[0;32m    310\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[0;32m    311\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[0;32m    312\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[0;32m    313\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable,\n\u001b[0;32m    314\u001b[0m      differentiable\u001b[39m=\u001b[39;49mdifferentiable,\n\u001b[0;32m    315\u001b[0m      grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[0;32m    316\u001b[0m      found_inf\u001b[39m=\u001b[39;49mfound_inf)\n",
      "File \u001b[1;32md:\\Anaconda3\\lib\\site-packages\\torch\\optim\\adam.py:363\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    360\u001b[0m     param \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mview_as_real(param)\n\u001b[0;32m    362\u001b[0m \u001b[39m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[1;32m--> 363\u001b[0m exp_avg\u001b[39m.\u001b[39;49mmul_(beta1)\u001b[39m.\u001b[39madd_(grad, alpha\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m beta1)\n\u001b[0;32m    364\u001b[0m exp_avg_sq\u001b[39m.\u001b[39mmul_(beta2)\u001b[39m.\u001b[39maddcmul_(grad, grad\u001b[39m.\u001b[39mconj(), value\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m beta2)\n\u001b[0;32m    366\u001b[0m \u001b[39mif\u001b[39;00m capturable \u001b[39mor\u001b[39;00m differentiable:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbef171",
   "metadata": {},
   "source": [
    "__TODO__ do hyperparameter search over learning rate?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb04008",
   "metadata": {},
   "source": [
    "__TODO__ is the normalization done correctly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "8337841e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.41859103563728\n",
      "tensor([0.8938, 0.6918, 0.7415])\n",
      "tensor([-0.0249], grad_fn=<SqueezeBackward3>)\n"
     ]
    }
   ],
   "source": [
    "index = 2\n",
    "print(train_df[\"p\"][index])\n",
    "example = torch.from_numpy(np.array([train_df[\"S\"][index], train_df[\"D\"][index], train_df[\"tau\"][index]])).float()\n",
    "print(example)\n",
    "# Check the results\n",
    "print(model(example))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ad41d2a",
   "metadata": {},
   "source": [
    "# NNE2T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "86a9e249",
   "metadata": {},
   "source": [
    "I was wondering if it would be easy to convert in some way from temperature to energy, as that is done as well in the code with rootfinding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3416ec59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNE2T(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements a neural network for the energy to temperature conversion, using tabulated SLy4 EOS.\n",
    "    \"\"\"\n",
    "    def __init__(self, h: list = [10, 20], reg: bool = False, activation_function = torch.nn.Sigmoid) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the neural network class.\n",
    "        \"\"\"\n",
    "        # Call the super constructor first\n",
    "        super(NNE2T, self).__init__()\n",
    "        \n",
    "        # For convenience, save the sizes of the hidden layers as fields as well\n",
    "        self.h = h\n",
    "        # Add visible layers as well: input is 3D and output is 1D\n",
    "        self.h_augmented = [1] + h + [1]\n",
    "\n",
    "        # Add field to specify whether or not we do regularization\n",
    "        self.regularization = reg\n",
    "\n",
    "        # Define the layers:\n",
    "        for i in range(len(self.h_augmented)-1):\n",
    "            if i == len(self.h_augmented)-2:\n",
    "                setattr(self, f\"linear{i+1}\", nn.Linear(self.h_augmented[i], self.h_augmented[i+1], bias=False))\n",
    "            else:\n",
    "                setattr(self, f\"linear{i+1}\", nn.Linear(self.h_augmented[i], self.h_augmented[i+1]))\n",
    "                setattr(self, f\"activation{i+1}\", activation_function())\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Computes a forward step given the input x.\n",
    "        :param x: Input for the neural network.\n",
    "        :return: x: Output neural network\n",
    "        \"\"\"\n",
    "\n",
    "        for i, module in enumerate(self.modules()):\n",
    "            # The first module is the whole NNC2P object, continue\n",
    "            if i == 0:\n",
    "                continue\n",
    "            x = module(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48c2780",
   "metadata": {},
   "source": [
    "Get the training data as DataSet and DataLoader objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9d340baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data as pandas dataframes\n",
    "train_df = pd.read_csv(os.path.join(master_dir, \"Data/SLy4_training_data.csv\"))\n",
    "test_df  = pd.read_csv(os.path.join(master_dir, \"Data/SLy4_test_data.csv\"))\n",
    "# Convert to PyTorch Datasets as we defined them\n",
    "train_dataset = data.CustomDataset(train_df, feature_names = [\"eps\"], label_names = [\"temp\"], normalize=False)\n",
    "test_dataset  = data.CustomDataset(test_df, feature_names = [\"eps\"], label_names = [\"temp\"], mean = train_dataset.mean, std = test_dataset.std, normalize=False)\n",
    "# Then create dataloaders, with batch size 32, from datasets\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32)\n",
    "test_dataloader  = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7c09765f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "train_dataset.mean == test_dataset.mean"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "45d605ca",
   "metadata": {},
   "source": [
    "Check normalization procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ac944622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rho</th>\n",
       "      <th>eps</th>\n",
       "      <th>v</th>\n",
       "      <th>temp</th>\n",
       "      <th>ye</th>\n",
       "      <th>p</th>\n",
       "      <th>D</th>\n",
       "      <th>S</th>\n",
       "      <th>tau</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.590663</td>\n",
       "      <td>19.381445</td>\n",
       "      <td>0.683568</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.045</td>\n",
       "      <td>31.985334</td>\n",
       "      <td>18.620245</td>\n",
       "      <td>580.748110</td>\n",
       "      <td>655.358209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.457329</td>\n",
       "      <td>28.786040</td>\n",
       "      <td>0.041886</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>0.545</td>\n",
       "      <td>34.766248</td>\n",
       "      <td>6.463001</td>\n",
       "      <td>13.269992</td>\n",
       "      <td>186.431092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.323996</td>\n",
       "      <td>19.654200</td>\n",
       "      <td>0.558550</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.535</td>\n",
       "      <td>30.418591</td>\n",
       "      <td>13.652070</td>\n",
       "      <td>310.329455</td>\n",
       "      <td>393.570454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.723996</td>\n",
       "      <td>19.246855</td>\n",
       "      <td>0.009527</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>0.095</td>\n",
       "      <td>26.341137</td>\n",
       "      <td>8.724392</td>\n",
       "      <td>2.749496</td>\n",
       "      <td>167.935288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.523996</td>\n",
       "      <td>29.186040</td>\n",
       "      <td>0.334705</td>\n",
       "      <td>2.033333</td>\n",
       "      <td>0.095</td>\n",
       "      <td>34.232914</td>\n",
       "      <td>5.862105</td>\n",
       "      <td>103.365923</td>\n",
       "      <td>195.482542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>3.323996</td>\n",
       "      <td>25.652376</td>\n",
       "      <td>0.577186</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.435</td>\n",
       "      <td>28.498601</td>\n",
       "      <td>4.070468</td>\n",
       "      <td>125.881369</td>\n",
       "      <td>157.178893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>9.757329</td>\n",
       "      <td>19.124371</td>\n",
       "      <td>0.376611</td>\n",
       "      <td>-2.900000</td>\n",
       "      <td>0.295</td>\n",
       "      <td>27.371010</td>\n",
       "      <td>10.532847</td>\n",
       "      <td>140.768515</td>\n",
       "      <td>238.842241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>9.590663</td>\n",
       "      <td>19.114310</td>\n",
       "      <td>0.266570</td>\n",
       "      <td>-0.833333</td>\n",
       "      <td>0.305</td>\n",
       "      <td>27.176186</td>\n",
       "      <td>9.950723</td>\n",
       "      <td>90.427775</td>\n",
       "      <td>207.064143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>14.690663</td>\n",
       "      <td>20.976110</td>\n",
       "      <td>0.476948</td>\n",
       "      <td>2.233333</td>\n",
       "      <td>0.485</td>\n",
       "      <td>35.391058</td>\n",
       "      <td>16.714229</td>\n",
       "      <td>326.155098</td>\n",
       "      <td>461.688397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>7.590663</td>\n",
       "      <td>19.036140</td>\n",
       "      <td>0.589693</td>\n",
       "      <td>-2.133333</td>\n",
       "      <td>0.455</td>\n",
       "      <td>24.684220</td>\n",
       "      <td>9.398714</td>\n",
       "      <td>224.588620</td>\n",
       "      <td>275.127114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             rho        eps         v      temp     ye          p          D  \\\n",
       "0      13.590663  19.381445  0.683568 -0.333333  0.045  31.985334  18.620245   \n",
       "1       6.457329  28.786040  0.041886  2.166667  0.545  34.766248   6.463001   \n",
       "2      11.323996  19.654200  0.558550  0.866667  0.535  30.418591  13.652070   \n",
       "3       8.723996  19.246855  0.009527 -0.300000  0.095  26.341137   8.724392   \n",
       "4       5.523996  29.186040  0.334705  2.033333  0.095  34.232914   5.862105   \n",
       "...          ...        ...       ...       ...    ...        ...        ...   \n",
       "99995   3.323996  25.652376  0.577186  0.600000  0.435  28.498601   4.070468   \n",
       "99996   9.757329  19.124371  0.376611 -2.900000  0.295  27.371010  10.532847   \n",
       "99997   9.590663  19.114310  0.266570 -0.833333  0.305  27.176186   9.950723   \n",
       "99998  14.690663  20.976110  0.476948  2.233333  0.485  35.391058  16.714229   \n",
       "99999   7.590663  19.036140  0.589693 -2.133333  0.455  24.684220   9.398714   \n",
       "\n",
       "                S         tau  \n",
       "0      580.748110  655.358209  \n",
       "1       13.269992  186.431092  \n",
       "2      310.329455  393.570454  \n",
       "3        2.749496  167.935288  \n",
       "4      103.365923  195.482542  \n",
       "...           ...         ...  \n",
       "99995  125.881369  157.178893  \n",
       "99996  140.768515  238.842241  \n",
       "99997   90.427775  207.064143  \n",
       "99998  326.155098  461.688397  \n",
       "99999  224.588620  275.127114  \n",
       "\n",
       "[100000 rows x 9 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([19.3814])\n",
      "[21.05666875] [2.88130898]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([19.3814]), tensor([-0.3333]))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = 0\n",
    "example = torch.from_numpy(np.array([train_df[\"eps\"][index]])).float()\n",
    "print(example)\n",
    "print(train_dataset.mean, train_dataset.std)\n",
    "train_dataset.__getitem__(index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "08c12480",
   "metadata": {},
   "source": [
    "Create a new instance of the neural net:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "52a29615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NNE2T(\n",
       "  (linear1): Linear(in_features=1, out_features=100, bias=True)\n",
       "  (activation1): ReLU()\n",
       "  (linear2): Linear(in_features=100, out_features=200, bias=True)\n",
       "  (activation2): ReLU()\n",
       "  (linear3): Linear(in_features=200, out_features=1, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NNE2T([100, 200], activation_function=nn.ReLU)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dcd015",
   "metadata": {},
   "source": [
    "Create a trainer object from it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "77253d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = nnc2p.Trainer(model, 0.1, train_dataloader=train_dataloader, test_dataloader=test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "88d38780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20600"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnc2p.count_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204f037c",
   "metadata": {},
   "source": [
    "## Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5de815ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model for 500 epochs.\n",
      "\n",
      " Epoch 0 \n",
      " --------------\n",
      "Train loss: 2.05E+00\n",
      "Test  loss: 2.07E+00\n",
      "\n",
      " Epoch 1 \n",
      " --------------\n",
      "Train loss: 2.07E+00\n",
      "Test  loss: 2.08E+00\n",
      "\n",
      " Epoch 2 \n",
      " --------------\n",
      "Train loss: 2.06E+00\n",
      "Test  loss: 2.08E+00\n",
      "\n",
      " Epoch 3 \n",
      " --------------\n",
      "Train loss: 2.55E+00\n",
      "Test  loss: 2.57E+00\n",
      "\n",
      " Epoch 4 \n",
      " --------------\n",
      "Train loss: 2.55E+00\n",
      "Test  loss: 2.57E+00\n",
      "\n",
      " Epoch 5 \n",
      " --------------\n",
      "Train loss: 2.55E+00\n",
      "Test  loss: 2.57E+00\n",
      "\n",
      " Epoch 6 \n",
      " --------------\n",
      "Train loss: 2.55E+00\n",
      "Test  loss: 2.57E+00\n",
      "\n",
      " Epoch 7 \n",
      " --------------\n",
      "Train loss: 2.55E+00\n",
      "Test  loss: 2.57E+00\n",
      "\n",
      " Epoch 8 \n",
      " --------------\n",
      "Train loss: 2.55E+00\n",
      "Test  loss: 2.57E+00\n",
      "\n",
      " Epoch 9 \n",
      " --------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[111], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[1;32md:\\Coding\\master-thesis-AI\\Code\\nnc2p.py:407\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, adaptation_threshold, adaptation_multiplier, number_of_epochs, log_file, csv_file)\u001b[0m\n\u001b[0;32m    405\u001b[0m write_to_txt(log_file, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m Epoch \u001b[39m\u001b[39m{\u001b[39;00mepoch_counter\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m --------------\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    406\u001b[0m \u001b[39m# Train the network\u001b[39;00m\n\u001b[1;32m--> 407\u001b[0m train_loop(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_dataloader, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss_fn, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer, use_c2p_loss\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49muse_c2p_loss)\n\u001b[0;32m    408\u001b[0m \u001b[39m# Test on the training data\u001b[39;00m\n\u001b[0;32m    409\u001b[0m average_train_loss \u001b[39m=\u001b[39m test_loop(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_dataloader, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_fn)\n",
      "File \u001b[1;32md:\\Coding\\master-thesis-AI\\Code\\nnc2p.py:287\u001b[0m, in \u001b[0;36mtrain_loop\u001b[1;34m(dataloader, model, loss_fn, optimizer, report_progress, use_c2p_loss)\u001b[0m\n\u001b[0;32m    285\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m    286\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m--> 287\u001b[0m optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[0;32m    289\u001b[0m \u001b[39m# If we want to report progress during training (not recommended - obstructs view)\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39mif\u001b[39;00m report_progress:\n",
      "File \u001b[1;32md:\\Anaconda3\\lib\\site-packages\\torch\\optim\\optimizer.py:142\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m obj\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m--> 142\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d0e87f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.65420023247585\n",
      "tensor([0.8667])\n",
      "tensor([1.2086], grad_fn=<SqueezeBackward3>)\n"
     ]
    }
   ],
   "source": [
    "index = 2\n",
    "print(train_df[\"eps\"][index])\n",
    "example = torch.from_numpy(np.array([train_df[\"temp\"][index]])).float()\n",
    "print(example)\n",
    "# Check the results\n",
    "print(model(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f36b5d",
   "metadata": {},
   "source": [
    "# Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "abb635c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We successfully loaded the EOS table. We have 391 rho, 163 temp, 66 ye points.\n",
      "We have 4206378 data points.\n"
     ]
    }
   ],
   "source": [
    "# Open the HDF5 file\n",
    "with h5py.File(eos_table_filename, 'r') as file:\n",
    "    eos_table = file\n",
    "    Abar = file[\"Abar\"][()]\n",
    "    Albar = file[\"Albar\"][()]\n",
    "    Xa = file[\"Xa\"][()]\n",
    "    Xh = file[\"Xh\"][()]\n",
    "    Xn = file[\"Xn\"][()]\n",
    "    Xp = file[\"Xp\"][()]\n",
    "    Zbar = file[\"Zbar\"][()]\n",
    "    cs2 = file[\"cs2\"][()]\n",
    "    dedt = file[\"dedt\"][()]\n",
    "    dpderho = file[\"dpderho\"][()]\n",
    "    dpdrhoe = file[\"dpdrhoe\"][()]\n",
    "    energy_shift = file[\"energy_shift\"][()]\n",
    "    entropy = file[\"entropy\"][()]\n",
    "    gamma = file[\"gamma\"][()]\n",
    "    logenergy = file[\"logenergy\"][()]\n",
    "    logpress = file[\"logpress\"][()]\n",
    "    logrho = file[\"logrho\"][()]\n",
    "    logtemp = file[\"logtemp\"][()]\n",
    "    mu_e = file[\"mu_e\"][()]\n",
    "    mu_n = file[\"mu_n\"][()]\n",
    "    muhat = file[\"muhat\"][()]\n",
    "    munu = file[\"munu\"][()]\n",
    "    pointsrho = file[\"pointsrho\"][()]\n",
    "    pointstemp = file[\"pointstemp\"][()]\n",
    "    pointsye = file[\"pointsye\"][()]\n",
    "    u = file[\"u\"][()] ## these don't exist???\n",
    "    r = file[\"r\"][()]\n",
    "    ye = file[\"ye\"][()]\n",
    "# Print message\n",
    "print(f\"We successfully loaded the EOS table. We have {pointsrho[0]} rho, {pointstemp[0]} temp, {pointsye[0]} ye points.\")\n",
    "print(f\"We have {pointsrho[0]*pointstemp[0]*pointsye[0]} data points.\")"
   ]
  }
 ],
 "metadata": {
  "author": "Thibeau Wouters",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
