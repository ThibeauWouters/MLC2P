{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2350117",
   "metadata": {},
   "source": [
    "# Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0bb9f224",
   "metadata": {
    "executionInfo": {
     "elapsed": 8764,
     "status": "ok",
     "timestamp": 1681398656896,
     "user": {
      "displayName": "Thibeau Wouters",
      "userId": "14702334917940433667"
     },
     "user_tz": -120
    },
    "id": "0bb9f224"
   },
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import random\n",
    "import csv\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import gc  # garbage collection\n",
    "# Scikit learn libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# PyTorch libraries\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# from torchvision.transforms import ToTensor, Normalize \n",
    "# Get dirs\n",
    "import os\n",
    "cwd = os.getcwd()# \"Code\" folder\n",
    "master_dir = os.path.abspath(os.path.join(cwd, \"..\"))\n",
    "## ONNX\n",
    "# import onnx\n",
    "# import onnxruntime\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [\"Computer Modern Roman\"],  # \"Times\", \"Palatino\", \"New Century Schoolbook\", \"Bookman\", \n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c465f7c",
   "metadata": {
    "id": "4c465f7c"
   },
   "source": [
    "When using __Google Colab__, run the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75bacf53",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19202,
     "status": "ok",
     "timestamp": 1681398681220,
     "user": {
      "displayName": "Thibeau Wouters",
      "userId": "14702334917940433667"
     },
     "user_tz": -120
    },
    "id": "bbeb496d",
    "outputId": "30fa916e-e8c0-4fbe-de12-cd51790fc6a3"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# code_dir = \"/content/drive/MyDrive/KUL/MAI thesis/Code\"\n",
    "# master_dir = os.path.join(code_dir, \"..\")\n",
    "# os.chdir(code_dir)\n",
    "# print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36bbffc0",
   "metadata": {
    "executionInfo": {
     "elapsed": 1462,
     "status": "ok",
     "timestamp": 1681398682653,
     "user": {
      "displayName": "Thibeau Wouters",
      "userId": "14702334917940433667"
     },
     "user_tz": -120
    },
    "id": "36bbffc0"
   },
   "outputs": [],
   "source": [
    "# Load own scripts:\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import physics\n",
    "import data\n",
    "import nnc2p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3393c80",
   "metadata": {
    "id": "c3393c80"
   },
   "source": [
    "Point towards the folder where we store the EOS tables (__Note:__ they are not in the Github as these are very large files. Look inside the notebook to see which EOS tables we use, they can be downloaded from the stellarcollapse webpage.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efbc8d2b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1681398682653,
     "user": {
      "displayName": "Thibeau Wouters",
      "userId": "14702334917940433667"
     },
     "user_tz": -120
    },
    "id": "efbc8d2b",
    "outputId": "49af00ba-c706-4dd9-fd2c-ee828683afe1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to look for EOS tables at D:/Coding/Datasets/eos_tables\n"
     ]
    }
   ],
   "source": [
    "eos_tables_dir = os.path.join(\"D:/Coding/Datasets/eos_tables\")  # offline\n",
    "# eos_tables_dir = os.path.join(master_dir, \"Data\")  # in Google Colab\n",
    "print(f\"Going to look for EOS tables at {eos_tables_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vqCsP2sKAeCm",
   "metadata": {
    "id": "vqCsP2sKAeCm"
   },
   "source": [
    "For the training, check if GPU is available (**Google Colab**):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "P8YoVE15AhRC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1681398682654,
     "user": {
      "displayName": "Thibeau Wouters",
      "userId": "14702334917940433667"
     },
     "user_tz": -120
    },
    "id": "P8YoVE15AhRC",
    "outputId": "4f6e373c-7e27-4461-f5cf-51b91d99d440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device for training: cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available(): \n",
    "    DEVICE = \"cuda:0\" \n",
    "    torch.set_default_device('cuda')\n",
    "else: \n",
    "    DEVICE = \"cpu\" \n",
    "print(f\"Device for training: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fb3c8c",
   "metadata": {
    "id": "02fb3c8c"
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ab265e",
   "metadata": {
    "id": "96ab265e"
   },
   "source": [
    "Here, we try to find a way to generalize the NN approach from the first semester to the situation of tabular EOS. \n",
    "\n",
    "*Note*: We use HDF5 files, but you have to close them manually. Forgot to close one? Check if there is still an open HDF5 file with garbage collect in the memory, and close it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "17ceb9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Closed HDF5 file>\n",
      "<Closed HDF5 file>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Browse through objects\n",
    "for obj in gc.get_objects():\n",
    "    # see if is an HDF5 file\n",
    "    if isinstance(obj, h5py.File):\n",
    "        print(obj)\n",
    "        try:\n",
    "            obj.close()\n",
    "            del obj\n",
    "        except:\n",
    "            pass\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf08ad4a",
   "metadata": {
    "id": "cf08ad4a"
   },
   "source": [
    "# Exploring EOS tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e6c124",
   "metadata": {},
   "source": [
    "Specify the EOS. Other downloaded EOS tables: `\"GShen_NL3EOS_rho280_temp180_ye52_version_1.1_20120817.h5\"`, `\"SLy4_0000_rho391_temp163_ye66.h5\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "4d5e6fdb",
   "metadata": {
    "executionInfo": {
     "elapsed": 380,
     "status": "ok",
     "timestamp": 1681398683009,
     "user": {
      "displayName": "Thibeau Wouters",
      "userId": "14702334917940433667"
     },
     "user_tz": -120
    },
    "id": "4d5e6fdb"
   },
   "outputs": [],
   "source": [
    "# Then specify which we are going to use here\n",
    "eos_table_filename = \"SLy4_0000_rho391_temp163_ye66.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d8f465",
   "metadata": {
    "id": "78d8f465"
   },
   "source": [
    "Read in the SLy4 EOS table using our py script: (make sure to close HDF5 files!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "913d9582",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 660,
     "status": "ok",
     "timestamp": 1681398683667,
     "user": {
      "displayName": "Thibeau Wouters",
      "userId": "14702334917940433667"
     },
     "user_tz": -120
    },
    "id": "913d9582",
    "outputId": "677bba7a-6c4a-4190-a9fa-8f0bbca82bfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This EOS table has dimensions (ye, T, rho): 66 x 163 x 391\n",
      "Example: (3.0239960056064277, -3.0, 0.005) we have (log eps, log p, cs2): (19.2791052025363, 17.99956975587081, 1575737840983096.0).\n"
     ]
    }
   ],
   "source": [
    "# Open EOS table\n",
    "eos_table = physics.read_eos_table(os.path.join(eos_tables_dir, eos_table_filename))\n",
    "# Read in the most important variables and convert them to np arrays\n",
    "dim_ye, dim_temp, dim_rho = eos_table[\"pointsye\"][()][0], eos_table[\"pointstemp\"][()][0], eos_table[\"pointsrho\"][()][0]\n",
    "logrho       = eos_table[\"logrho\"][()]\n",
    "logtemp      = eos_table[\"logtemp\"][()]\n",
    "ye           = eos_table[\"ye\"][()]\n",
    "logpress     = eos_table[\"logpress\"][()]\n",
    "logenergy    = eos_table[\"logenergy\"][()]\n",
    "energy_shift = eos_table[\"energy_shift\"][()][0]\n",
    "cs2          = eos_table[\"cs2\"][()]\n",
    "print(f\"This EOS table has dimensions (ye, T, rho): {dim_ye} x {dim_temp} x {dim_rho}\")\n",
    "# Small test to see the output of the EOS table\n",
    "test_ye      = eos_table[\"ye\"][()][0]\n",
    "test_temp    = eos_table[\"logtemp\"][()][0]\n",
    "test_rho     = eos_table[\"logrho\"][()][0]\n",
    "# Get an example output\n",
    "test_press, test_eps = eos_table[\"logpress\"][()][0, 0, 0], eos_table[\"logenergy\"][()][0, 0, 0]\n",
    "print(f\"Example: ({test_rho}, {test_temp}, {test_ye}) we have (log eps, log p, cs2): ({test_eps}, {test_press}, {cs2[0, 0, 0]}).\")\n",
    "eos_table.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349fa6ca",
   "metadata": {},
   "source": [
    "__Extra:__ Save only most important variables for epsilon to energy procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "404f5c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with h5py.File(os.path.join(eos_tables_dir, \"energy_table.h5\"), 'w') as f:\n",
    "#     # Save the features and labels data\n",
    "#     dataset = f.create_dataset(\"logrho\", data=logrho)\n",
    "#     dataset = f.create_dataset(\"logtemp\", data=logtemp)\n",
    "#     dataset = f.create_dataset(\"ye\", data=ye)\n",
    "#     dataset = f.create_dataset(\"logenergy\", data=logenergy)\n",
    "#     dataset = f.create_dataset(\"energy_shift\", data=energy_shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "8dd7c23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt(\"energy_shift.txt\", [energy_shift])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a105d6b7",
   "metadata": {},
   "source": [
    "What is the input range of this table?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "e19b3314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logrho    range:(3.0239960056064277, 16.023996005606428)\n",
      "logtemp range:(-3.0, 2.4000000000000004)\n",
      "ye             range:(0.005, 0.655)\n"
     ]
    }
   ],
   "source": [
    "print(f\"logrho    range:({min(logrho)}, {max(logrho)})\")\n",
    "print(f\"logtemp range:({min(logtemp)}, {max(logtemp)})\")\n",
    "print(f\"ye             range:({min(ye)}, {max(ye)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0167f31",
   "metadata": {
    "id": "f0167f31"
   },
   "source": [
    "See what is inside this EOS table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "316b6963",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 517,
     "status": "ok",
     "timestamp": 1681398689771,
     "user": {
      "displayName": "Thibeau Wouters",
      "userId": "14702334917940433667"
     },
     "user_tz": -120
    },
    "id": "316b6963",
    "outputId": "77b6ecac-15ea-461d-f76a-b641a290fd63"
   },
   "outputs": [],
   "source": [
    "# # Iterate over keys and save them to list for simplified viewing\n",
    "# keys = []\n",
    "# for key in eos_table:\n",
    "#     keys.append(key)\n",
    "# print(keys)\n",
    "# print(len(keys))\n",
    "\n",
    "## Output\n",
    "# ['Abar', 'Albar', 'MERGE-space.in', 'MERGE-src.tar.gz', 'MERGE-tables.in', 'MERGE-transition.in', 'SNA-skyrme.in', 'SNA-space.in', 'SNA-src.tar.gz', 'Xa', 'Xh', 'Xl', 'Xn', 'Xp', 'Zbar', 'Zlbar', 'cs2', 'dedt', 'dpderho', 'dpdrhoe', 'energy_shift', 'entropy', 'gamma', 'have_rel_cs2', 'logenergy', 'logpress', 'logrho', 'logtemp', 'meffn', 'meffp', 'mu_e', 'mu_n', 'mu_p', 'muhat', 'munu', 'pointsrho', 'pointstemp', 'pointsye', 'r', 'u', 'ye']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad5186a",
   "metadata": {},
   "source": [
    "The universal neural network architecture that we will rely on for the tasks defined below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "e465bee0",
   "metadata": {
    "executionInfo": {
     "elapsed": 215,
     "status": "ok",
     "timestamp": 1681398697956,
     "user": {
      "displayName": "Thibeau Wouters",
      "userId": "14702334917940433667"
     },
     "user_tz": -120
    },
    "id": "270fd513"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements a simple feedforward neural network.\n",
    "    \"\"\"\n",
    "    def __init__(self, nb_of_inputs: int = 3, nb_of_outputs: int = 1, h: list = [600, 200], reg: bool = False, \n",
    "                 activation_function = torch.nn.Sigmoid, output_bias=True) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the neural network class.\n",
    "        \"\"\"\n",
    "        # Call the super constructor first\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # For convenience, save the sizes of the hidden layers as fields as well\n",
    "        self.h = h\n",
    "        # Add visible layers as well: input is 3D and output is 1D\n",
    "        self.h_augmented = [nb_of_inputs] + h + [nb_of_outputs]\n",
    "\n",
    "        # Add field to specify whether or not we do regularization\n",
    "        self.regularization = reg\n",
    "\n",
    "        # Define the layers:\n",
    "        for i in range(len(self.h_augmented)-1):\n",
    "            if i == len(self.h_augmented)-2:\n",
    "                setattr(self, f\"linear{i+1}\", nn.Linear(self.h_augmented[i], self.h_augmented[i+1], bias=output_bias))\n",
    "            else:\n",
    "                setattr(self, f\"linear{i+1}\", nn.Linear(self.h_augmented[i], self.h_augmented[i+1]))\n",
    "                setattr(self, f\"activation{i+1}\", activation_function())\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Computes a forward step given the input x.\n",
    "        :param x: Input for the neural network.\n",
    "        :return: x: Output neural network\n",
    "        \"\"\"\n",
    "        \n",
    "        for i, module in enumerate(self.modules()):\n",
    "            # The first module is the whole NNC2P object, continue\n",
    "            if i == 0:\n",
    "                continue\n",
    "            x = module(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd2f127",
   "metadata": {
    "id": "8fd2f127"
   },
   "source": [
    "# First goal: NNEOS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5850152",
   "metadata": {
    "id": "e5850152"
   },
   "source": [
    "__NNEOS__: try to replicate the EOS table (at least the core variables we are interested in) using the \"input\" variables logrho, logtemp, ye."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12089f53",
   "metadata": {
    "id": "12089f53"
   },
   "source": [
    "## Convert EOS table to table of training examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "7a92994d",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1681398700618,
     "user": {
      "displayName": "Thibeau Wouters",
      "userId": "14702334917940433667"
     },
     "user_tz": -120
    },
    "id": "7a92994d"
   },
   "outputs": [],
   "source": [
    "# Get the filename of converted training data\n",
    "filename = os.path.join(eos_tables_dir, \"train_eos_table.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "051199cf",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1681398701905,
     "user": {
      "displayName": "Thibeau Wouters",
      "userId": "14702334917940433667"
     },
     "user_tz": -120
    },
    "id": "051199cf"
   },
   "outputs": [],
   "source": [
    "# # Create new dataset (if desired)\n",
    "# # Specify output vars as \"var_names\" argument in this function - see physics.py\n",
    "# eos_table = physics.read_eos_table(os.path.join(eos_tables_dir, eos_table_filename))\n",
    "# physics.generate_eos_data(eos_table, save_name=filename)\n",
    "# eos_table.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "ccbc983b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2035,
     "status": "ok",
     "timestamp": 1681398704133,
     "user": {
      "displayName": "Thibeau Wouters",
      "userId": "14702334917940433667"
     },
     "user_tz": -120
    },
    "id": "ccbc983b",
    "outputId": "a345b306-1aba-427e-874c-daa97b43cdca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output variables are [b'logenergy' b'logpress' b'cs2']. Number of examples: 4206378\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset afterwards\n",
    "train_eos_table = h5py.File(filename, 'r')\n",
    "# Get the data saved in the HDF5 file\n",
    "features  = train_eos_table[\"features\"][:]\n",
    "labels    = train_eos_table[\"labels\"][:]\n",
    "var_names = train_eos_table[\"var_names\"][:]\n",
    "size_eos_table = len(features)\n",
    "print(f\"The output variables are {var_names}. Number of examples: {size_eos_table}\")\n",
    "# Close the file\n",
    "train_eos_table.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805525b8",
   "metadata": {},
   "source": [
    "## Preprocess the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370870df",
   "metadata": {},
   "source": [
    "An example of a features/labels pair:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "947c812f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.02399601 -3.          0.005     ]\n",
      "[16.02399601  2.4         0.655     ]\n"
     ]
    }
   ],
   "source": [
    "print(np.min(features, axis=0))\n",
    "print(np.max(features, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "0d8a4d14",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1681398706075,
     "user": {
      "displayName": "Thibeau Wouters",
      "userId": "14702334917940433667"
     },
     "user_tz": -120
    },
    "id": "0d8a4d14",
    "outputId": "0f2e12a5-cd17-4dcb-ac27-f09ecee5e38a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.02399601 -3.          0.005     ]\n",
      "[1.92791052e+01 1.79995698e+01 1.57573784e+15]\n"
     ]
    }
   ],
   "source": [
    "print(features[0])\n",
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ffe6ce",
   "metadata": {},
   "source": [
    "### Delete negative $c_s^2$ values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ff9a72",
   "metadata": {},
   "source": [
    "There are apparently a few negative values for the speed of sound... They are likely a bug in the code? We'll remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "4dd3f488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.57573784e+15, 1.53801127e+15, 1.49992954e+15, ...,\n",
       "       1.34334539e+21, 1.34446322e+21, 1.34570741e+21])"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs_values = labels[:, 2]\n",
    "cs_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "afe39d42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3629826],\n",
       "       [3629892],\n",
       "       [3629958],\n",
       "       [3630024],\n",
       "       [3630090],\n",
       "       [3630156],\n",
       "       [3630222],\n",
       "       [3630288],\n",
       "       [3630354]], dtype=int64)"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_indices = np.argwhere(cs_values < 0)\n",
    "negative_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "318b7b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.delete(features, negative_indices, axis=0)\n",
    "labels = np.delete(labels, negative_indices, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae7707a",
   "metadata": {},
   "source": [
    "### Use log values for $c_s^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c4f2e6",
   "metadata": {},
   "source": [
    "If we are using cs2 in the output, you see that its values are huge -- we will also output log cs2 values to improve training the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "c822a63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: binary text!\n",
    "if b\"cs2\" in var_names:\n",
    "    cs_index = np.where(var_names == b\"cs2\")[0][0]\n",
    "    labels[:, cs_index] = np.log(labels[:, cs_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "7e8b787d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.02399601 -3.          0.005     ]\n",
      "[19.2791052  17.99956976 34.99350003]\n"
     ]
    }
   ],
   "source": [
    "print(features[0])\n",
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1d1381",
   "metadata": {},
   "source": [
    "### Explore the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1076edfe",
   "metadata": {},
   "source": [
    "The range of the datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "eb2c3936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19.02463658 17.42022108 33.74498022]\n",
      "[33.15270695 38.1640256  48.77010732]\n"
     ]
    }
   ],
   "source": [
    "min_values = np.min(labels, axis=0)\n",
    "print(min_values)\n",
    "max_values = np.max(labels, axis=0)\n",
    "print(max_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95206a4e",
   "metadata": {},
   "source": [
    "### Convert to Torch `Datasets` for training the network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6d6047",
   "metadata": {
    "id": "ec6d6047"
   },
   "source": [
    "Get the training data as DataSet and DataLoader objects. Note on normalization: we fit transform on the training data, then use the fitted scaler object to transform (i.e. using same transformation as the training data) the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "ec910284",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1126,
     "status": "ok",
     "timestamp": 1681398709169,
     "user": {
      "displayName": "Thibeau Wouters",
      "userId": "14702334917940433667"
     },
     "user_tz": -120
    },
    "id": "ec910284",
    "outputId": "4f15e095-7252-40dc-c90d-2bafae1c6cb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3154776\n",
      "157738\n"
     ]
    }
   ],
   "source": [
    "# For normalization, use sklearn's StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# We fit the scaler on the entire dataset to have it as efficient as possible\n",
    "scaler.fit(features)\n",
    "# Do train test split here\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, random_state=42)\n",
    "# \"Cutoff\": only use certain portion of the data for training and testing, to speed up training when tuning architecture \n",
    "cutoff = 0.05\n",
    "print(len(train_features))\n",
    "end = int(cutoff*len(train_features))\n",
    "train_features = train_features[:end]\n",
    "train_labels = train_labels[:end]\n",
    "end = int(cutoff*len(test_features))\n",
    "test_features = test_features[:end]\n",
    "test_labels = test_labels[:end]\n",
    "print(len(train_features))\n",
    "# Convert to PyTorch Datasets as we defined them\n",
    "train_dataset = data.HDF5Dataset(train_features, train_labels, normalization_function = scaler.transform) \n",
    "test_dataset  = data.HDF5Dataset(test_features, test_labels, normalization_function = scaler.transform)\n",
    "# Then create dataloaders, with batch size 32, from datasets\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = 32)\n",
    "test_dataloader  = DataLoader(test_dataset, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "f34be5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9.52398588 -0.29999922  0.33000018]\n",
      "[3.7623846  1.5684403  0.19050388]\n"
     ]
    }
   ],
   "source": [
    "print(scaler.mean_)\n",
    "print(scaler.scale_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6b7f7d",
   "metadata": {},
   "source": [
    "### Training and inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12e532a",
   "metadata": {
    "id": "f12e532a"
   },
   "source": [
    "Create a new instance of the Net:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "be7a388c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1681398714800,
     "user": {
      "displayName": "Thibeau Wouters",
      "userId": "14702334917940433667"
     },
     "user_tz": -120
    },
    "id": "be7a388c",
    "outputId": "c92948dd-975b-4e2f-81a0-ee0661b400ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (linear1): Linear(in_features=3, out_features=20, bias=True)\n",
       "  (activation1): ReLU()\n",
       "  (linear2): Linear(in_features=20, out_features=20, bias=True)\n",
       "  (activation2): ReLU()\n",
       "  (linear3): Linear(in_features=20, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net(nb_of_inputs=3, nb_of_outputs=3, h=[20, 20], activation_function=torch.nn.ReLU, output_bias=True).double()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c77cbe9",
   "metadata": {},
   "source": [
    "Or load from earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "e51cd03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.load(\"../Models/taboes_3_20_20_3_relu.pt\")\n",
    "# test_input = [[1, 1, 1]]\n",
    "# test_input = scaler.transform(test_input)\n",
    "# test_input = torch.from_numpy(test_input).float()\n",
    "# with torch.no_grad():\n",
    "#     pred = model.float()(test_input).numpy()[0]\n",
    "# print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "49922025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9.52398588 -0.29999922  0.33000018]\n",
      "[3.7623846  1.5684403  0.19050388]\n"
     ]
    }
   ],
   "source": [
    "print(scaler.mean_)\n",
    "print(scaler.scale_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "ecb7b796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.state_dict()[\"linear1.bias\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "5a0e1f63",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1681398716642,
     "user": {
      "displayName": "Thibeau Wouters",
      "userId": "14702334917940433667"
     },
     "user_tz": -120
    },
    "id": "5a0e1f63",
    "outputId": "474f33c1-c8a7-4433-9f4d-9738b0a08141"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "563"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnc2p.count_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1e3745",
   "metadata": {
    "id": "1e1e3745"
   },
   "source": [
    "Create a trainer object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "df92e917",
   "metadata": {
    "executionInfo": {
     "elapsed": 705,
     "status": "ok",
     "timestamp": 1681398719638,
     "user": {
      "displayName": "Thibeau Wouters",
      "userId": "14702334917940433667"
     },
     "user_tz": -120
    },
    "id": "df92e917"
   },
   "outputs": [],
   "source": [
    "trainer = nnc2p.Trainer(model, 1e-2, train_dataloader=train_dataloader, test_dataloader=test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227207f2",
   "metadata": {},
   "source": [
    "Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "53ce8669",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 171807,
     "status": "ok",
     "timestamp": 1681398892786,
     "user": {
      "displayName": "Thibeau Wouters",
      "userId": "14702334917940433667"
     },
     "user_tz": -120
    },
    "id": "53ce8669",
    "outputId": "711c53ca-cf46-43e3-8d63-6625ebdf0880"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model for 1000 epochs.\n",
      "\n",
      " Epoch 0 \n",
      " --------------\n",
      "Train loss: 2.58E-02\n",
      "Test  loss: 2.58E-02\n",
      "\n",
      " Epoch 1 \n",
      " --------------\n",
      "Train loss: 1.78E-02\n",
      "Test  loss: 1.78E-02\n",
      "\n",
      " Epoch 2 \n",
      " --------------\n",
      "Train loss: 1.44E-02\n",
      "Test  loss: 1.44E-02\n",
      "\n",
      " Epoch 3 \n",
      " --------------\n",
      "Train loss: 1.49E-02\n",
      "Test  loss: 1.48E-02\n",
      "\n",
      " Epoch 4 \n",
      " --------------\n",
      "Train loss: 1.58E-02\n",
      "Test  loss: 1.58E-02\n",
      "\n",
      " Epoch 5 \n",
      " --------------\n",
      "Train loss: 2.64E-02\n",
      "Test  loss: 2.64E-02\n",
      "\n",
      " Epoch 6 \n",
      " --------------\n",
      "Train loss: 2.59E-02\n",
      "Test  loss: 2.57E-02\n",
      "\n",
      " Epoch 7 \n",
      " --------------\n",
      "Train loss: 1.81E-02\n",
      "Test  loss: 1.80E-02\n",
      "\n",
      " Epoch 8 \n",
      " --------------\n",
      "Train loss: 1.86E-02\n",
      "Test  loss: 1.85E-02\n",
      "\n",
      " Epoch 9 \n",
      " --------------\n",
      "Train loss: 1.88E-02\n",
      "Test  loss: 1.88E-02\n",
      "\n",
      " Epoch 10 \n",
      " --------------\n",
      "Train loss: 1.26E-02\n",
      "Test  loss: 1.26E-02\n",
      "\n",
      " Epoch 11 \n",
      " --------------\n",
      "Train loss: 3.04E-02\n",
      "Test  loss: 3.03E-02\n",
      "\n",
      " Epoch 12 \n",
      " --------------\n",
      "Train loss: 3.42E-02\n",
      "Test  loss: 3.41E-02\n",
      "\n",
      " Epoch 13 \n",
      " --------------\n",
      "Train loss: 2.64E-02\n",
      "Test  loss: 2.63E-02\n",
      "\n",
      " Epoch 14 \n",
      " --------------\n",
      "Train loss: 2.23E-02\n",
      "Test  loss: 2.23E-02\n",
      "\n",
      " Epoch 15 \n",
      " --------------\n",
      "Adapting learning rate to 0.005\n",
      "Train loss: 1.96E-02\n",
      "Test  loss: 1.96E-02\n",
      "\n",
      " Epoch 16 \n",
      " --------------\n",
      "Train loss: 5.81E-03\n",
      "Test  loss: 5.80E-03\n",
      "\n",
      " Epoch 17 \n",
      " --------------\n",
      "Train loss: 5.81E-03\n",
      "Test  loss: 5.81E-03\n",
      "\n",
      " Epoch 18 \n",
      " --------------\n",
      "Train loss: 6.10E-03\n",
      "Test  loss: 6.09E-03\n",
      "\n",
      " Epoch 19 \n",
      " --------------\n",
      "Train loss: 5.94E-03\n",
      "Test  loss: 5.93E-03\n",
      "\n",
      " Epoch 20 \n",
      " --------------\n",
      "Train loss: 5.92E-03\n",
      "Test  loss: 5.95E-03\n",
      "\n",
      " Epoch 21 \n",
      " --------------\n",
      "Train loss: 5.83E-03\n",
      "Test  loss: 5.86E-03\n",
      "\n",
      " Epoch 22 \n",
      " --------------\n",
      "Train loss: 5.51E-03\n",
      "Test  loss: 5.54E-03\n",
      "\n",
      " Epoch 23 \n",
      " --------------\n",
      "Train loss: 5.58E-03\n",
      "Test  loss: 5.62E-03\n",
      "\n",
      " Epoch 24 \n",
      " --------------\n",
      "Train loss: 5.31E-03\n",
      "Test  loss: 5.35E-03\n",
      "\n",
      " Epoch 25 \n",
      " --------------\n",
      "Train loss: 5.57E-03\n",
      "Test  loss: 5.61E-03\n",
      "\n",
      " Epoch 26 \n",
      " --------------\n",
      "Train loss: 5.22E-03\n",
      "Test  loss: 5.25E-03\n",
      "\n",
      " Epoch 27 \n",
      " --------------\n",
      "Train loss: 4.91E-03\n",
      "Test  loss: 4.94E-03\n",
      "\n",
      " Epoch 28 \n",
      " --------------\n",
      "Train loss: 4.80E-03\n",
      "Test  loss: 4.82E-03\n",
      "\n",
      " Epoch 29 \n",
      " --------------\n",
      "Train loss: 4.55E-03\n",
      "Test  loss: 4.57E-03\n",
      "\n",
      " Epoch 30 \n",
      " --------------\n",
      "Train loss: 3.95E-03\n",
      "Test  loss: 3.97E-03\n",
      "\n",
      " Epoch 31 \n",
      " --------------\n",
      "Train loss: 4.96E-03\n",
      "Test  loss: 4.99E-03\n",
      "\n",
      " Epoch 32 \n",
      " --------------\n",
      "Train loss: 4.41E-03\n",
      "Test  loss: 4.44E-03\n",
      "\n",
      " Epoch 33 \n",
      " --------------\n",
      "Train loss: 4.44E-03\n",
      "Test  loss: 4.46E-03\n",
      "\n",
      " Epoch 34 \n",
      " --------------\n",
      "Train loss: 3.83E-03\n",
      "Test  loss: 3.86E-03\n",
      "\n",
      " Epoch 35 \n",
      " --------------\n",
      "Train loss: 3.78E-03\n",
      "Test  loss: 3.81E-03\n",
      "\n",
      " Epoch 36 \n",
      " --------------\n",
      "Train loss: 4.42E-03\n",
      "Test  loss: 4.46E-03\n",
      "\n",
      " Epoch 37 \n",
      " --------------\n",
      "Train loss: 4.00E-03\n",
      "Test  loss: 4.03E-03\n",
      "\n",
      " Epoch 38 \n",
      " --------------\n",
      "Train loss: 4.14E-03\n",
      "Test  loss: 4.18E-03\n",
      "\n",
      " Epoch 39 \n",
      " --------------\n",
      "Train loss: 3.95E-03\n",
      "Test  loss: 3.99E-03\n",
      "\n",
      " Epoch 40 \n",
      " --------------\n",
      "Train loss: 3.77E-03\n",
      "Test  loss: 3.81E-03\n",
      "\n",
      " Epoch 41 \n",
      " --------------\n",
      "Train loss: 3.94E-03\n",
      "Test  loss: 3.97E-03\n",
      "\n",
      " Epoch 42 \n",
      " --------------\n",
      "Train loss: 3.74E-03\n",
      "Test  loss: 3.77E-03\n",
      "\n",
      " Epoch 43 \n",
      " --------------\n",
      "Train loss: 3.79E-03\n",
      "Test  loss: 3.83E-03\n",
      "\n",
      " Epoch 44 \n",
      " --------------\n",
      "Train loss: 4.03E-03\n",
      "Test  loss: 4.07E-03\n",
      "\n",
      " Epoch 45 \n",
      " --------------\n",
      "Train loss: 3.91E-03\n",
      "Test  loss: 3.95E-03\n",
      "\n",
      " Epoch 46 \n",
      " --------------\n",
      "Train loss: 3.90E-03\n",
      "Test  loss: 3.94E-03\n",
      "\n",
      " Epoch 47 \n",
      " --------------\n",
      "Adapting learning rate to 0.0025\n",
      "Train loss: 4.10E-03\n",
      "Test  loss: 4.15E-03\n",
      "\n",
      " Epoch 48 \n",
      " --------------\n",
      "Train loss: 4.77E-03\n",
      "Test  loss: 4.82E-03\n",
      "\n",
      " Epoch 49 \n",
      " --------------\n",
      "Train loss: 4.67E-03\n",
      "Test  loss: 4.72E-03\n",
      "\n",
      " Epoch 50 \n",
      " --------------\n",
      "Train loss: 4.80E-03\n",
      "Test  loss: 4.84E-03\n",
      "\n",
      " Epoch 51 \n",
      " --------------\n",
      "Train loss: 4.91E-03\n",
      "Test  loss: 4.96E-03\n",
      "\n",
      " Epoch 52 \n",
      " --------------\n",
      "Train loss: 4.71E-03\n",
      "Test  loss: 4.75E-03\n",
      "\n",
      " Epoch 53 \n",
      " --------------\n",
      "Train loss: 4.68E-03\n",
      "Test  loss: 4.73E-03\n",
      "\n",
      " Epoch 54 \n",
      " --------------\n",
      "Train loss: 4.36E-03\n",
      "Test  loss: 4.41E-03\n",
      "\n",
      " Epoch 55 \n",
      " --------------\n",
      "Train loss: 4.19E-03\n",
      "Test  loss: 4.24E-03\n",
      "\n",
      " Epoch 56 \n",
      " --------------\n",
      "Train loss: 4.27E-03\n",
      "Test  loss: 4.32E-03\n",
      "\n",
      " Epoch 57 \n",
      " --------------\n",
      "Train loss: 4.58E-03\n",
      "Test  loss: 4.62E-03\n",
      "\n",
      " Epoch 58 \n",
      " --------------\n",
      "Train loss: 4.51E-03\n",
      "Test  loss: 4.55E-03\n",
      "\n",
      " Epoch 59 \n",
      " --------------\n",
      "Train loss: 4.37E-03\n",
      "Test  loss: 4.42E-03\n",
      "\n",
      " Epoch 60 \n",
      " --------------\n",
      "Train loss: 4.15E-03\n",
      "Test  loss: 4.20E-03\n",
      "\n",
      " Epoch 61 \n",
      " --------------\n",
      "Train loss: 4.04E-03\n",
      "Test  loss: 4.09E-03\n",
      "\n",
      " Epoch 62 \n",
      " --------------\n",
      "Train loss: 3.99E-03\n",
      "Test  loss: 4.04E-03\n",
      "\n",
      " Epoch 63 \n",
      " --------------\n",
      "Train loss: 4.15E-03\n",
      "Test  loss: 4.21E-03\n",
      "\n",
      " Epoch 64 \n",
      " --------------\n",
      "Train loss: 3.98E-03\n",
      "Test  loss: 4.03E-03\n",
      "\n",
      " Epoch 65 \n",
      " --------------\n",
      "Train loss: 3.85E-03\n",
      "Test  loss: 3.91E-03\n",
      "\n",
      " Epoch 66 \n",
      " --------------\n",
      "Train loss: 3.86E-03\n",
      "Test  loss: 3.91E-03\n",
      "\n",
      " Epoch 67 \n",
      " --------------\n",
      "Train loss: 3.82E-03\n",
      "Test  loss: 3.87E-03\n",
      "\n",
      " Epoch 68 \n",
      " --------------\n",
      "Train loss: 3.83E-03\n",
      "Test  loss: 3.88E-03\n",
      "\n",
      " Epoch 69 \n",
      " --------------\n",
      "Train loss: 3.78E-03\n",
      "Test  loss: 3.83E-03\n",
      "\n",
      " Epoch 70 \n",
      " --------------\n",
      "Train loss: 3.82E-03\n",
      "Test  loss: 3.87E-03\n",
      "\n",
      " Epoch 71 \n",
      " --------------\n",
      "Train loss: 3.92E-03\n",
      "Test  loss: 3.96E-03\n",
      "\n",
      " Epoch 72 \n",
      " --------------\n",
      "Train loss: 3.85E-03\n",
      "Test  loss: 3.90E-03\n",
      "\n",
      " Epoch 73 \n",
      " --------------\n",
      "Train loss: 3.64E-03\n",
      "Test  loss: 3.68E-03\n",
      "\n",
      " Epoch 74 \n",
      " --------------\n",
      "Train loss: 3.75E-03\n",
      "Test  loss: 3.80E-03\n",
      "\n",
      " Epoch 75 \n",
      " --------------\n",
      "Train loss: 3.52E-03\n",
      "Test  loss: 3.57E-03\n",
      "\n",
      " Epoch 76 \n",
      " --------------\n",
      "Train loss: 3.42E-03\n",
      "Test  loss: 3.47E-03\n",
      "\n",
      " Epoch 77 \n",
      " --------------\n",
      "Train loss: 3.46E-03\n",
      "Test  loss: 3.50E-03\n",
      "\n",
      " Epoch 78 \n",
      " --------------\n",
      "Train loss: 3.49E-03\n",
      "Test  loss: 3.54E-03\n",
      "\n",
      " Epoch 79 \n",
      " --------------\n",
      "Train loss: 3.45E-03\n",
      "Test  loss: 3.50E-03\n",
      "\n",
      " Epoch 80 \n",
      " --------------\n",
      "Train loss: 3.42E-03\n",
      "Test  loss: 3.47E-03\n",
      "\n",
      " Epoch 81 \n",
      " --------------\n",
      "Train loss: 3.30E-03\n",
      "Test  loss: 3.35E-03\n",
      "\n",
      " Epoch 82 \n",
      " --------------\n",
      "Train loss: 3.38E-03\n",
      "Test  loss: 3.43E-03\n",
      "\n",
      " Epoch 83 \n",
      " --------------\n",
      "Train loss: 3.32E-03\n",
      "Test  loss: 3.37E-03\n",
      "\n",
      " Epoch 84 \n",
      " --------------\n",
      "Train loss: 3.29E-03\n",
      "Test  loss: 3.34E-03\n",
      "\n",
      " Epoch 85 \n",
      " --------------\n",
      "Train loss: 3.23E-03\n",
      "Test  loss: 3.28E-03\n",
      "\n",
      " Epoch 86 \n",
      " --------------\n",
      "Train loss: 3.21E-03\n",
      "Test  loss: 3.26E-03\n",
      "\n",
      " Epoch 87 \n",
      " --------------\n",
      "Train loss: 3.18E-03\n",
      "Test  loss: 3.24E-03\n",
      "\n",
      " Epoch 88 \n",
      " --------------\n",
      "Train loss: 3.14E-03\n",
      "Test  loss: 3.19E-03\n",
      "\n",
      " Epoch 89 \n",
      " --------------\n",
      "Train loss: 3.21E-03\n",
      "Test  loss: 3.26E-03\n",
      "\n",
      " Epoch 90 \n",
      " --------------\n",
      "Train loss: 3.19E-03\n",
      "Test  loss: 3.24E-03\n",
      "\n",
      " Epoch 91 \n",
      " --------------\n",
      "Train loss: 3.12E-03\n",
      "Test  loss: 3.17E-03\n",
      "\n",
      " Epoch 92 \n",
      " --------------\n",
      "Train loss: 3.24E-03\n",
      "Test  loss: 3.29E-03\n",
      "\n",
      " Epoch 93 \n",
      " --------------\n",
      "Train loss: 3.17E-03\n",
      "Test  loss: 3.22E-03\n",
      "\n",
      " Epoch 94 \n",
      " --------------\n",
      "Train loss: 3.09E-03\n",
      "Test  loss: 3.14E-03\n",
      "\n",
      " Epoch 95 \n",
      " --------------\n",
      "Train loss: 3.03E-03\n",
      "Test  loss: 3.09E-03\n",
      "\n",
      " Epoch 96 \n",
      " --------------\n",
      "Train loss: 3.10E-03\n",
      "Test  loss: 3.15E-03\n",
      "\n",
      " Epoch 97 \n",
      " --------------\n",
      "Train loss: 3.12E-03\n",
      "Test  loss: 3.17E-03\n",
      "\n",
      " Epoch 98 \n",
      " --------------\n",
      "Train loss: 3.08E-03\n",
      "Test  loss: 3.13E-03\n",
      "\n",
      " Epoch 99 \n",
      " --------------\n",
      "Train loss: 3.12E-03\n",
      "Test  loss: 3.17E-03\n",
      "\n",
      " Epoch 100 \n",
      " --------------\n",
      "Adapting learning rate to 0.00125\n",
      "Train loss: 3.13E-03\n",
      "Test  loss: 3.19E-03\n",
      "\n",
      " Epoch 101 \n",
      " --------------\n",
      "Train loss: 2.76E-03\n",
      "Test  loss: 2.82E-03\n",
      "\n",
      " Epoch 102 \n",
      " --------------\n",
      "Train loss: 2.76E-03\n",
      "Test  loss: 2.82E-03\n",
      "\n",
      " Epoch 103 \n",
      " --------------\n",
      "Train loss: 2.76E-03\n",
      "Test  loss: 2.82E-03\n",
      "\n",
      " Epoch 104 \n",
      " --------------\n",
      "Train loss: 2.75E-03\n",
      "Test  loss: 2.81E-03\n",
      "\n",
      " Epoch 105 \n",
      " --------------\n",
      "Train loss: 2.75E-03\n",
      "Test  loss: 2.81E-03\n",
      "\n",
      " Epoch 106 \n",
      " --------------\n",
      "Train loss: 2.73E-03\n",
      "Test  loss: 2.79E-03\n",
      "\n",
      " Epoch 107 \n",
      " --------------\n",
      "Train loss: 2.72E-03\n",
      "Test  loss: 2.79E-03\n",
      "\n",
      " Epoch 108 \n",
      " --------------\n",
      "Train loss: 2.73E-03\n",
      "Test  loss: 2.80E-03\n",
      "\n",
      " Epoch 109 \n",
      " --------------\n",
      "Train loss: 2.73E-03\n",
      "Test  loss: 2.79E-03\n",
      "\n",
      " Epoch 110 \n",
      " --------------\n",
      "Train loss: 2.72E-03\n",
      "Test  loss: 2.79E-03\n",
      "\n",
      " Epoch 111 \n",
      " --------------\n",
      "Train loss: 2.72E-03\n",
      "Test  loss: 2.78E-03\n",
      "\n",
      " Epoch 112 \n",
      " --------------\n",
      "Train loss: 2.70E-03\n",
      "Test  loss: 2.77E-03\n",
      "\n",
      " Epoch 113 \n",
      " --------------\n",
      "Train loss: 2.70E-03\n",
      "Test  loss: 2.76E-03\n",
      "\n",
      " Epoch 114 \n",
      " --------------\n",
      "Train loss: 2.71E-03\n",
      "Test  loss: 2.77E-03\n",
      "\n",
      " Epoch 115 \n",
      " --------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.70E-03\n",
      "Test  loss: 2.76E-03\n",
      "\n",
      " Epoch 116 \n",
      " --------------\n",
      "Train loss: 2.70E-03\n",
      "Test  loss: 2.76E-03\n",
      "\n",
      " Epoch 117 \n",
      " --------------\n",
      "Train loss: 2.71E-03\n",
      "Test  loss: 2.77E-03\n",
      "\n",
      " Epoch 118 \n",
      " --------------\n",
      "Train loss: 2.70E-03\n",
      "Test  loss: 2.77E-03\n",
      "\n",
      " Epoch 119 \n",
      " --------------\n",
      "Train loss: 2.69E-03\n",
      "Test  loss: 2.75E-03\n",
      "\n",
      " Epoch 120 \n",
      " --------------\n",
      "Train loss: 2.70E-03\n",
      "Test  loss: 2.76E-03\n",
      "\n",
      " Epoch 121 \n",
      " --------------\n",
      "Train loss: 2.68E-03\n",
      "Test  loss: 2.74E-03\n",
      "\n",
      " Epoch 122 \n",
      " --------------\n",
      "Train loss: 2.68E-03\n",
      "Test  loss: 2.74E-03\n",
      "\n",
      " Epoch 123 \n",
      " --------------\n",
      "Train loss: 2.69E-03\n",
      "Test  loss: 2.75E-03\n",
      "\n",
      " Epoch 124 \n",
      " --------------\n",
      "Train loss: 2.68E-03\n",
      "Test  loss: 2.74E-03\n",
      "\n",
      " Epoch 125 \n",
      " --------------\n",
      "Train loss: 2.68E-03\n",
      "Test  loss: 2.74E-03\n",
      "\n",
      " Epoch 126 \n",
      " --------------\n",
      "Train loss: 2.67E-03\n",
      "Test  loss: 2.73E-03\n",
      "\n",
      " Epoch 127 \n",
      " --------------\n",
      "Train loss: 2.68E-03\n",
      "Test  loss: 2.74E-03\n",
      "\n",
      " Epoch 128 \n",
      " --------------\n",
      "Train loss: 2.71E-03\n",
      "Test  loss: 2.78E-03\n",
      "\n",
      " Epoch 129 \n",
      " --------------\n",
      "Train loss: 2.71E-03\n",
      "Test  loss: 2.78E-03\n",
      "\n",
      " Epoch 130 \n",
      " --------------\n",
      "Train loss: 2.72E-03\n",
      "Test  loss: 2.78E-03\n",
      "\n",
      " Epoch 131 \n",
      " --------------\n",
      "Train loss: 2.67E-03\n",
      "Test  loss: 2.73E-03\n",
      "\n",
      " Epoch 132 \n",
      " --------------\n",
      "Train loss: 2.73E-03\n",
      "Test  loss: 2.79E-03\n",
      "\n",
      " Epoch 133 \n",
      " --------------\n",
      "Train loss: 2.71E-03\n",
      "Test  loss: 2.77E-03\n",
      "\n",
      " Epoch 134 \n",
      " --------------\n",
      "Train loss: 2.71E-03\n",
      "Test  loss: 2.77E-03\n",
      "\n",
      " Epoch 135 \n",
      " --------------\n",
      "Train loss: 2.71E-03\n",
      "Test  loss: 2.77E-03\n",
      "\n",
      " Epoch 136 \n",
      " --------------\n",
      "Adapting learning rate to 0.000625\n",
      "Train loss: 2.73E-03\n",
      "Test  loss: 2.79E-03\n",
      "\n",
      " Epoch 137 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 138 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 139 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 140 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 141 \n",
      " --------------\n",
      "Train loss: 2.30E-03\n",
      "Test  loss: 2.36E-03\n",
      "\n",
      " Epoch 142 \n",
      " --------------\n",
      "Train loss: 2.30E-03\n",
      "Test  loss: 2.37E-03\n",
      "\n",
      " Epoch 143 \n",
      " --------------\n",
      "Train loss: 2.30E-03\n",
      "Test  loss: 2.36E-03\n",
      "\n",
      " Epoch 144 \n",
      " --------------\n",
      "Train loss: 2.30E-03\n",
      "Test  loss: 2.37E-03\n",
      "\n",
      " Epoch 145 \n",
      " --------------\n",
      "Train loss: 2.31E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 146 \n",
      " --------------\n",
      "Train loss: 2.30E-03\n",
      "Test  loss: 2.36E-03\n",
      "\n",
      " Epoch 147 \n",
      " --------------\n",
      "Adapting learning rate to 0.0003125\n",
      "Train loss: 2.31E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 148 \n",
      " --------------\n",
      "Train loss: 2.43E-03\n",
      "Test  loss: 2.50E-03\n",
      "\n",
      " Epoch 149 \n",
      " --------------\n",
      "Train loss: 2.43E-03\n",
      "Test  loss: 2.50E-03\n",
      "\n",
      " Epoch 150 \n",
      " --------------\n",
      "Train loss: 2.43E-03\n",
      "Test  loss: 2.50E-03\n",
      "\n",
      " Epoch 151 \n",
      " --------------\n",
      "Train loss: 2.43E-03\n",
      "Test  loss: 2.50E-03\n",
      "\n",
      " Epoch 152 \n",
      " --------------\n",
      "Train loss: 2.43E-03\n",
      "Test  loss: 2.50E-03\n",
      "\n",
      " Epoch 153 \n",
      " --------------\n",
      "Train loss: 2.43E-03\n",
      "Test  loss: 2.50E-03\n",
      "\n",
      " Epoch 154 \n",
      " --------------\n",
      "Train loss: 2.42E-03\n",
      "Test  loss: 2.49E-03\n",
      "\n",
      " Epoch 155 \n",
      " --------------\n",
      "Train loss: 2.42E-03\n",
      "Test  loss: 2.49E-03\n",
      "\n",
      " Epoch 156 \n",
      " --------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.train(number_of_epochs = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40f398a",
   "metadata": {},
   "source": [
    "Quickly check some error rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "7b2e3e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02167531 0.03401273 0.04514123]\n",
      "[0.00083762 0.00171825 0.00472396]\n",
      "[0.18167502 0.36557974 1.67024518]\n"
     ]
    }
   ],
   "source": [
    "test_input = train_features\n",
    "test_input = scaler.transform(test_input)\n",
    "test_input = torch.from_numpy(test_input).float()\n",
    "with torch.no_grad():\n",
    "    predictions = model.float()(test_input)\n",
    "    predictions = predictions.numpy()\n",
    "print(nnc2p.l1_norm(predictions, train_labels))\n",
    "print(nnc2p.l2_norm(predictions, train_labels))\n",
    "print(nnc2p.linfty_norm(predictions, train_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a15ce4",
   "metadata": {},
   "source": [
    "Baseline: the bigger model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "6c91af3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline = torch.load(\"../Models/tabeos_3_50_50_3.pt\")\n",
    "# test_input = train_features\n",
    "# test_input = scaler.transform(test_input)\n",
    "# test_input = torch.from_numpy(test_input).float()\n",
    "# with torch.no_grad():\n",
    "#     predictions = baseline(test_input)\n",
    "#     predictions = predictions.numpy()\n",
    "# print(nnc2p.l1_norm(predictions, train_labels))\n",
    "# print(nnc2p.l2_norm(predictions, train_labels))\n",
    "# print(nnc2p.linfty_norm(predictions, train_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce4c2e3",
   "metadata": {},
   "source": [
    "For export: test input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "e4074bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions\n",
      "[29.429901 31.321573 46.91765 ]\n"
     ]
    }
   ],
   "source": [
    "test_input = np.array([[1, 1, 1]])\n",
    "test_input = scaler.transform(test_input)\n",
    "test_input = torch.from_numpy(test_input).float()\n",
    "with torch.no_grad():\n",
    "    predictions = model.float()(test_input)\n",
    "    predictions = predictions.numpy()\n",
    "print(\"Predictions\")\n",
    "print(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00bda2a",
   "metadata": {},
   "source": [
    "Save architecture if desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "b3272e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"../Models/final_taboes_3_20_20_3_relu.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c550e901",
   "metadata": {},
   "source": [
    "Report architecture (this saves info to a CSV, such as hidden layer set-up, nb of epochs trained, loss after training,... in order to compare performances across different architecture details)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "2f3a92f7",
   "metadata": {
    "id": "2f3a92f7"
   },
   "outputs": [],
   "source": [
    "# trainer.report_training(\"NNEOS_tab_experiments.csv\", comment = \"logeps, logpress and log cs2.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296ab01e",
   "metadata": {
    "id": "296ab01e"
   },
   "source": [
    "Create a quick sketch of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "f8056faf",
   "metadata": {
    "id": "f8056faf"
   },
   "outputs": [],
   "source": [
    "# plt.plot(trainer.train_losses, color='red', label=\"Train loss\")\n",
    "# plt.plot(trainer.test_losses, color='blue', label=\"Test loss\")\n",
    "\n",
    "# plt.grid()\n",
    "# plt.legend()\n",
    "# for ind in trainer.adaptation_indices:\n",
    "#     plt.axvline(ind, ls = '--', color='grey')\n",
    "# plt.yscale('log')\n",
    "# plt.xlabel(\"Epochs\")\n",
    "# plt.ylabel(\"MSE Loss\")\n",
    "# plt.title(\"Training (50, 50) network tabular EOS for p and eps\")\n",
    "# plt.savefig(\"testing_training_tab_eos_network_50_50.pdf\", bbox_inches = 'tight')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6333ce5c",
   "metadata": {},
   "source": [
    "### Load model after training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9081c5c",
   "metadata": {},
   "source": [
    "In case we have an already trained model, load it here. We have a network in `nn_tabeos_3_50_50_3.pth` (its state dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "0122bd66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (linear1): Linear(in_features=3, out_features=20, bias=True)\n",
       "  (activation1): ReLU()\n",
       "  (linear2): Linear(in_features=20, out_features=20, bias=True)\n",
       "  (activation2): ReLU()\n",
       "  (linear3): Linear(in_features=20, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load(\"../Models/final_taboes_3_20_20_3_relu.pt\")\n",
    "model\n",
    "# model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d9f955",
   "metadata": {},
   "source": [
    "For export:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "c7aeb681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 1, 1]]\n",
      "[[-2.26558068  0.82884839  3.51698775]]\n",
      "29.429901\n",
      "31.321573\n",
      "46.91765\n"
     ]
    }
   ],
   "source": [
    "test_input = [[1, 1, 1]]\n",
    "# test_input = [features[0]]\n",
    "print(test_input)\n",
    "test_input = scaler.transform(test_input)\n",
    "print(test_input)\n",
    "with torch.no_grad():\n",
    "    test_input = torch.from_numpy(test_input).float()\n",
    "    preds = model(test_input)[0].numpy()\n",
    "print(preds[0])\n",
    "print(preds[1])\n",
    "print(preds[2])\n",
    "# print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "696610d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9.52398588 -0.29999922  0.33000018]\n",
      "[3.7623846  1.5684403  0.19050388]\n"
     ]
    }
   ],
   "source": [
    "print(scaler.mean_)\n",
    "print(scaler.scale_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "871831b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succesfully exported model parameters to CSV file, at ../Models/paramvals_tabeos_20_relu\n"
     ]
    }
   ],
   "source": [
    "nnc2p.export_model(\"../Models/final_taboes_3_20_20_3_relu.pt\", \"../Models/paramvals_tabeos_20_relu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd574d7f",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "6117dbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_l1(y, yhat, ax = 0):\n",
    "    return np.mean(abs(y-yhat)/abs(y), axis=ax)\n",
    "\n",
    "def relative_l2(y, yhat, ax = 0):\n",
    "    return np.mean((y-yhat)**2/y**2, axis=ax)\n",
    "\n",
    "def relative_linfty(y, yhat, ax = 0):\n",
    "    return np.max(abs(y-yhat)/abs(y), axis=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "258ab3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On training set:\n",
      "['2.168e-02', '3.401e-02', '4.514e-02']\n",
      "['8.376e-04', '1.718e-03', '4.724e-03']\n",
      "['1.817e-01', '3.656e-01', '1.670e+00']\n",
      "On entire dataset:\n",
      "['2.173e-02', '3.404e-02', '4.521e-02']\n",
      "['8.407e-04', '1.724e-03', '4.828e-03']\n",
      "['1.921e-01', '3.731e-01', '5.199e+00']\n"
     ]
    }
   ],
   "source": [
    "model = model.float()\n",
    "include_rel = False\n",
    "for a in range(2):\n",
    "    if a == 0:\n",
    "        print(\"On training set:\")\n",
    "        features_ = train_features\n",
    "        labels_ = train_labels\n",
    "    else:\n",
    "        print(\"On entire dataset:\")\n",
    "        features_ = features\n",
    "        labels_ = labels\n",
    "\n",
    "    with torch.no_grad():\n",
    "        test_input = scaler.transform(features_)\n",
    "        test_input = torch.from_numpy(test_input).float()\n",
    "        predictions = model(test_input)\n",
    "        predictions = predictions.numpy()\n",
    "\n",
    "    l1       = nnc2p.l1_norm(predictions, labels_)\n",
    "    l1_r     = relative_l1(predictions, labels_)\n",
    "    l2       = nnc2p.l2_norm(predictions, labels_)\n",
    "    l2_r     = relative_l2(predictions, labels_)\n",
    "    linfty   = nnc2p.linfty_norm(predictions, labels_)\n",
    "    linfty_r = relative_linfty(predictions, labels_)\n",
    "\n",
    "    if include_rel:\n",
    "        names = [\"L1\", \"L2\", \"Linfty\", \"L1 r\", \"L2 r\", \"Linfty r\"]\n",
    "        err_list = [l1, l1_r, l2, l2_r, linfty, linfty_r]\n",
    "    else:\n",
    "        names = [\"L1\", \"L2\", \"Linfty\"]\n",
    "        err_list = [l1, l2, linfty]\n",
    "    for i, err in enumerate(err_list):\n",
    "        print([np.format_float_scientific(val, precision=3) for val in err])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70c0189",
   "metadata": {},
   "source": [
    "We will analyze the performance of the code in its accuracy as a function of the different domains. We fix the $Y_e$ value, and look at the error rates (absolute values) on the three as a function of log T and log rho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "a9c410c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix a ye value here, can severely affect the results?\n",
    "ye_index = len(ye) // 2\n",
    "ye_value = ye[ye_index]\n",
    "# Get the ranges\n",
    "# n_logrho, n_logtemp = targets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f4ce48",
   "metadata": {},
   "source": [
    "Prepare the values to determine the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "a0b062c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66, 163, 391)"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logenergy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "05493601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the values at this ye index: these are the \"targets\"\n",
    "targets = logenergy[ye_index]\n",
    "targets = np.swapaxes(targets, 0, 1)\n",
    "n_logrho, n_logtemp = targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "3b64cfd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(391, 163)"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53144b7",
   "metadata": {},
   "source": [
    "Get the input values right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "7373cc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_values = []\n",
    "for logtemp_value in logtemp:\n",
    "    for logrho_value in logrho:\n",
    "        new_row = [logrho_value, logtemp_value, ye_value]\n",
    "        input_values.append(new_row)\n",
    "input_values = np.array(input_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d9864a",
   "metadata": {},
   "source": [
    "Scaler transform & to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "78e02dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    input_values = scaler.transform(input_values)\n",
    "    input_values = torch.from_numpy(input_values).float()\n",
    "    predictions = model(input_values)\n",
    "    predictions = predictions.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "48a4cbc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17.577488, 17.616627, 17.65577 , ..., 25.575678, 25.621254,\n",
       "        25.666828],\n",
       "       [25.712408, 25.757982, 25.803558, ..., 32.80769 , 32.85062 ,\n",
       "        32.89355 ],\n",
       "       [32.93648 , 32.979416, 33.022346, ..., 22.447376, 22.499681,\n",
       "        22.551985],\n",
       "       ...,\n",
       "       [35.59527 , 35.59677 , 35.598278, ..., 35.714817, 35.714825,\n",
       "        35.714836],\n",
       "       [35.714844, 35.714855, 35.71486 , ..., 35.71965 , 35.719685,\n",
       "        35.71972 ],\n",
       "       [35.719757, 35.71979 , 35.719826, ..., 37.98176 , 38.068935,\n",
       "        38.15324 ]], dtype=float32)"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check = predictions[:, 1]\n",
    "check = check.reshape((n_logrho, n_logtemp))\n",
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "9f1070f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LogNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "b77ea408",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thibe\\AppData\\Local\\Temp\\ipykernel_8344\\1325347311.py:5: RuntimeWarning: invalid value encountered in log\n",
      "  targets_list = [logenergy, logpress, np.log(cs2)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(391, 163)\n",
      "(391, 163)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1100x300 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert model to float\n",
    "model = model.float()\n",
    "\n",
    "# Target list\n",
    "targets_list = [logenergy, logpress, np.log(cs2)]\n",
    "titles_list = [\"eps\", \"p\", \"cs2\"]\n",
    "\n",
    "# Initialize the plot\n",
    "fig, axs = plt.subplots(1, 2, sharey=True, figsize=(11,3))\n",
    "\n",
    "# Choose the norm function to compare targets against predictions\n",
    "norm_function = nnc2p.l2_norm\n",
    "\n",
    "for i, ax in enumerate(axs):\n",
    "    # Slice predictions\n",
    "    sliced_predictions = predictions[:, i]\n",
    "    values = targets_list[i]\n",
    "    # Initialize v and zero the matrix\n",
    "    targets = values[ye_index]\n",
    "    targets = np.swapaxes(targets, 0, 1)\n",
    "    print(targets.shape)\n",
    "    # \"Flatten\" the array, but have to do it manually for some reason\n",
    "    target_values = []\n",
    "    for a in range(n_logtemp):\n",
    "        for b in range(n_logrho):\n",
    "            target_values.append(targets[b, a])\n",
    "    target_values = np.array(target_values)\n",
    "    delta_vals = norm_function(target_values, sliced_predictions, reduction=False)\n",
    "    delta_vals = delta_vals.reshape((n_logtemp, n_logrho))\n",
    "    # Then plot it\n",
    "    im = ax.imshow(delta_vals, origin=\"lower\") # norm=plt.colors.LogNorm(vmin=1e-9, vmax=1e0)\n",
    "    ax.set_xlabel(\"log rho\")\n",
    "    if i == 0:\n",
    "        ax.set_ylabel(\"log T\")\n",
    "    ax.set_title(titles_list[i])\n",
    "\n",
    "cbar = fig.colorbar(im, ax=axs) # shrink=0.6\n",
    "# cbar.ax.set_yscale('log')\n",
    "plt.savefig(os.path.join(master_dir, \"Plots/recovery_tabular_EOS.pdf\"), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d94ad6c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09353939852511672"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(delta_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8206b9e",
   "metadata": {
    "id": "8fd2f127"
   },
   "source": [
    "# Now, NNEOS with eps as input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c75ccd",
   "metadata": {
    "id": "e5850152"
   },
   "source": [
    "__NNEOS__: try to replicate the EOS table (at least the core variables we are interested in) using the \"input\" variables logrho, logtemp, ye."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2b23e2",
   "metadata": {
    "id": "12089f53"
   },
   "source": [
    "## Convert EOS table to table of training examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "025e4ff0",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1681398700618,
     "user": {
      "displayName": "Thibeau Wouters",
      "userId": "14702334917940433667"
     },
     "user_tz": -120
    },
    "id": "7a92994d"
   },
   "outputs": [],
   "source": [
    "# Get the filename of converted training data\n",
    "filename = os.path.join(eos_tables_dir, \"converted_eos_table.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "9ba726d2",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1681398701905,
     "user": {
      "displayName": "Thibeau Wouters",
      "userId": "14702334917940433667"
     },
     "user_tz": -120
    },
    "id": "051199cf"
   },
   "outputs": [],
   "source": [
    "# # Create new dataset (if desired)\n",
    "# # Specify output vars as \"var_names\" argument in this function - see physics.py\n",
    "# eos_table = physics.read_eos_table(os.path.join(eos_tables_dir, eos_table_filename))\n",
    "# physics.convert_eos_table(eos_table, save_name=filename)\n",
    "# eos_table.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "ce66f03c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2035,
     "status": "ok",
     "timestamp": 1681398704133,
     "user": {
      "displayName": "Thibeau Wouters",
      "userId": "14702334917940433667"
     },
     "user_tz": -120
    },
    "id": "ccbc983b",
    "outputId": "a345b306-1aba-427e-874c-daa97b43cdca"
   },
   "outputs": [],
   "source": [
    "# Load the dataset afterwards\n",
    "train_eos_table = h5py.File(filename, 'r')\n",
    "# Get the data saved in the HDF5 file\n",
    "logrho    = train_eos_table[\"logrho\"][:]\n",
    "logtemp   = train_eos_table[\"logtemp\"][:]\n",
    "ye        = train_eos_table[\"ye\"][:]\n",
    "logenergy = train_eos_table[\"logenergy\"][:]\n",
    "logpress  = train_eos_table[\"logpress\"][:]\n",
    "cs2       = train_eos_table[\"cs2\"][:]\n",
    "# Close the file\n",
    "train_eos_table.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c46e040",
   "metadata": {},
   "source": [
    "## Preprocess the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f08210",
   "metadata": {},
   "source": [
    "### Delete negative $c_s^2$ values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b7c5b4",
   "metadata": {},
   "source": [
    "There are apparently a few negative values for the speed of sound... They are likely a bug in the code? We'll remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "15530f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3629826],\n",
       "       [3629892],\n",
       "       [3629958],\n",
       "       [3630024],\n",
       "       [3630090],\n",
       "       [3630156],\n",
       "       [3630222],\n",
       "       [3630288],\n",
       "       [3630354]], dtype=int64)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_indices = np.argwhere(cs2 < 0)\n",
    "negative_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "96a3ea0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "logrho    = np.delete(logrho, negative_indices, axis=0)\n",
    "logtemp   = np.delete(logtemp, negative_indices, axis=0)\n",
    "ye        = np.delete(ye, negative_indices, axis=0)\n",
    "logenergy = np.delete(logenergy, negative_indices, axis=0)\n",
    "logpress  = np.delete(logpress, negative_indices, axis=0)\n",
    "cs2       = np.delete(cs2, negative_indices, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9316e2",
   "metadata": {},
   "source": [
    "### Use log values for $c_s^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745a91e5",
   "metadata": {},
   "source": [
    "Use ln-log for the cs2 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "b9cc7a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "logcs2 = np.log(cs2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1cd051",
   "metadata": {},
   "source": [
    "### Convert to Torch `Datasets` for training the network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eba0e1e",
   "metadata": {},
   "source": [
    "Get into features and labels arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "b8ae365c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.transpose(np.array([logrho, logtemp, ye]))\n",
    "labels   = np.transpose(np.array([logpress, logenergy, logcs2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "25f62d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.02399601e+00, -3.00000000e+00,  5.00000000e-03],\n",
       "       [ 3.02399601e+00, -3.00000000e+00,  1.50000000e-02],\n",
       "       [ 3.02399601e+00, -3.00000000e+00,  2.50000000e-02],\n",
       "       ...,\n",
       "       [ 1.60239960e+01,  2.40000000e+00,  6.35000000e-01],\n",
       "       [ 1.60239960e+01,  2.40000000e+00,  6.45000000e-01],\n",
       "       [ 1.60239960e+01,  2.40000000e+00,  6.55000000e-01]])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "f5466cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4206369, 3)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c28096",
   "metadata": {
    "id": "ec6d6047"
   },
   "source": [
    "Get the training data as DataSet and DataLoader objects. Note on normalization: we fit transform on the training data, then use the fitted scaler object to transform (i.e. using same transformation as the training data) the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "82453a30",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1126,
     "status": "ok",
     "timestamp": 1681398709169,
     "user": {
      "displayName": "Thibeau Wouters",
      "userId": "14702334917940433667"
     },
     "user_tz": -120
    },
    "id": "ec910284",
    "outputId": "4f15e095-7252-40dc-c90d-2bafae1c6cb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3154776\n",
      "78869\n"
     ]
    }
   ],
   "source": [
    "# For normalization, use sklearn's StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# Do train test split here\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, random_state=42)\n",
    "# \"Cutoff\": only use certain portion of the data for training and testing, to speed up training when tuning architecture \n",
    "cutoff = 0.025\n",
    "print(len(train_features))\n",
    "end = int(cutoff*len(train_features))\n",
    "train_features = train_features[:end]\n",
    "train_labels = train_labels[:end]\n",
    "end = int(cutoff*len(test_features))\n",
    "test_features = test_features[:end]\n",
    "test_labels = test_labels[:end]\n",
    "print(len(train_features))\n",
    "# Convert to PyTorch Datasets as we defined them\n",
    "train_dataset = data.HDF5Dataset(train_features, train_labels, normalization_function = scaler.fit_transform) \n",
    "test_dataset  = data.HDF5Dataset(test_features, test_labels, normalization_function = scaler.transform)\n",
    "# Then create dataloaders, with batch size 32, from datasets\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = 32)\n",
    "test_dataloader  = DataLoader(test_dataset, batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdbc458",
   "metadata": {},
   "source": [
    "### Training and inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1749c8a",
   "metadata": {
    "id": "f12e532a"
   },
   "source": [
    "Create a new instance of the Net:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "61035a8d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1681398714800,
     "user": {
      "displayName": "Thibeau Wouters",
      "userId": "14702334917940433667"
     },
     "user_tz": -120
    },
    "id": "be7a388c",
    "outputId": "c92948dd-975b-4e2f-81a0-ee0661b400ff"
   },
   "outputs": [],
   "source": [
    "model = Net(nb_of_inputs=3, nb_of_outputs=3, h=[20, 20], activation_function=torch.nn.ReLU).double()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f562074",
   "metadata": {},
   "source": [
    "Or load from earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "064a8f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.load(\"../Models/tabeos_3_50_50_3.pt\")\n",
    "# test_input = [[1,1,1]]\n",
    "# test_input = scaler.transform(test_input)\n",
    "# test_input = torch.from_numpy(test_input).float()\n",
    "# model(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "d9114e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9.51608373 -0.30081866  0.32936217]\n",
      "[3.76043372 1.56992791 0.19028245]\n"
     ]
    }
   ],
   "source": [
    "print(scaler.mean_)\n",
    "print(scaler.scale_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "b081c245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.state_dict()[\"linear1.bias\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "bae7d44a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1681398716642,
     "user": {
      "displayName": "Thibeau Wouters",
      "userId": "14702334917940433667"
     },
     "user_tz": -120
    },
    "id": "5a0e1f63",
    "outputId": "474f33c1-c8a7-4433-9f4d-9738b0a08141"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "563"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnc2p.count_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7715e86",
   "metadata": {
    "id": "1e1e3745"
   },
   "source": [
    "Create a trainer object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "37576585",
   "metadata": {
    "executionInfo": {
     "elapsed": 705,
     "status": "ok",
     "timestamp": 1681398719638,
     "user": {
      "displayName": "Thibeau Wouters",
      "userId": "14702334917940433667"
     },
     "user_tz": -120
    },
    "id": "df92e917"
   },
   "outputs": [],
   "source": [
    "trainer = nnc2p.Trainer(model, 1e-2, train_dataloader=train_dataloader, test_dataloader=test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79267457",
   "metadata": {},
   "source": [
    "Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "9832a19a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 171807,
     "status": "ok",
     "timestamp": 1681398892786,
     "user": {
      "displayName": "Thibeau Wouters",
      "userId": "14702334917940433667"
     },
     "user_tz": -120
    },
    "id": "53ce8669",
    "outputId": "711c53ca-cf46-43e3-8d63-6625ebdf0880"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model for 1000 epochs.\n",
      "\n",
      " Epoch 0 \n",
      " --------------\n",
      "Train loss: 4.06E-02\n",
      "Test  loss: 4.06E-02\n",
      "\n",
      " Epoch 1 \n",
      " --------------\n",
      "Train loss: 3.91E-02\n",
      "Test  loss: 3.92E-02\n",
      "\n",
      " Epoch 2 \n",
      " --------------\n",
      "Train loss: 4.17E-02\n",
      "Test  loss: 4.19E-02\n",
      "\n",
      " Epoch 3 \n",
      " --------------\n",
      "Train loss: 4.09E-02\n",
      "Test  loss: 4.11E-02\n",
      "\n",
      " Epoch 4 \n",
      " --------------\n",
      "Train loss: 4.10E-02\n",
      "Test  loss: 4.12E-02\n",
      "\n",
      " Epoch 5 \n",
      " --------------\n",
      "Train loss: 4.13E-02\n",
      "Test  loss: 4.15E-02\n",
      "\n",
      " Epoch 6 \n",
      " --------------\n",
      "Train loss: 4.31E-02\n",
      "Test  loss: 4.34E-02\n",
      "\n",
      " Epoch 7 \n",
      " --------------\n",
      "Train loss: 4.13E-02\n",
      "Test  loss: 4.16E-02\n",
      "\n",
      " Epoch 8 \n",
      " --------------\n",
      "Train loss: 4.20E-02\n",
      "Test  loss: 4.23E-02\n",
      "\n",
      " Epoch 9 \n",
      " --------------\n",
      "Train loss: 3.31E-02\n",
      "Test  loss: 3.34E-02\n",
      "\n",
      " Epoch 10 \n",
      " --------------\n",
      "Train loss: 3.12E-02\n",
      "Test  loss: 3.14E-02\n",
      "\n",
      " Epoch 11 \n",
      " --------------\n",
      "Train loss: 3.40E-02\n",
      "Test  loss: 3.39E-02\n",
      "\n",
      " Epoch 12 \n",
      " --------------\n",
      "Train loss: 3.69E-02\n",
      "Test  loss: 3.68E-02\n",
      "\n",
      " Epoch 13 \n",
      " --------------\n",
      "Train loss: 2.68E-02\n",
      "Test  loss: 2.68E-02\n",
      "\n",
      " Epoch 14 \n",
      " --------------\n",
      "Train loss: 2.20E-02\n",
      "Test  loss: 2.19E-02\n",
      "\n",
      " Epoch 15 \n",
      " --------------\n",
      "Train loss: 1.82E-02\n",
      "Test  loss: 1.81E-02\n",
      "\n",
      " Epoch 16 \n",
      " --------------\n",
      "Train loss: 1.84E-02\n",
      "Test  loss: 1.83E-02\n",
      "\n",
      " Epoch 17 \n",
      " --------------\n",
      "Train loss: 1.80E-02\n",
      "Test  loss: 1.78E-02\n",
      "\n",
      " Epoch 18 \n",
      " --------------\n",
      "Train loss: 1.55E-02\n",
      "Test  loss: 1.54E-02\n",
      "\n",
      " Epoch 19 \n",
      " --------------\n",
      "Train loss: 1.36E-02\n",
      "Test  loss: 1.34E-02\n",
      "\n",
      " Epoch 20 \n",
      " --------------\n",
      "Train loss: 1.19E-02\n",
      "Test  loss: 1.17E-02\n",
      "\n",
      " Epoch 21 \n",
      " --------------\n",
      "Train loss: 1.14E-02\n",
      "Test  loss: 1.12E-02\n",
      "\n",
      " Epoch 22 \n",
      " --------------\n",
      "Train loss: 1.21E-02\n",
      "Test  loss: 1.19E-02\n",
      "\n",
      " Epoch 23 \n",
      " --------------\n",
      "Train loss: 1.31E-02\n",
      "Test  loss: 1.29E-02\n",
      "\n",
      " Epoch 24 \n",
      " --------------\n",
      "Train loss: 1.01E-02\n",
      "Test  loss: 1.01E-02\n",
      "\n",
      " Epoch 25 \n",
      " --------------\n",
      "Train loss: 8.75E-03\n",
      "Test  loss: 8.74E-03\n",
      "\n",
      " Epoch 26 \n",
      " --------------\n",
      "Train loss: 8.01E-03\n",
      "Test  loss: 8.02E-03\n",
      "\n",
      " Epoch 27 \n",
      " --------------\n",
      "Train loss: 1.24E-02\n",
      "Test  loss: 1.23E-02\n",
      "\n",
      " Epoch 28 \n",
      " --------------\n",
      "Train loss: 8.92E-03\n",
      "Test  loss: 8.95E-03\n",
      "\n",
      " Epoch 29 \n",
      " --------------\n",
      "Train loss: 7.71E-03\n",
      "Test  loss: 7.77E-03\n",
      "\n",
      " Epoch 30 \n",
      " --------------\n",
      "Train loss: 9.16E-03\n",
      "Test  loss: 9.21E-03\n",
      "\n",
      " Epoch 31 \n",
      " --------------\n",
      "Train loss: 8.59E-03\n",
      "Test  loss: 8.64E-03\n",
      "\n",
      " Epoch 32 \n",
      " --------------\n",
      "Train loss: 8.11E-03\n",
      "Test  loss: 8.15E-03\n",
      "\n",
      " Epoch 33 \n",
      " --------------\n",
      "Train loss: 7.72E-03\n",
      "Test  loss: 7.78E-03\n",
      "\n",
      " Epoch 34 \n",
      " --------------\n",
      "Train loss: 6.54E-03\n",
      "Test  loss: 6.59E-03\n",
      "\n",
      " Epoch 35 \n",
      " --------------\n",
      "Train loss: 6.48E-03\n",
      "Test  loss: 6.55E-03\n",
      "\n",
      " Epoch 36 \n",
      " --------------\n",
      "Train loss: 6.40E-03\n",
      "Test  loss: 6.46E-03\n",
      "\n",
      " Epoch 37 \n",
      " --------------\n",
      "Train loss: 6.29E-03\n",
      "Test  loss: 6.34E-03\n",
      "\n",
      " Epoch 38 \n",
      " --------------\n",
      "Train loss: 6.28E-03\n",
      "Test  loss: 6.33E-03\n",
      "\n",
      " Epoch 39 \n",
      " --------------\n",
      "Train loss: 6.09E-03\n",
      "Test  loss: 6.16E-03\n",
      "\n",
      " Epoch 40 \n",
      " --------------\n",
      "Train loss: 6.89E-03\n",
      "Test  loss: 6.97E-03\n",
      "\n",
      " Epoch 41 \n",
      " --------------\n",
      "Train loss: 6.22E-03\n",
      "Test  loss: 6.28E-03\n",
      "\n",
      " Epoch 42 \n",
      " --------------\n",
      "Train loss: 7.30E-03\n",
      "Test  loss: 7.38E-03\n",
      "\n",
      " Epoch 43 \n",
      " --------------\n",
      "Train loss: 7.04E-03\n",
      "Test  loss: 7.10E-03\n",
      "\n",
      " Epoch 44 \n",
      " --------------\n",
      "Train loss: 5.89E-03\n",
      "Test  loss: 5.96E-03\n",
      "\n",
      " Epoch 45 \n",
      " --------------\n",
      "Train loss: 6.27E-03\n",
      "Test  loss: 6.32E-03\n",
      "\n",
      " Epoch 46 \n",
      " --------------\n",
      "Train loss: 5.20E-03\n",
      "Test  loss: 5.26E-03\n",
      "\n",
      " Epoch 47 \n",
      " --------------\n",
      "Train loss: 6.73E-03\n",
      "Test  loss: 6.80E-03\n",
      "\n",
      " Epoch 48 \n",
      " --------------\n",
      "Train loss: 4.95E-03\n",
      "Test  loss: 4.98E-03\n",
      "\n",
      " Epoch 49 \n",
      " --------------\n",
      "Train loss: 5.39E-03\n",
      "Test  loss: 5.43E-03\n",
      "\n",
      " Epoch 50 \n",
      " --------------\n",
      "Train loss: 5.57E-03\n",
      "Test  loss: 5.62E-03\n",
      "\n",
      " Epoch 51 \n",
      " --------------\n",
      "Train loss: 6.97E-03\n",
      "Test  loss: 7.02E-03\n",
      "\n",
      " Epoch 52 \n",
      " --------------\n",
      "Train loss: 8.10E-03\n",
      "Test  loss: 8.18E-03\n",
      "\n",
      " Epoch 53 \n",
      " --------------\n",
      "Adapting learning rate to 0.005\n",
      "Train loss: 8.19E-03\n",
      "Test  loss: 8.27E-03\n",
      "\n",
      " Epoch 54 \n",
      " --------------\n",
      "Train loss: 4.71E-03\n",
      "Test  loss: 4.71E-03\n",
      "\n",
      " Epoch 55 \n",
      " --------------\n",
      "Train loss: 4.47E-03\n",
      "Test  loss: 4.47E-03\n",
      "\n",
      " Epoch 56 \n",
      " --------------\n",
      "Train loss: 4.51E-03\n",
      "Test  loss: 4.53E-03\n",
      "\n",
      " Epoch 57 \n",
      " --------------\n",
      "Train loss: 4.59E-03\n",
      "Test  loss: 4.61E-03\n",
      "\n",
      " Epoch 58 \n",
      " --------------\n",
      "Train loss: 4.59E-03\n",
      "Test  loss: 4.61E-03\n",
      "\n",
      " Epoch 59 \n",
      " --------------\n",
      "Train loss: 4.54E-03\n",
      "Test  loss: 4.57E-03\n",
      "\n",
      " Epoch 60 \n",
      " --------------\n",
      "Train loss: 4.47E-03\n",
      "Test  loss: 4.50E-03\n",
      "\n",
      " Epoch 61 \n",
      " --------------\n",
      "Train loss: 4.53E-03\n",
      "Test  loss: 4.56E-03\n",
      "\n",
      " Epoch 62 \n",
      " --------------\n",
      "Train loss: 4.58E-03\n",
      "Test  loss: 4.61E-03\n",
      "\n",
      " Epoch 63 \n",
      " --------------\n",
      "Train loss: 4.59E-03\n",
      "Test  loss: 4.62E-03\n",
      "\n",
      " Epoch 64 \n",
      " --------------\n",
      "Train loss: 4.33E-03\n",
      "Test  loss: 4.37E-03\n",
      "\n",
      " Epoch 65 \n",
      " --------------\n",
      "Train loss: 4.60E-03\n",
      "Test  loss: 4.64E-03\n",
      "\n",
      " Epoch 66 \n",
      " --------------\n",
      "Train loss: 4.68E-03\n",
      "Test  loss: 4.73E-03\n",
      "\n",
      " Epoch 67 \n",
      " --------------\n",
      "Train loss: 4.70E-03\n",
      "Test  loss: 4.74E-03\n",
      "\n",
      " Epoch 68 \n",
      " --------------\n",
      "Train loss: 4.63E-03\n",
      "Test  loss: 4.67E-03\n",
      "\n",
      " Epoch 69 \n",
      " --------------\n",
      "Adapting learning rate to 0.0025\n",
      "Train loss: 4.77E-03\n",
      "Test  loss: 4.81E-03\n",
      "\n",
      " Epoch 70 \n",
      " --------------\n",
      "Train loss: 4.44E-03\n",
      "Test  loss: 4.48E-03\n",
      "\n",
      " Epoch 71 \n",
      " --------------\n",
      "Train loss: 4.47E-03\n",
      "Test  loss: 4.51E-03\n",
      "\n",
      " Epoch 72 \n",
      " --------------\n",
      "Train loss: 4.39E-03\n",
      "Test  loss: 4.43E-03\n",
      "\n",
      " Epoch 73 \n",
      " --------------\n",
      "Train loss: 4.32E-03\n",
      "Test  loss: 4.36E-03\n",
      "\n",
      " Epoch 74 \n",
      " --------------\n",
      "Train loss: 4.34E-03\n",
      "Test  loss: 4.39E-03\n",
      "\n",
      " Epoch 75 \n",
      " --------------\n",
      "Train loss: 4.42E-03\n",
      "Test  loss: 4.47E-03\n",
      "\n",
      " Epoch 76 \n",
      " --------------\n",
      "Train loss: 4.27E-03\n",
      "Test  loss: 4.32E-03\n",
      "\n",
      " Epoch 77 \n",
      " --------------\n",
      "Train loss: 4.28E-03\n",
      "Test  loss: 4.33E-03\n",
      "\n",
      " Epoch 78 \n",
      " --------------\n",
      "Train loss: 4.32E-03\n",
      "Test  loss: 4.36E-03\n",
      "\n",
      " Epoch 79 \n",
      " --------------\n",
      "Train loss: 4.30E-03\n",
      "Test  loss: 4.35E-03\n",
      "\n",
      " Epoch 80 \n",
      " --------------\n",
      "Train loss: 4.27E-03\n",
      "Test  loss: 4.32E-03\n",
      "\n",
      " Epoch 81 \n",
      " --------------\n",
      "Train loss: 4.29E-03\n",
      "Test  loss: 4.34E-03\n",
      "\n",
      " Epoch 82 \n",
      " --------------\n",
      "Train loss: 4.27E-03\n",
      "Test  loss: 4.32E-03\n",
      "\n",
      " Epoch 83 \n",
      " --------------\n",
      "Train loss: 4.26E-03\n",
      "Test  loss: 4.31E-03\n",
      "\n",
      " Epoch 84 \n",
      " --------------\n",
      "Train loss: 4.24E-03\n",
      "Test  loss: 4.29E-03\n",
      "\n",
      " Epoch 85 \n",
      " --------------\n",
      "Train loss: 4.22E-03\n",
      "Test  loss: 4.27E-03\n",
      "\n",
      " Epoch 86 \n",
      " --------------\n",
      "Train loss: 4.22E-03\n",
      "Test  loss: 4.27E-03\n",
      "\n",
      " Epoch 87 \n",
      " --------------\n",
      "Train loss: 4.21E-03\n",
      "Test  loss: 4.26E-03\n",
      "\n",
      " Epoch 88 \n",
      " --------------\n",
      "Train loss: 4.23E-03\n",
      "Test  loss: 4.27E-03\n",
      "\n",
      " Epoch 89 \n",
      " --------------\n",
      "Train loss: 4.27E-03\n",
      "Test  loss: 4.33E-03\n",
      "\n",
      " Epoch 90 \n",
      " --------------\n",
      "Train loss: 4.26E-03\n",
      "Test  loss: 4.31E-03\n",
      "\n",
      " Epoch 91 \n",
      " --------------\n",
      "Train loss: 4.25E-03\n",
      "Test  loss: 4.30E-03\n",
      "\n",
      " Epoch 92 \n",
      " --------------\n",
      "Adapting learning rate to 0.00125\n",
      "Train loss: 4.24E-03\n",
      "Test  loss: 4.29E-03\n",
      "\n",
      " Epoch 93 \n",
      " --------------\n",
      "Train loss: 4.59E-03\n",
      "Test  loss: 4.65E-03\n",
      "\n",
      " Epoch 94 \n",
      " --------------\n",
      "Train loss: 4.59E-03\n",
      "Test  loss: 4.64E-03\n",
      "\n",
      " Epoch 95 \n",
      " --------------\n",
      "Train loss: 4.57E-03\n",
      "Test  loss: 4.63E-03\n",
      "\n",
      " Epoch 96 \n",
      " --------------\n",
      "Train loss: 4.57E-03\n",
      "Test  loss: 4.63E-03\n",
      "\n",
      " Epoch 97 \n",
      " --------------\n",
      "Train loss: 4.61E-03\n",
      "Test  loss: 4.67E-03\n",
      "\n",
      " Epoch 98 \n",
      " --------------\n",
      "Train loss: 4.60E-03\n",
      "Test  loss: 4.66E-03\n",
      "\n",
      " Epoch 99 \n",
      " --------------\n",
      "Train loss: 4.59E-03\n",
      "Test  loss: 4.65E-03\n",
      "\n",
      " Epoch 100 \n",
      " --------------\n",
      "Train loss: 4.56E-03\n",
      "Test  loss: 4.62E-03\n",
      "\n",
      " Epoch 101 \n",
      " --------------\n",
      "Train loss: 4.55E-03\n",
      "Test  loss: 4.62E-03\n",
      "\n",
      " Epoch 102 \n",
      " --------------\n",
      "Train loss: 4.51E-03\n",
      "Test  loss: 4.57E-03\n",
      "\n",
      " Epoch 103 \n",
      " --------------\n",
      "Train loss: 4.49E-03\n",
      "Test  loss: 4.55E-03\n",
      "\n",
      " Epoch 104 \n",
      " --------------\n",
      "Train loss: 4.45E-03\n",
      "Test  loss: 4.51E-03\n",
      "\n",
      " Epoch 105 \n",
      " --------------\n",
      "Train loss: 4.40E-03\n",
      "Test  loss: 4.46E-03\n",
      "\n",
      " Epoch 106 \n",
      " --------------\n",
      "Train loss: 4.37E-03\n",
      "Test  loss: 4.43E-03\n",
      "\n",
      " Epoch 107 \n",
      " --------------\n",
      "Train loss: 4.32E-03\n",
      "Test  loss: 4.38E-03\n",
      "\n",
      " Epoch 108 \n",
      " --------------\n",
      "Train loss: 4.25E-03\n",
      "Test  loss: 4.31E-03\n",
      "\n",
      " Epoch 109 \n",
      " --------------\n",
      "Train loss: 4.21E-03\n",
      "Test  loss: 4.27E-03\n",
      "\n",
      " Epoch 110 \n",
      " --------------\n",
      "Train loss: 4.18E-03\n",
      "Test  loss: 4.24E-03\n",
      "\n",
      " Epoch 111 \n",
      " --------------\n",
      "Train loss: 4.11E-03\n",
      "Test  loss: 4.17E-03\n",
      "\n",
      " Epoch 112 \n",
      " --------------\n",
      "Train loss: 4.10E-03\n",
      "Test  loss: 4.16E-03\n",
      "\n",
      " Epoch 113 \n",
      " --------------\n",
      "Train loss: 4.07E-03\n",
      "Test  loss: 4.13E-03\n",
      "\n",
      " Epoch 114 \n",
      " --------------\n",
      "Train loss: 4.04E-03\n",
      "Test  loss: 4.11E-03\n",
      "\n",
      " Epoch 115 \n",
      " --------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.03E-03\n",
      "Test  loss: 4.09E-03\n",
      "\n",
      " Epoch 116 \n",
      " --------------\n",
      "Train loss: 4.01E-03\n",
      "Test  loss: 4.08E-03\n",
      "\n",
      " Epoch 117 \n",
      " --------------\n",
      "Train loss: 4.00E-03\n",
      "Test  loss: 4.07E-03\n",
      "\n",
      " Epoch 118 \n",
      " --------------\n",
      "Train loss: 4.01E-03\n",
      "Test  loss: 4.07E-03\n",
      "\n",
      " Epoch 119 \n",
      " --------------\n",
      "Train loss: 3.96E-03\n",
      "Test  loss: 4.03E-03\n",
      "\n",
      " Epoch 120 \n",
      " --------------\n",
      "Train loss: 3.93E-03\n",
      "Test  loss: 4.00E-03\n",
      "\n",
      " Epoch 121 \n",
      " --------------\n",
      "Train loss: 3.92E-03\n",
      "Test  loss: 3.98E-03\n",
      "\n",
      " Epoch 122 \n",
      " --------------\n",
      "Train loss: 3.88E-03\n",
      "Test  loss: 3.95E-03\n",
      "\n",
      " Epoch 123 \n",
      " --------------\n",
      "Train loss: 3.86E-03\n",
      "Test  loss: 3.93E-03\n",
      "\n",
      " Epoch 124 \n",
      " --------------\n",
      "Train loss: 3.84E-03\n",
      "Test  loss: 3.90E-03\n",
      "\n",
      " Epoch 125 \n",
      " --------------\n",
      "Train loss: 3.81E-03\n",
      "Test  loss: 3.88E-03\n",
      "\n",
      " Epoch 126 \n",
      " --------------\n",
      "Train loss: 3.80E-03\n",
      "Test  loss: 3.87E-03\n",
      "\n",
      " Epoch 127 \n",
      " --------------\n",
      "Train loss: 3.79E-03\n",
      "Test  loss: 3.86E-03\n",
      "\n",
      " Epoch 128 \n",
      " --------------\n",
      "Train loss: 3.76E-03\n",
      "Test  loss: 3.83E-03\n",
      "\n",
      " Epoch 129 \n",
      " --------------\n",
      "Train loss: 3.76E-03\n",
      "Test  loss: 3.83E-03\n",
      "\n",
      " Epoch 130 \n",
      " --------------\n",
      "Train loss: 3.75E-03\n",
      "Test  loss: 3.82E-03\n",
      "\n",
      " Epoch 131 \n",
      " --------------\n",
      "Train loss: 3.75E-03\n",
      "Test  loss: 3.82E-03\n",
      "\n",
      " Epoch 132 \n",
      " --------------\n",
      "Train loss: 3.70E-03\n",
      "Test  loss: 3.77E-03\n",
      "\n",
      " Epoch 133 \n",
      " --------------\n",
      "Train loss: 3.69E-03\n",
      "Test  loss: 3.76E-03\n",
      "\n",
      " Epoch 134 \n",
      " --------------\n",
      "Train loss: 3.67E-03\n",
      "Test  loss: 3.74E-03\n",
      "\n",
      " Epoch 135 \n",
      " --------------\n",
      "Train loss: 3.66E-03\n",
      "Test  loss: 3.73E-03\n",
      "\n",
      " Epoch 136 \n",
      " --------------\n",
      "Train loss: 3.64E-03\n",
      "Test  loss: 3.71E-03\n",
      "\n",
      " Epoch 137 \n",
      " --------------\n",
      "Train loss: 3.62E-03\n",
      "Test  loss: 3.70E-03\n",
      "\n",
      " Epoch 138 \n",
      " --------------\n",
      "Train loss: 3.61E-03\n",
      "Test  loss: 3.68E-03\n",
      "\n",
      " Epoch 139 \n",
      " --------------\n",
      "Train loss: 3.59E-03\n",
      "Test  loss: 3.67E-03\n",
      "\n",
      " Epoch 140 \n",
      " --------------\n",
      "Train loss: 3.59E-03\n",
      "Test  loss: 3.67E-03\n",
      "\n",
      " Epoch 141 \n",
      " --------------\n",
      "Train loss: 3.59E-03\n",
      "Test  loss: 3.66E-03\n",
      "\n",
      " Epoch 142 \n",
      " --------------\n",
      "Train loss: 3.57E-03\n",
      "Test  loss: 3.65E-03\n",
      "\n",
      " Epoch 143 \n",
      " --------------\n",
      "Train loss: 3.56E-03\n",
      "Test  loss: 3.64E-03\n",
      "\n",
      " Epoch 144 \n",
      " --------------\n",
      "Train loss: 3.55E-03\n",
      "Test  loss: 3.62E-03\n",
      "\n",
      " Epoch 145 \n",
      " --------------\n",
      "Train loss: 3.55E-03\n",
      "Test  loss: 3.62E-03\n",
      "\n",
      " Epoch 146 \n",
      " --------------\n",
      "Train loss: 3.54E-03\n",
      "Test  loss: 3.61E-03\n",
      "\n",
      " Epoch 147 \n",
      " --------------\n",
      "Train loss: 3.54E-03\n",
      "Test  loss: 3.61E-03\n",
      "\n",
      " Epoch 148 \n",
      " --------------\n",
      "Train loss: 3.52E-03\n",
      "Test  loss: 3.60E-03\n",
      "\n",
      " Epoch 149 \n",
      " --------------\n",
      "Train loss: 3.51E-03\n",
      "Test  loss: 3.59E-03\n",
      "\n",
      " Epoch 150 \n",
      " --------------\n",
      "Train loss: 3.50E-03\n",
      "Test  loss: 3.57E-03\n",
      "\n",
      " Epoch 151 \n",
      " --------------\n",
      "Train loss: 3.49E-03\n",
      "Test  loss: 3.56E-03\n",
      "\n",
      " Epoch 152 \n",
      " --------------\n",
      "Train loss: 3.49E-03\n",
      "Test  loss: 3.56E-03\n",
      "\n",
      " Epoch 153 \n",
      " --------------\n",
      "Train loss: 3.46E-03\n",
      "Test  loss: 3.53E-03\n",
      "\n",
      " Epoch 154 \n",
      " --------------\n",
      "Train loss: 3.45E-03\n",
      "Test  loss: 3.53E-03\n",
      "\n",
      " Epoch 155 \n",
      " --------------\n",
      "Train loss: 3.45E-03\n",
      "Test  loss: 3.52E-03\n",
      "\n",
      " Epoch 156 \n",
      " --------------\n",
      "Train loss: 3.44E-03\n",
      "Test  loss: 3.51E-03\n",
      "\n",
      " Epoch 157 \n",
      " --------------\n",
      "Train loss: 3.43E-03\n",
      "Test  loss: 3.51E-03\n",
      "\n",
      " Epoch 158 \n",
      " --------------\n",
      "Train loss: 3.42E-03\n",
      "Test  loss: 3.50E-03\n",
      "\n",
      " Epoch 159 \n",
      " --------------\n",
      "Train loss: 3.42E-03\n",
      "Test  loss: 3.49E-03\n",
      "\n",
      " Epoch 160 \n",
      " --------------\n",
      "Train loss: 3.44E-03\n",
      "Test  loss: 3.51E-03\n",
      "\n",
      " Epoch 161 \n",
      " --------------\n",
      "Train loss: 3.43E-03\n",
      "Test  loss: 3.51E-03\n",
      "\n",
      " Epoch 162 \n",
      " --------------\n",
      "Train loss: 3.40E-03\n",
      "Test  loss: 3.47E-03\n",
      "\n",
      " Epoch 163 \n",
      " --------------\n",
      "Train loss: 3.39E-03\n",
      "Test  loss: 3.47E-03\n",
      "\n",
      " Epoch 164 \n",
      " --------------\n",
      "Train loss: 3.38E-03\n",
      "Test  loss: 3.46E-03\n",
      "\n",
      " Epoch 165 \n",
      " --------------\n",
      "Train loss: 3.41E-03\n",
      "Test  loss: 3.48E-03\n",
      "\n",
      " Epoch 166 \n",
      " --------------\n",
      "Train loss: 3.37E-03\n",
      "Test  loss: 3.44E-03\n",
      "\n",
      " Epoch 167 \n",
      " --------------\n",
      "Train loss: 3.36E-03\n",
      "Test  loss: 3.44E-03\n",
      "\n",
      " Epoch 168 \n",
      " --------------\n",
      "Train loss: 3.36E-03\n",
      "Test  loss: 3.43E-03\n",
      "\n",
      " Epoch 169 \n",
      " --------------\n",
      "Train loss: 3.35E-03\n",
      "Test  loss: 3.43E-03\n",
      "\n",
      " Epoch 170 \n",
      " --------------\n",
      "Train loss: 3.35E-03\n",
      "Test  loss: 3.42E-03\n",
      "\n",
      " Epoch 171 \n",
      " --------------\n",
      "Train loss: 3.34E-03\n",
      "Test  loss: 3.41E-03\n",
      "\n",
      " Epoch 172 \n",
      " --------------\n",
      "Train loss: 3.33E-03\n",
      "Test  loss: 3.40E-03\n",
      "\n",
      " Epoch 173 \n",
      " --------------\n",
      "Train loss: 3.36E-03\n",
      "Test  loss: 3.44E-03\n",
      "\n",
      " Epoch 174 \n",
      " --------------\n",
      "Train loss: 3.35E-03\n",
      "Test  loss: 3.43E-03\n",
      "\n",
      " Epoch 175 \n",
      " --------------\n",
      "Train loss: 3.30E-03\n",
      "Test  loss: 3.38E-03\n",
      "\n",
      " Epoch 176 \n",
      " --------------\n",
      "Train loss: 3.31E-03\n",
      "Test  loss: 3.38E-03\n",
      "\n",
      " Epoch 177 \n",
      " --------------\n",
      "Train loss: 3.30E-03\n",
      "Test  loss: 3.37E-03\n",
      "\n",
      " Epoch 178 \n",
      " --------------\n",
      "Train loss: 3.30E-03\n",
      "Test  loss: 3.37E-03\n",
      "\n",
      " Epoch 179 \n",
      " --------------\n",
      "Train loss: 3.29E-03\n",
      "Test  loss: 3.36E-03\n",
      "\n",
      " Epoch 180 \n",
      " --------------\n",
      "Train loss: 3.29E-03\n",
      "Test  loss: 3.36E-03\n",
      "\n",
      " Epoch 181 \n",
      " --------------\n",
      "Train loss: 3.27E-03\n",
      "Test  loss: 3.34E-03\n",
      "\n",
      " Epoch 182 \n",
      " --------------\n",
      "Train loss: 3.26E-03\n",
      "Test  loss: 3.33E-03\n",
      "\n",
      " Epoch 183 \n",
      " --------------\n",
      "Train loss: 3.26E-03\n",
      "Test  loss: 3.33E-03\n",
      "\n",
      " Epoch 184 \n",
      " --------------\n",
      "Train loss: 3.24E-03\n",
      "Test  loss: 3.31E-03\n",
      "\n",
      " Epoch 185 \n",
      " --------------\n",
      "Train loss: 3.24E-03\n",
      "Test  loss: 3.31E-03\n",
      "\n",
      " Epoch 186 \n",
      " --------------\n",
      "Train loss: 3.24E-03\n",
      "Test  loss: 3.31E-03\n",
      "\n",
      " Epoch 187 \n",
      " --------------\n",
      "Train loss: 3.23E-03\n",
      "Test  loss: 3.30E-03\n",
      "\n",
      " Epoch 188 \n",
      " --------------\n",
      "Train loss: 3.24E-03\n",
      "Test  loss: 3.31E-03\n",
      "\n",
      " Epoch 189 \n",
      " --------------\n",
      "Train loss: 3.23E-03\n",
      "Test  loss: 3.30E-03\n",
      "\n",
      " Epoch 190 \n",
      " --------------\n",
      "Train loss: 3.20E-03\n",
      "Test  loss: 3.27E-03\n",
      "\n",
      " Epoch 191 \n",
      " --------------\n",
      "Train loss: 3.18E-03\n",
      "Test  loss: 3.25E-03\n",
      "\n",
      " Epoch 192 \n",
      " --------------\n",
      "Train loss: 3.19E-03\n",
      "Test  loss: 3.26E-03\n",
      "\n",
      " Epoch 193 \n",
      " --------------\n",
      "Train loss: 3.18E-03\n",
      "Test  loss: 3.25E-03\n",
      "\n",
      " Epoch 194 \n",
      " --------------\n",
      "Train loss: 3.17E-03\n",
      "Test  loss: 3.24E-03\n",
      "\n",
      " Epoch 195 \n",
      " --------------\n",
      "Train loss: 3.18E-03\n",
      "Test  loss: 3.24E-03\n",
      "\n",
      " Epoch 196 \n",
      " --------------\n",
      "Train loss: 3.13E-03\n",
      "Test  loss: 3.20E-03\n",
      "\n",
      " Epoch 197 \n",
      " --------------\n",
      "Train loss: 3.10E-03\n",
      "Test  loss: 3.17E-03\n",
      "\n",
      " Epoch 198 \n",
      " --------------\n",
      "Train loss: 3.09E-03\n",
      "Test  loss: 3.16E-03\n",
      "\n",
      " Epoch 199 \n",
      " --------------\n",
      "Train loss: 3.10E-03\n",
      "Test  loss: 3.17E-03\n",
      "\n",
      " Epoch 200 \n",
      " --------------\n",
      "Train loss: 3.08E-03\n",
      "Test  loss: 3.14E-03\n",
      "\n",
      " Epoch 201 \n",
      " --------------\n",
      "Train loss: 3.08E-03\n",
      "Test  loss: 3.14E-03\n",
      "\n",
      " Epoch 202 \n",
      " --------------\n",
      "Train loss: 3.12E-03\n",
      "Test  loss: 3.18E-03\n",
      "\n",
      " Epoch 203 \n",
      " --------------\n",
      "Train loss: 3.10E-03\n",
      "Test  loss: 3.17E-03\n",
      "\n",
      " Epoch 204 \n",
      " --------------\n",
      "Train loss: 3.10E-03\n",
      "Test  loss: 3.16E-03\n",
      "\n",
      " Epoch 205 \n",
      " --------------\n",
      "Adapting learning rate to 0.000625\n",
      "Train loss: 3.10E-03\n",
      "Test  loss: 3.16E-03\n",
      "\n",
      " Epoch 206 \n",
      " --------------\n",
      "Train loss: 2.96E-03\n",
      "Test  loss: 3.02E-03\n",
      "\n",
      " Epoch 207 \n",
      " --------------\n",
      "Train loss: 2.96E-03\n",
      "Test  loss: 3.01E-03\n",
      "\n",
      " Epoch 208 \n",
      " --------------\n",
      "Train loss: 2.95E-03\n",
      "Test  loss: 3.01E-03\n",
      "\n",
      " Epoch 209 \n",
      " --------------\n",
      "Train loss: 2.95E-03\n",
      "Test  loss: 3.01E-03\n",
      "\n",
      " Epoch 210 \n",
      " --------------\n",
      "Train loss: 2.95E-03\n",
      "Test  loss: 3.00E-03\n",
      "\n",
      " Epoch 211 \n",
      " --------------\n",
      "Train loss: 2.94E-03\n",
      "Test  loss: 3.00E-03\n",
      "\n",
      " Epoch 212 \n",
      " --------------\n",
      "Train loss: 2.94E-03\n",
      "Test  loss: 2.99E-03\n",
      "\n",
      " Epoch 213 \n",
      " --------------\n",
      "Train loss: 2.94E-03\n",
      "Test  loss: 2.99E-03\n",
      "\n",
      " Epoch 214 \n",
      " --------------\n",
      "Train loss: 2.93E-03\n",
      "Test  loss: 2.98E-03\n",
      "\n",
      " Epoch 215 \n",
      " --------------\n",
      "Train loss: 2.93E-03\n",
      "Test  loss: 2.98E-03\n",
      "\n",
      " Epoch 216 \n",
      " --------------\n",
      "Train loss: 2.91E-03\n",
      "Test  loss: 2.96E-03\n",
      "\n",
      " Epoch 217 \n",
      " --------------\n",
      "Train loss: 2.91E-03\n",
      "Test  loss: 2.96E-03\n",
      "\n",
      " Epoch 218 \n",
      " --------------\n",
      "Train loss: 2.91E-03\n",
      "Test  loss: 2.96E-03\n",
      "\n",
      " Epoch 219 \n",
      " --------------\n",
      "Train loss: 2.90E-03\n",
      "Test  loss: 2.95E-03\n",
      "\n",
      " Epoch 220 \n",
      " --------------\n",
      "Train loss: 2.89E-03\n",
      "Test  loss: 2.94E-03\n",
      "\n",
      " Epoch 221 \n",
      " --------------\n",
      "Train loss: 2.89E-03\n",
      "Test  loss: 2.94E-03\n",
      "\n",
      " Epoch 222 \n",
      " --------------\n",
      "Train loss: 2.88E-03\n",
      "Test  loss: 2.93E-03\n",
      "\n",
      " Epoch 223 \n",
      " --------------\n",
      "Train loss: 2.89E-03\n",
      "Test  loss: 2.93E-03\n",
      "\n",
      " Epoch 224 \n",
      " --------------\n",
      "Train loss: 2.89E-03\n",
      "Test  loss: 2.94E-03\n",
      "\n",
      " Epoch 225 \n",
      " --------------\n",
      "Train loss: 2.87E-03\n",
      "Test  loss: 2.92E-03\n",
      "\n",
      " Epoch 226 \n",
      " --------------\n",
      "Train loss: 2.87E-03\n",
      "Test  loss: 2.92E-03\n",
      "\n",
      " Epoch 227 \n",
      " --------------\n",
      "Train loss: 2.87E-03\n",
      "Test  loss: 2.92E-03\n",
      "\n",
      " Epoch 228 \n",
      " --------------\n",
      "Train loss: 2.87E-03\n",
      "Test  loss: 2.91E-03\n",
      "\n",
      " Epoch 229 \n",
      " --------------\n",
      "Train loss: 2.86E-03\n",
      "Test  loss: 2.91E-03\n",
      "\n",
      " Epoch 230 \n",
      " --------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.86E-03\n",
      "Test  loss: 2.91E-03\n",
      "\n",
      " Epoch 231 \n",
      " --------------\n",
      "Train loss: 2.85E-03\n",
      "Test  loss: 2.90E-03\n",
      "\n",
      " Epoch 232 \n",
      " --------------\n",
      "Train loss: 2.82E-03\n",
      "Test  loss: 2.87E-03\n",
      "\n",
      " Epoch 233 \n",
      " --------------\n",
      "Train loss: 2.81E-03\n",
      "Test  loss: 2.86E-03\n",
      "\n",
      " Epoch 234 \n",
      " --------------\n",
      "Train loss: 2.81E-03\n",
      "Test  loss: 2.86E-03\n",
      "\n",
      " Epoch 235 \n",
      " --------------\n",
      "Train loss: 2.81E-03\n",
      "Test  loss: 2.86E-03\n",
      "\n",
      " Epoch 236 \n",
      " --------------\n",
      "Train loss: 2.81E-03\n",
      "Test  loss: 2.86E-03\n",
      "\n",
      " Epoch 237 \n",
      " --------------\n",
      "Train loss: 2.80E-03\n",
      "Test  loss: 2.85E-03\n",
      "\n",
      " Epoch 238 \n",
      " --------------\n",
      "Train loss: 2.80E-03\n",
      "Test  loss: 2.85E-03\n",
      "\n",
      " Epoch 239 \n",
      " --------------\n",
      "Train loss: 2.79E-03\n",
      "Test  loss: 2.84E-03\n",
      "\n",
      " Epoch 240 \n",
      " --------------\n",
      "Train loss: 2.79E-03\n",
      "Test  loss: 2.83E-03\n",
      "\n",
      " Epoch 241 \n",
      " --------------\n",
      "Train loss: 2.78E-03\n",
      "Test  loss: 2.83E-03\n",
      "\n",
      " Epoch 242 \n",
      " --------------\n",
      "Train loss: 2.78E-03\n",
      "Test  loss: 2.83E-03\n",
      "\n",
      " Epoch 243 \n",
      " --------------\n",
      "Train loss: 2.78E-03\n",
      "Test  loss: 2.82E-03\n",
      "\n",
      " Epoch 244 \n",
      " --------------\n",
      "Train loss: 2.76E-03\n",
      "Test  loss: 2.80E-03\n",
      "\n",
      " Epoch 245 \n",
      " --------------\n",
      "Train loss: 2.75E-03\n",
      "Test  loss: 2.80E-03\n",
      "\n",
      " Epoch 246 \n",
      " --------------\n",
      "Train loss: 2.75E-03\n",
      "Test  loss: 2.80E-03\n",
      "\n",
      " Epoch 247 \n",
      " --------------\n",
      "Train loss: 2.75E-03\n",
      "Test  loss: 2.80E-03\n",
      "\n",
      " Epoch 248 \n",
      " --------------\n",
      "Train loss: 2.75E-03\n",
      "Test  loss: 2.79E-03\n",
      "\n",
      " Epoch 249 \n",
      " --------------\n",
      "Train loss: 2.75E-03\n",
      "Test  loss: 2.79E-03\n",
      "\n",
      " Epoch 250 \n",
      " --------------\n",
      "Train loss: 2.74E-03\n",
      "Test  loss: 2.79E-03\n",
      "\n",
      " Epoch 251 \n",
      " --------------\n",
      "Train loss: 2.74E-03\n",
      "Test  loss: 2.78E-03\n",
      "\n",
      " Epoch 252 \n",
      " --------------\n",
      "Train loss: 2.73E-03\n",
      "Test  loss: 2.78E-03\n",
      "\n",
      " Epoch 253 \n",
      " --------------\n",
      "Train loss: 2.73E-03\n",
      "Test  loss: 2.78E-03\n",
      "\n",
      " Epoch 254 \n",
      " --------------\n",
      "Train loss: 2.73E-03\n",
      "Test  loss: 2.78E-03\n",
      "\n",
      " Epoch 255 \n",
      " --------------\n",
      "Train loss: 2.72E-03\n",
      "Test  loss: 2.77E-03\n",
      "\n",
      " Epoch 256 \n",
      " --------------\n",
      "Train loss: 2.72E-03\n",
      "Test  loss: 2.77E-03\n",
      "\n",
      " Epoch 257 \n",
      " --------------\n",
      "Train loss: 2.72E-03\n",
      "Test  loss: 2.77E-03\n",
      "\n",
      " Epoch 258 \n",
      " --------------\n",
      "Train loss: 2.71E-03\n",
      "Test  loss: 2.76E-03\n",
      "\n",
      " Epoch 259 \n",
      " --------------\n",
      "Train loss: 2.72E-03\n",
      "Test  loss: 2.76E-03\n",
      "\n",
      " Epoch 260 \n",
      " --------------\n",
      "Train loss: 2.71E-03\n",
      "Test  loss: 2.76E-03\n",
      "\n",
      " Epoch 261 \n",
      " --------------\n",
      "Train loss: 2.71E-03\n",
      "Test  loss: 2.76E-03\n",
      "\n",
      " Epoch 262 \n",
      " --------------\n",
      "Train loss: 2.71E-03\n",
      "Test  loss: 2.76E-03\n",
      "\n",
      " Epoch 263 \n",
      " --------------\n",
      "Train loss: 2.71E-03\n",
      "Test  loss: 2.76E-03\n",
      "\n",
      " Epoch 264 \n",
      " --------------\n",
      "Train loss: 2.70E-03\n",
      "Test  loss: 2.75E-03\n",
      "\n",
      " Epoch 265 \n",
      " --------------\n",
      "Train loss: 2.70E-03\n",
      "Test  loss: 2.75E-03\n",
      "\n",
      " Epoch 266 \n",
      " --------------\n",
      "Train loss: 2.70E-03\n",
      "Test  loss: 2.75E-03\n",
      "\n",
      " Epoch 267 \n",
      " --------------\n",
      "Train loss: 2.69E-03\n",
      "Test  loss: 2.74E-03\n",
      "\n",
      " Epoch 268 \n",
      " --------------\n",
      "Train loss: 2.69E-03\n",
      "Test  loss: 2.74E-03\n",
      "\n",
      " Epoch 269 \n",
      " --------------\n",
      "Train loss: 2.68E-03\n",
      "Test  loss: 2.73E-03\n",
      "\n",
      " Epoch 270 \n",
      " --------------\n",
      "Train loss: 2.68E-03\n",
      "Test  loss: 2.73E-03\n",
      "\n",
      " Epoch 271 \n",
      " --------------\n",
      "Train loss: 2.68E-03\n",
      "Test  loss: 2.73E-03\n",
      "\n",
      " Epoch 272 \n",
      " --------------\n",
      "Train loss: 2.68E-03\n",
      "Test  loss: 2.73E-03\n",
      "\n",
      " Epoch 273 \n",
      " --------------\n",
      "Train loss: 2.68E-03\n",
      "Test  loss: 2.73E-03\n",
      "\n",
      " Epoch 274 \n",
      " --------------\n",
      "Train loss: 2.68E-03\n",
      "Test  loss: 2.73E-03\n",
      "\n",
      " Epoch 275 \n",
      " --------------\n",
      "Train loss: 2.67E-03\n",
      "Test  loss: 2.72E-03\n",
      "\n",
      " Epoch 276 \n",
      " --------------\n",
      "Train loss: 2.67E-03\n",
      "Test  loss: 2.72E-03\n",
      "\n",
      " Epoch 277 \n",
      " --------------\n",
      "Train loss: 2.67E-03\n",
      "Test  loss: 2.72E-03\n",
      "\n",
      " Epoch 278 \n",
      " --------------\n",
      "Train loss: 2.66E-03\n",
      "Test  loss: 2.72E-03\n",
      "\n",
      " Epoch 279 \n",
      " --------------\n",
      "Train loss: 2.66E-03\n",
      "Test  loss: 2.71E-03\n",
      "\n",
      " Epoch 280 \n",
      " --------------\n",
      "Train loss: 2.66E-03\n",
      "Test  loss: 2.71E-03\n",
      "\n",
      " Epoch 281 \n",
      " --------------\n",
      "Train loss: 2.66E-03\n",
      "Test  loss: 2.71E-03\n",
      "\n",
      " Epoch 282 \n",
      " --------------\n",
      "Train loss: 2.66E-03\n",
      "Test  loss: 2.71E-03\n",
      "\n",
      " Epoch 283 \n",
      " --------------\n",
      "Train loss: 2.66E-03\n",
      "Test  loss: 2.71E-03\n",
      "\n",
      " Epoch 284 \n",
      " --------------\n",
      "Train loss: 2.65E-03\n",
      "Test  loss: 2.71E-03\n",
      "\n",
      " Epoch 285 \n",
      " --------------\n",
      "Train loss: 2.65E-03\n",
      "Test  loss: 2.70E-03\n",
      "\n",
      " Epoch 286 \n",
      " --------------\n",
      "Train loss: 2.65E-03\n",
      "Test  loss: 2.70E-03\n",
      "\n",
      " Epoch 287 \n",
      " --------------\n",
      "Train loss: 2.65E-03\n",
      "Test  loss: 2.70E-03\n",
      "\n",
      " Epoch 288 \n",
      " --------------\n",
      "Train loss: 2.65E-03\n",
      "Test  loss: 2.70E-03\n",
      "\n",
      " Epoch 289 \n",
      " --------------\n",
      "Train loss: 2.65E-03\n",
      "Test  loss: 2.70E-03\n",
      "\n",
      " Epoch 290 \n",
      " --------------\n",
      "Train loss: 2.65E-03\n",
      "Test  loss: 2.70E-03\n",
      "\n",
      " Epoch 291 \n",
      " --------------\n",
      "Train loss: 2.65E-03\n",
      "Test  loss: 2.70E-03\n",
      "\n",
      " Epoch 292 \n",
      " --------------\n",
      "Train loss: 2.64E-03\n",
      "Test  loss: 2.70E-03\n",
      "\n",
      " Epoch 293 \n",
      " --------------\n",
      "Train loss: 2.64E-03\n",
      "Test  loss: 2.69E-03\n",
      "\n",
      " Epoch 294 \n",
      " --------------\n",
      "Train loss: 2.64E-03\n",
      "Test  loss: 2.69E-03\n",
      "\n",
      " Epoch 295 \n",
      " --------------\n",
      "Train loss: 2.64E-03\n",
      "Test  loss: 2.69E-03\n",
      "\n",
      " Epoch 296 \n",
      " --------------\n",
      "Train loss: 2.64E-03\n",
      "Test  loss: 2.69E-03\n",
      "\n",
      " Epoch 297 \n",
      " --------------\n",
      "Train loss: 2.64E-03\n",
      "Test  loss: 2.69E-03\n",
      "\n",
      " Epoch 298 \n",
      " --------------\n",
      "Train loss: 2.63E-03\n",
      "Test  loss: 2.69E-03\n",
      "\n",
      " Epoch 299 \n",
      " --------------\n",
      "Train loss: 2.63E-03\n",
      "Test  loss: 2.68E-03\n",
      "\n",
      " Epoch 300 \n",
      " --------------\n",
      "Train loss: 2.63E-03\n",
      "Test  loss: 2.68E-03\n",
      "\n",
      " Epoch 301 \n",
      " --------------\n",
      "Train loss: 2.63E-03\n",
      "Test  loss: 2.68E-03\n",
      "\n",
      " Epoch 302 \n",
      " --------------\n",
      "Train loss: 2.63E-03\n",
      "Test  loss: 2.68E-03\n",
      "\n",
      " Epoch 303 \n",
      " --------------\n",
      "Train loss: 2.62E-03\n",
      "Test  loss: 2.68E-03\n",
      "\n",
      " Epoch 304 \n",
      " --------------\n",
      "Train loss: 2.62E-03\n",
      "Test  loss: 2.68E-03\n",
      "\n",
      " Epoch 305 \n",
      " --------------\n",
      "Train loss: 2.62E-03\n",
      "Test  loss: 2.68E-03\n",
      "\n",
      " Epoch 306 \n",
      " --------------\n",
      "Train loss: 2.62E-03\n",
      "Test  loss: 2.67E-03\n",
      "\n",
      " Epoch 307 \n",
      " --------------\n",
      "Train loss: 2.62E-03\n",
      "Test  loss: 2.67E-03\n",
      "\n",
      " Epoch 308 \n",
      " --------------\n",
      "Train loss: 2.62E-03\n",
      "Test  loss: 2.67E-03\n",
      "\n",
      " Epoch 309 \n",
      " --------------\n",
      "Train loss: 2.62E-03\n",
      "Test  loss: 2.67E-03\n",
      "\n",
      " Epoch 310 \n",
      " --------------\n",
      "Train loss: 2.61E-03\n",
      "Test  loss: 2.67E-03\n",
      "\n",
      " Epoch 311 \n",
      " --------------\n",
      "Train loss: 2.61E-03\n",
      "Test  loss: 2.67E-03\n",
      "\n",
      " Epoch 312 \n",
      " --------------\n",
      "Train loss: 2.61E-03\n",
      "Test  loss: 2.67E-03\n",
      "\n",
      " Epoch 313 \n",
      " --------------\n",
      "Train loss: 2.61E-03\n",
      "Test  loss: 2.67E-03\n",
      "\n",
      " Epoch 314 \n",
      " --------------\n",
      "Train loss: 2.61E-03\n",
      "Test  loss: 2.66E-03\n",
      "\n",
      " Epoch 315 \n",
      " --------------\n",
      "Train loss: 2.61E-03\n",
      "Test  loss: 2.66E-03\n",
      "\n",
      " Epoch 316 \n",
      " --------------\n",
      "Train loss: 2.60E-03\n",
      "Test  loss: 2.66E-03\n",
      "\n",
      " Epoch 317 \n",
      " --------------\n",
      "Train loss: 2.58E-03\n",
      "Test  loss: 2.64E-03\n",
      "\n",
      " Epoch 318 \n",
      " --------------\n",
      "Train loss: 2.58E-03\n",
      "Test  loss: 2.64E-03\n",
      "\n",
      " Epoch 319 \n",
      " --------------\n",
      "Train loss: 2.58E-03\n",
      "Test  loss: 2.64E-03\n",
      "\n",
      " Epoch 320 \n",
      " --------------\n",
      "Train loss: 2.58E-03\n",
      "Test  loss: 2.63E-03\n",
      "\n",
      " Epoch 321 \n",
      " --------------\n",
      "Train loss: 2.58E-03\n",
      "Test  loss: 2.64E-03\n",
      "\n",
      " Epoch 322 \n",
      " --------------\n",
      "Train loss: 2.58E-03\n",
      "Test  loss: 2.63E-03\n",
      "\n",
      " Epoch 323 \n",
      " --------------\n",
      "Train loss: 2.58E-03\n",
      "Test  loss: 2.63E-03\n",
      "\n",
      " Epoch 324 \n",
      " --------------\n",
      "Train loss: 2.58E-03\n",
      "Test  loss: 2.63E-03\n",
      "\n",
      " Epoch 325 \n",
      " --------------\n",
      "Train loss: 2.57E-03\n",
      "Test  loss: 2.62E-03\n",
      "\n",
      " Epoch 326 \n",
      " --------------\n",
      "Train loss: 2.57E-03\n",
      "Test  loss: 2.63E-03\n",
      "\n",
      " Epoch 327 \n",
      " --------------\n",
      "Train loss: 2.57E-03\n",
      "Test  loss: 2.63E-03\n",
      "\n",
      " Epoch 328 \n",
      " --------------\n",
      "Train loss: 2.57E-03\n",
      "Test  loss: 2.63E-03\n",
      "\n",
      " Epoch 329 \n",
      " --------------\n",
      "Train loss: 2.57E-03\n",
      "Test  loss: 2.62E-03\n",
      "\n",
      " Epoch 330 \n",
      " --------------\n",
      "Adapting learning rate to 0.0003125\n",
      "Train loss: 2.57E-03\n",
      "Test  loss: 2.63E-03\n",
      "\n",
      " Epoch 331 \n",
      " --------------\n",
      "Train loss: 2.47E-03\n",
      "Test  loss: 2.52E-03\n",
      "\n",
      " Epoch 332 \n",
      " --------------\n",
      "Train loss: 2.47E-03\n",
      "Test  loss: 2.53E-03\n",
      "\n",
      " Epoch 333 \n",
      " --------------\n",
      "Train loss: 2.47E-03\n",
      "Test  loss: 2.52E-03\n",
      "\n",
      " Epoch 334 \n",
      " --------------\n",
      "Train loss: 2.47E-03\n",
      "Test  loss: 2.52E-03\n",
      "\n",
      " Epoch 335 \n",
      " --------------\n",
      "Train loss: 2.47E-03\n",
      "Test  loss: 2.52E-03\n",
      "\n",
      " Epoch 336 \n",
      " --------------\n",
      "Train loss: 2.47E-03\n",
      "Test  loss: 2.52E-03\n",
      "\n",
      " Epoch 337 \n",
      " --------------\n",
      "Train loss: 2.47E-03\n",
      "Test  loss: 2.52E-03\n",
      "\n",
      " Epoch 338 \n",
      " --------------\n",
      "Train loss: 2.47E-03\n",
      "Test  loss: 2.52E-03\n",
      "\n",
      " Epoch 339 \n",
      " --------------\n",
      "Train loss: 2.47E-03\n",
      "Test  loss: 2.52E-03\n",
      "\n",
      " Epoch 340 \n",
      " --------------\n",
      "Train loss: 2.47E-03\n",
      "Test  loss: 2.52E-03\n",
      "\n",
      " Epoch 341 \n",
      " --------------\n",
      "Train loss: 2.47E-03\n",
      "Test  loss: 2.52E-03\n",
      "\n",
      " Epoch 342 \n",
      " --------------\n",
      "Train loss: 2.47E-03\n",
      "Test  loss: 2.52E-03\n",
      "\n",
      " Epoch 343 \n",
      " --------------\n",
      "Train loss: 2.47E-03\n",
      "Test  loss: 2.52E-03\n",
      "\n",
      " Epoch 344 \n",
      " --------------\n",
      "Train loss: 2.47E-03\n",
      "Test  loss: 2.52E-03\n",
      "\n",
      " Epoch 345 \n",
      " --------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adapting learning rate to 0.00015625\n",
      "Train loss: 2.47E-03\n",
      "Test  loss: 2.52E-03\n",
      "\n",
      " Epoch 346 \n",
      " --------------\n",
      "Train loss: 2.48E-03\n",
      "Test  loss: 2.53E-03\n",
      "\n",
      " Epoch 347 \n",
      " --------------\n",
      "Train loss: 2.48E-03\n",
      "Test  loss: 2.53E-03\n",
      "\n",
      " Epoch 348 \n",
      " --------------\n",
      "Train loss: 2.48E-03\n",
      "Test  loss: 2.53E-03\n",
      "\n",
      " Epoch 349 \n",
      " --------------\n",
      "Train loss: 2.48E-03\n",
      "Test  loss: 2.53E-03\n",
      "\n",
      " Epoch 350 \n",
      " --------------\n",
      "Train loss: 2.48E-03\n",
      "Test  loss: 2.53E-03\n",
      "\n",
      " Epoch 351 \n",
      " --------------\n",
      "Train loss: 2.48E-03\n",
      "Test  loss: 2.53E-03\n",
      "\n",
      " Epoch 352 \n",
      " --------------\n",
      "Train loss: 2.48E-03\n",
      "Test  loss: 2.53E-03\n",
      "\n",
      " Epoch 353 \n",
      " --------------\n",
      "Train loss: 2.48E-03\n",
      "Test  loss: 2.53E-03\n",
      "\n",
      " Epoch 354 \n",
      " --------------\n",
      "Train loss: 2.48E-03\n",
      "Test  loss: 2.53E-03\n",
      "\n",
      " Epoch 355 \n",
      " --------------\n",
      "Train loss: 2.48E-03\n",
      "Test  loss: 2.53E-03\n",
      "\n",
      " Epoch 356 \n",
      " --------------\n",
      "Adapting learning rate to 7.8125e-05\n",
      "Train loss: 2.48E-03\n",
      "Test  loss: 2.53E-03\n",
      "\n",
      " Epoch 357 \n",
      " --------------\n",
      "Train loss: 2.39E-03\n",
      "Test  loss: 2.44E-03\n",
      "\n",
      " Epoch 358 \n",
      " --------------\n",
      "Train loss: 2.39E-03\n",
      "Test  loss: 2.44E-03\n",
      "\n",
      " Epoch 359 \n",
      " --------------\n",
      "Train loss: 2.39E-03\n",
      "Test  loss: 2.44E-03\n",
      "\n",
      " Epoch 360 \n",
      " --------------\n",
      "Train loss: 2.39E-03\n",
      "Test  loss: 2.44E-03\n",
      "\n",
      " Epoch 361 \n",
      " --------------\n",
      "Train loss: 2.39E-03\n",
      "Test  loss: 2.44E-03\n",
      "\n",
      " Epoch 362 \n",
      " --------------\n",
      "Train loss: 2.39E-03\n",
      "Test  loss: 2.44E-03\n",
      "\n",
      " Epoch 363 \n",
      " --------------\n",
      "Train loss: 2.39E-03\n",
      "Test  loss: 2.44E-03\n",
      "\n",
      " Epoch 364 \n",
      " --------------\n",
      "Train loss: 2.39E-03\n",
      "Test  loss: 2.44E-03\n",
      "\n",
      " Epoch 365 \n",
      " --------------\n",
      "Train loss: 2.39E-03\n",
      "Test  loss: 2.44E-03\n",
      "\n",
      " Epoch 366 \n",
      " --------------\n",
      "Train loss: 2.39E-03\n",
      "Test  loss: 2.44E-03\n",
      "\n",
      " Epoch 367 \n",
      " --------------\n",
      "Adapting learning rate to 3.90625e-05\n",
      "Train loss: 2.39E-03\n",
      "Test  loss: 2.44E-03\n",
      "\n",
      " Epoch 368 \n",
      " --------------\n",
      "Train loss: 2.36E-03\n",
      "Test  loss: 2.41E-03\n",
      "\n",
      " Epoch 369 \n",
      " --------------\n",
      "Train loss: 2.36E-03\n",
      "Test  loss: 2.41E-03\n",
      "\n",
      " Epoch 370 \n",
      " --------------\n",
      "Train loss: 2.36E-03\n",
      "Test  loss: 2.41E-03\n",
      "\n",
      " Epoch 371 \n",
      " --------------\n",
      "Train loss: 2.36E-03\n",
      "Test  loss: 2.41E-03\n",
      "\n",
      " Epoch 372 \n",
      " --------------\n",
      "Train loss: 2.36E-03\n",
      "Test  loss: 2.41E-03\n",
      "\n",
      " Epoch 373 \n",
      " --------------\n",
      "Train loss: 2.36E-03\n",
      "Test  loss: 2.41E-03\n",
      "\n",
      " Epoch 374 \n",
      " --------------\n",
      "Train loss: 2.36E-03\n",
      "Test  loss: 2.41E-03\n",
      "\n",
      " Epoch 375 \n",
      " --------------\n",
      "Train loss: 2.36E-03\n",
      "Test  loss: 2.41E-03\n",
      "\n",
      " Epoch 376 \n",
      " --------------\n",
      "Train loss: 2.36E-03\n",
      "Test  loss: 2.41E-03\n",
      "\n",
      " Epoch 377 \n",
      " --------------\n",
      "Train loss: 2.36E-03\n",
      "Test  loss: 2.41E-03\n",
      "\n",
      " Epoch 378 \n",
      " --------------\n",
      "Adapting learning rate to 1.953125e-05\n",
      "Train loss: 2.36E-03\n",
      "Test  loss: 2.41E-03\n",
      "\n",
      " Epoch 379 \n",
      " --------------\n",
      "Train loss: 2.35E-03\n",
      "Test  loss: 2.40E-03\n",
      "\n",
      " Epoch 380 \n",
      " --------------\n",
      "Train loss: 2.35E-03\n",
      "Test  loss: 2.40E-03\n",
      "\n",
      " Epoch 381 \n",
      " --------------\n",
      "Train loss: 2.35E-03\n",
      "Test  loss: 2.40E-03\n",
      "\n",
      " Epoch 382 \n",
      " --------------\n",
      "Train loss: 2.35E-03\n",
      "Test  loss: 2.40E-03\n",
      "\n",
      " Epoch 383 \n",
      " --------------\n",
      "Train loss: 2.35E-03\n",
      "Test  loss: 2.40E-03\n",
      "\n",
      " Epoch 384 \n",
      " --------------\n",
      "Train loss: 2.35E-03\n",
      "Test  loss: 2.40E-03\n",
      "\n",
      " Epoch 385 \n",
      " --------------\n",
      "Train loss: 2.35E-03\n",
      "Test  loss: 2.40E-03\n",
      "\n",
      " Epoch 386 \n",
      " --------------\n",
      "Train loss: 2.35E-03\n",
      "Test  loss: 2.40E-03\n",
      "\n",
      " Epoch 387 \n",
      " --------------\n",
      "Train loss: 2.35E-03\n",
      "Test  loss: 2.40E-03\n",
      "\n",
      " Epoch 388 \n",
      " --------------\n",
      "Train loss: 2.35E-03\n",
      "Test  loss: 2.40E-03\n",
      "\n",
      " Epoch 389 \n",
      " --------------\n",
      "Adapting learning rate to 9.765625e-06\n",
      "Train loss: 2.35E-03\n",
      "Test  loss: 2.40E-03\n",
      "\n",
      " Epoch 390 \n",
      " --------------\n",
      "Train loss: 2.34E-03\n",
      "Test  loss: 2.39E-03\n",
      "\n",
      " Epoch 391 \n",
      " --------------\n",
      "Train loss: 2.34E-03\n",
      "Test  loss: 2.39E-03\n",
      "\n",
      " Epoch 392 \n",
      " --------------\n",
      "Train loss: 2.34E-03\n",
      "Test  loss: 2.39E-03\n",
      "\n",
      " Epoch 393 \n",
      " --------------\n",
      "Train loss: 2.34E-03\n",
      "Test  loss: 2.39E-03\n",
      "\n",
      " Epoch 394 \n",
      " --------------\n",
      "Train loss: 2.34E-03\n",
      "Test  loss: 2.39E-03\n",
      "\n",
      " Epoch 395 \n",
      " --------------\n",
      "Train loss: 2.34E-03\n",
      "Test  loss: 2.39E-03\n",
      "\n",
      " Epoch 396 \n",
      " --------------\n",
      "Train loss: 2.34E-03\n",
      "Test  loss: 2.39E-03\n",
      "\n",
      " Epoch 397 \n",
      " --------------\n",
      "Train loss: 2.34E-03\n",
      "Test  loss: 2.39E-03\n",
      "\n",
      " Epoch 398 \n",
      " --------------\n",
      "Train loss: 2.34E-03\n",
      "Test  loss: 2.39E-03\n",
      "\n",
      " Epoch 399 \n",
      " --------------\n",
      "Train loss: 2.34E-03\n",
      "Test  loss: 2.39E-03\n",
      "\n",
      " Epoch 400 \n",
      " --------------\n",
      "Adapting learning rate to 4.8828125e-06\n",
      "Train loss: 2.34E-03\n",
      "Test  loss: 2.39E-03\n",
      "\n",
      " Epoch 401 \n",
      " --------------\n",
      "Train loss: 2.33E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 402 \n",
      " --------------\n",
      "Train loss: 2.33E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 403 \n",
      " --------------\n",
      "Train loss: 2.33E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 404 \n",
      " --------------\n",
      "Train loss: 2.33E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 405 \n",
      " --------------\n",
      "Train loss: 2.33E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 406 \n",
      " --------------\n",
      "Train loss: 2.33E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 407 \n",
      " --------------\n",
      "Train loss: 2.33E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 408 \n",
      " --------------\n",
      "Train loss: 2.33E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 409 \n",
      " --------------\n",
      "Train loss: 2.33E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 410 \n",
      " --------------\n",
      "Train loss: 2.33E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 411 \n",
      " --------------\n",
      "Adapting learning rate to 2.44140625e-06\n",
      "Train loss: 2.33E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 412 \n",
      " --------------\n",
      "Train loss: 2.33E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 413 \n",
      " --------------\n",
      "Train loss: 2.33E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 414 \n",
      " --------------\n",
      "Train loss: 2.33E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 415 \n",
      " --------------\n",
      "Train loss: 2.33E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 416 \n",
      " --------------\n",
      "Train loss: 2.33E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 417 \n",
      " --------------\n",
      "Train loss: 2.33E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 418 \n",
      " --------------\n",
      "Train loss: 2.33E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 419 \n",
      " --------------\n",
      "Train loss: 2.33E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 420 \n",
      " --------------\n",
      "Train loss: 2.33E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 421 \n",
      " --------------\n",
      "Train loss: 2.33E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 422 \n",
      " --------------\n",
      "Adapting learning rate to 1.220703125e-06\n",
      "Train loss: 2.33E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 423 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 424 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 425 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 426 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 427 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 428 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 429 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 430 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 431 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 432 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 433 \n",
      " --------------\n",
      "Adapting learning rate to 6.103515625e-07\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 434 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 435 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 436 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 437 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 438 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 439 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 440 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 441 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 442 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 443 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 444 \n",
      " --------------\n",
      "Adapting learning rate to 3.0517578125e-07\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 445 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 446 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 447 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 448 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 449 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 450 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 451 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 452 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 453 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 454 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 455 \n",
      " --------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adapting learning rate to 1.52587890625e-07\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 456 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 457 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 458 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 459 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 460 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 461 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 462 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 463 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 464 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 465 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 466 \n",
      " --------------\n",
      "Adapting learning rate to 7.62939453125e-08\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 467 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 468 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 469 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 470 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 471 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 472 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 473 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 474 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 475 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 476 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 477 \n",
      " --------------\n",
      "Adapting learning rate to 3.814697265625e-08\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 478 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 479 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 480 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 481 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 482 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 483 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 484 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 485 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 486 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 487 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 488 \n",
      " --------------\n",
      "Adapting learning rate to 1.9073486328125e-08\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 489 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 490 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 491 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 492 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 493 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 494 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 495 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 496 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 497 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 498 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 499 \n",
      " --------------\n",
      "Adapting learning rate to 9.5367431640625e-09\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 500 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 501 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 502 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 503 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 504 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 505 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 506 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 507 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 508 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 509 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 510 \n",
      " --------------\n",
      "Adapting learning rate to 4.76837158203125e-09\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 511 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 512 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 513 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 514 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 515 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 516 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 517 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 518 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 519 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 520 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 521 \n",
      " --------------\n",
      "Adapting learning rate to 2.384185791015625e-09\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 522 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 523 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 524 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 525 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 526 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 527 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 528 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 529 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 530 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 531 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 532 \n",
      " --------------\n",
      "Adapting learning rate to 1.1920928955078125e-09\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 533 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 534 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 535 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 536 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 537 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 538 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 539 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 540 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 541 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 542 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 543 \n",
      " --------------\n",
      "Adapting learning rate to 5.960464477539063e-10\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 544 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 545 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 546 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 547 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 548 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 549 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 550 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 551 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 552 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 553 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 554 \n",
      " --------------\n",
      "Adapting learning rate to 2.9802322387695313e-10\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 555 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 556 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 557 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 558 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 559 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 560 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 561 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 562 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 563 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 564 \n",
      " --------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 565 \n",
      " --------------\n",
      "Adapting learning rate to 1.4901161193847657e-10\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 566 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 567 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 568 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 569 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 570 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 571 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 572 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 573 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 574 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 575 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 576 \n",
      " --------------\n",
      "Adapting learning rate to 7.450580596923828e-11\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 577 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 578 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 579 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 580 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 581 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 582 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 583 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 584 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 585 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 586 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 587 \n",
      " --------------\n",
      "Adapting learning rate to 3.725290298461914e-11\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 588 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 589 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 590 \n",
      " --------------\n",
      "Train loss: 2.32E-03\n",
      "Test  loss: 2.38E-03\n",
      "\n",
      " Epoch 591 \n",
      " --------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[231], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumber_of_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Coding\\master-thesis-AI\\Code\\nnc2p.py:460\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, adaptation_threshold, adaptation_multiplier, number_of_epochs, log_file, csv_file)\u001b[0m\n\u001b[0;32m    458\u001b[0m write_to_txt(log_file, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_counter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m --------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    459\u001b[0m \u001b[38;5;66;03m# Train the network\u001b[39;00m\n\u001b[1;32m--> 460\u001b[0m \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_c2p_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse_c2p_loss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;66;03m# Test on the training data\u001b[39;00m\n\u001b[0;32m    462\u001b[0m average_train_loss \u001b[38;5;241m=\u001b[39m test_loop(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_dataloader, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn)\n",
      "File \u001b[1;32mD:\\Coding\\master-thesis-AI\\Code\\nnc2p.py:340\u001b[0m, in \u001b[0;36mtrain_loop\u001b[1;34m(dataloader, model, loss_fn, optimizer, report_progress, use_c2p_loss)\u001b[0m\n\u001b[0;32m    338\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m    339\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m--> 340\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;66;03m# If we want to report progress during training (not recommended - obstructs view)\u001b[39;00m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m report_progress:\n",
      "File \u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\optim\\optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[1;32m--> 140\u001b[0m     out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\optim\\optimizer.py:23\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     22\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 23\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     25\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\optim\\adam.py:234\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[0;32m    231\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`requires_grad` is not supported for `step` in differentiable mode\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    232\u001b[0m             state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m--> 234\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m         \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[43m         \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[43m         \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[43m         \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[43m         \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[43m         \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[43m         \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[43m         \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[43m         \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[43m         \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[43m         \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m         \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\optim\\adam.py:300\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    298\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 300\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    303\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    304\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    305\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    306\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    307\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    308\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    309\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\optim\\adam.py:364\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m    363\u001b[0m exp_avg\u001b[38;5;241m.\u001b[39mmul_(beta1)\u001b[38;5;241m.\u001b[39madd_(grad, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1)\n\u001b[1;32m--> 364\u001b[0m \u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad\u001b[38;5;241m.\u001b[39mconj(), value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n\u001b[0;32m    367\u001b[0m     step \u001b[38;5;241m=\u001b[39m step_t\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train(number_of_epochs = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3c43ab",
   "metadata": {},
   "source": [
    "Save architecture if desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "14b5c04f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Thibeau\\\\master-thesis-AI\\\\Code'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "8a8d4f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, \"../Models/taboes_3_20_20_3_relu.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "90934c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory not found. Making new one at ../Models/paramvals_tabeos_final_20_relu\n",
      "Succesfully exported model parameters to CSV file, at ../Models/paramvals_tabeos_final_20_relu\n"
     ]
    }
   ],
   "source": [
    "# nnc2p.export_model(\"../Models/taboes_3_20_20_3_relu.pt\", \"../Models/paramvals_tabeos_final_20_relu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ce4a3f",
   "metadata": {},
   "source": [
    "Report architecture (this saves info to a CSV, such as hidden layer set-up, nb of epochs trained, loss after training,... in order to compare performances across different architecture details)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "241c2422",
   "metadata": {
    "id": "2f3a92f7"
   },
   "outputs": [],
   "source": [
    "# trainer.report_training(\"NNEOS_tab_experiments.csv\", comment = \"logeps, logpress and log cs2.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631d0405",
   "metadata": {
    "id": "296ab01e"
   },
   "source": [
    "Create a quick sketch of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1318bb00",
   "metadata": {
    "id": "f8056faf"
   },
   "outputs": [],
   "source": [
    "# plt.plot(trainer.train_losses, color='red', label=\"Train loss\")\n",
    "# plt.plot(trainer.test_losses, color='blue', label=\"Test loss\")\n",
    "\n",
    "# plt.grid()\n",
    "# plt.legend()\n",
    "# for ind in trainer.adaptation_indices:\n",
    "#     plt.axvline(ind, ls = '--', color='grey')\n",
    "# plt.yscale('log')\n",
    "# plt.xlabel(\"Epochs\")\n",
    "# plt.ylabel(\"MSE Loss\")\n",
    "# plt.title(\"Training (50, 50) network tabular EOS for p and eps\")\n",
    "# plt.savefig(\"testing_training_tab_eos_network_50_50.pdf\", bbox_inches = 'tight')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2980397a",
   "metadata": {},
   "source": [
    "### Load model after training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a6b6ba",
   "metadata": {},
   "source": [
    "In case we have an already trained model, load it here. We have a network in `nn_tabeos_3_50_50_3.pth` (its state dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bf5a333b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# state_dict = torch.load(\"nn_tabeos_3_50_50_3.pth\")\n",
    "# model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948b09d6",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfcb69a",
   "metadata": {},
   "source": [
    "Get the errors on the different outputs, for different norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "616847c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb175c1",
   "metadata": {},
   "source": [
    "We will analyze the performance of the code in its accuracy as a function of the different domains. We fix the $Y_e$ value, and look at the error rates (absolute values) on the three as a function of log T and log rho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "c8107562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix a ye value here, can severely affect the results?\n",
    "ye_index = len(ye) // 2\n",
    "ye_value = ye[ye_index]\n",
    "# Get the ranges\n",
    "n_logrho, n_logtemp = targets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfef7433",
   "metadata": {},
   "source": [
    "Prepare the values to determine the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "de15bc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the values at this ye index: these are the \"targets\"\n",
    "targets = logenergy[ye_index]\n",
    "targets = np.swapaxes(targets, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320f0256",
   "metadata": {},
   "source": [
    "Get the input values right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "174d4c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_values = []\n",
    "for logtemp_value in logtemp:\n",
    "    for logrho_value in logrho:\n",
    "        new_row = [logrho_value, logtemp_value, ye_value]\n",
    "        input_values.append(new_row)\n",
    "input_values = np.array(input_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ba8840",
   "metadata": {},
   "source": [
    "Scaler transform & to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d05067c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_values = scaler.transform(input_values)\n",
    "input_values = torch.from_numpy(input_values).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "d8cd8238",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    predictions = model(input_values)\n",
    "    predictions = predictions.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "bc0bf9f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19.290712, 18.032537, 35.008884],\n",
       "       [19.291523, 18.063354, 35.008648],\n",
       "       [19.292202, 18.09436 , 35.008568],\n",
       "       ...,\n",
       "       [21.827118, 37.9868  , 48.73516 ],\n",
       "       [21.876057, 38.07058 , 48.745255],\n",
       "       [21.923769, 38.151787, 48.754364]], dtype=float32)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a12dfa",
   "metadata": {},
   "source": [
    "## Load and export model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e9ef41",
   "metadata": {},
   "source": [
    "If desired, save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7f5344f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, \"nn_tabeos_3_50_50_3.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbaefc43",
   "metadata": {},
   "source": [
    "If desired, load the original architecture (`tabular_eos_14_04.pth` contains for h = 50, 100, 20). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "84a8d614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = Net(nb_of_inputs=3, nb_of_outputs=3, h=[50, 50]).float()\n",
    "# # Load the state dict\n",
    "# state_dict = torch.load(\"nn_tabeos_3_50_50_3.pth\") \n",
    "# # Convert everything to floats rather than doubles\n",
    "# for key in state_dict:\n",
    "#     state_dict[key] = state_dict[key].float()\n",
    "# model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fef6616",
   "metadata": {},
   "source": [
    "# Speed and timing tests: NN vs trilinear interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751ad8d9",
   "metadata": {},
   "source": [
    "## Compare performance against trilinear interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "be6b1508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logcs2 = np.log(cs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a8b5739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sample features and their labels\n",
    "# n_samples = 10000\n",
    "# sample_ind = np.random.choice(len(features), size=min(len(features), n_samples), replace=False)\n",
    "# sample_features = features[sample_ind]\n",
    "# sample_labels = labels[sample_ind]\n",
    "# # Get predictions\n",
    "# with torch.no_grad():\n",
    "#     # Don't forget to apply normalization!!! We fixed the random seed for reproducibility\n",
    "#     sample_features = scaler.transform(sample_features)\n",
    "#     predictions = model(torch.from_numpy(sample_features).float())\n",
    "#     predictions = predictions.numpy()\n",
    "    \n",
    "# # print(sample_labels[0])\n",
    "# # print(predictions[0])\n",
    "# print(\"L2       difference on sample: \", nnc2p.l2_norm(sample_labels, predictions))\n",
    "# # print(nnc2p.l1_norm(sample_labels, predictions))\n",
    "# print(\"Linfty difference on sample: \",nnc2p.linfty_norm(sample_labels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617ca2f7",
   "metadata": {},
   "source": [
    "Don't forget normalization (note: we can export the normalization procedure later on by saving the mean and std)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1f1060b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: [ 9.51608373 -0.30081866  0.32936217], std: [3.76043372 1.56992791 0.19028245]\n"
     ]
    }
   ],
   "source": [
    "# print(f\"Mean: {scaler.mean_}, std: {scaler.scale_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3438e32b",
   "metadata": {},
   "source": [
    "## Compare network with trilinear interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040e1408",
   "metadata": {},
   "source": [
    "We use scipy for the interpolation: see [this docs page](https://docs.scipy.org/doc/scipy/reference/generated/scipy.interpolate.interpn.html#scipy.interpolate.interpn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4eaa66fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interpn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c7d3e7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomn(a, b):\n",
    "    \"\"\"Generate a random number in the range [a, b]\"\"\"\n",
    "    \n",
    "    return a + (b-a)*np.random.rand()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c041a544",
   "metadata": {},
   "source": [
    "We define our own trilinear interpolation routine based on scipy to replicate having to to interpn three times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f009fd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trilinear_interpolation(points, values_list, test_points):\n",
    "    \"\"\"\n",
    "    Does a single prediction using trilinear interpolation.\n",
    "    \"\"\"\n",
    "    # Make the predictions\n",
    "    predictions = np.zeros((len(test_points), len(values_list)))\n",
    "    for i in range(len(values_list)):\n",
    "        predictions[:, i] = interpn(points, values_list[i], test_points)\n",
    "    # Return transpose: shape is (n_samples, n_vars) similar to neural network\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0805f55e",
   "metadata": {},
   "source": [
    "For the grid points, we reverse the order compared to the EOS table. That is, the EOS table uses (ye, logtemp, logrho), but we will use (logrho, logtemp, ye)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b22ff32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(391, 163, 66)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thibe\\AppData\\Local\\Temp\\ipykernel_8344\\1402824072.py:3: RuntimeWarning: invalid value encountered in log\n",
      "  logcs2_reversed = np.swapaxes(np.log(cs2), 0, 2)\n"
     ]
    }
   ],
   "source": [
    "logpress_reversed = np.swapaxes(logpress, 0, 2)\n",
    "logenergy_reversed = np.swapaxes(logenergy, 0, 2)\n",
    "logcs2_reversed = np.swapaxes(np.log(cs2), 0, 2)\n",
    "print(logpress_reversed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "24facc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_eos(logrho, logtemp, ye, n_examples = 1):\n",
    "    \"\"\"\n",
    "    Simple auxiliary function that returns a random input data point for an EOS table, based on its (logrho, logtemp, ye) values.\n",
    "    \"\"\"\n",
    "    \n",
    "    return np.stack([[randomn(min(logrho), max(logrho)), randomn(min(logtemp), max(logtemp)), randomn(min(ye), max(ye))] for _ in range(n_examples)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0b48f682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get an array of test cases:\n",
    "n_examples = 10000\n",
    "test_points = sample_eos(logrho, logtemp, ye, n_examples=n_examples)\n",
    "# Grid of tables\n",
    "points = (logrho, logtemp, ye)\n",
    "# Variables we wish to get\n",
    "values_list = [logenergy_reversed, logpress_reversed, logcs2_reversed]\n",
    "# Interpolation\n",
    "interpolated = trilinear_interpolation(points, values_list, test_points)\n",
    "# print(interpolated)  # print in case n_examples is low\n",
    "# Compare with neural net\n",
    "with torch.no_grad():\n",
    "    # Don't forget normalization!!!\n",
    "    test_points_n = scaler.transform(test_points)\n",
    "    model = model.float()\n",
    "    predictions = model(torch.from_numpy(test_points_n).float())\n",
    "    predictions = predictions.numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6165a0d3",
   "metadata": {},
   "source": [
    "Now get error rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "51b66e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_error, l2_error, linfty_error = nnc2p.l1_norm(interpolated, predictions), nnc2p.l2_norm(interpolated, predictions), nnc2p.linfty_norm(interpolated, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "48ee6869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00565407 0.0081235  0.01305064]\n",
      "[5.65448465e-05 1.19128211e-04 7.66002332e-04]\n",
      "[0.05040054 0.08126448 0.99801589]\n"
     ]
    }
   ],
   "source": [
    "print(l1_error)\n",
    "print(l2_error)\n",
    "print(linfty_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ccc391",
   "metadata": {},
   "source": [
    "## Compare performance of methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e72317",
   "metadata": {},
   "source": [
    "Here, we will try to compare the performance of the methods, by measuring the time they take (CPU time) through `timeit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1d6f2327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get a single point that has to be predicted\n",
    "test_point = sample_eos(logrho, logtemp, ye)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02146ac",
   "metadata": {},
   "source": [
    "Choose the number of runs and number of loops within each run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dba98145",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 10\n",
    "n_loops = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "96877c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_execution(func, n_runs=10, n_loops=10000, verbose=True):\n",
    "    # Save all the runtimes\n",
    "    runtimes = []\n",
    "    for _ in range(n_runs):\n",
    "        # Start timer each run\n",
    "        start = time.process_time_ns()\n",
    "        for _ in range(n_loops):\n",
    "            func()\n",
    "        end = time.process_time_ns()\n",
    "        # Convert to micro seconds and get average for one loop\n",
    "        time_run = (end-start)/1000\n",
    "        time_loop = time_run/n_loops\n",
    "        runtimes.append(time_loop)\n",
    "    \n",
    "    # Convert to mean adn std\n",
    "    mu, sigma = np.mean(runtimes), np.std(runtimes)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"{mu} \\pm {sigma} per loop ({n_runs} runs, {n_loops} each)\")\n",
    "    \n",
    "    return mu, sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3266a43e",
   "metadata": {},
   "source": [
    "### Trilinear interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77be19ac",
   "metadata": {},
   "source": [
    "Performance of trilinear interpolation with Scipy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6da37954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which values to predict?\n",
    "values_list = [logenergy_reversed]\n",
    "# single value:\n",
    "val = logenergy_reversed\n",
    "def function_interpn():\n",
    "    [interpn(points, val, test_point) for val in values_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2210bea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %timeit -r10 -n10000 interpn(points, logenergy_reversed, test_point)  # measure Scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57960034",
   "metadata": {},
   "source": [
    "### Neural network (using PyTorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d75e58d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 10\n",
    "act_func = torch.nn.ReLU\n",
    "model = Net(nb_of_inputs=3, nb_of_outputs=3, h=[hidden_size, hidden_size], activation_function=act_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa6d74c",
   "metadata": {},
   "source": [
    "Performance of running the network with PyTorch built-ins: first convert point to right format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "53c473f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_point_n = scaler.transform(test_point)\n",
    "test_point_torch = torch.from_numpy(test_point_n).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f700b984",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_pytorch():\n",
    "    model(test_point_torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d903553",
   "metadata": {},
   "source": [
    "### Neural network (using PyTorch, no grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f7dc09",
   "metadata": {},
   "source": [
    "It might be that saving the gradients etc in PyTorch can slow down the inference: check performance with grads disabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "69bb21dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_pytorch_no_grad():\n",
    "    with torch.no_grad():\n",
    "        model(test_point_torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7320f22f",
   "metadata": {},
   "source": [
    "### Neural network (using ONNX Runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "eab43d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def function4():\n",
    "#     ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(x)}\n",
    "#     ort_outs = ort_session.run(None, ort_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7dbd218",
   "metadata": {},
   "source": [
    "### Neural network (using Numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7476d3d2",
   "metadata": {},
   "source": [
    "Other comparison: the neural network but just the matrices and using Numpy! Save everything externally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5552111b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_point_np = test_point_n[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e39a3e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7ce3a3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(x, 0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "dd1d0e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_nn_sigmoid(x):\n",
    "    x = np.matmul(w1, x) + b1\n",
    "    x = sigmoid(x)\n",
    "    x = np.matmul(w2, x) + b2\n",
    "    x = sigmoid(x)\n",
    "    x = np.matmul(w3, x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bf25ad1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_nn_relu(x):\n",
    "    x = np.matmul(w1, x) + b1\n",
    "    x = relu(x)\n",
    "    x = np.matmul(w2, x) + b2\n",
    "    x = relu(x)\n",
    "    x = np.matmul(w3, x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "814df05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check if we get the same results -- OK\n",
    "# print(test_point)\n",
    "# test1 = run_nn(test_point[0])\n",
    "# print(test1)\n",
    "# with torch.no_grad():\n",
    "#     test2 = model(torch.from_numpy(test_point[0]).float())\n",
    "#     test2 = test2.numpy()\n",
    "# print(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c87285fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_numpy_sigmoid():\n",
    "    run_nn_sigmoid(test_point_np)\n",
    "def function_numpy_relu():\n",
    "    run_nn_relu(test_point_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e70883",
   "metadata": {},
   "source": [
    "### Python (no packages) -- DEPRECATED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c826585c",
   "metadata": {},
   "source": [
    "Convert everything to lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "916ba2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5463538641652405], [0.09203259199418481], [-1.280980106027008]]\n"
     ]
    }
   ],
   "source": [
    "# test_point_list = test_point_np.tolist()\n",
    "# test_point_list = [[val] for val in test_point_list]\n",
    "# print(test_point_list)\n",
    "# w1_list = w1.tolist()\n",
    "# # b1_list = b1.tolist()\n",
    "# b1_list = [[b1[i]] for i in range(len(b1))]\n",
    "# # b1_list = [b1_list]\n",
    "# w2_list = w2.tolist()\n",
    "# b2_list = [[b2[i]] for i in range(len(b2))]\n",
    "# w3_list = w3.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4f1ef8",
   "metadata": {},
   "source": [
    "Get sigmoid function without numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "ff76dfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sigmoid_list(x):\n",
    "#     return [[1/(1+2.71828182845904523536028747135266249**(-x[i][0]))] for i in range(len(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "4d6b49e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mm(A, B):\n",
    "#     \"\"\"Matrix multiplication, pure Python\"\"\"\n",
    "#     return [[sum(a*b for a,b in zip(A_row, B_col)) for B_col in zip(*B)] for A_row in A]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "0daf7f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2], [4], [6]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[2.731058578630005], [4.880797077977882], [6.952574126822433]]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a = [[2, 0, 0], [0, 2, 0], [0, 0, 2]]\n",
    "# b = [[1],[2],[3]]\n",
    "# first = mm(a,b)\n",
    "# print(first)\n",
    "# second = sigmoid_list(b)\n",
    "# [[first[i][0] + second[i][0]] for i in range(len(first))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "46596592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_nn_list(x):\n",
    "#     x = mm(w1_list, x)\n",
    "#     x = [[x[i][0] + b1_list[i][0]] for i in range(len(x))]\n",
    "#     x = sigmoid_list(x)\n",
    "#     x = mm(w2_list, x)\n",
    "#     x = [[x[i][0] + b2_list[i][0]] for i in range(len(x))]\n",
    "#     x = sigmoid_list(x)\n",
    "#     x = mm(w3_list, x)\n",
    "    \n",
    "#     return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f01dc3",
   "metadata": {},
   "source": [
    "The shape is slightly different, but this is good enough!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "bfee6f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19.28380190064578], [29.502848125783046], [41.66890742358023]]\n",
      "[[19.283802 29.50285  41.668907]]\n"
     ]
    }
   ],
   "source": [
    "# # Check if we get the same results -- OK\n",
    "# test1 = run_nn_list(test_point_list)\n",
    "# print(test1)\n",
    "# with torch.no_grad():\n",
    "#     test2 = model(test_point_torch)\n",
    "#     test2 = test2.numpy()\n",
    "# print(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "432f3553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def function6():\n",
    "#     run_nn_list(test_point_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a5abb1",
   "metadata": {},
   "source": [
    "## Perform the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e2101dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define new model and take care of it\n",
    "hidden_size = 10\n",
    "act_func = torch.nn.ReLU\n",
    "model = Net(nb_of_inputs=3, nb_of_outputs=3, h=[hidden_size, hidden_size], activation_function=act_func)\n",
    "\n",
    "w1 = model.state_dict()[\"linear1.weight\"].numpy()\n",
    "b1 = model.state_dict()[\"linear1.bias\"].numpy()\n",
    "w2 = model.state_dict()[\"linear2.weight\"].numpy()\n",
    "b2 = model.state_dict()[\"linear2.bias\"].numpy()\n",
    "w3 = model.state_dict()[\"linear3.weight\"].numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dea986",
   "metadata": {},
   "source": [
    "__Do the runtime analysis__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "643e25e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Interpolation ---\n",
      "251.09375 \\pm 5.9313290300319705 per loop (10 runs, 10000 each)\n",
      "--- PyTorch ---\n",
      "104.0625 \\pm 3.9031237489989987 per loop (10 runs, 10000 each)\n",
      "--- PyTorch (no grad) ---\n",
      "53.4375 \\pm 10.265042316035526 per loop (10 runs, 10000 each)\n",
      "--- Numpy ---\n",
      "10.78125 \\pm 3.3838137230793306 per loop (10 runs, 10000 each)\n"
     ]
    }
   ],
   "source": [
    "# Empty lists\n",
    "mu_list, sigma_list = [], []\n",
    "# Functions & names for runtime analysis\n",
    "funcs = [function_interpn, function_pytorch, function_pytorch_no_grad, function_numpy] # \n",
    "method_names = [\"Interpolation\", \"PyTorch\", \"PyTorch (no grad)\", \"Numpy\"] # \n",
    "for i, func in enumerate(funcs):\n",
    "    print(f\"--- {method_names[i]} ---\")\n",
    "    mu, sigma = time_execution(func)\n",
    "    mu_list.append(mu)\n",
    "    sigma_list.append(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ffc19f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best neural net implementation is around 23x faster.\n"
     ]
    }
   ],
   "source": [
    "speedup = round(mu_list[0]/mu_list[-1])\n",
    "print(f\"Best neural net implementation is around {speedup}x faster.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dedea2b",
   "metadata": {},
   "source": [
    "## Performance for NN architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "67b5c6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden size: 10. Act func: <class 'torch.nn.modules.activation.ReLU'>\n",
      "ReLU\n",
      "--- PyTorch ---\n",
      "99.84375 \\pm 5.387793640489583 per loop (10 runs, 10000 each)\n",
      "--- PyTorch (no grad) ---\n",
      "69.21875 \\pm 3.2059819576067485 per loop (10 runs, 10000 each)\n",
      "--- Numpy ---\n",
      "18.28125 \\pm 1.0004881620988826 per loop (10 runs, 10000 each)\n",
      "Hidden size: 10. Act func: <class 'torch.nn.modules.activation.Sigmoid'>\n",
      "Sigmoid\n",
      "--- PyTorch ---\n",
      "96.25 \\pm 2.724311839712921 per loop (10 runs, 10000 each)\n",
      "--- PyTorch (no grad) ---\n",
      "66.71875 \\pm 3.0498783274911148 per loop (10 runs, 10000 each)\n",
      "--- Numpy ---\n",
      "17.96875 \\pm 1.4405538214520137 per loop (10 runs, 10000 each)\n",
      "Hidden size: 20. Act func: <class 'torch.nn.modules.activation.ReLU'>\n",
      "ReLU\n",
      "--- PyTorch ---\n",
      "105.78125 \\pm 3.6342822967540647 per loop (10 runs, 10000 each)\n",
      "--- PyTorch (no grad) ---\n",
      "72.03125 \\pm 3.5251606789620245 per loop (10 runs, 10000 each)\n",
      "--- Numpy ---\n",
      "18.125 \\pm 1.0364452469860626 per loop (10 runs, 10000 each)\n",
      "Hidden size: 20. Act func: <class 'torch.nn.modules.activation.Sigmoid'>\n",
      "Sigmoid\n",
      "--- PyTorch ---\n",
      "103.90625 \\pm 3.2960973608951543 per loop (10 runs, 10000 each)\n",
      "--- PyTorch (no grad) ---\n",
      "67.65625 \\pm 3.28125 per loop (10 runs, 10000 each)\n",
      "--- Numpy ---\n",
      "17.65625 \\pm 2.71083618326523 per loop (10 runs, 10000 each)\n",
      "Hidden size: 50. Act func: <class 'torch.nn.modules.activation.ReLU'>\n",
      "ReLU\n",
      "--- PyTorch ---\n",
      "101.5625 \\pm 3.3511891546136274 per loop (10 runs, 10000 each)\n",
      "--- PyTorch (no grad) ---\n",
      "71.5625 \\pm 2.1875 per loop (10 runs, 10000 each)\n",
      "--- Numpy ---\n",
      "22.03125 \\pm 1.09375 per loop (10 runs, 10000 each)\n",
      "Hidden size: 50. Act func: <class 'torch.nn.modules.activation.Sigmoid'>\n",
      "Sigmoid\n",
      "--- PyTorch ---\n",
      "101.875 \\pm 4.980430453284134 per loop (10 runs, 10000 each)\n",
      "--- PyTorch (no grad) ---\n",
      "69.84375 \\pm 1.8553659510996745 per loop (10 runs, 10000 each)\n",
      "--- Numpy ---\n",
      "22.8125 \\pm 1.0364452469860626 per loop (10 runs, 10000 each)\n"
     ]
    }
   ],
   "source": [
    "hidden_size_list = [10, 20, 50]\n",
    "act_func_list = [torch.nn.ReLU, torch.nn.Sigmoid]\n",
    "\n",
    "mu_dict = {\"Hidden size\": [], \"Act func\": [], \"Method\": [], \"Result\": []}\n",
    "sigma_dict = {\"Hidden size\": [], \"Act func\": [], \"Method\": [], \"Result\": []}\n",
    "funcs = [function_pytorch, function_pytorch_no_grad, function_numpy]\n",
    "\n",
    "for hidden_size in hidden_size_list:\n",
    "    for act_func in act_func_list:\n",
    "        # Define new model and take care of it\n",
    "        print(f\"Hidden size: {hidden_size}. Act func: {act_func}\")\n",
    "        if act_func == torch.nn.Sigmoid:\n",
    "            act_func_name = \"Sigmoid\"\n",
    "            print(act_func_name)\n",
    "            function_numpy = function_numpy_sigmoid\n",
    "        else:\n",
    "            act_func_name = \"ReLU\"\n",
    "            print(act_func_name)\n",
    "            function_numpy = function_numpy_relu\n",
    "        # Define the model\n",
    "        model = Net(nb_of_inputs=3, nb_of_outputs=3, h=[hidden_size, hidden_size], activation_function=act_func)\n",
    "        # Get the matrices, for the numpy implementation\n",
    "        w1 = model.state_dict()[\"linear1.weight\"].numpy()\n",
    "        b1 = model.state_dict()[\"linear1.bias\"].numpy()\n",
    "        w2 = model.state_dict()[\"linear2.weight\"].numpy()\n",
    "        b2 = model.state_dict()[\"linear2.bias\"].numpy()\n",
    "        w3 = model.state_dict()[\"linear3.weight\"].numpy()\n",
    "        # Functions & names for runtime analysis\n",
    "        \n",
    "        method_names = [\"PyTorch\", \"PyTorch (no grad)\", \"Numpy\"] # \n",
    "        for i, func in enumerate(funcs):\n",
    "            print(f\"--- {method_names[i]} ---\")\n",
    "            mu, sigma = time_execution(func)\n",
    "            # Append everything\n",
    "            mu_dict[\"Hidden size\"].append(hidden_size)\n",
    "            mu_dict[\"Act func\"].append(act_func_name)\n",
    "            mu_dict[\"Method\"].append(method_names[i])\n",
    "            mu_dict[\"Result\"].append(mu)\n",
    "            sigma_dict[\"Hidden size\"].append(hidden_size)\n",
    "            sigma_dict[\"Act func\"].append(act_func_name)\n",
    "            sigma_dict[\"Method\"].append(method_names[i])\n",
    "            sigma_dict[\"Result\"].append(sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95368896",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "78e080e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9476d2f0",
   "metadata": {},
   "source": [
    "Comparison of hidden sizes and activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f6b6644a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1100x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select which inference method to check\n",
    "choice = \"Numpy\"\n",
    "\n",
    "# Load data\n",
    "mu_df = pd.DataFrame.from_dict(mu_dict)\n",
    "sigma_df = pd.DataFrame.from_dict(sigma_dict)\n",
    "# Limit to one choice\n",
    "mu_df = mu_df[mu_df[\"Method\"] == choice]\n",
    "sigma_df = sigma_df[sigma_df[\"Method\"] == choice]\n",
    "# Get vals\n",
    "hidden_size_list = np.unique(mu_df[\"Hidden size\"].values)\n",
    "\n",
    "plt.figure(figsize = (11,3))\n",
    "names = [\"Sigmoid\", \"ReLU\"]\n",
    "colors = [\"blue\", \"red\"]\n",
    "for i, name in enumerate(names):\n",
    "    y = mu_df[mu_df[\"Act func\"] == name][\"Result\"]\n",
    "    yerr = sigma_df[sigma_df[\"Act func\"] == name][\"Result\"]\n",
    "    plt.errorbar(hidden_size_list, y, yerr = yerr, fmt = '-o', color=colors[i], capsize=5, label = name)\n",
    "plt.legend(fontsize=fs-3)\n",
    "plt.grid()\n",
    "plt.xlabel(r\"Hidden layer size\", fontsize=fs)\n",
    "plt.ylabel(r\"Time/prediction ($\\mu s$)\", fontsize=fs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b11a53",
   "metadata": {},
   "source": [
    "Comparison of different methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "df9b298e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Result</th>\n",
       "      <th>Sigma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PyTorch</td>\n",
       "      <td>105.78125</td>\n",
       "      <td>3.634282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PyTorch (no grad)</td>\n",
       "      <td>72.03125</td>\n",
       "      <td>3.525161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Numpy</td>\n",
       "      <td>18.12500</td>\n",
       "      <td>1.036445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Method     Result     Sigma\n",
       "6            PyTorch  105.78125  3.634282\n",
       "7  PyTorch (no grad)   72.03125  3.525161\n",
       "8              Numpy   18.12500  1.036445"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_df    = pd.DataFrame.from_dict(mu_dict)\n",
    "sigma_df = pd.DataFrame.from_dict(sigma_dict)\n",
    "# Limit to one choice\n",
    "act_func = \"ReLU\"\n",
    "hidden = 20\n",
    "mu_df = mu_df[((mu_df[\"Act func\"] == act_func) & (mu_df[\"Hidden size\"] == hidden))]\n",
    "sigma_df = sigma_df[((sigma_df[\"Act func\"] == act_func) & (sigma_df[\"Hidden size\"] == hidden))]\n",
    "mu_df[\"Sigma\"] = sigma_df[\"Result\"]\n",
    "mu_df.drop([\"Hidden size\", \"Act func\"], axis=1, inplace=True)\n",
    "mu_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "45634fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrr}\n",
      "\\toprule\n",
      "{} &             Method &     Result &     Sigma \\\\\n",
      "\\midrule\n",
      "6 &            PyTorch &  105.78125 &  3.634282 \\\\\n",
      "7 &  PyTorch (no grad) &   72.03125 &  3.525161 \\\\\n",
      "8 &              Numpy &   18.12500 &  1.036445 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thibe\\AppData\\Local\\Temp\\ipykernel_8344\\1619524569.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(mu_df.to_latex())\n"
     ]
    }
   ],
   "source": [
    "print(mu_df.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642fbcd0",
   "metadata": {},
   "source": [
    "Interpolation was: 251.09 \\pm 5.93"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "eddb983d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/cAAAEaCAYAAABUw6e6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA41klEQVR4nO3dX2xbZ37n/w/HMVxkEPOICiabzBiIDhNg0b34RSQ1F/srdjoW6WwHRbqISKkXvVpEZNKb3QZj0uxNJjeVqaoDbC8aH8m9XGAkcTwLFJhOTdqz024XizFFe272JuaxB2kTzHREHSto8DM0Dn8XnMOI4n8dUhLl9wsQEp3z8DyPKPHx+Z7neb6Pr1ar1QQAAAAAAMbWl467AQAAAAAAwBuCewAAAAAAxhzBPQAAAAAAY47gHgAAAACAMUdwDwAAAADAmCO4BwAAAABgzBHcAwAAAAAw5p457gaMk88//1wff/yxnnvuOfl8vuNuDgAAAADglKvVavr000/10ksv6Utf6jw+T3A/gI8//lgXLlw47mYAAAAAAJ4yH330kb72ta91PE9wP4DnnntOUv1NPX/+/DG3prO9vT3dvHlTly5d0tmzZ4+7OQBOIfoZAKNGPwNg1Maln9nd3dWFCxca8WgnBPcDcKfinz9//sQH988++6zOnz9/ov9IAYwv+hkAo0Y/A2DUxq2f6bU0nIR6AAAAAACMOYJ7AAAAAADGHME9AAAAAABjjuAeAAAAAIAxR3APAAAAAMCYI7gHAAAAAGDMEdwDAAAAADDm2Od+jH3ySf3roF//WqpU/Lp7V3qmzW/4xRfrXwAAAACA0+HEB/fFYlGFQkGO48i2bSUSCSWTyaYy4XBY2WxW0WhUkrS6uipJSqfTjTK2bSuXyykYDEqSDMNouc64sSzp/ffbnTkr6Xc7vu6996TvfGc0bQIAAAAAHL0THdwXi0WVy2XlcjlJkuM4CofD2trakmVZjXLlclmJRKLxfTKZbDpv27bC4bAePHggwzAkSZlMRsvLy00PAMZNKiW98cYX39++LS0vS//yL18c+8pXpMuXpYsXvzjGqD0AAAAAnC4nOri3LEubm5uN7w3DUCaTUSqVUiaTkWmakurBfDgcliRFo9HGcVcul1MymWwE9pKUzWY1MTEx1sH9/un1N25I6bRUqzWX+Zd/qR/P56U33zz6NgIAAAAARu9EJ9TL5/PKZDJNxyKRiKT6qL4rGAwqmUwqmUy2BPaStLGx0ZiO73ID/f3XGVdPnkj/5b+0BvbSF8f+63+tlwMAAAAAnD4nOriPx+MtQXknjuM0pvEfPO44Ttug3zCMlvLj6B/+Qfqnf+p8vlaTPvqoXg4AAAAAcPqc6Gn5+6fku0qlkiQ1kudJUqFQkGmaikajsm1bsVhMuVxOoVBItm13vH4gEND29nbH848fP9bjx48b3+/u7kqS9vb2tLe3N/DPMyoffeRTP7/Kjz76tfb22gzvA8CA3D7wJPWFAE4X+hkAozYu/Uy/7TvRwX07uVxOuVyuaSTesqzG96FQSKlUSolEQpVKpef1HMfpeG5paUnvt0lHf/PmTT377LODN35Efv7zSUm/00e5/6Mf/rDzwwwAGFShUDjuJgA45ehnAIzaSe9nPvvss77K+Wq1diu1B7e7u6tqtdqYAn/+/PlhXLZJIpFQIBBoyoTfjm3bCgaDjRF99//3j/ZL0sTEhObn5zter93I/YULF/SrX/1qJD/fYT15Ir3yyjP6+GOpVvO1nPf5avrqV6UPP/y1zpw5hgYCOHX29vZUKBQUi8V09uzZ424OgFOIfgbAqI1LP7O7u6vnn39ejx496hqHHnrkfnd3V6urqyoUCo2kdPufE/h8PhmGoUgkokQiobfeeuuwVUmq713fLrDPZDJaWFhQKBRqHAsEApLqQb6bgK/dCL3jOE0Z9A86d+6czp0713L87NmzJ+qXf/as9Jd/KcXjks/XnFjP55Mkn/7bf5N+67dOTpsBnA4nrT8EcPrQzwAYtZPez/TbtoET6j18+FDz8/OamprST3/6U8XjcZVKJVWrVX3++eeNr2q1qmKx2Dj/yiuvaGFhQQ8fPhy0SuXzeTmO0xTYu8H68vJyYx2+q1qtSpJM05RhGDIMo3HsoFgsNnB7TopPPpHK5frXyy/X97h//vnmMl/5Sv34yy9/UfaTT46jtQAAAACAURlo5H5tbU2WZelP//RPtbGx0bWs3+/X9PS0pqentbi4KKkepCeTSV26dEnf/va3+6qzXC6rWq027UfvZsaPx+ONPez3KxaLMgyjMQ1/fn6+Zf29m2jv4FT9cWJZUpuUAE1+8Qvp8uXmY++9J33nOyNrFgAAAADgiPUd3F+5ckXPP/98yyj5IOLxuOLxuNbW1pTNZrW0tNS1vG3bWlpa0sLCgvL5fON4oVBQKpWSVE+gl8/nFY/HJdUD/1wup7W1tUb5TCbTyKDvsiyr59r9ky6Vkt54o/X4r3+9p//1v/5Rv/M7/6+eeaZ1CseLLx5B4wAAAAAAR6avhHp3796VJE1PTw+t4rt378rn8+m1117rWGZiYqJjNvv9zS4Wi40Mh7ZtK5VKtYzIl8tlra+va2ZmpjFqv382QD92d3fl9/t7JjI4bnt7e/rhD3+ob33rWyd67QiA8UU/A2DU6GcAjNq49DP9xqF9jdwPM6gf5Jo7Ozt9XSsajfacXh8KhZqS7gEAAAAAcFoMnFAPAAAAAACcLJ6D++9///uKRCKamZlpHLt+/bpWVlYOlRkfAAAAAAAMxnNwXyqVVCqVdPXqVUn1zPSpVKqxTV42m/XcSAAAAAAA0Jnn4D4QCEiSZmdn9ejRI+XzeaXTaW1sbKhUKikSiejGjRueGwoAAAAAANrzHNz7fL7G/xeLRfl8Pi0sLDSOzc3NtewxDwAAAAAAhsdzcO/3+3X9+nXt7u7KsiwZhtGyvZ1hGF6rAQAAAAAAHXgO7hcXF7WzsyPDMFQsFpXL5VrKPHr0yGs1AAAAAACgg6FshXf58mV9/vnn+vzzz/XWW29Jkt5++2394R/+oXZ3d1Wr1YZRDQAAAAAAaGNk+9xHo1Hdv39fS0tLunz58qiqAQAAAADgqffMqC4cj8cVj8dHdXkAAAAAAPAbIxu5v3fvnnZ3d0d1eQAAAAAA8Bueg/uHDx+2DeKnpqa0vr6ubDarhw8feq0GAAAAAAB04Dm4j0ajmpiY0Kuvvqp33nlHP/jBD7S7uyu/36/FxUUtLS0pn88Po60AAAAAAKANz2vu79+/r3w+r2KxqEKhIMuy5PP5ZJqmwuGwpqamZNv2MNoKAAAAAADaGEpCvf3J8x49eqRCoaA7d+5obW1Nk5OT2tzcHEY1AAAAAACgjaEn1PP7/YrH48rlcqpWq0omkzIMY9jVAAAAAACA3xhZtnzX5cuXWXMPAAAAAMAIeQ7u2fIOAAAAAIDj5Tm4j8fjbbPl71epVLxWAwAAAAAAOvAc3N+/f19/93d/p7m5Od25c0dzc3OamJjQ5OSkZmZmdObMGdbcAwAAAAAwQkPJlh+NRhWNRiXVs+XfuXNHhUJBt27dUq1W0/LysvL5vKLRqC5duqTZ2VmdP39+GFUDAAAAAPDUG0pwv5/f728J9ovFogqFggqFgizLks/nU6FQ0MWLF4ddPQAAAAAAT52hB/cH+f1+zc3NaW5uTlI92C+VSgqHw6OuGgAAAACAp8LIg/uD/H6/Zmdnj7paAAAAAABOrb4S6j148EDZbHaoFWezWd27d2+o1wQAAAAA4GnUV3A/NTWl+fl5vf766/r5z3/uqcKHDx/q9ddfVywW02uvvebpWgAAAAAAYIBp+dPT01pfX9f8/Lx8Pp8ymcxACfFu376ta9eu6dGjR7p27ZqmpqYO1WAAAAAAANBsoDX3hmHo5s2bunXrlq5du6Z4PK5gMKhoNKrJyUkZhqFAIKBqtSrHcbS9va1isahyuaxQKKQrV640EusBAAAAAIDhOFRCvdnZ2UZSvO9///u6c+eOfvrTn8pxHNm2LcMwZJqmAoGAksmkotEoI/UAAAAAAIyI52z5+7e5AwAAAAAAR+/It8IbVLFYVKFQaMwKSCQSSiaTTWVs21Yul1MwGJRUXz5wmDIAAAAAAIyjEx3cu+v1c7mcJMlxHIXDYW1tbcmyLEn1oD0cDuvBgwcyDEOSlMlktLy8rHQ63XcZAAAAAADGVV9b4R0Xy7Kagm/DMJTJZLS6uirbtiVJuVxOyWSyEbRLUjabVSaTaXzfTxkAAAAAAMbViQ7u8/l8SwAeiUQk1Uf1JWljY6Mx1d7lBvGDlAEAAAAAYFyd6ODe3WqvE8dx5DiOTNNsOWcYhsrlcl9lAAAAAAAYZyd6zf3m5mbLsVKpJEmKRqONqfntBAIBbW9v91Wmk8ePH+vx48eN73d3dyVJe3t72tvb69n+4+K27SS3EcB4o58BMGr0MwBGbVz6mX7bd6KD+3ZyuZxyuZxM0+w56u44Ts/rdSuztLSk999/v+X4zZs39eyzz/a89nErFArH3QQApxz9DIBRo58BMGonvZ/57LPP+ip3JMH9jRs39Oabb3q+TiKRUDQabSTZ258g76Bqtdp3mU6y2azefffdxve7u7u6cOGCLl26pPPnz/ff8CO2t7enQqGgWCyms2fPHndzAJxC9DMARo1+BsCojUs/484g7+VIgnvLsjwH96urqwoEAo0t8KT6tHqp/ei74zgyDKOvMp2cO3dO586dazl+9uzZE/3Ld41LOwGML/oZAKNGPwNg1E56P9Nv24YS3K+srGh9fb3tOcdxuq5770c+n5fjOE2BvRuYG4bRcQQ+Fov1VQYAAAAAgHHmObi/cuWKVldXFYlE2mak397e7jn9vZtyuaxqtdq0373jOCoWi4rH45qfn1elUml6jfswIRqNSlJfZQAAAAAAGFeeg3vbtnsG7/Pz84e+9tLSkhYWFpTP5xvHC4WCUqmUJCmTySgWiymXyzXOW5bVNMrfTxkAAAAAAMaV5+C+n2nt+4PqQYTDYTmO0xTYu9zA3DRNbW5uKpPJaGZmRrZta3JyUslkslG2nzIAAAAAAIwrz8F9P9vNPXjwQFNTUwNfe2dnp69yoVBIoVDIcxkAAAAAAMbRl7xeIJlMamVlRQ8fPuxYhunvAAAAAACMjueR+2QyKcdxlMlkGlvP7d9ebhjZ8gEAAAAAQGeeg/tCoaBIJKK5ubnGnvL7ec2WDwAAAAAAuvMc3JumqZs3b3Ytc9hs+QAAAAAAoDfPa+7X1tZ6ljlstnwAAAAAANCb5+B+enq6Z5nDZMoHAAAAAAD98Rzcu27cuKFXX31VZ86c0ZkzZ/Tqq6/qr//6r4d1eQAAAAAA0IHnNfdSfU19sVhUNBrV7OysJKlarWpxcVGbm5v60Y9+NIxqAAAAAABAG56D+7W1NZmm2TEj/ttvv63r16/rrbfe8loVAAAAAABow/O0/EqloqtXr3Y8f+3aNZVKJa/VAAAAAACADjwH95OTkz3LBINBr9UAAAAAAIAOPAf3Pp+vZ5lOU/YBAAAAAIB3noP7Wq2mGzdudDx//fp11Wo1r9UAAAAAAIAOPCfUu3z5siKRiCzLUiKRUCAQkCTZtq319XU5jqMPP/zQc0MBAAAAAEB7Q9kKr1QqKZVKKZlMNh2Px+NaW1sbRhUAAAAAAKCDoQT3kmRZlizL0t27d1WtVhWJROT3+4d1eQAAAAAA0MHQgnvX9PR0y7F79+7ptddeG3ZVAAAAAABAQ0io14+lpaWjqAYAAAAAgKfSQCP3KysrKpVK+t73vtc4NjMz0/U1juPItu3DtQ4AAAAAAPQ0UHD/wQcf6OHDh03BfaVSUSQSkWmabV9Tq9XY5x4AAAAAgBEaKLgvl8stgXokEtHNmze7vm5nZ2fwlgEAAAAAgL4MFNz7/f6WDPiWZfV8XS6XG6xVAAAAAACgb54T6k1NTbU9/vDhQ+3u7nYtAwAAAAAAvPMc3Gez2ZZjjx49UqVSUaFQ0MrKim7fvu21GgAAAAAA0IHnfe4rlUrLMb/fr9nZ2cb3KysrunjxoteqAAAAAABAG55H7n0+X88yhULBazUAAAAAAKCDgUfur1y5Itu29ejRI0lSqVTS66+/3rF8qVRSMpk8fAsBAAAAAEBXAwf3V69elSTl83klk0n5fD7VarW2ZQ3D0NWrV7W4uOitlQAAAAAAoKNDr7mPx+MKhUK6cuWKNjY2htkmAAAAAAAwAE9r7k3T1MLCwrDaAgAAAAAADsFztvy5ublhtKOr1dVVVSoV5XK5lnPhcFjZbFbRaLRRVpLS6XSjjG3byuVyCgaDkurLBcgDAAAAAAA4LTxny5ekW7duaWFhQTdu3Gg6vra21nKsX7ZtK5VKKZVKKZPJdCxXLpeVSCQ0MTGhiYkJVSqVlsA+HA4rl8spnU4rnU6rUqloeXn5UO0CAAAAAOCk8Txyf/v2bRUKBW1tbUmS3nzzzca5xcVF3b17V7dv3x54n3vTNGVZlqR6xv1OksmkwuGwJCkajco0zabzuVxOyWRShmE0jmWzWU1MTDQ9BAAAAAAAYFx5HrkvFAq6evWq7t+/r/X19Zbz09PTsm3bazUdBYNBJZNJJZPJlsBekjY2NhrT8V1uoF8sFkfWLgAAAAAAjornkft+OI4z8uuXSiUFAgGFQqGm447jtA36DcNQuVxurNVv5/Hjx3r8+HHj+93dXUnS3t6e9vb2hvgTDJfbtpPcRgDjjX4GwKjRzwAYtXHpZ/ptn+fgfmdnp2eZSqXitZqOCoWCTNNUNBqVbduKxWLK5XIKhUJdZwwEAgFtb293vfbS0pLef//9luM3b97Us88+67nto1YoFI67CQBOOfoZAKNGPwNg1E56P/PZZ5/1Vc5zcB8Oh/XOO+9oeXlZzz33XMv5bDbbtN592CzLaozMh0IhpVIpJRKJvh4o9JpRkM1m9e677za+393d1YULF3Tp0iWdP3/eU7tHaW9vT4VCQbFYTGfPnj3u5gA4hehnAIwa/QyAURuXfsadQd6L5+B+cXFRiURChmEokUhoampKk5OTqlQqjTXtH374oddqOjo45d4dsS8Wi22n47uq1WrPa587d07nzp1rOX727NkT/ct3jUs7AYwv+hkAo0Y/A2DUTno/02/bhrLmfnNzU6urq7py5UrTaHg8Htfa2towqmgrk8loYWGhaZ19IBCQVN8CLxKJSGo/Qu84zkhnFAAAAAAAcFSGss+9VN+SrlqtamdnR5VKRZ9//rk2Njbk9/uHVUWL5eXllm3y3BF50zRlGIYMw+g4Sh+LxUbWNgAAAAAAjsrQgnuX3+/X1NRU07F79+4NuxpJX+xhv1+xWJRhGI0s+PPz8y3r791Ee90y5QMAAAAAMC6GHty3s7S05On17pZ2B4VCIeXz+aZyuVyuaSlAJpNpKiPVk/BZluWpTQAAAAAAnBQDrblfWVlRqVTS9773vcaxmZmZrq9xHKfrlnTdXre0tNR4/cbGhiQpGAwqnU5Lqo+8F4tFZTIZSfURecuymkbkTdPU5uamMpmMZmZmZNu2JicnW0b8AQAAAAAYVwMF9x988IEePnzYFNxXKhVFIpGOmelrtVpfmekPMgxDuVxOkrqOskej0Z7T60OhUFPSPQAAAAAATpOBgvtyudwSqEciEd28ebPr63Z2dgZvGQAAAAAA6MtAwb3f72/Jft/P2nV3BB4AAAAAAAyf54R6BzPjt/Po0SOv1QAAAAAAgA6OJFv+4uLiUVQDAAAAAMBTaaBp+QsLCwNd3HEcVavVQ2XLBwAAAAAA/RkouC8UCjJNU4FAoOl4qVRqe9wN7HttlwcAAAAAAA5voODeNE2VSqWmY7du3ZIkzc7Otn3N2toawT0AAAAAACM00Jr7dlnvHzx40DGwl+rr7dfX1wdvGQAAAAAA6MtAwX27IN5xnJ6vOzhdHwAAAAAADI/nbPmVSqVnGZ/P57UaAAAAAADQgefg3jRNZbPZjudv3LihX/3qV16rAQAAAAAAHQyUUK+dy5cvKxwOa3V1VQsLCzJNU1J9RL9YLMowDN25c8dzQwEAAAAAQHueg3tJ2traUiaT0draWtMa/HQ6ratXrw6jCgAAAAAA0MFQgnupnkk/l8vpwYMHkqSpqalhXRoAAAAAAHQxtODeRVAPAAAAAMDR8pxQT5Lu3bunS5cuaXJyUtevX28cf/vtt3X79u1hVAEAAAAAADrwHNzfvXtXFy9elGEYLevrr127pp2dHd27d89rNQAAAAAAoAPPwf3Vq1e1tbWljY0NLS4utpyfm5tTsVj0Wg0AAAAAAOjAc3A/NTXFOnsAAAAAAI6R5+D++eefb/q+Vqu1lNne3vZaDQAAAAAA6MBzcH///n397Gc/a3zv8/mazq+srHitAgAAAAAAdOF5K7yrV6/KNE3FYjHNzMyoUqkoEAjItm1ZliXDMHTnzp1htBUAAAAAALThObg3DEOlUkmpVErpdFqSZFmWJCmdTrdk0AcAAAAAAMPlObiXJNM0VSgU9OjRI5VKJQUCAU1PTw/j0gAAAAAAoAfPa+6///3va2FhQZLk9/s1OztLYA8AAAAAwBHyHNxblqWtrS3t7u4Ooz0AgBPuyRPpJz/x6e///qv6yU98evLkuFsEAAAAz8F9LBbT/fv3df78+Y5lyJgPAOPpk0+kcvmLr5UV6aWXpFjsGX33uxHFYs/opZfqx/eX++ST4245AADA08XzmvtoNKqVlRUlk8mOAT7Z8gFgPFmW9P773cv88pfS5cvNx957T/rOd0bWLAAAABzgObjf2NiQ4ziampqSaZoKBAIyDKNx3nEcFYtFr9UAAI5BKiW98UZ9Kv7v/349kO/khRekv/kb6cwZ6cUXj66NAAAAGEJwb1mWAoGAwuGwJKlWq2lnZ8dzwwAAx+/FF+tf//N/dg/sJekXv5D+9V+l3/3do2gZAAAA9vMc3JumqVKp1LXM/Py8pzpWV1dVqVSUy+Vaztm2rVwup2AwKEkyDEPJZHLgMgCAzvpdQ89aewAAgOPhObhvF3AflM1mB76uG5BL9an/7YJx27YVDof14MGDxlKATCaj5eVlpdPpvssAALrrd5o90/EBAACOh+fgfnZ2tul7d0u8/cn1DrPvvWmasixLkjrODMjlckomk01r/LPZrCYmJhqBez9lAADtffJJ/evLX5a+8pXea+6//OV6tnx3Oj8AAACOhuet8FzZbFaTk5OamJjQxMSEJicn9Rd/8RfDunxbGxsbjan2LjeId5P49VMGANCeZUnhsPT1r/e35v7rX6+X/82zWQAAABwRzyP3khSJRFQulxWPx2WapiRpa2tLly9fVqFQ0I9+9KNhVNPEcRw5jtOobz/DMFQulxWJRHqWiUajHet4/PixHj9+3PjenZWwt7envb29IfwUo+G27SS3EcB4+M//WfrWt774/sc/9um73z2jX/7S1zj2wgs1/cmfPNE3v1lrHPs3/0aiCwLgBfczAEZtXPqZftvnObi/cuWKTNPUrVu35Pf7m845jqNkMqnr16/rrbfe8lpVE9u2O54LBALa3t7uq0w3S0tLer/NBs83b97Us88+239jj0mhUDjuJgA4Zf7tv5U++ED6v/93Ujs7v6WJif9Pv/3b2zpzpjmZ3iefSHfvHl87AZwe3M8AGLWT3s989tlnfZXzHNzbtq2NjY225wzD0MbGht55552hB/e9OI7juUw2m9W7777b+H53d1cXLlzQpUuXmnIKnDR7e3sqFAqKxWI6e/bscTcHwCn0H/8j/QyA0eJ+BsCojUs/484g72UoW+ENo8yg9ifIO6harfZdpptz587p3LlzLcfPnj17on/5rnFpJ4DxRT8DYNToZwCM2knvZ/pt29AS6nXTLri/ffu2p2sGAgFJ7UffHceRYRh9lQEAAAAAYNx5Du5jsZiuX7/e8fzt27c1MTHRctzymErZMAwZhtFxBD4Wi/VVBgAAAACAced5Wr5lWbp165Ysy2qMlLuq1aps21YkElEul2s6Xi6XvVat+fl5VSqVpmNuEj03C34/ZQAAAAAAGGeeR+6LxaKmpqY0MTGhWq3W9DUxMaFwONxyvFar9b7wPu62dwdlMhnl8/mmY5ZlNc0K6KcMAAAAAADjbCgJ9Uql0sCvm5+f73recRwtLS3JcZymjPzBYFDpdLpR9+bmpjKZjGZmZmTbtiYnJ5VMJpva16sMAAAAAADjzHNwv3+6/SCy2WzX84ZhNK7dbZQ9FAopFAp1vVY/ZQAAAAAAGFeep+XPzs4e6nXT09NeqwYAAAAAAOozuH/w4IGuX7+u3d3dUbcHAAAAAAAMqK/gfmpqSrVaTRcvXtTrr7+uGzdujLpdAAAAAACgT31Py19cXFSpVNK1a9f005/+VK+88ooWFhZ0+/btUbYPAAAAAAD0MPCa+6mpKV29elX379/XlStXtLGxoVdffVXZbFYPHz4cQRMBAAAAAEA3nhLqTU9P69q1a/rwww8ViUSUTqc1MzOjlZUV1ucDAAAAAHBEPGfLd83NzWljY0PFYlF+v7+xPv/69evDqgIAAAAAALQxtODe5ff7G+vzNzY2tLOzo0gkwvp8AAAAAABGZOjB/X5+v1+XL19WqVTSlStXdPPmTb3yyit65513dO/evVFWDQAAAADAU2Okwf1+09PTjUR88Xhcf/Znf0aADwAAAADAEDxzHJXOzs5qdnb2OKoGAAAAAODUOZbgHgAAAJCkTz6pf+335IlUKvn0j//4qj7+2KdIRDpzprnMiy/WvwAAdUMJ7u/du6dMJqNSqaRcLqe33npLkvT2229rfn5eFy9eHEY1AAAAOGUsS3r//XZnnpH02/rv/7396957T/rOd0bXLgAYN57X3N+9e1cXL16U3+/X1atXm85du3ZNOzs7rK0HAABAW6mUtLVV//rzP+9e9s///IuyqdTRtA8AxoXnkfurV69qa2tLU1NTktSyr/3c3JxWVlb02muvea0KAAAAp4w7vf7JE+kP/qBzOZ9P+su/lP7kT1qn6AMAhjByPzU11QjsAQAAgMP4h3+Q/umfOp+v1aSPPqqXAwC08hzcP//8803f12q1ljLb29teqwEAAMApdjCpntdyAPC08Rzc379/Xz/72c8a3/t8vqbzKysrXqsAAADAKddv5nsy5ANAe0NZc2+apmKxmGZmZlSpVBQIBGTbtizLkmEYunPnzjDaCgAAgFPG3Qrvy1+WvvIV6Ze/7Fz2hRfq5cpltsIDgIM8j9wbhqFSqaRqtap0Oi3LshSPx5VOpzU3N0dgDwAAgI4sSwqHpa9/vXtgL0m/+EW9XDhcfx0A4AtD2efeNE0VCgU9evRIpVJJgUBA09PTw7g0AAAATrFUSnrjjS++v327vuXd/kD/hRekb39bunjxi2OM2gNAs6EE9y6/36/Z2dmW4zdu3NCbb745zKoAAABwChycXh8K1be7+/GPf62//dt7+r3fe03f/OYzbH8HAD14npbfD4t5UwAAAOjTmTPSN75R03/4D/+sb3yjRmAPAH0Yysj9ysqK1tfX5ThO2/O2bQ+jGgAAAAAA0Ibn4P7KlStaXV1VJBJROBxuOb+9va1qteq1GgAAAAAA0IHn4N627Z7B+/z8vNdqAAAAAABAB57X3M/MzPQsk8vlvFYDAAAAAAA6OJKEeg8ePDiKagAAAAAAeCp5Du6TyaRWVlb08OHDjmXIlg8AAAAAwOh4XnPv9/v1q1/9SsFgUIZhKBAIyDCMxnnHcUaeLT8cDiubzSoajUqSVldXJUnpdLpRxrZt5XI5BYNBSZJhGEomkyNtFwAAAAAAR8FzcP/2229rY2NDs7OzMk2z5fxRZMsvl8tKJBKN75PJZNNsAdu2FQ6H9eDBg8aDh0wmo+Xl5aYHAAAAAAAAjCPPwX21Wj32bPnJZLKxDV80Gm15yJDL5ZRMJptmFGSzWU1MTBDcAwAAAADGnuc197FYrGeZUWfLDwaDSiaTSiaTbWcPbGxsNKbju9xAv1gsjrRtAAAAAACMmufg3nGcnmWOIlu+4zgqFosql8stxx3HaRv0G4bRUh4AAAAAgHHjeVq+my0/Ho/r5ZdfblvGsixdvHjRa1UdFQoFmaapaDQq27YVi8WUy+UUCoW6JvMLBALa3t7ueP7x48d6/Phx4/vd3V1J0t7envb29ob3AwyZ27aT3EYA441+BsCo0c8AGLVx6Wf6bd9QgnvHcZTJZI4tW75lWY2R+VAopFQqpUQioUql0vO13WYeLC0t6f333285fvPmTT377LOHbu9RKRQKx90EAKcc/QyAUaOfATBqJ72f+eyzz/oq5zm4LxQKikQimpubUyAQaDl/FNnyD065d0fsi8Vi2+n4rl7tymazevfddxvf7+7u6sKFC7p06ZLOnz/vrdEjtLe3p0KhoFgsprNnzx53cwCcQvQzAEaNfgbAqI1LP+POIO/Fc3BvmqZu3rzZtcwos+VnMhktLCwoFAo1jrkPGWzbViQSkdR+hN5xnKZZBgedO3dO586dazl+9uzZE/3Ld41LOwGML/oZAKNGPwNg1E56P9Nv2zwn1FtbW+tZZpTZ8peXl1UqlZqOuSPypmnKMAwZhtFxlL6fbP8AAAAAAJxknoP76enpnmUePXrktZqO3D3s9ysWizIMQ9FoVFJ95sDB9fduHgC3DAAAAAAA48pzcN+PpaWlkV07FAopn883vnccR7lcrmlGQSaTaSoj1ZPwWZY1snYBAAAAAHBUBlpzv7KyolKppO9973uNYzMzM11fM+ps+dFoVMViUZlMRlJ9RN6yrKYRedM0tbm5qUwmo5mZGdm2rcnJyZYRfwAAAAAAxtFAwf0HH3yghw8fNgX3lUpFkUikY1b6Wq028mz50Wi05/T6UCjUlHQPAAAAAIDTYqDgvlwutwTqkUikZ7b8nZ2dwVsGAAAAAAD6MlBw7/f75ff7m471s259lNnyAQAAAAB42nlOqDc1NTWUMgAAAAAA4HAGGrm/fv26KpWKHMeR3++Xz+cbaSZ8AAAAAADQ20DB/dWrVxUOh7W6utoyPR8AAAAAAByPgYJ7SVpbW9P58+dH0RYAAAAAAHAIA625N03zUIH99evXB34NAAAAAADoz0DBvWEYh6pka2vrUK8DAAAAAAC9DRTc+3y+Q1Vi2/ahXgcAAAAAAHobaM391taWXn/99YFG8B3HUbFYHLRdAAAAAACgTwMn1CsUCgNXctgRfwAAAAAA0NtAwb1pmgOvn6/VaopEIgO9BgAAAAAA9G+g4N4wjEPtbx8KhQZ+DQAAAAAA6M+RJNQLBAKHeh0AAAAAAOhtoOD+sFnvr127dqjXAQAAAACA3gYK7nd2dvSDH/xgVG0BAAAAAGDknjyRfvITn/7+77+qn/zEpydPjrtF3g0U3Pv9fs3NzWlhYUHXr1/X7du3R9UuAAAAAACG7sYN6eWXpVjsGX33uxHFYs/o5Zfrx8fZwPvcux49enToafoAAAAAABy1GzekeFyq1ZqP//M/14/n89Kbbx5P27waeJ97l9/v1/T09DDbAgAAAADAUH3ySf3ryRPpnXdaA3vpi2N//MfShQvSmTPSiy/Wv8bFQNPyAQAAAAAYJ5YlhcPS178u/fKX3cv+4hf1cuFw/XXj5NAj9wAAAAAAnHT/6T9Jr74q/e//Lf3VX/Uu/8d/LP37fy/9u3838qYNFSP3AAAAAIBT63/8D+mP/qi/wF6ql/ujP6q/bpwwcg8AAAAAOLVSKemNN+pr7n//97tPzX/hBelv/uaLNffjhOAeAAAAAHBq7U+M98EH9az4UnNiPZ+v/t+/+itpZuZo2zcsTMsHAAAAADwV3nyzvt3dV7/afPxrXxvvbfAkRu4BAAAAAE+RN9+U/uAPpB//+Nf627+9p9/7vdf0zW8+ozNnjrtl3hDcAwAAAACeKmfOSN/4Rk3/+q//rG984/8Z+8BeYlo+AAAAAABjj+AeAAAAAIAxR3APAAAAAMCYY839AGq/2Sthd3f3mFvS3d7enj777DPt7u7q7Nmzx90cAKcQ/QyAUaOfATBq49LPuPFnbf/efW0Q3A/g008/lSRduHDhmFsCAAAAAHiafPrpp/L7/R3P+2q9wn80fP755/r444/13HPPyefzHXdzOtrd3dWFCxf00Ucf6fz588fdHACnEP0MgFGjnwEwauPSz9RqNX366ad66aWX9KUvdV5Zz8j9AL70pS/pa1/72nE3o2/nz58/0X+kAMYf/QyAUaOfATBq49DPdBuxd5FQDwAAAACAMUdwDwAAAADAmCO4P4XOnTun9957T+fOnTvupgA4pehnAIwa/QyAUTtt/QwJ9QAAAAAAGHOM3AMAAAAAMOYI7gEAAAAAGHME9wAAAAAAjLlTH9zbtq1EIqFwOCyfzyefz6dEIqFUKnXcTTs2tm0rHA5rYmJC4XB4ZPU4jqNgMKjl5eWR1QGcdu36r/1fsVhMqVRKjuN4qiccDisYDCocDjddOxgMKhgMtj22uro6nB+yT+VyudF3xWKxI60bwMlg2/ZxN2GslMvl424C0JbjOI37Cvcep93nu1gsNu6D3H//6Qc6e2oS6jmOo4mJCZmmqUql4vl6mUxGuVxuCC07PrFYTNVqVVtbW56u0+m9sG1bwWBQ8Xhcm5ubnuoAnnY+n0+hUKjt5zWVSml1dVWFQkHRaPTQ19/c3FQ8Hm8cc/vNaDSqQqHQdHxxcVGmaR5LPzisvgvAeCmXy1pfXx/7+6+jxHuGcRCLxVQsFjve50j1eGNmZqbpPgWtnjnuBhwVwzCa/uvVaXhiZJqmqtWq5+t0ei9M09RT8uwIOFaWZalYLCqRSOjBgweH6ufi8XjHfzAPXs8wDK2trSmTyRyitd4Nq+8ChiGRSMi27cYI6cHPkeM4jQdhXu5BwuGwHMeRYRgyTbNxbfff4FAo1HIsk8komUweus5BlctlLS4uyrZtRSKRpoeCXjmOo0wmM9RrnhbFYlGZTEa2bSsajTYNqIRCIRWLRa2urh7p3wIwiFAopFAopOXl5Y5/qzMzM41+Dp09NcH9MOXzec9TYE8L3gvgZIhGo1pdXVWxWBz4qbbjOANPczcMY2gPS4Fx5gZS7uyadjPVUqmUJiYmPM2uKZfLXWfX7K/XnV0zjJmKg3BH3dzZNcOUSCRkWdZQr3laRKNRbW1tdVxqmU6nFQ6HFY1GGw+GgJMml8spn88rlUrxt+rBqV9zP2y2bWtxcfG4m3Ei8F4Ap4Nt2/wjCoyQZVkyTVOJROLQD8QPM7vmuB6+D7s/KRaLI7nuaRMIBDqey2azxzbbCuiX+5Dyac6N5tVTP3K/fwpZNBrV2tqaVldXZRiGCoVC05rSfD6v9fV1SVKpVFIikZCklnWn7tSxYDCo7e1t2batbDbbmEqyf/pUMpnUwsKCisWiCoWCUqmUDMNoml6VSqUa09Dcm/Bua6f2J7Db3t5WMBgcaCqWbduyLEuTk5Pa3t6WpJb6er0Xtm0rlUqpVCrJNM2262d6tXOQ3w3wtHNvft1RwdXVVVmWpXK5LMMwlEwmm/oy9zN7cD39IPZ//np9nnv1e/uDltXVVW1tbTUCllgs1na003GcRlK/O3fu0CfgRGN2zeFZlkVg6lE8Htfi4mJjaQdwEoVCIaXT6a7T813744T9sUY/x9vFFYFAQJZl9by3OLgMplecdhT3Y01qTxFJtVAo1PZcNBqtRaPRWi6XazpuGEbLMbdsO5VKpWYYRm1ra6vrsVqtVjNNs5ZMJhvXN02zFo/HG+dDoVDNMIyaZVlNr4vH4x1/jlAoVNvc3Gw6lk6nm67rSiaTba+TTCZbXt/rfeskGo22fe0g7RzkdwOcVt36r1wuV5NUKxQKLedM02z7GU2n0y19y0E7Ozs1SW0/l/sN8nnu1e/F4/G2fdD+n83tu+gTcJJ0+4zWavW/W0ktn5V+bG1ttf189/qMptPpgesahk73F4dlGMbQrnVUKpXKkdcZjUa79tfxeJw+EifSwb7KNM2apNrOzk7j2ObmZtvPVSgUatvfdIpBusUV6XS673uLQeM0L/djg3jqR+5dhmEon8+3rOeKRCJaX19XOp3u6zruOpH9CR9M01Q0Gm1JBGOapjY2NvTgwQNJahqpkr6YXnXwqdXa2pomJiZastSnUikFAoGWEYFcLqeJiQnl8/meowVu0pVEItEYKctms1peXu7r9Qe1S3w1aDuH9bsBxp1t2y2jV7ZtKxAIqFKptJ2ymkqlOo54DSO50qCf52793urqqvL5vHZ2dpqulc/nG0/IXe764/3oE3CSMbvmcLNr8vl8277Ny+w+rzMcXW6fPDMzo0qlomAwKMMwFAgEtL6+roWFhabZmN3e135mTR78GfbX2c+ShVgsps3NTfpInHibm5uNrXl79X+mabZN7m0YRtvcH93iCvdzdfB4u3uLw8Rpo7wfaxjaY4IxoC5P1ZPJZNsnw+2ePncarXafoLd7umNZVsv1Oz1R6lVPrVZ/KnTwepI6PvmJx+M10zSbjrX72SqVSi0ajbY8Gev0c/UauW9Xx2Ha2e/vBjituvVf3bj90v7P3M7OTl+jN/2M3A/6ee7W7xmG0baueDzeNNpJn4CTqNtnlNk1dYeZXZNOp7vOQBh0dt8g70U3Ozs7NcMwmn7uaDTaeG+2traaRh17va+DzJoMhUIt70mhUOjYh7q2trZqT9mtP8ZEu894Op1uusfoNHLfbSZyp+Od7iE6HT94L1OrDR6nebkfGwQj9/t0S0TSj1KpJEmqVCqNJ9X7tXsCe9g6TdOU4ziNtVPuFjydrhcIBPravs80zcYTMnc7Hfd17pNkLw7bTq+/G+BpZRiGotGoLMtqPBne2NgYylPiYX6e3f6s3ehTu+zj9Ak4iZhdM/zZNbZta2ZmpuP5QWb3DWOGo2t1dVWO4zT9zIlEQqlUSrlcrmXLrm7v6yCzJt1ZAAfvKfvJLr5/C0XW3eOk2589f35+fqjX7nbfMgwH4zRptPdj+xHc73PYjs79xbl/ELFYrO9/HIbVuQ5zyxn3H8lQKKSFhQXF4/G+29nrH4zDtpN/hIDDS6VSjb24TdNUpVIZymdqmJ9n91qTk5OHvgZw3A4z7TyZTCqTyTQlj3Icp+/PQi/u9P923CWDB+9ZTNNsuiF1uWUPfv7c+4X92k0Vb7dUr5de9xWBQKDvug7zXnTS7mGN+71t22334+70vrrLN/dfzz1/8AHp6upqx0CnV2DiXrNardKHYizsn54/zAz6nf7+R/25GNX92H5shTcEpVKpqSPvZ4TcK3eNnvsHEYlEutZdrVb7Wo+1urqqxcVFWZbV9slzL+570cmw2gmgf+7NqmVZPUfBBjHMz7Nb7qj35QaO2/7RHNc4zq45GBQPawTMnfnQTT91DWuGoyscDreUd7ce7HTv1Klud9akO9pXLpeVz+clNc+atG1bjuMoGAz23c52jmuLRGBQoVBIyWRSxWKx44O5ToY58Dmog3Gaa1T3Y/sR3B/CwV+U4ziNDjudTnf84zvME6d2f5iO46hYLCqbzTa1KR6PN7anOyifz/e1jUwmk9H8/HzLP977/yHYn4im23vRzrDaCWAwyWSyMaV20MSYnQz78xyPxxtJxw5qt9QJOC1SqZTK5XIjWGR2TfN1ev0c/dQ17Bv9+fl5GYbR1Gf1WnLQrZ35fF6xWExLS0uSNNCsyUExiIJxYlmWTNPseH8gtX9gVS6XR/4gq984bb9R3I/t99QE9+4vt9MvuVqttj3X7ngsFmusr5fqT1LdDjiXy8kwjKYAWGrOfNuuXZ3Ytt3yx7y4uKhoNNryD8ja2lpTZlqXm8G/3SjAwfrbPbnO5/OKRqNt29rtvehUx6DtHOR3A5xmXv7eU6mUHMc5VO6MbvUOo9/Zfy1JLQ8EyuVy00ND+gScNsyu6V7vMD7Xw545aBiG5ufntbm5qUwm08iaP+iyDKn/WZNefwfu+8iUfJwktm03ZtZ00m3U3p3mvp+7y0a74HvQe4huDwYHidNcXu7H+jLU9HwnUKVSaWRLlFST1JTNtFKpNDIa6jcZZwuFQsvxaDTalF01nU43srO2y37rZnfN5XK1XC7XtMf91tZWLR6PN9rTad9RNwtjoVCobW5u1nK5XC2ZTPbMnru/7nblO/3MtVo9a2M8Hm/8bLlcrlapVBpZ9NPpdFP2107vRbs69r8HXtrZ63cDnCbt+q/D7l1tmmbL57BTnW6m+4P9Zqf+p9fnud9+z72Wm1Xasqyu/Qp9Ak4KHXJHC5ebqXmQzMn9ZMvvtOdyrdZ+t4tue6W32wHDtf86g2av7iaZTHbt8wapa9D3ohv33qxf3d5XwzBasuW7bXJ/dvfvIp1Od/wdhEKhrjsYbW1ttc0GDhyHnZ2dWjQabfzbHQqFun4Gk8lk22z5tVr98+HeV7jxiNunujtk9HsP0e+9xWHjtFqt//uxwzj1wf0467XNHAAM4rAPBQD0Jqlj0NUPd5uyQT6nbnDf7V5hZ2enZppmyw1nMpls+7pu9x7utQ62cWtrq+mmt9NDgG4PBzqxLKvrA4FB6hr0veimUqnUQqFQrVAo1La2thoDIZ10e1/bbYe4ubnZNBi1/6FPu+383C2Xu71XlmVxXwkMiZc4bZT3Y0/NtHwAeJoNIwkTgFapVErhcFhSfYpmLBY7VO6YUCgk0zRbss53qjORSDTqLRaLisViSqVSLUtkDMNQpVJRpVJRJpPR8vJyo83u1rdSfflLIpFQsVhUsVhUIpFoWWLoXsttw/LyslZXV1WtVhWPx2XbduMa3f4/Fos1Esb1Eo1G207ZPUxd/b4X/TBNU4FAQLFYTOFwWMFgUMFgUD6fT4lEojG9t5/31d0WLxaLaXl5WcvLywqFQo1lGplMpmmJ09bWlu7cudMom8lkFIlEFIlEZNu2wuFw2/dsa2ur7RJRAEdn1PdjvlqtVhvZ1eFJLBaTpIH/wQGAcrms9fX1xvpPd/sk1loCJ1cmkznUmu3TLhwOK5fLNe0pf9xSqZSCwWDTulrHcVQqlRoPd7a2to6reW0Fg0F2JAGGpN847ajvxxi5P8Gq1eqxbuMAYHytr683RqvcXSwI7IGTi9k1nWWz2YG3wRqlYrGoUqnUkjDL3dbw1q1bR5KpexD5fH7g7Y0BdNZvnHbU92ME9yeQO4WrXC43TecCgH5ls1nF4/HGtNlRbLcC4PDK5XLT9P2NjQ3Nz88fY4tOrng8LsdxBtqH/ji5N+4n6YGqm4kfgDeDxmlHfT/GtHwAAIAjlslklM/nValUGvsi8xCuM9u2lUqlTsxSxVgsplgs1na7q0QioZmZma573h+l1dVVOY5zYtoDYHQI7gEAAI6Y4zhaWlrS5OSkJBF49aFYLKpQKJyYEeh8Pq9CodC0nKJSqSiRSJyY/AAH1/sCON0I7gEAADAWyuUya8cHwPsFPF0I7gEAAAAAGHMk1AMAAAAAYMwR3AMAAAAAMOYI7gEAAAAAGHME9wAAAAAAjDmCewAAAAAAxhzBPQAAAAAAY47gHgAAAACAMUdwDwAAAADAmPv/Aav7ZyyeTXZmAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Select which inference method to check\n",
    "# # choice = \"Numpy\"\n",
    "# act_func = \"ReLU\"\n",
    "# hidden = 20\n",
    "# # Load data\n",
    "# mu_df = pd.DataFrame.from_dict(mu_dict)\n",
    "# sigma_df = pd.DataFrame.from_dict(sigma_dict)\n",
    "# # Limit to one choice\n",
    "\n",
    "# mu_df = mu_df[((mu_df[\"Act func\"] == act_func) & (mu_df[\"Hidden size\"] == hidden))]\n",
    "# sigma_df = sigma_df[((sigma_df[\"Act func\"] == act_func) & (sigma_df[\"Hidden size\"] == hidden))]\n",
    "# # Get vals\n",
    "# hidden_size_list = np.unique(mu_df[\"Hidden size\"].values)\n",
    "\n",
    "# plt.figure(figsize = (12, 3))\n",
    "# y    = mu_df[((mu_df[\"Act func\"] == act_func) & (mu_df[\"Hidden size\"] == hidden))][\"Result\"]\n",
    "# yerr = sigma_df[((sigma_df[\"Act func\"] == act_func) & (sigma_df[\"Hidden size\"] == hidden))][\"Result\"]\n",
    "\n",
    "# plt.errorbar([0], [251.09375], yerr = [5.931], fmt = 'o', color=\"blue\", capsize=5, label = name)\n",
    "# plt.errorbar([1,2,3], y, yerr = yerr, fmt = 'o', color=\"blue\", capsize=5, label = name)\n",
    "# plt.xticks([0,1,2,3], labels = [\"Interpolation\", \"PyTorch\", \"PyTorch (no grad)\", \"Numpy\"], rotation = 0, fontsize=fs)\n",
    "# plt.yticks(fontsize=fs-2)\n",
    "# plt.grid()\n",
    "# plt.ylabel(r\"Time/prediction ($\\mu s$)\", fontsize=fs)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96262a6f",
   "metadata": {},
   "source": [
    "# Export model params to replicate the analysis in Fortran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "010ee05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183\n",
      "Directory not found. Making new one at ../Models/paramvals_tabeos_single_10_sigmoid\n",
      "Succesfully exported model parameters to CSV file, at ../Models/paramvals_tabeos_single_10_sigmoid\n",
      "183\n",
      "Directory not found. Making new one at ../Models/paramvals_tabeos_single_10_relu\n",
      "Succesfully exported model parameters to CSV file, at ../Models/paramvals_tabeos_single_10_relu\n",
      "563\n",
      "Succesfully exported model parameters to CSV file, at ../Models/paramvals_tabeos_single_20_sigmoid\n",
      "563\n",
      "Succesfully exported model parameters to CSV file, at ../Models/paramvals_tabeos_single_20_relu\n",
      "2903\n",
      "Succesfully exported model parameters to CSV file, at ../Models/paramvals_tabeos_single_50_sigmoid\n",
      "2903\n",
      "Succesfully exported model parameters to CSV file, at ../Models/paramvals_tabeos_single_50_relu\n"
     ]
    }
   ],
   "source": [
    "act_func_names = [\"sigmoid\", \"relu\"]\n",
    "hidden_size_list = [20, 50, 70]\n",
    "hidden_size_list = [10, 20, 50]\n",
    "for hidden_size in hidden_size_list:\n",
    "    for i, act_func in enumerate(act_func_list):\n",
    "        model = Net(nb_of_inputs=3, nb_of_outputs=3, h=[hidden_size, hidden_size], activation_function=act_func)\n",
    "        print(nnc2p.count_parameters(model))\n",
    "        # Export the model\n",
    "        torch.save(model, \"../Models/ignore_me.pt\")\n",
    "        save_name = f\"../Models/paramvals_tabeos_single_{hidden_size}_{act_func_names[i]}\"\n",
    "        nnc2p.export_model(\"../Models/ignore_me.pt\", save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43aa06f",
   "metadata": {},
   "source": [
    "Results will be recorded here:\n",
    "- sigmoid\n",
    "- relu_max, implemented with max function\n",
    "- relu, standard implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b63c89",
   "metadata": {},
   "source": [
    "## Measure speeds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106ef0a5",
   "metadata": {},
   "source": [
    "Wrong: these are for 3 predictions in a row but we have to compare against a single prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "88d245d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fortran_interpolation = np.array([1.1943418979644774e-6, \\\n",
    "#                                   1.2492423057556153e-6, \\\n",
    "#                                   1.4265980124473571e-6, \\\n",
    "#                                   1.1522794961929322e-6, \\\n",
    "#                                   1.3419776558876037e-6, \\\n",
    "#                                   1.2229737639427184e-6, \\\n",
    "#                                   1.2357207536697389e-6, \\\n",
    "#                                   1.1515803337097169e-6, \\\n",
    "#                                   1.1628186106681824e-6, \\\n",
    "#                                   1.1426681280136109e-6, \\\n",
    "#                                   1.1674029231071473e-6, \\\n",
    "#                                   1.1869792342185975e-6, \\\n",
    "#                                   1.2122482657432556e-6, \\\n",
    "#                                   1.2581764459609986e-6, \\\n",
    "#                                   1.2601274251937866e-6, \\\n",
    "#                                   1.2311937808990478e-6, \\\n",
    "#                                   1.3119986057281493e-6, \\\n",
    "#                                   1.2949457168579102e-6, \\\n",
    "#                                   1.3183966875076295e-6, \\\n",
    "#                                   1.1574876308441161e-6, \\\n",
    "#                                   1.2880070209503174e-6\n",
    "#                                  ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb58cb3c",
   "metadata": {},
   "source": [
    "These are for interpolation predicting only one column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "d2064a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "fortran_interpolation = np.array([8.4825992584228511e-7, \\\n",
    "                                  8.2161378860473635e-7, \\\n",
    "                                  8.7507796287536619e-7, \\\n",
    "                                  8.5263025760650636e-7, \\\n",
    "                                  9.0884041786193846e-7, \\\n",
    "                                  9.2787605524063105e-7, \\\n",
    "                                  8.3888393640518191e-7, \\\n",
    "                                  8.0844181776046748e-7, \\\n",
    "                                  7.9883116483688353e-7, \\\n",
    "                                  8.3878827095031742e-7, \\\n",
    "                                  8.0311286449432373e-7\n",
    "                                 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "1da03cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fortran_sigmoid       = {10: [9.3441748619079588e-7, \\\n",
    "                              9.2670011520385738e-7, \\\n",
    "                              9.2636156082153317e-7, \\\n",
    "                              8.8198614120483396e-7, \\\n",
    "                              9.2840200662612914e-7, \\\n",
    "                              8.9005309343338012e-7, \\\n",
    "                              9.2985749244689940e-7, \\\n",
    "                              8.8784492015838626e-7, \\\n",
    "                              8.7760967016220088e-7, \\\n",
    "                              8.7397480010986333e-7, \\\n",
    "                              8.8543587923049932e-7], \n",
    "                         20: [1.2631109356880188e-6, \\\n",
    "                              1.3248761892318727e-6, \\\n",
    "                              1.2622952461242677e-6, \\\n",
    "                              1.3545445203781128e-6, \\\n",
    "                              1.2575612068176268e-6, \\\n",
    "                              1.1978712081909180e-6, \\\n",
    "                              1.2112507820129394e-6, \\\n",
    "                              1.2595268487930299e-6, \\\n",
    "                              1.2371557950973510e-6, \\\n",
    "                              1.3366787433624267e-6\n",
    "                             ],\n",
    "                         50: [2.9304871559143067e-6, \\\n",
    "                              2.7196670174598695e-6, \\\n",
    "                              2.5697495937347413e-6, \\\n",
    "                              2.6253808140754702e-6, \\\n",
    "                              2.5486350655555724e-6, \\\n",
    "                              2.6479148268699645e-6, \\\n",
    "                              2.6181338429450987e-6, \\\n",
    "                              2.5736796855926515e-6, \\\n",
    "                              2.5205017328262330e-6, \\\n",
    "                              2.5094261169433596e-6                             \n",
    "                         ]\n",
    "                        }\n",
    "\n",
    "fortran_relu_max      = {10: [7.3742908239364624e-7, \\\n",
    "                              7.4901795387268063e-7, \\\n",
    "                              7.7237284183502198e-7, \\\n",
    "                              7.5893640518188474e-7, \\\n",
    "                              7.9469406604766843e-7, \\\n",
    "                              7.7821362018585203e-7, \\\n",
    "                              8.4216290712356567e-7, \\\n",
    "                              7.7764701843261717e-7, \\\n",
    "                              7.5764548778533941e-7, \\\n",
    "                              7.6082623004913326e-7\n",
    "                             ],\n",
    "                        20: [9.5538818836212154e-7, \\\n",
    "                             9.8768472671508782e-7, \\\n",
    "                             9.7171586751937859e-7, \\\n",
    "                             9.6920156478881842e-7, \\\n",
    "                             9.4863593578338618e-7, \\\n",
    "                             1.0146088004112243e-6, \\\n",
    "                             9.3995338678359981e-7, \\\n",
    "                             9.4664561748504638e-7, \\\n",
    "                             9.4261842966079711e-7, \\\n",
    "                             9.3299466371536254e-7\n",
    "                            ],\n",
    "                        50: [1.7813495397567748e-6, \\\n",
    "                             1.8087434172630310e-6, \\\n",
    "                             1.8768922090530395e-6, \\\n",
    "                             1.8062906265258790e-6, \\\n",
    "                             1.7930529117584229e-6, \\\n",
    "                             1.8185124397277832e-6, \\\n",
    "                             1.8465325832366944e-6, \\\n",
    "                             1.7979505062103272e-6, \\\n",
    "                             1.7861731052398682e-6, \\\n",
    "                             1.8594285845756530e-6\n",
    "                            ]}\n",
    "\n",
    "fortran_relu          = {10: [7.4908113479614259e-7, \\\n",
    "                              7.5351035594940190e-7, \\\n",
    "                              7.5944864749908447e-7, \\\n",
    "                              7.6549577713012697e-7, \\\n",
    "                              7.7743101119995114e-7, \\\n",
    "                              7.6206517219543459e-7, \\\n",
    "                              7.5476324558258061e-7, \\\n",
    "                              7.5979411602020264e-7, \\\n",
    "                              7.7378511428833013e-7, \\\n",
    "                              7.4373769760131835e-7\n",
    "                             ],\n",
    "                        20: [9.4275051355361941e-7, \\\n",
    "                             9.6708679199218757e-7, \\\n",
    "                             9.6439296007156381e-7, \\\n",
    "                             9.8073935508728031e-7, \\\n",
    "                             1.0076233744621276e-6, \\\n",
    "                             9.8190152645111080e-7, \\\n",
    "                             1.0246781110763550e-6, \\\n",
    "                             1.0190943479537964e-6, \\\n",
    "                             9.9296319484710702e-7, \\\n",
    "                             9.6782040596008292e-7\n",
    "                            ],\n",
    "                        50: [2.0380783081054688e-6, \\\n",
    "                             1.8350322842597962e-6, \\\n",
    "                             1.8680638074874878e-6, \\\n",
    "                             1.8157511353492737e-6, \\\n",
    "                             1.9213995933532717e-6, \\\n",
    "                             1.8739464282989501e-6, \\\n",
    "                             1.7961593866348267e-6, \\\n",
    "                             1.8243160247802734e-6, \\\n",
    "                             1.8296554088592529e-6, \\\n",
    "                             1.8083146810531616e-6\n",
    "                            ]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547d7bcb",
   "metadata": {},
   "source": [
    "Single layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "2ca8548c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fortran_sigmoid_single = {20: [8.8422411680221555e-7, \\\n",
    "                               9.2766052484512329e-7, \\\n",
    "                               9.0931558609008790e-7, \\\n",
    "                               9.2620706558227536e-7, \\\n",
    "                               9.3423449993133547e-7, \\\n",
    "                               9.2991966009140019e-7, \\\n",
    "                               9.5376998186111459e-7, \\\n",
    "                               9.1550111770629883e-7, \\\n",
    "                               9.5793610811233529e-7, \\\n",
    "                               8.7101125717163087e-7\n",
    "                              ],\n",
    "                         50: [1.3135874867439269e-6, \\\n",
    "                              1.2462930679321288e-6, \\\n",
    "                              1.2182465195655822e-6, \\\n",
    "                              1.3025012016296386e-6, \\\n",
    "                              1.3376687765121459e-6, \\\n",
    "                              1.2974005937576295e-6, \\\n",
    "                              1.4645587205886840e-6, \\\n",
    "                              1.3120357990264893e-6, \\\n",
    "                              1.3318451046943665e-6, \\\n",
    "                              1.3591961860656738e-6\n",
    "                             ],\n",
    "                         70: [1.4925893545150757e-6, \\\n",
    "                              1.5304015278816223e-6, \\\n",
    "                              1.5216457247734070e-6, \\\n",
    "                              1.5077395439147949e-6, \\\n",
    "                              1.5441306829452514e-6, \\\n",
    "                              1.6862218379974365e-6, \\\n",
    "                              1.5267245173454285e-6, \\\n",
    "                              1.6295769214630126e-6, \\\n",
    "                              1.4693150520324706e-6, \\\n",
    "                              1.4698832035064696e-6\n",
    "                             ]}\n",
    "\n",
    "fortran_relu_single = {20: [7.4636149406433103e-7, \\\n",
    "                            7.5247341394424438e-7, \\\n",
    "                            7.5171309709548953e-7, \\\n",
    "                            7.8268545866012572e-7, \\\n",
    "                            7.4827289581298829e-7, \\\n",
    "                            7.4540895223617551e-7, \\\n",
    "                            7.5198465585708616e-7, \\\n",
    "                            7.6176834106445316e-7, \\\n",
    "                            7.4094623327255251e-7, \\\n",
    "                            7.7116000652313231e-7\n",
    "                           ],\n",
    "                      50: [9.2674583196640019e-7, \\\n",
    "                           9.5915114879608147e-7, \\\n",
    "                           9.3898320198059085e-7, \\\n",
    "                           9.0106201171875000e-7, \\\n",
    "                           8.8890844583511351e-7, \\\n",
    "                           8.7947177886962894e-7, \\\n",
    "                           8.9343988895416255e-7, \\\n",
    "                           8.9994609355926512e-7, \\\n",
    "                           9.1378533840179443e-7, \\\n",
    "                           9.1908794641494748e-7, \\\n",
    "                           8.9844727516174318e-7\n",
    "                          ],\n",
    "                      70: [1.0014158487319946e-6, \\\n",
    "                           1.1096044778823853e-6, \\\n",
    "                           9.9048733711242668e-7, \\\n",
    "                           1.0040555596351624e-6, \\\n",
    "                           9.7174286842346186e-7, \\\n",
    "                           9.9844294786453252e-7, \\\n",
    "                           9.6122008562088014e-7, \\\n",
    "                           9.9813699722290040e-7, \\\n",
    "                           9.9091988801956185e-7, \\\n",
    "                           9.8674577474594109e-7\n",
    "                          ]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbfd38a",
   "metadata": {},
   "source": [
    "## Analyze speeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "a04ec5c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (8, 3))\n",
    "fortran_timings = [fortran_sigmoid, fortran_relu] # fortran_relu_max\n",
    "sizes = [10, 20, 50]\n",
    "colors = [\"blue\", \"red\", \"green\"]\n",
    "names = [\"Sigmoid\", \"ReLU\", \"ReLU (max)\"]\n",
    "\n",
    "for i, timing in enumerate(fortran_timings):\n",
    "    x    = sizes\n",
    "    y    = []\n",
    "    yerr = []\n",
    "    for s in sizes:\n",
    "        y.append(np.mean(timing[s]))\n",
    "        yerr.append(np.std(timing[s]))\n",
    "    plt.errorbar(x, y, yerr = yerr, fmt = '-o', color=colors[i], capsize=5, label = names[i])\n",
    "# Shade the baseline determined by the linear interpolation methods\n",
    "mu = np.mean(fortran_interpolation)\n",
    "sigma = np.std(fortran_interpolation)\n",
    "lower_bound = mu - sigma\n",
    "upper_bound = mu + sigma\n",
    "plt.axhspan(lower_bound, upper_bound, alpha=0.3, color='gray', label='Interpolation')\n",
    "# plt.legend(fontsize=fs-3)\n",
    "plt.grid()\n",
    "plt.yscale('log')\n",
    "plt.title(\"Two hidden layers\", fontsize=fs)\n",
    "plt.xlabel(r\"Hidden layer size\", fontsize=fs)\n",
    "# plt.ylabel(r\"Time/prediction ($\\mu s$)\", fontsize=fs)\n",
    "plt.savefig(\"../Plots/Final/nneos_timing_measurements_fortran.pdf\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "8c0c7211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x300 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1100x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (8, 3))\n",
    "fortran_timings = [fortran_sigmoid, fortran_relu] # fortran_relu_max\n",
    "fortran_timings_single = [fortran_sigmoid_single, fortran_relu_single] # fortran_relu_max\n",
    "sizes_single = [20, 50, 70]\n",
    "sizes = [10, 20, 50] \n",
    "colors = [\"blue\", \"red\", \"green\"]\n",
    "names = [\"Sigmoid\", \"ReLU\", \"ReLU (max)\"]\n",
    "\n",
    "# Shade the baseline determined by the linear interpolation methods\n",
    "mu = np.mean(fortran_interpolation)\n",
    "sigma = np.std(fortran_interpolation)\n",
    "lower_bound = mu - sigma\n",
    "upper_bound = mu + sigma\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(11,3), sharey=True)\n",
    "ax1, ax2 = axs\n",
    "\n",
    "for ax in axs:\n",
    "    if ax == ax1:\n",
    "        timings = fortran_timings_single\n",
    "        size_list = sizes_single\n",
    "        ax.set_ylabel(r\"Time/prediction ($\\mu s$)\", fontsize=fs)\n",
    "        ax.set_title(\"One hidden layer\", fontsize=fs)\n",
    "    else:\n",
    "        timings = fortran_timings\n",
    "        size_list = sizes\n",
    "        ax.set_title(\"Two hidden layers\", fontsize=fs)\n",
    "    for i, timing in enumerate(timings):\n",
    "        x    = size_list\n",
    "        y    = []\n",
    "        yerr = []\n",
    "        for s in size_list:\n",
    "            y.append(np.mean(timing[s]))\n",
    "            yerr.append(np.std(timing[s]))\n",
    "        ax.errorbar(x, y, yerr = yerr, fmt = '-o', color=colors[i], capsize=5, label = names[i])\n",
    "    # Shared:\n",
    "    ax1.legend(fontsize=fs-3, loc=\"upper left\")\n",
    "    ax.grid()\n",
    "    ax.set_xlabel(r\"Hidden layer size\", fontsize=fs)\n",
    "\n",
    "    ax.axhspan(lower_bound, upper_bound, alpha=0.3, color='gray', label='Interpolation')\n",
    "    ax.set_yscale('log')\n",
    "\n",
    "plt.savefig(\"../Plots/Final/nneos_timing_measurements_fortran_both.pdf\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a601dbb",
   "metadata": {},
   "source": [
    "For the report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "80f1ff78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.84905058145523e-07\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(fortran_relu[20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d3ae53",
   "metadata": {},
   "source": [
    "What if it is in terms of nb of params?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "ba1d4794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1100x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (11, 3))\n",
    "fortran_timings = [fortran_sigmoid_single, fortran_relu_single] # fortran_relu_max\n",
    "\n",
    "colors = [\"blue\", \"red\", \"green\"]\n",
    "names = [\"Sigmoid\", \"ReLU\", \"ReLU (max)\"]\n",
    "\n",
    "## Single\n",
    "sizes = [20, 50, 70]\n",
    "for i, timing in enumerate([fortran_sigmoid_single, fortran_relu_single]):\n",
    "    x    = [143, 353, 493]\n",
    "    y    = []\n",
    "    yerr = []\n",
    "    for s in sizes:\n",
    "        y.append(np.mean(timing[s]))\n",
    "        yerr.append(np.std(timing[s]))\n",
    "    plt.errorbar(x, y, yerr = yerr, fmt = '-o', color=colors[i], capsize=5, label = names[i])\n",
    "    \n",
    "## Double\n",
    "sizes = [10, 20, 50]\n",
    "for i, timing in enumerate([fortran_sigmoid, fortran_relu]):\n",
    "    x    = [183, 563, 2903]\n",
    "    y    = []\n",
    "    yerr = []\n",
    "    for s in sizes:\n",
    "        y.append(np.mean(timing[s]))\n",
    "        yerr.append(np.std(timing[s]))\n",
    "    plt.errorbar(x, y, yerr = yerr, fmt = '-o', color=colors[i], capsize=5, label = names[i])\n",
    "    \n",
    "# Shade the baseline determined by the linear interpolation methods\n",
    "mu = np.mean(fortran_interpolation)\n",
    "sigma = np.std(fortran_interpolation)\n",
    "lower_bound = mu - sigma\n",
    "upper_bound = mu + sigma\n",
    "plt.axhspan(lower_bound, upper_bound, alpha=0.3, color='gray', label='Interpolation')\n",
    "plt.legend(fontsize=fs-3)\n",
    "plt.grid()\n",
    "plt.yscale('log')\n",
    "plt.xlabel(r\"Number of parameters\", fontsize=fs)\n",
    "plt.ylabel(r\"Time/prediction ($\\mu s$)\", fontsize=fs)\n",
    "# plt.savefig(\"../Plots/Final/nneos_timing_measurements_fortran_single.pdf\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "b3ef8205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cutoff = 5\n",
    "\n",
    "# # Get vals more clearly, do cutoff\n",
    "# xvals = xticks[:cutoff]\n",
    "# yvals = mu_list[:cutoff]\n",
    "# yerrs = sigma_list[:cutoff]\n",
    "# # Swap based on performance  ## NOT WORKING FOR SOME REASON\n",
    "# # sort_ind = np.argsort(yvals)[::-1]\n",
    "# # # Sort\n",
    "# # xvals = my_sort(xvals, sort_ind)\n",
    "# # yvals = my_sort(yvals, sort_ind)\n",
    "# # yerrs = my_sort(yerrs, sort_ind)\n",
    "# # method_names = my_sort(method_names, sort_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "8036f717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Preparation\n",
    "# plt.errorbar(xticks, yvals, yerrs, fmt=\"o\", color=\"blue\", capsize=5)\n",
    "# plt.xticks(ticks=xticks, labels = method_names, rotation=30)\n",
    "# plt.ylabel(\"CPU time/prediction (s)\")\n",
    "# plt.grid()\n",
    "# plt.savefig(\"Time comparison single prediction\")\n",
    "# # plt.savefig(\"interpolation_neuralnet_speed_comparison.pdf\", bbox_inches='tight')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377b0cbf",
   "metadata": {
    "id": "377b0cbf"
   },
   "source": [
    "# Second goal: NNC2P"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf95fa58",
   "metadata": {
    "id": "bf95fa58"
   },
   "source": [
    "__TO DO__ think about design of architecture AND fix the conserved variable values -- I think they were not computed correctly before! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b454181",
   "metadata": {
    "id": "2b454181"
   },
   "source": [
    "__NNC2P__: try to replicate the full C2P conversion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4cbd43",
   "metadata": {},
   "source": [
    "Generate training data through sampling and looking-up in the table. Save/load from our eos tables dir, where all (too large) datasets related to the EOS tables are saved to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f29af16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/Coding/Datasets/eos_tables\n"
     ]
    }
   ],
   "source": [
    "print(eos_tables_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76af5a83",
   "metadata": {},
   "source": [
    "Construct datasets if desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "99825613",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Open EOS table\n",
    "# eos_table = physics.read_eos_table(os.path.join(eos_tables_dir, eos_table_filename))\n",
    "# physics.generate_c2p_data_tabular_eos(eos_table, number_of_points=100000, save_name=os.path.join(eos_tables_dir, \"train_c2p_data.h5\"))\n",
    "# eos_table.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67325d0b",
   "metadata": {},
   "source": [
    "Load in the dataset afterwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3f177869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset afterwards\n",
    "train_c2p_table = h5py.File(os.path.join(eos_tables_dir, \"train_c2p_data.h5\"), 'r')\n",
    "# Get the data saved in the HDF5 file for training\n",
    "# NOTE have to convert to float not double, otherwise PyTorch gives an error\n",
    "features = train_c2p_table[\"features\"][:].astype(np.float32)\n",
    "labels = train_c2p_table[\"labels\"][:].astype(np.float32)\n",
    "# # See what's in there\n",
    "# for key in train_c2p_table:\n",
    "#     print(key)\n",
    "\n",
    "# Close the file\n",
    "train_c2p_table.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc9f687",
   "metadata": {},
   "source": [
    "Explore this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "76c0ffe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min of input\n",
      "[3.0239964e+00 1.9037802e+01 2.2053352e+01 4.9999999e-03]\n",
      "Max of input\n",
      "[16.18306  38.488518 38.472675  0.655   ]\n",
      "---\n",
      "Min of output\n",
      "[17.457466]\n",
      "Max of output\n",
      "[38.162045]\n"
     ]
    }
   ],
   "source": [
    "print(\"Min of input\")\n",
    "print(np.min(features, axis=0))\n",
    "print(\"Max of input\")\n",
    "print(np.max(features, axis=0))\n",
    "print(\"---\")\n",
    "print(\"Min of output\")\n",
    "print(np.min(labels, axis=0))\n",
    "print(\"Max of output\")\n",
    "print(np.max(labels, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4a0dd3",
   "metadata": {},
   "source": [
    "### Convert to Torch `Datasets` for training the network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00a58be",
   "metadata": {
    "id": "ec6d6047"
   },
   "source": [
    "Get the training data as DataSet and DataLoader objects. Note on normalization: we fit transform on the training data, then use the fitted scaler object to transform (i.e. using same transformation as the training data) the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c5ae5950",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1126,
     "status": "ok",
     "timestamp": 1681398709169,
     "user": {
      "displayName": "Thibeau Wouters",
      "userId": "14702334917940433667"
     },
     "user_tz": -120
    },
    "id": "ec910284",
    "outputId": "4f15e095-7252-40dc-c90d-2bafae1c6cb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size training data: 75000\n",
      "Size testing data: 25000\n",
      "Size training data (cutoff): 75000\n"
     ]
    }
   ],
   "source": [
    "# For normalization, use sklearn's StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# Do train test split here\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, random_state=42)\n",
    "# \"Cutoff\": only use certain portion of the data for training and testing, to speed up training when tuning architecture \n",
    "# Note - our sampling procedure above guarantees we can ignore the cutoff, unlike the NNEOS code above which had 4 million datapoints in total\n",
    "cutoff = 1\n",
    "print(f\"Size training data: {len(train_features)}\")\n",
    "print(f\"Size testing data: {len(test_features)}\")\n",
    "end = int(cutoff*len(train_features))\n",
    "train_features = train_features[:end]\n",
    "train_labels = train_labels[:end]\n",
    "end = int(cutoff*len(test_features))\n",
    "test_features = test_features[:end]\n",
    "test_labels = test_labels[:end]\n",
    "print(f\"Size training data (cutoff): {len(train_features)}\")\n",
    "# Convert to PyTorch Datasets as we defined them\n",
    "train_dataset = data.HDF5Dataset(train_features, train_labels, normalization_function = scaler.fit_transform) \n",
    "test_dataset  = data.HDF5Dataset(test_features, test_labels, normalization_function = scaler.transform)\n",
    "# Then create dataloaders, with batch size 32, from datasets\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = 32)\n",
    "test_dataloader  = DataLoader(test_dataset, batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca38f996",
   "metadata": {},
   "source": [
    "Get the scaler's attributes: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f0b1f85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler mean: [ 9.58863041 30.23533938 30.7298278   0.3288648 ], \n",
      " Scaler std: [3.76007097 4.0125932  3.91964587 0.1902224 ]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Scaler mean: {scaler.mean_}, \\n Scaler std: {scaler.scale_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f631da5",
   "metadata": {},
   "source": [
    "### Archive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e96de6",
   "metadata": {
    "id": "24e96de6"
   },
   "source": [
    "Create a new instance of the Net:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d08aa592",
   "metadata": {
    "id": "d08aa592",
    "outputId": "1a3ec4f4-f574-496b-d3a8-25cfc9c30361"
   },
   "outputs": [],
   "source": [
    "model = Net(nb_of_inputs = 4, nb_of_outputs = 1, h=[600, 200], activation_function=torch.nn.ReLU)\n",
    "model = model.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "504399cb",
   "metadata": {
    "id": "504399cb",
    "outputId": "aa1b5560-9e9b-461b-a9e5-3eb90573d2c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123400"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnc2p.count_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da83cead",
   "metadata": {
    "id": "da83cead"
   },
   "source": [
    "Create a trainer object from it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7fffc1e4",
   "metadata": {
    "id": "7fffc1e4"
   },
   "outputs": [],
   "source": [
    "trainer = nnc2p.Trainer(model, 1e-3, train_dataloader=train_dataloader, test_dataloader=test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0369872",
   "metadata": {
    "id": "e0369872",
    "outputId": "324b4965-3166-4d96-dac7-ff9fa27aae78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model for 500 epochs.\n",
      "\n",
      " Epoch 0 \n",
      " --------------\n",
      "Train loss: 5.70E-02\n",
      "Test  loss: 5.92E-02\n",
      "\n",
      " Epoch 1 \n",
      " --------------\n",
      "Train loss: 5.69E-02\n",
      "Test  loss: 5.90E-02\n",
      "\n",
      " Epoch 2 \n",
      " --------------\n",
      "Train loss: 5.66E-02\n",
      "Test  loss: 5.87E-02\n",
      "\n",
      " Epoch 3 \n",
      " --------------\n",
      "Train loss: 5.64E-02\n",
      "Test  loss: 5.85E-02\n",
      "\n",
      " Epoch 4 \n",
      " --------------\n",
      "Train loss: 5.63E-02\n",
      "Test  loss: 5.84E-02\n",
      "\n",
      " Epoch 5 \n",
      " --------------\n",
      "Train loss: 5.63E-02\n",
      "Test  loss: 5.83E-02\n",
      "\n",
      " Epoch 6 \n",
      " --------------\n",
      "Train loss: 5.61E-02\n",
      "Test  loss: 5.81E-02\n",
      "\n",
      " Epoch 7 \n",
      " --------------\n",
      "Train loss: 5.59E-02\n",
      "Test  loss: 5.80E-02\n",
      "\n",
      " Epoch 8 \n",
      " --------------\n",
      "Train loss: 5.57E-02\n",
      "Test  loss: 5.78E-02\n",
      "\n",
      " Epoch 9 \n",
      " --------------\n",
      "Train loss: 5.57E-02\n",
      "Test  loss: 5.78E-02\n",
      "\n",
      " Epoch 10 \n",
      " --------------\n",
      "Train loss: 5.53E-02\n",
      "Test  loss: 5.74E-02\n",
      "\n",
      " Epoch 11 \n",
      " --------------\n",
      "Train loss: 5.54E-02\n",
      "Test  loss: 5.75E-02\n",
      "\n",
      " Epoch 12 \n",
      " --------------\n",
      "Train loss: 5.52E-02\n",
      "Test  loss: 5.73E-02\n",
      "\n",
      " Epoch 13 \n",
      " --------------\n",
      "Train loss: 5.51E-02\n",
      "Test  loss: 5.71E-02\n",
      "\n",
      " Epoch 14 \n",
      " --------------\n",
      "Train loss: 5.50E-02\n",
      "Test  loss: 5.71E-02\n",
      "\n",
      " Epoch 15 \n",
      " --------------\n",
      "Train loss: 5.49E-02\n",
      "Test  loss: 5.69E-02\n",
      "\n",
      " Epoch 16 \n",
      " --------------\n",
      "Train loss: 5.47E-02\n",
      "Test  loss: 5.67E-02\n",
      "\n",
      " Epoch 17 \n",
      " --------------\n",
      "Train loss: 5.45E-02\n",
      "Test  loss: 5.65E-02\n",
      "\n",
      " Epoch 18 \n",
      " --------------\n",
      "Train loss: 5.44E-02\n",
      "Test  loss: 5.64E-02\n",
      "\n",
      " Epoch 19 \n",
      " --------------\n",
      "Train loss: 5.43E-02\n",
      "Test  loss: 5.63E-02\n",
      "\n",
      " Epoch 20 \n",
      " --------------\n",
      "Train loss: 5.42E-02\n",
      "Test  loss: 5.62E-02\n",
      "\n",
      " Epoch 21 \n",
      " --------------\n",
      "Train loss: 5.40E-02\n",
      "Test  loss: 5.61E-02\n",
      "\n",
      " Epoch 22 \n",
      " --------------\n",
      "Train loss: 5.39E-02\n",
      "Test  loss: 5.60E-02\n",
      "\n",
      " Epoch 23 \n",
      " --------------\n",
      "Train loss: 5.39E-02\n",
      "Test  loss: 5.60E-02\n",
      "\n",
      " Epoch 24 \n",
      " --------------\n",
      "Train loss: 5.39E-02\n",
      "Test  loss: 5.59E-02\n",
      "\n",
      " Epoch 25 \n",
      " --------------\n",
      "Train loss: 5.39E-02\n",
      "Test  loss: 5.59E-02\n",
      "\n",
      " Epoch 26 \n",
      " --------------\n",
      "Train loss: 5.38E-02\n",
      "Test  loss: 5.58E-02\n",
      "\n",
      " Epoch 27 \n",
      " --------------\n",
      "Train loss: 5.38E-02\n",
      "Test  loss: 5.58E-02\n",
      "\n",
      " Epoch 28 \n",
      " --------------\n",
      "Train loss: 5.37E-02\n",
      "Test  loss: 5.57E-02\n",
      "\n",
      " Epoch 29 \n",
      " --------------\n",
      "Train loss: 5.36E-02\n",
      "Test  loss: 5.56E-02\n",
      "\n",
      " Epoch 30 \n",
      " --------------\n",
      "Train loss: 5.35E-02\n",
      "Test  loss: 5.55E-02\n",
      "\n",
      " Epoch 31 \n",
      " --------------\n",
      "Train loss: 5.35E-02\n",
      "Test  loss: 5.54E-02\n",
      "\n",
      " Epoch 32 \n",
      " --------------\n",
      "Train loss: 5.35E-02\n",
      "Test  loss: 5.54E-02\n",
      "\n",
      " Epoch 33 \n",
      " --------------\n",
      "Train loss: 5.34E-02\n",
      "Test  loss: 5.53E-02\n",
      "\n",
      " Epoch 34 \n",
      " --------------\n",
      "Train loss: 5.34E-02\n",
      "Test  loss: 5.53E-02\n",
      "\n",
      " Epoch 35 \n",
      " --------------\n",
      "Train loss: 5.33E-02\n",
      "Test  loss: 5.53E-02\n",
      "\n",
      " Epoch 36 \n",
      " --------------\n",
      "Train loss: 5.29E-02\n",
      "Test  loss: 5.49E-02\n",
      "\n",
      " Epoch 37 \n",
      " --------------\n",
      "Train loss: 5.30E-02\n",
      "Test  loss: 5.49E-02\n",
      "\n",
      " Epoch 38 \n",
      " --------------\n",
      "Train loss: 5.28E-02\n",
      "Test  loss: 5.47E-02\n",
      "\n",
      " Epoch 39 \n",
      " --------------\n",
      "Train loss: 5.29E-02\n",
      "Test  loss: 5.48E-02\n",
      "\n",
      " Epoch 40 \n",
      " --------------\n",
      "Train loss: 5.27E-02\n",
      "Test  loss: 5.46E-02\n",
      "\n",
      " Epoch 41 \n",
      " --------------\n",
      "Train loss: 5.27E-02\n",
      "Test  loss: 5.46E-02\n",
      "\n",
      " Epoch 42 \n",
      " --------------\n",
      "Train loss: 5.26E-02\n",
      "Test  loss: 5.45E-02\n",
      "\n",
      " Epoch 43 \n",
      " --------------\n",
      "Train loss: 5.27E-02\n",
      "Test  loss: 5.46E-02\n",
      "\n",
      " Epoch 44 \n",
      " --------------\n",
      "Train loss: 5.28E-02\n",
      "Test  loss: 5.48E-02\n",
      "\n",
      " Epoch 45 \n",
      " --------------\n",
      "Train loss: 5.27E-02\n",
      "Test  loss: 5.46E-02\n",
      "\n",
      " Epoch 46 \n",
      " --------------\n",
      "Train loss: 5.27E-02\n",
      "Test  loss: 5.46E-02\n",
      "\n",
      " Epoch 47 \n",
      " --------------\n",
      "Adapting learning rate to 0.0005\n",
      "Train loss: 5.28E-02\n",
      "Test  loss: 5.47E-02\n",
      "\n",
      " Epoch 48 \n",
      " --------------\n",
      "Train loss: 5.02E-02\n",
      "Test  loss: 5.23E-02\n",
      "\n",
      " Epoch 49 \n",
      " --------------\n",
      "Train loss: 5.01E-02\n",
      "Test  loss: 5.23E-02\n",
      "\n",
      " Epoch 50 \n",
      " --------------\n",
      "Train loss: 5.01E-02\n",
      "Test  loss: 5.22E-02\n",
      "\n",
      " Epoch 51 \n",
      " --------------\n",
      "Train loss: 5.01E-02\n",
      "Test  loss: 5.22E-02\n",
      "\n",
      " Epoch 52 \n",
      " --------------\n",
      "Train loss: 5.00E-02\n",
      "Test  loss: 5.21E-02\n",
      "\n",
      " Epoch 53 \n",
      " --------------\n",
      "Train loss: 5.00E-02\n",
      "Test  loss: 5.21E-02\n",
      "\n",
      " Epoch 54 \n",
      " --------------\n",
      "Train loss: 5.00E-02\n",
      "Test  loss: 5.21E-02\n",
      "\n",
      " Epoch 55 \n",
      " --------------\n",
      "Train loss: 4.99E-02\n",
      "Test  loss: 5.21E-02\n",
      "\n",
      " Epoch 56 \n",
      " --------------\n",
      "Train loss: 4.99E-02\n",
      "Test  loss: 5.20E-02\n",
      "\n",
      " Epoch 57 \n",
      " --------------\n",
      "Train loss: 4.99E-02\n",
      "Test  loss: 5.20E-02\n",
      "\n",
      " Epoch 58 \n",
      " --------------\n",
      "Train loss: 4.98E-02\n",
      "Test  loss: 5.19E-02\n",
      "\n",
      " Epoch 59 \n",
      " --------------\n",
      "Train loss: 4.98E-02\n",
      "Test  loss: 5.19E-02\n",
      "\n",
      " Epoch 60 \n",
      " --------------\n",
      "Train loss: 4.98E-02\n",
      "Test  loss: 5.19E-02\n",
      "\n",
      " Epoch 61 \n",
      " --------------\n",
      "Train loss: 4.98E-02\n",
      "Test  loss: 5.18E-02\n",
      "\n",
      " Epoch 62 \n",
      " --------------\n",
      "Train loss: 4.97E-02\n",
      "Test  loss: 5.18E-02\n",
      "\n",
      " Epoch 63 \n",
      " --------------\n",
      "Train loss: 4.97E-02\n",
      "Test  loss: 5.17E-02\n",
      "\n",
      " Epoch 64 \n",
      " --------------\n",
      "Train loss: 4.97E-02\n",
      "Test  loss: 5.17E-02\n",
      "\n",
      " Epoch 65 \n",
      " --------------\n",
      "Train loss: 4.96E-02\n",
      "Test  loss: 5.17E-02\n",
      "\n",
      " Epoch 66 \n",
      " --------------\n",
      "Train loss: 4.96E-02\n",
      "Test  loss: 5.16E-02\n",
      "\n",
      " Epoch 67 \n",
      " --------------\n",
      "Train loss: 4.96E-02\n",
      "Test  loss: 5.16E-02\n",
      "\n",
      " Epoch 68 \n",
      " --------------\n",
      "Train loss: 4.95E-02\n",
      "Test  loss: 5.16E-02\n",
      "\n",
      " Epoch 69 \n",
      " --------------\n",
      "Train loss: 4.95E-02\n",
      "Test  loss: 5.15E-02\n",
      "\n",
      " Epoch 70 \n",
      " --------------\n",
      "Train loss: 4.95E-02\n",
      "Test  loss: 5.15E-02\n",
      "\n",
      " Epoch 71 \n",
      " --------------\n",
      "Train loss: 4.95E-02\n",
      "Test  loss: 5.15E-02\n",
      "\n",
      " Epoch 72 \n",
      " --------------\n",
      "Train loss: 4.94E-02\n",
      "Test  loss: 5.14E-02\n",
      "\n",
      " Epoch 73 \n",
      " --------------\n",
      "Train loss: 4.94E-02\n",
      "Test  loss: 5.14E-02\n",
      "\n",
      " Epoch 74 \n",
      " --------------\n",
      "Train loss: 4.94E-02\n",
      "Test  loss: 5.14E-02\n",
      "\n",
      " Epoch 75 \n",
      " --------------\n",
      "Train loss: 4.94E-02\n",
      "Test  loss: 5.13E-02\n",
      "\n",
      " Epoch 76 \n",
      " --------------\n",
      "Train loss: 4.93E-02\n",
      "Test  loss: 5.13E-02\n",
      "\n",
      " Epoch 77 \n",
      " --------------\n",
      "Train loss: 4.93E-02\n",
      "Test  loss: 5.13E-02\n",
      "\n",
      " Epoch 78 \n",
      " --------------\n",
      "Train loss: 4.93E-02\n",
      "Test  loss: 5.13E-02\n",
      "\n",
      " Epoch 79 \n",
      " --------------\n",
      "Train loss: 4.93E-02\n",
      "Test  loss: 5.13E-02\n",
      "\n",
      " Epoch 80 \n",
      " --------------\n",
      "Train loss: 4.93E-02\n",
      "Test  loss: 5.12E-02\n",
      "\n",
      " Epoch 81 \n",
      " --------------\n",
      "Train loss: 4.93E-02\n",
      "Test  loss: 5.12E-02\n",
      "\n",
      " Epoch 82 \n",
      " --------------\n",
      "Train loss: 4.92E-02\n",
      "Test  loss: 5.12E-02\n",
      "\n",
      " Epoch 83 \n",
      " --------------\n",
      "Train loss: 4.92E-02\n",
      "Test  loss: 5.12E-02\n",
      "\n",
      " Epoch 84 \n",
      " --------------\n",
      "Train loss: 4.92E-02\n",
      "Test  loss: 5.11E-02\n",
      "\n",
      " Epoch 85 \n",
      " --------------\n",
      "Train loss: 4.92E-02\n",
      "Test  loss: 5.12E-02\n",
      "\n",
      " Epoch 86 \n",
      " --------------\n",
      "Train loss: 4.92E-02\n",
      "Test  loss: 5.11E-02\n",
      "\n",
      " Epoch 87 \n",
      " --------------\n",
      "Train loss: 4.92E-02\n",
      "Test  loss: 5.11E-02\n",
      "\n",
      " Epoch 88 \n",
      " --------------\n",
      "Train loss: 4.91E-02\n",
      "Test  loss: 5.11E-02\n",
      "\n",
      " Epoch 89 \n",
      " --------------\n",
      "Train loss: 4.91E-02\n",
      "Test  loss: 5.10E-02\n",
      "\n",
      " Epoch 90 \n",
      " --------------\n",
      "Train loss: 4.91E-02\n",
      "Test  loss: 5.10E-02\n",
      "\n",
      " Epoch 91 \n",
      " --------------\n",
      "Train loss: 4.91E-02\n",
      "Test  loss: 5.10E-02\n",
      "\n",
      " Epoch 92 \n",
      " --------------\n",
      "Train loss: 4.90E-02\n",
      "Test  loss: 5.10E-02\n",
      "\n",
      " Epoch 93 \n",
      " --------------\n",
      "Train loss: 4.91E-02\n",
      "Test  loss: 5.10E-02\n",
      "\n",
      " Epoch 94 \n",
      " --------------\n",
      "Train loss: 4.90E-02\n",
      "Test  loss: 5.10E-02\n",
      "\n",
      " Epoch 95 \n",
      " --------------\n",
      "Train loss: 4.90E-02\n",
      "Test  loss: 5.10E-02\n",
      "\n",
      " Epoch 96 \n",
      " --------------\n",
      "Train loss: 4.90E-02\n",
      "Test  loss: 5.09E-02\n",
      "\n",
      " Epoch 97 \n",
      " --------------\n",
      "Train loss: 4.89E-02\n",
      "Test  loss: 5.09E-02\n",
      "\n",
      " Epoch 98 \n",
      " --------------\n",
      "Train loss: 4.89E-02\n",
      "Test  loss: 5.09E-02\n",
      "\n",
      " Epoch 99 \n",
      " --------------\n",
      "Train loss: 4.89E-02\n",
      "Test  loss: 5.09E-02\n",
      "\n",
      " Epoch 100 \n",
      " --------------\n",
      "Train loss: 4.89E-02\n",
      "Test  loss: 5.09E-02\n",
      "\n",
      " Epoch 101 \n",
      " --------------\n",
      "Train loss: 4.88E-02\n",
      "Test  loss: 5.08E-02\n",
      "\n",
      " Epoch 102 \n",
      " --------------\n",
      "Train loss: 4.88E-02\n",
      "Test  loss: 5.08E-02\n",
      "\n",
      " Epoch 103 \n",
      " --------------\n",
      "Train loss: 4.88E-02\n",
      "Test  loss: 5.08E-02\n",
      "\n",
      " Epoch 104 \n",
      " --------------\n",
      "Train loss: 4.87E-02\n",
      "Test  loss: 5.08E-02\n",
      "\n",
      " Epoch 105 \n",
      " --------------\n",
      "Train loss: 4.87E-02\n",
      "Test  loss: 5.08E-02\n",
      "\n",
      " Epoch 106 \n",
      " --------------\n",
      "Train loss: 4.87E-02\n",
      "Test  loss: 5.07E-02\n",
      "\n",
      " Epoch 107 \n",
      " --------------\n",
      "Train loss: 4.87E-02\n",
      "Test  loss: 5.07E-02\n",
      "\n",
      " Epoch 108 \n",
      " --------------\n",
      "Train loss: 4.87E-02\n",
      "Test  loss: 5.07E-02\n",
      "\n",
      " Epoch 109 \n",
      " --------------\n",
      "Train loss: 4.86E-02\n",
      "Test  loss: 5.07E-02\n",
      "\n",
      " Epoch 110 \n",
      " --------------\n",
      "Train loss: 4.86E-02\n",
      "Test  loss: 5.07E-02\n",
      "\n",
      " Epoch 111 \n",
      " --------------\n",
      "Train loss: 4.86E-02\n",
      "Test  loss: 5.07E-02\n",
      "\n",
      " Epoch 112 \n",
      " --------------\n",
      "Train loss: 4.86E-02\n",
      "Test  loss: 5.06E-02\n",
      "\n",
      " Epoch 113 \n",
      " --------------\n",
      "Train loss: 4.85E-02\n",
      "Test  loss: 5.06E-02\n",
      "\n",
      " Epoch 114 \n",
      " --------------\n",
      "Train loss: 4.85E-02\n",
      "Test  loss: 5.06E-02\n",
      "\n",
      " Epoch 115 \n",
      " --------------\n",
      "Train loss: 4.85E-02\n",
      "Test  loss: 5.06E-02\n",
      "\n",
      " Epoch 116 \n",
      " --------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.85E-02\n",
      "Test  loss: 5.05E-02\n",
      "\n",
      " Epoch 117 \n",
      " --------------\n",
      "Train loss: 4.85E-02\n",
      "Test  loss: 5.05E-02\n",
      "\n",
      " Epoch 118 \n",
      " --------------\n",
      "Train loss: 4.84E-02\n",
      "Test  loss: 5.05E-02\n",
      "\n",
      " Epoch 119 \n",
      " --------------\n",
      "Train loss: 4.84E-02\n",
      "Test  loss: 5.05E-02\n",
      "\n",
      " Epoch 120 \n",
      " --------------\n",
      "Train loss: 4.84E-02\n",
      "Test  loss: 5.05E-02\n",
      "\n",
      " Epoch 121 \n",
      " --------------\n",
      "Train loss: 4.84E-02\n",
      "Test  loss: 5.05E-02\n",
      "\n",
      " Epoch 122 \n",
      " --------------\n",
      "Train loss: 4.84E-02\n",
      "Test  loss: 5.04E-02\n",
      "\n",
      " Epoch 123 \n",
      " --------------\n",
      "Train loss: 4.84E-02\n",
      "Test  loss: 5.05E-02\n",
      "\n",
      " Epoch 124 \n",
      " --------------\n",
      "Train loss: 4.84E-02\n",
      "Test  loss: 5.04E-02\n",
      "\n",
      " Epoch 125 \n",
      " --------------\n",
      "Train loss: 4.84E-02\n",
      "Test  loss: 5.04E-02\n",
      "\n",
      " Epoch 126 \n",
      " --------------\n",
      "Train loss: 4.84E-02\n",
      "Test  loss: 5.04E-02\n",
      "\n",
      " Epoch 127 \n",
      " --------------\n",
      "Train loss: 4.83E-02\n",
      "Test  loss: 5.04E-02\n",
      "\n",
      " Epoch 128 \n",
      " --------------\n",
      "Train loss: 4.83E-02\n",
      "Test  loss: 5.04E-02\n",
      "\n",
      " Epoch 129 \n",
      " --------------\n",
      "Train loss: 4.83E-02\n",
      "Test  loss: 5.04E-02\n",
      "\n",
      " Epoch 130 \n",
      " --------------\n",
      "Train loss: 4.83E-02\n",
      "Test  loss: 5.03E-02\n",
      "\n",
      " Epoch 131 \n",
      " --------------\n",
      "Train loss: 4.83E-02\n",
      "Test  loss: 5.03E-02\n",
      "\n",
      " Epoch 132 \n",
      " --------------\n",
      "Train loss: 4.83E-02\n",
      "Test  loss: 5.04E-02\n",
      "\n",
      " Epoch 133 \n",
      " --------------\n",
      "Train loss: 4.83E-02\n",
      "Test  loss: 5.03E-02\n",
      "\n",
      " Epoch 134 \n",
      " --------------\n",
      "Train loss: 4.83E-02\n",
      "Test  loss: 5.03E-02\n",
      "\n",
      " Epoch 135 \n",
      " --------------\n",
      "Train loss: 4.82E-02\n",
      "Test  loss: 5.02E-02\n",
      "\n",
      " Epoch 136 \n",
      " --------------\n",
      "Train loss: 4.83E-02\n",
      "Test  loss: 5.03E-02\n",
      "\n",
      " Epoch 137 \n",
      " --------------\n",
      "Train loss: 4.82E-02\n",
      "Test  loss: 5.02E-02\n",
      "\n",
      " Epoch 138 \n",
      " --------------\n",
      "Train loss: 4.82E-02\n",
      "Test  loss: 5.03E-02\n",
      "\n",
      " Epoch 139 \n",
      " --------------\n",
      "Train loss: 4.82E-02\n",
      "Test  loss: 5.03E-02\n",
      "\n",
      " Epoch 140 \n",
      " --------------\n",
      "Adapting learning rate to 0.00025\n",
      "Train loss: 4.82E-02\n",
      "Test  loss: 5.03E-02\n",
      "\n",
      " Epoch 141 \n",
      " --------------\n",
      "Train loss: 4.80E-02\n",
      "Test  loss: 5.02E-02\n",
      "\n",
      " Epoch 142 \n",
      " --------------\n",
      "Train loss: 4.80E-02\n",
      "Test  loss: 5.02E-02\n",
      "\n",
      " Epoch 143 \n",
      " --------------\n",
      "Train loss: 4.80E-02\n",
      "Test  loss: 5.02E-02\n",
      "\n",
      " Epoch 144 \n",
      " --------------\n",
      "Train loss: 4.79E-02\n",
      "Test  loss: 5.02E-02\n",
      "\n",
      " Epoch 145 \n",
      " --------------\n",
      "Train loss: 4.79E-02\n",
      "Test  loss: 5.01E-02\n",
      "\n",
      " Epoch 146 \n",
      " --------------\n",
      "Train loss: 4.79E-02\n",
      "Test  loss: 5.02E-02\n",
      "\n",
      " Epoch 147 \n",
      " --------------\n",
      "Train loss: 4.79E-02\n",
      "Test  loss: 5.02E-02\n",
      "\n",
      " Epoch 148 \n",
      " --------------\n",
      "Train loss: 4.79E-02\n",
      "Test  loss: 5.02E-02\n",
      "\n",
      " Epoch 149 \n",
      " --------------\n",
      "Train loss: 4.79E-02\n",
      "Test  loss: 5.02E-02\n",
      "\n",
      " Epoch 150 \n",
      " --------------\n",
      "Train loss: 4.79E-02\n",
      "Test  loss: 5.01E-02\n",
      "\n",
      " Epoch 151 \n",
      " --------------\n",
      "Train loss: 4.79E-02\n",
      "Test  loss: 5.01E-02\n",
      "\n",
      " Epoch 152 \n",
      " --------------\n",
      "Train loss: 4.79E-02\n",
      "Test  loss: 5.02E-02\n",
      "\n",
      " Epoch 153 \n",
      " --------------\n",
      "Adapting learning rate to 0.000125\n",
      "Train loss: 4.79E-02\n",
      "Test  loss: 5.01E-02\n",
      "\n",
      " Epoch 154 \n",
      " --------------\n",
      "Train loss: 4.75E-02\n",
      "Test  loss: 4.97E-02\n",
      "\n",
      " Epoch 155 \n",
      " --------------\n",
      "Train loss: 4.75E-02\n",
      "Test  loss: 4.97E-02\n",
      "\n",
      " Epoch 156 \n",
      " --------------\n",
      "Train loss: 4.75E-02\n",
      "Test  loss: 4.97E-02\n",
      "\n",
      " Epoch 157 \n",
      " --------------\n",
      "Train loss: 4.75E-02\n",
      "Test  loss: 4.97E-02\n",
      "\n",
      " Epoch 158 \n",
      " --------------\n",
      "Train loss: 4.75E-02\n",
      "Test  loss: 4.97E-02\n",
      "\n",
      " Epoch 159 \n",
      " --------------\n",
      "Train loss: 4.75E-02\n",
      "Test  loss: 4.96E-02\n",
      "\n",
      " Epoch 160 \n",
      " --------------\n",
      "Train loss: 4.75E-02\n",
      "Test  loss: 4.97E-02\n",
      "\n",
      " Epoch 161 \n",
      " --------------\n",
      "Train loss: 4.75E-02\n",
      "Test  loss: 4.96E-02\n",
      "\n",
      " Epoch 162 \n",
      " --------------\n",
      "Train loss: 4.75E-02\n",
      "Test  loss: 4.96E-02\n",
      "\n",
      " Epoch 163 \n",
      " --------------\n",
      "Train loss: 4.75E-02\n",
      "Test  loss: 4.96E-02\n",
      "\n",
      " Epoch 164 \n",
      " --------------\n",
      "Train loss: 4.75E-02\n",
      "Test  loss: 4.96E-02\n",
      "\n",
      " Epoch 165 \n",
      " --------------\n",
      "Train loss: 4.75E-02\n",
      "Test  loss: 4.96E-02\n",
      "\n",
      " Epoch 166 \n",
      " --------------\n",
      "Train loss: 4.75E-02\n",
      "Test  loss: 4.96E-02\n",
      "\n",
      " Epoch 167 \n",
      " --------------\n",
      "Train loss: 4.75E-02\n",
      "Test  loss: 4.96E-02\n",
      "\n",
      " Epoch 168 \n",
      " --------------\n",
      "Adapting learning rate to 6.25e-05\n",
      "Train loss: 4.75E-02\n",
      "Test  loss: 4.96E-02\n",
      "\n",
      " Epoch 169 \n",
      " --------------\n",
      "Train loss: 4.75E-02\n",
      "Test  loss: 4.96E-02\n",
      "\n",
      " Epoch 170 \n",
      " --------------\n",
      "Train loss: 4.75E-02\n",
      "Test  loss: 4.96E-02\n",
      "\n",
      " Epoch 171 \n",
      " --------------\n",
      "Train loss: 4.75E-02\n",
      "Test  loss: 4.96E-02\n",
      "\n",
      " Epoch 172 \n",
      " --------------\n",
      "Train loss: 4.75E-02\n",
      "Test  loss: 4.96E-02\n",
      "\n",
      " Epoch 173 \n",
      " --------------\n",
      "Train loss: 4.75E-02\n",
      "Test  loss: 4.96E-02\n",
      "\n",
      " Epoch 174 \n",
      " --------------\n",
      "Train loss: 4.75E-02\n",
      "Test  loss: 4.96E-02\n",
      "\n",
      " Epoch 175 \n",
      " --------------\n",
      "Train loss: 4.75E-02\n",
      "Test  loss: 4.96E-02\n",
      "\n",
      " Epoch 176 \n",
      " --------------\n",
      "Train loss: 4.75E-02\n",
      "Test  loss: 4.96E-02\n",
      "\n",
      " Epoch 177 \n",
      " --------------\n",
      "Train loss: 4.75E-02\n",
      "Test  loss: 4.96E-02\n",
      "\n",
      " Epoch 178 \n",
      " --------------\n",
      "Train loss: 4.74E-02\n",
      "Test  loss: 4.96E-02\n",
      "\n",
      " Epoch 179 \n",
      " --------------\n",
      "Adapting learning rate to 3.125e-05\n",
      "Train loss: 4.74E-02\n",
      "Test  loss: 4.96E-02\n",
      "\n",
      " Epoch 180 \n",
      " --------------\n",
      "Train loss: 4.73E-02\n",
      "Test  loss: 4.94E-02\n",
      "\n",
      " Epoch 181 \n",
      " --------------\n",
      "Train loss: 4.73E-02\n",
      "Test  loss: 4.94E-02\n",
      "\n",
      " Epoch 182 \n",
      " --------------\n",
      "Train loss: 4.73E-02\n",
      "Test  loss: 4.94E-02\n",
      "\n",
      " Epoch 183 \n",
      " --------------\n",
      "Train loss: 4.73E-02\n",
      "Test  loss: 4.94E-02\n",
      "\n",
      " Epoch 184 \n",
      " --------------\n",
      "Train loss: 4.73E-02\n",
      "Test  loss: 4.94E-02\n",
      "\n",
      " Epoch 185 \n",
      " --------------\n",
      "Train loss: 4.73E-02\n",
      "Test  loss: 4.94E-02\n",
      "\n",
      " Epoch 186 \n",
      " --------------\n",
      "Train loss: 4.73E-02\n",
      "Test  loss: 4.94E-02\n",
      "\n",
      " Epoch 187 \n",
      " --------------\n",
      "Train loss: 4.73E-02\n",
      "Test  loss: 4.94E-02\n",
      "\n",
      " Epoch 188 \n",
      " --------------\n",
      "Train loss: 4.73E-02\n",
      "Test  loss: 4.94E-02\n",
      "\n",
      " Epoch 189 \n",
      " --------------\n",
      "Train loss: 4.73E-02\n",
      "Test  loss: 4.94E-02\n",
      "\n",
      " Epoch 190 \n",
      " --------------\n",
      "Adapting learning rate to 1.5625e-05\n",
      "Train loss: 4.73E-02\n",
      "Test  loss: 4.94E-02\n",
      "\n",
      " Epoch 191 \n",
      " --------------\n",
      "Train loss: 4.73E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 192 \n",
      " --------------\n",
      "Train loss: 4.73E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 193 \n",
      " --------------\n",
      "Train loss: 4.73E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 194 \n",
      " --------------\n",
      "Train loss: 4.73E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 195 \n",
      " --------------\n",
      "Train loss: 4.73E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 196 \n",
      " --------------\n",
      "Train loss: 4.73E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 197 \n",
      " --------------\n",
      "Train loss: 4.73E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 198 \n",
      " --------------\n",
      "Train loss: 4.73E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 199 \n",
      " --------------\n",
      "Train loss: 4.73E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 200 \n",
      " --------------\n",
      "Train loss: 4.73E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 201 \n",
      " --------------\n",
      "Adapting learning rate to 7.8125e-06\n",
      "Train loss: 4.73E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 202 \n",
      " --------------\n",
      "Train loss: 4.73E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 203 \n",
      " --------------\n",
      "Train loss: 4.73E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 204 \n",
      " --------------\n",
      "Train loss: 4.73E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 205 \n",
      " --------------\n",
      "Train loss: 4.73E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 206 \n",
      " --------------\n",
      "Train loss: 4.73E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 207 \n",
      " --------------\n",
      "Train loss: 4.73E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 208 \n",
      " --------------\n",
      "Train loss: 4.73E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 209 \n",
      " --------------\n",
      "Train loss: 4.73E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 210 \n",
      " --------------\n",
      "Train loss: 4.73E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 211 \n",
      " --------------\n",
      "Train loss: 4.73E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 212 \n",
      " --------------\n",
      "Adapting learning rate to 3.90625e-06\n",
      "Train loss: 4.73E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 213 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 214 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 215 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 216 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 217 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 218 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 219 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 220 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 221 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 222 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 223 \n",
      " --------------\n",
      "Adapting learning rate to 1.953125e-06\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 224 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 225 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 226 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 227 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 228 \n",
      " --------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 229 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 230 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 231 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 232 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 233 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 234 \n",
      " --------------\n",
      "Adapting learning rate to 9.765625e-07\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 235 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 236 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 237 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 238 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 239 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 240 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 241 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 242 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 243 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 244 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 245 \n",
      " --------------\n",
      "Adapting learning rate to 4.8828125e-07\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 246 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 247 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 248 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 249 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 250 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 251 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 252 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 253 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 254 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 255 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 256 \n",
      " --------------\n",
      "Adapting learning rate to 2.44140625e-07\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 257 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 258 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 259 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 260 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 261 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 262 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 263 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 264 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 265 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 266 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 267 \n",
      " --------------\n",
      "Adapting learning rate to 1.220703125e-07\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 268 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 269 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 270 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 271 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 272 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 273 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 274 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 275 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 276 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 277 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 278 \n",
      " --------------\n",
      "Adapting learning rate to 6.103515625e-08\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 279 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 280 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 281 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 282 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 283 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 284 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 285 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 286 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 287 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 288 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 289 \n",
      " --------------\n",
      "Adapting learning rate to 3.0517578125e-08\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 290 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 291 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 292 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 293 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 294 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 295 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 296 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 297 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 298 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 299 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 300 \n",
      " --------------\n",
      "Adapting learning rate to 1.52587890625e-08\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 301 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 302 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 303 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 304 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 305 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 306 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 307 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 308 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 309 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 310 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 311 \n",
      " --------------\n",
      "Adapting learning rate to 7.62939453125e-09\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 312 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 313 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 314 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 315 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 316 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 317 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 318 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 319 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 320 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 321 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 322 \n",
      " --------------\n",
      "Adapting learning rate to 3.814697265625e-09\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 323 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 324 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 325 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 326 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 327 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 328 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 329 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 330 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 331 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 332 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 333 \n",
      " --------------\n",
      "Adapting learning rate to 1.9073486328125e-09\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 334 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 335 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 336 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 337 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 338 \n",
      " --------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 339 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 340 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 341 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 342 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 343 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 344 \n",
      " --------------\n",
      "Adapting learning rate to 9.5367431640625e-10\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 345 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 346 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 347 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 348 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 349 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 350 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 351 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 352 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 353 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 354 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 355 \n",
      " --------------\n",
      "Adapting learning rate to 4.76837158203125e-10\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 356 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 357 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 358 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 359 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 360 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 361 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 362 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 363 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 364 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 365 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 366 \n",
      " --------------\n",
      "Adapting learning rate to 2.384185791015625e-10\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 367 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 368 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 369 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 370 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 371 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 372 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 373 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 374 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 375 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 376 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 377 \n",
      " --------------\n",
      "Adapting learning rate to 1.1920928955078125e-10\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 378 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 379 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 380 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 381 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 382 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 383 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 384 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 385 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 386 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 387 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 388 \n",
      " --------------\n",
      "Adapting learning rate to 5.960464477539063e-11\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 389 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 390 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 391 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 392 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 393 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 394 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 395 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 396 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 397 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 398 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 399 \n",
      " --------------\n",
      "Adapting learning rate to 2.980232238769531e-11\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 400 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 401 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 402 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 403 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 404 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 405 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 406 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 407 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 408 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 409 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 410 \n",
      " --------------\n",
      "Adapting learning rate to 1.4901161193847657e-11\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 411 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 412 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 413 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 414 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 415 \n",
      " --------------\n",
      "Train loss: 4.72E-02\n",
      "Test  loss: 4.93E-02\n",
      "\n",
      " Epoch 416 \n",
      " --------------\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8a5288",
   "metadata": {
    "id": "1b8a5288"
   },
   "source": [
    "Create a quick sketch of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07eb521",
   "metadata": {
    "id": "f07eb521"
   },
   "outputs": [],
   "source": [
    "# plt.plot(trainer.train_losses, color='red', label=\"Train loss\")\n",
    "# plt.plot(trainer.test_losses, color='blue', label=\"Test loss\")\n",
    "\n",
    "# plt.grid()\n",
    "# plt.legend()\n",
    "# for ind in trainer.adaptation_indices:\n",
    "#     plt.axvline(ind, ls = '--', color='grey')\n",
    "# plt.yscale('log')\n",
    "# plt.xlabel(\"Epochs\")\n",
    "# plt.xlabel(\"MSE Loss\")\n",
    "# plt.title(\"Training (100, 100) network tabular EOS for p and eps\")\n",
    "# plt.savefig(\"testing_training_tab_eos_network_100_100.pdf\", bbox_inches = 'tight')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad41d2a",
   "metadata": {
    "id": "8ad41d2a"
   },
   "source": [
    "# Archive: NNE2T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391a25b5",
   "metadata": {
    "id": "391a25b5"
   },
   "source": [
    "__NNE2T__: try to replicate the conversion from energy to temperature, which is currently done by rootfinding approximations & lookups in the EOS table (see Gmunu code). It seemed harder than I initially thought to model and train this; and in the end, I'm not sure how useful it'll be, so I'm archiving this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f48e387",
   "metadata": {
    "id": "7f48e387"
   },
   "source": [
    "Get the training data as DataSet and DataLoader objects. Note on normalization: we fit transform on the training data, then use the fitted scaler object to transform (i.e. using same transformation as the training data) the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88f2675",
   "metadata": {
    "id": "b88f2675"
   },
   "outputs": [],
   "source": [
    "# Give the names of the input vars (features) and output vars (labels)\n",
    "in_vars = [\"rho\", \"eps\", \"ye\"]\n",
    "out_vars = [\"temp\"]\n",
    "# For normalization, use sklearn's StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# Read the sampled data as pandas dataframes\n",
    "train_df = pd.read_csv(os.path.join(master_dir, \"Data/SLy4_training_data.csv\"))\n",
    "test_df  = pd.read_csv(os.path.join(master_dir, \"Data/SLy4_test_data.csv\"))\n",
    "# Convert to PyTorch Datasets as we defined them\n",
    "train_dataset = data.CustomDataset(train_df, feature_names = in_vars, label_names = out_vars, normalization_function = scaler.fit_transform) \n",
    "test_dataset  = data.CustomDataset(test_df, feature_names = in_vars, label_names = out_vars, normalization_function = scaler.transform)\n",
    "# Then create dataloaders, with batch size 32, from datasets\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32)\n",
    "test_dataloader  = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abee61f0",
   "metadata": {
    "id": "abee61f0"
   },
   "source": [
    "Create a new instance of the Net:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b990a7ff",
   "metadata": {
    "id": "b990a7ff",
    "outputId": "76d4c28e-ca6a-423d-e905-27d55d54b42e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (linear1): Linear(in_features=3, out_features=50, bias=True)\n",
       "  (activation1): Sigmoid()\n",
       "  (linear2): Linear(in_features=50, out_features=50, bias=True)\n",
       "  (activation2): Sigmoid()\n",
       "  (linear3): Linear(in_features=50, out_features=1, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net(nb_of_inputs = 3, nb_of_outputs = 1, h=[50, 50])\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312052a9",
   "metadata": {
    "id": "312052a9",
    "outputId": "18d37e9e-a86e-48e2-87bd-c82646596aeb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2800"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnc2p.count_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f23d022",
   "metadata": {
    "id": "1f23d022"
   },
   "source": [
    "Create a trainer object from it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06becda4",
   "metadata": {
    "id": "06becda4"
   },
   "outputs": [],
   "source": [
    "trainer = nnc2p.Trainer(model, 1e-1, train_dataloader=train_dataloader, test_dataloader=test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ce3bda",
   "metadata": {
    "id": "93ce3bda",
    "outputId": "f4a25ecd-bfdf-4140-b06d-6c414eaf8736"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model for 500 epochs.\n",
      "\n",
      " Epoch 0 \n",
      " --------------\n",
      "Train loss: 7.59E-01\n",
      "Test  loss: 7.62E-01\n",
      "\n",
      " Epoch 1 \n",
      " --------------\n",
      "Train loss: 9.92E-01\n",
      "Test  loss: 9.98E-01\n",
      "\n",
      " Epoch 2 \n",
      " --------------\n",
      "Train loss: 9.45E-01\n",
      "Test  loss: 9.61E-01\n",
      "\n",
      " Epoch 3 \n",
      " --------------\n",
      "Train loss: 8.24E-01\n",
      "Test  loss: 8.29E-01\n",
      "\n",
      " Epoch 4 \n",
      " --------------\n",
      "Train loss: 9.10E-01\n",
      "Test  loss: 9.16E-01\n",
      "\n",
      " Epoch 5 \n",
      " --------------\n",
      "Train loss: 8.80E-01\n",
      "Test  loss: 8.91E-01\n",
      "\n",
      " Epoch 6 \n",
      " --------------\n",
      "Train loss: 8.62E-01\n",
      "Test  loss: 8.67E-01\n",
      "\n",
      " Epoch 7 \n",
      " --------------\n",
      "Train loss: 8.20E-01\n",
      "Test  loss: 8.27E-01\n",
      "\n",
      " Epoch 8 \n",
      " --------------\n",
      "Train loss: 8.80E-01\n",
      "Test  loss: 8.94E-01\n",
      "\n",
      " Epoch 9 \n",
      " --------------\n",
      "Train loss: 9.20E-01\n",
      "Test  loss: 9.26E-01\n",
      "\n",
      " Epoch 10 \n",
      " --------------\n",
      "Train loss: 7.34E-01\n",
      "Test  loss: 7.39E-01\n",
      "\n",
      " Epoch 11 \n",
      " --------------\n",
      "Train loss: 7.48E-01\n",
      "Test  loss: 7.56E-01\n",
      "\n",
      " Epoch 12 \n",
      " --------------\n",
      "Train loss: 7.28E-01\n",
      "Test  loss: 7.31E-01\n",
      "\n",
      " Epoch 13 \n",
      " --------------\n",
      "Train loss: 8.87E-01\n",
      "Test  loss: 8.99E-01\n",
      "\n",
      " Epoch 14 \n",
      " --------------\n",
      "Train loss: 8.02E-01\n",
      "Test  loss: 8.09E-01\n",
      "\n",
      " Epoch 15 \n",
      " --------------\n",
      "Train loss: 8.11E-01\n",
      "Test  loss: 8.20E-01\n",
      "\n",
      " Epoch 16 \n",
      " --------------\n",
      "Train loss: 8.02E-01\n",
      "Test  loss: 8.08E-01\n",
      "\n",
      " Epoch 17 \n",
      " --------------\n",
      "Adapting learning rate to 0.05\n",
      "Train loss: 8.70E-01\n",
      "Test  loss: 8.79E-01\n",
      "\n",
      " Epoch 18 \n",
      " --------------\n",
      "Train loss: 6.88E-01\n",
      "Test  loss: 6.92E-01\n",
      "\n",
      " Epoch 19 \n",
      " --------------\n",
      "Train loss: 6.24E-01\n",
      "Test  loss: 6.25E-01\n",
      "\n",
      " Epoch 20 \n",
      " --------------\n",
      "Train loss: 6.42E-01\n",
      "Test  loss: 6.46E-01\n",
      "\n",
      " Epoch 21 \n",
      " --------------\n",
      "Train loss: 6.21E-01\n",
      "Test  loss: 6.25E-01\n",
      "\n",
      " Epoch 22 \n",
      " --------------\n",
      "Train loss: 6.29E-01\n",
      "Test  loss: 6.32E-01\n",
      "\n",
      " Epoch 23 \n",
      " --------------\n",
      "Train loss: 6.30E-01\n",
      "Test  loss: 6.33E-01\n",
      "\n",
      " Epoch 24 \n",
      " --------------\n",
      "Train loss: 6.13E-01\n",
      "Test  loss: 6.16E-01\n",
      "\n",
      " Epoch 25 \n",
      " --------------\n",
      "Train loss: 6.25E-01\n",
      "Test  loss: 6.27E-01\n",
      "\n",
      " Epoch 26 \n",
      " --------------\n",
      "Train loss: 6.75E-01\n",
      "Test  loss: 6.81E-01\n",
      "\n",
      " Epoch 27 \n",
      " --------------\n",
      "Train loss: 6.22E-01\n",
      "Test  loss: 6.23E-01\n",
      "\n",
      " Epoch 28 \n",
      " --------------\n",
      "Train loss: 6.77E-01\n",
      "Test  loss: 6.81E-01\n",
      "\n",
      " Epoch 29 \n",
      " --------------\n",
      "Adapting learning rate to 0.025\n",
      "Train loss: 6.98E-01\n",
      "Test  loss: 6.99E-01\n",
      "\n",
      " Epoch 30 \n",
      " --------------\n",
      "Train loss: 5.71E-01\n",
      "Test  loss: 5.74E-01\n",
      "\n",
      " Epoch 31 \n",
      " --------------\n",
      "Train loss: 5.77E-01\n",
      "Test  loss: 5.81E-01\n",
      "\n",
      " Epoch 32 \n",
      " --------------\n",
      "Train loss: 5.69E-01\n",
      "Test  loss: 5.74E-01\n",
      "\n",
      " Epoch 33 \n",
      " --------------\n",
      "Train loss: 5.65E-01\n",
      "Test  loss: 5.69E-01\n",
      "\n",
      " Epoch 34 \n",
      " --------------\n",
      "Train loss: 5.63E-01\n",
      "Test  loss: 5.67E-01\n",
      "\n",
      " Epoch 35 \n",
      " --------------\n",
      "Train loss: 5.60E-01\n",
      "Test  loss: 5.65E-01\n",
      "\n",
      " Epoch 36 \n",
      " --------------\n",
      "Train loss: 5.67E-01\n",
      "Test  loss: 5.70E-01\n",
      "\n",
      " Epoch 37 \n",
      " --------------\n",
      "Train loss: 5.58E-01\n",
      "Test  loss: 5.60E-01\n",
      "\n",
      " Epoch 38 \n",
      " --------------\n",
      "Train loss: 5.62E-01\n",
      "Test  loss: 5.66E-01\n",
      "\n",
      " Epoch 39 \n",
      " --------------\n",
      "Train loss: 5.62E-01\n",
      "Test  loss: 5.66E-01\n",
      "\n",
      " Epoch 40 \n",
      " --------------\n",
      "Train loss: 5.62E-01\n",
      "Test  loss: 5.64E-01\n",
      "\n",
      " Epoch 41 \n",
      " --------------\n",
      "Train loss: 5.73E-01\n",
      "Test  loss: 5.75E-01\n",
      "\n",
      " Epoch 42 \n",
      " --------------\n",
      "Adapting learning rate to 0.0125\n",
      "Train loss: 5.69E-01\n",
      "Test  loss: 5.73E-01\n",
      "\n",
      " Epoch 43 \n",
      " --------------\n",
      "Train loss: 4.89E-01\n",
      "Test  loss: 4.92E-01\n",
      "\n",
      " Epoch 44 \n",
      " --------------\n",
      "Train loss: 4.87E-01\n",
      "Test  loss: 4.91E-01\n",
      "\n",
      " Epoch 45 \n",
      " --------------\n",
      "Train loss: 4.86E-01\n",
      "Test  loss: 4.91E-01\n",
      "\n",
      " Epoch 46 \n",
      " --------------\n",
      "Train loss: 4.83E-01\n",
      "Test  loss: 4.88E-01\n",
      "\n",
      " Epoch 47 \n",
      " --------------\n",
      "Train loss: 4.80E-01\n",
      "Test  loss: 4.85E-01\n",
      "\n",
      " Epoch 48 \n",
      " --------------\n",
      "Train loss: 4.78E-01\n",
      "Test  loss: 4.83E-01\n",
      "\n",
      " Epoch 49 \n",
      " --------------\n",
      "Train loss: 4.77E-01\n",
      "Test  loss: 4.81E-01\n",
      "\n",
      " Epoch 50 \n",
      " --------------\n",
      "Train loss: 4.75E-01\n",
      "Test  loss: 4.79E-01\n",
      "\n",
      " Epoch 51 \n",
      " --------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[118], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[1;32md:\\Coding\\master-thesis-AI\\Code\\nnc2p.py:407\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, adaptation_threshold, adaptation_multiplier, number_of_epochs, log_file, csv_file)\u001b[0m\n\u001b[0;32m    405\u001b[0m write_to_txt(log_file, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m Epoch \u001b[39m\u001b[39m{\u001b[39;00mepoch_counter\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m --------------\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    406\u001b[0m \u001b[39m# Train the network\u001b[39;00m\n\u001b[1;32m--> 407\u001b[0m train_loop(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_dataloader, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss_fn, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer, use_c2p_loss\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49muse_c2p_loss)\n\u001b[0;32m    408\u001b[0m \u001b[39m# Test on the training data\u001b[39;00m\n\u001b[0;32m    409\u001b[0m average_train_loss \u001b[39m=\u001b[39m test_loop(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_dataloader, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_fn)\n",
      "File \u001b[1;32md:\\Coding\\master-thesis-AI\\Code\\nnc2p.py:277\u001b[0m, in \u001b[0;36mtrain_loop\u001b[1;34m(dataloader, model, loss_fn, optimizer, report_progress, use_c2p_loss)\u001b[0m\n\u001b[0;32m    274\u001b[0m size \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(dataloader\u001b[39m.\u001b[39mdataset)\n\u001b[0;32m    275\u001b[0m \u001b[39mfor\u001b[39;00m batch, (X, y) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataloader):\n\u001b[0;32m    276\u001b[0m     \u001b[39m# Compute prediction \u001b[39;00m\n\u001b[1;32m--> 277\u001b[0m     prediction \u001b[39m=\u001b[39m model(X)\n\u001b[0;32m    278\u001b[0m     \u001b[39m# In case we use C2P loss function, have to provide conserved variables for the loss computation\u001b[39;00m\n\u001b[0;32m    279\u001b[0m     \u001b[39mif\u001b[39;00m use_c2p_loss:\n",
      "File \u001b[1;32md:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[25], line 39\u001b[0m, in \u001b[0;36mNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[39mif\u001b[39;00m i \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     38\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m     x \u001b[39m=\u001b[39m module(x)\n\u001b[0;32m     41\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32md:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc2a130",
   "metadata": {
    "id": "8cc2a130"
   },
   "source": [
    "Create a quick sketch of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5338413",
   "metadata": {
    "id": "c5338413"
   },
   "outputs": [],
   "source": [
    "# plt.plot(trainer.train_losses, color='red', label=\"Train loss\")\n",
    "# plt.plot(trainer.test_losses, color='blue', label=\"Test loss\")\n",
    "\n",
    "# plt.grid()\n",
    "# plt.legend()\n",
    "# for ind in trainer.adaptation_indices:\n",
    "#     plt.axvline(ind, ls = '--', color='grey')\n",
    "# plt.yscale('log')\n",
    "# plt.xlabel(\"Epochs\")\n",
    "# plt.xlabel(\"MSE Loss\")\n",
    "# plt.title(\"Training (100, 100) network tabular EOS for p and eps\")\n",
    "# plt.savefig(\"testing_training_tab_eos_network_100_100.pdf\", bbox_inches = 'tight')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ef6efc",
   "metadata": {},
   "source": [
    "# Archive (safely ignore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5445999",
   "metadata": {},
   "source": [
    "If desired, creat jit and onnx of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "46122082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example\n",
      "-1.728142261505127\n",
      "-1.4035654067993164\n",
      "-1.1849615573883057\n",
      "Output\n",
      "19.214147567749023\n",
      "18.384708404541016\n"
     ]
    }
   ],
   "source": [
    "# x = scaler.transform(features[1000].reshape(1,-1))\n",
    "# x = torch.from_numpy(x).float()\n",
    "# print(\"Example\")\n",
    "# print(x[0][0].item())\n",
    "# print(x[0][1].item())\n",
    "# print(x[0][2].item())\n",
    "# torch_out = model(x)\n",
    "# print(\"Output\")\n",
    "# print(torch_out[0][0].item())\n",
    "# print(torch_out[0][1].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c90a6573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## ONNX\n",
    "# # Export the model\n",
    "# torch.onnx.export(model,               # model being run\n",
    "#                   x,                         # model input (or a tuple for multiple inputs)\n",
    "#                   \"tab_eos.onnx\",   # where to save the model (can be a file or file-like object)\n",
    "#                   export_params=True,        # store the trained parameter weights inside the model file\n",
    "#                   opset_version=10,          # the ONNX version to export the model to\n",
    "#                   do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "#                   input_names = ['input'],   # the model's input names\n",
    "#                   output_names = ['output'], # the model's output names\n",
    "#                   dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
    "#                                 'output' : {0 : 'batch_size'}})\n",
    "# ## Torchscript\n",
    "# # Use torch.jit.trace to generate a torch.jit.ScriptModule via tracing.\n",
    "# traced_script_module = torch.jit.trace(model, x)\n",
    "\n",
    "# # Save the TorchScript model\n",
    "# traced_script_module.save(\"tab_eos.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb61e114",
   "metadata": {},
   "source": [
    "Testing ONNX here!!! See [this PyTorch docs page for info.](https://pytorch.org/tutorials/advanced/super_resolution_with_onnxruntime.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "351019ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# onnx_model = onnx.load(\"tab_eos.onnx\")\n",
    "# onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "844efce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported model has been tested with ONNXRuntime, and the result looks good!\n"
     ]
    }
   ],
   "source": [
    "# ort_session = onnxruntime.InferenceSession(\"tab_eos.onnx\")\n",
    "\n",
    "# def to_numpy(tensor):\n",
    "#     return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "# # compute ONNX Runtime output prediction\n",
    "# ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(x)}\n",
    "# ort_outs = ort_session.run(None, ort_inputs)\n",
    "\n",
    "# # compare ONNX Runtime and PyTorch results\n",
    "# np.testing.assert_allclose(to_numpy(torch_out), ort_outs[0], rtol=1e-03, atol=1e-05)\n",
    "\n",
    "# print(\"Exported model has been tested with ONNXRuntime, and the result looks good!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70689ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "author": "Thibeau Wouters",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
