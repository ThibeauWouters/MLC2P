{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af563537",
   "metadata": {},
   "source": [
    "%%latex\n",
    "\\tableofcontents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bb9f224",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "import random\n",
    "import csv\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import ToTensor \n",
    "import matplotlib.cm as cm\n",
    "# Own scripts:\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import physics\n",
    "import data\n",
    "import nnc2p\n",
    "from nnc2p import NeuralNetwork # our own architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fb3c8c",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ab265e",
   "metadata": {},
   "source": [
    "We have trained model which is succesful in the C2P conversion based on the paper by Dieselhorst et al., and this neural network is called NNC2Pv0. We trained it a bit longer compared to the paper, and ended up with an efficient network called `NNC2Pv0t2`. Naturally, we want to improve on these methods. One possibility is __pruning the neural network__ to speed up the computations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f423f2",
   "metadata": {},
   "source": [
    "__Get the data into dataloaders:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8f22ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the desired CSV file locations of train and test data\n",
    "training_data_csv = data.read_training_data(\"D:/Coding/master-thesis-AI/data/NNC2P_data_train.csv\")\n",
    "test_data_csv        = data.read_training_data(\"D:/Coding/master-thesis-AI/data/NNC2P_data_test.csv\")\n",
    "# Load them as CustomDatasets\n",
    "training_data = data.CustomDataset(training_data_csv)\n",
    "test_data        = data.CustomDataset(test_data_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0586eedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put this data into a DataLoader\n",
    "train_dataloader = DataLoader(training_data, batch_size=32)\n",
    "test_dataloader = DataLoader(test_data, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710e7420",
   "metadata": {},
   "source": [
    "# PyTorch pruning methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc54444",
   "metadata": {},
   "source": [
    "Load a previously trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c015d0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "# Initialize a random neural network\n",
    "model = NeuralNetwork().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32b8790f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the previously trained model and its parameters\n",
    "old_model = torch.load(\"D:/Coding/master-thesis-AI/Models/NNC2Pv0t2.pth\")\n",
    "model_state_dict = torch.load(\"D:/Coding/master-thesis-AI/Models/NNC2Pv0t2_state_dict.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "621eb177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['stack.0.weight', 'stack.0.bias', 'stack.2.weight', 'stack.2.bias', 'stack.4.weight', 'stack.4.bias'])\n"
     ]
    }
   ],
   "source": [
    "print(model_state_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6797b7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1305])\n"
     ]
    }
   ],
   "source": [
    "print(model_state_dict['stack.4.bias'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30b0477",
   "metadata": {},
   "source": [
    "Load the old model's parameters into the new architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "708ab316",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_parameters(model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40698ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (linear1): Linear(in_features=3, out_features=600, bias=True)\n",
      "  (linear2): Linear(in_features=600, out_features=200, bias=True)\n",
      "  (linear3): Linear(in_features=200, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3223102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.866371154785156\n"
     ]
    }
   ],
   "source": [
    "test = torch.tensor([10.204131145455385, 12.026584842282125, 22.131296926293793])\n",
    "print(model(test).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9227a551",
   "metadata": {},
   "source": [
    "What is the performance of this network?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09b18200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors for p: 2.623259e-04  with L1 and 8.344986e-03 with Linfty\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.00026232592464366463, 0.008344985544681549)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnc2p.measure_performance(model, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30eca406",
   "metadata": {},
   "source": [
    "PyTorch has a library for pruning, see [their pruning tutorial](https://pytorch.org/tutorials/intermediate/pruning_tutorial.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0783cbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.utils.prune as prune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1bbf64",
   "metadata": {},
   "source": [
    "For this test, we prune the second weight matrix of our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "162ac223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('weight', Parameter containing:\n",
      "tensor([[-0.2067,  0.0381,  0.0541,  ..., -0.1053,  0.0773, -0.0022],\n",
      "        [ 0.0454, -0.0570, -0.0544,  ...,  0.0199, -0.1168, -0.0555],\n",
      "        [-0.0048, -0.0284, -0.0800,  ..., -0.0789, -0.0413, -0.0859],\n",
      "        ...,\n",
      "        [ 0.0500, -0.0569, -0.0705,  ...,  0.0048, -0.0813, -0.0858],\n",
      "        [ 0.0667, -0.0904, -0.0727,  ...,  0.0317, -0.0615, -0.0056],\n",
      "        [-0.1763,  0.0120,  0.0712,  ..., -0.0230,  0.0433,  0.0013]],\n",
      "       requires_grad=True)), ('bias', Parameter containing:\n",
      "tensor([-0.0271, -0.0239, -0.0302, -0.0114, -0.0249,  0.0093, -0.0515, -0.0817,\n",
      "         0.0342, -0.0339, -0.0481,  0.0432, -0.0191,  0.0025, -0.0540, -0.0058,\n",
      "        -0.0647, -0.0440, -0.0351, -0.0593, -0.0735, -0.0544, -0.0814, -0.0214,\n",
      "        -0.0154, -0.0055, -0.0674,  0.0044, -0.0351, -0.0741,  0.0171, -0.0615,\n",
      "        -0.0459, -0.0020, -0.0305, -0.0228, -0.0305, -0.0376, -0.0454, -0.0744,\n",
      "         0.0535, -0.0635, -0.0144, -0.0232, -0.0254,  0.0227, -0.0344, -0.0436,\n",
      "        -0.0584,  0.0099, -0.0403, -0.0387, -0.0368,  0.0166,  0.0336, -0.0221,\n",
      "         0.0520, -0.0206,  0.0083, -0.0750, -0.0349, -0.0069, -0.0171,  0.0392,\n",
      "         0.0177, -0.0280,  0.0325,  0.0341, -0.0005, -0.0501, -0.0515, -0.0328,\n",
      "        -0.0284, -0.0531,  0.0279, -0.0303,  0.0078, -0.0676, -0.0238, -0.0261,\n",
      "        -0.0792,  0.0161, -0.0640,  0.0077, -0.0182,  0.0292,  0.0060,  0.0367,\n",
      "        -0.0227, -0.0028,  0.0066, -0.0860, -0.0802,  0.0037, -0.0384, -0.0578,\n",
      "        -0.0726,  0.0060, -0.0239, -0.0855, -0.0250, -0.0263,  0.0115, -0.0662,\n",
      "        -0.0285, -0.0276, -0.0946,  0.0428, -0.0400, -0.0256, -0.0032,  0.0145,\n",
      "        -0.0033, -0.0091, -0.0723, -0.0200, -0.0704, -0.0427,  0.0333, -0.0604,\n",
      "         0.0111,  0.0077, -0.0716, -0.0779, -0.0307, -0.0148,  0.0232,  0.0291,\n",
      "        -0.0622, -0.0294,  0.0257,  0.0165, -0.0498, -0.0171, -0.0305,  0.0129,\n",
      "         0.0129,  0.0155, -0.0162,  0.0116, -0.0579,  0.0244, -0.0378,  0.0376,\n",
      "        -0.0052, -0.0232, -0.0540,  0.0339, -0.0018, -0.0475, -0.0338, -0.0417,\n",
      "        -0.0022, -0.0551,  0.0414, -0.0723, -0.0047, -0.0709,  0.0090, -0.0440,\n",
      "        -0.0442, -0.0542,  0.0242, -0.0196, -0.0681, -0.0328, -0.0508, -0.0354,\n",
      "        -0.0399,  0.0588,  0.0258,  0.0199,  0.0177,  0.0257, -0.0361,  0.0115,\n",
      "        -0.0522,  0.0754, -0.0126,  0.0152, -0.0197,  0.0306, -0.0713,  0.0023,\n",
      "        -0.0181, -0.0771,  0.0207, -0.0439,  0.0010,  0.0851, -0.0483, -0.0554,\n",
      "        -0.0075, -0.0417,  0.0246,  0.0064,  0.0121, -0.0648, -0.0229, -0.0409],\n",
      "       requires_grad=True))]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Linear(in_features=600, out_features=200, bias=True)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module = model.linear2\n",
    "print(list(module.named_parameters()))\n",
    "prune.random_unstructured(module, name=\"weight\", amount=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "972e0c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('weight_mask', tensor([[0., 1., 0.,  ..., 0., 0., 1.],\n",
      "        [1., 0., 1.,  ..., 1., 1., 0.],\n",
      "        [1., 1., 0.,  ..., 1., 1., 0.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 0., 1., 1.],\n",
      "        [1., 0., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 0.,  ..., 1., 0., 0.]]))]\n"
     ]
    }
   ],
   "source": [
    "print(list(module.named_buffers()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f0fb8b",
   "metadata": {},
   "source": [
    "Pruning acts by removing weight from the parameters and replacing it with a new parameter called weight_orig (i.e. appending \"_orig\" to the initial parameter name). weight_orig stores the unpruned version of the tensor. The bias was not pruned, so it will remain intact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c460107a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('bias', Parameter containing:\n",
      "tensor([-0.0271, -0.0239, -0.0302, -0.0114, -0.0249,  0.0093, -0.0515, -0.0817,\n",
      "         0.0342, -0.0339, -0.0481,  0.0432, -0.0191,  0.0025, -0.0540, -0.0058,\n",
      "        -0.0647, -0.0440, -0.0351, -0.0593, -0.0735, -0.0544, -0.0814, -0.0214,\n",
      "        -0.0154, -0.0055, -0.0674,  0.0044, -0.0351, -0.0741,  0.0171, -0.0615,\n",
      "        -0.0459, -0.0020, -0.0305, -0.0228, -0.0305, -0.0376, -0.0454, -0.0744,\n",
      "         0.0535, -0.0635, -0.0144, -0.0232, -0.0254,  0.0227, -0.0344, -0.0436,\n",
      "        -0.0584,  0.0099, -0.0403, -0.0387, -0.0368,  0.0166,  0.0336, -0.0221,\n",
      "         0.0520, -0.0206,  0.0083, -0.0750, -0.0349, -0.0069, -0.0171,  0.0392,\n",
      "         0.0177, -0.0280,  0.0325,  0.0341, -0.0005, -0.0501, -0.0515, -0.0328,\n",
      "        -0.0284, -0.0531,  0.0279, -0.0303,  0.0078, -0.0676, -0.0238, -0.0261,\n",
      "        -0.0792,  0.0161, -0.0640,  0.0077, -0.0182,  0.0292,  0.0060,  0.0367,\n",
      "        -0.0227, -0.0028,  0.0066, -0.0860, -0.0802,  0.0037, -0.0384, -0.0578,\n",
      "        -0.0726,  0.0060, -0.0239, -0.0855, -0.0250, -0.0263,  0.0115, -0.0662,\n",
      "        -0.0285, -0.0276, -0.0946,  0.0428, -0.0400, -0.0256, -0.0032,  0.0145,\n",
      "        -0.0033, -0.0091, -0.0723, -0.0200, -0.0704, -0.0427,  0.0333, -0.0604,\n",
      "         0.0111,  0.0077, -0.0716, -0.0779, -0.0307, -0.0148,  0.0232,  0.0291,\n",
      "        -0.0622, -0.0294,  0.0257,  0.0165, -0.0498, -0.0171, -0.0305,  0.0129,\n",
      "         0.0129,  0.0155, -0.0162,  0.0116, -0.0579,  0.0244, -0.0378,  0.0376,\n",
      "        -0.0052, -0.0232, -0.0540,  0.0339, -0.0018, -0.0475, -0.0338, -0.0417,\n",
      "        -0.0022, -0.0551,  0.0414, -0.0723, -0.0047, -0.0709,  0.0090, -0.0440,\n",
      "        -0.0442, -0.0542,  0.0242, -0.0196, -0.0681, -0.0328, -0.0508, -0.0354,\n",
      "        -0.0399,  0.0588,  0.0258,  0.0199,  0.0177,  0.0257, -0.0361,  0.0115,\n",
      "        -0.0522,  0.0754, -0.0126,  0.0152, -0.0197,  0.0306, -0.0713,  0.0023,\n",
      "        -0.0181, -0.0771,  0.0207, -0.0439,  0.0010,  0.0851, -0.0483, -0.0554,\n",
      "        -0.0075, -0.0417,  0.0246,  0.0064,  0.0121, -0.0648, -0.0229, -0.0409],\n",
      "       requires_grad=True)), ('weight_orig', Parameter containing:\n",
      "tensor([[-0.2067,  0.0381,  0.0541,  ..., -0.1053,  0.0773, -0.0022],\n",
      "        [ 0.0454, -0.0570, -0.0544,  ...,  0.0199, -0.1168, -0.0555],\n",
      "        [-0.0048, -0.0284, -0.0800,  ..., -0.0789, -0.0413, -0.0859],\n",
      "        ...,\n",
      "        [ 0.0500, -0.0569, -0.0705,  ...,  0.0048, -0.0813, -0.0858],\n",
      "        [ 0.0667, -0.0904, -0.0727,  ...,  0.0317, -0.0615, -0.0056],\n",
      "        [-0.1763,  0.0120,  0.0712,  ..., -0.0230,  0.0433,  0.0013]],\n",
      "       requires_grad=True))]\n"
     ]
    }
   ],
   "source": [
    "print(list(module.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "df0f1882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('weight_mask', tensor([[0., 1., 0.,  ..., 0., 0., 1.],\n",
      "        [1., 0., 1.,  ..., 1., 1., 0.],\n",
      "        [1., 1., 0.,  ..., 1., 1., 0.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 0., 1., 1.],\n",
      "        [1., 0., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 0.,  ..., 1., 0., 0.]]))]\n"
     ]
    }
   ],
   "source": [
    "print(list(module.named_buffers()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d78f5a8",
   "metadata": {},
   "source": [
    "For the forward pass to work without modification, the weight attribute needs to exist. The pruning techniques implemented in torch.nn.utils.prune compute the pruned version of the weight (by combining the mask with the original parameter) and store them in the attribute weight. Note, this is no longer a parameter of the module, it is now simply an attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "da39a2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0000,  0.0381,  0.0000,  ..., -0.0000,  0.0000, -0.0022],\n",
      "        [ 0.0454, -0.0000, -0.0544,  ...,  0.0199, -0.1168, -0.0000],\n",
      "        [-0.0048, -0.0284, -0.0000,  ..., -0.0789, -0.0413, -0.0000],\n",
      "        ...,\n",
      "        [ 0.0500, -0.0569, -0.0705,  ...,  0.0000, -0.0813, -0.0858],\n",
      "        [ 0.0667, -0.0000, -0.0727,  ...,  0.0317, -0.0615, -0.0056],\n",
      "        [-0.1763,  0.0120,  0.0000,  ..., -0.0230,  0.0000,  0.0000]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(module.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6aa70a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b85e64a",
   "metadata": {},
   "source": [
    "# Own pruning methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2c92ab",
   "metadata": {},
   "source": [
    "__(From semester 1:)__ Here we implement functions which are able to prune a column and row of a tensor, thereby pruning neurons from the neural network architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4ed3d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_column_tensor(x, index):\n",
    "    \"\"\"x is a torch tensor with shape (n, m). Returns tensor with shape (n, m-1) and deletes the column at specified index.\"\"\"\n",
    "    \n",
    "    # Delete the column by splitting into two pieces, transpose the tensors for cat\n",
    "    a = torch.transpose(x[:, :index], 0, 1)\n",
    "    b = torch.transpose(x[:, index+1:], 0, 1)\n",
    "    \n",
    "    # Concatenate the two results, with the desired column deleted\n",
    "    new = torch.cat((a, b))\n",
    "    \n",
    "    return torch.transpose(new, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "219793c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_row_tensor(x, index):\n",
    "    \"\"\"x is a torch tensor with shape (n, m). Returns tensor with shape (n, m-1) and deletes the column at specified index.\"\"\"\n",
    "    \n",
    "    # Delete the column by splitting into two pieces, transpose the tensors for cat\n",
    "    a = x[:index]\n",
    "    b = x[index+1:]\n",
    "    \n",
    "    # Return concatenation    \n",
    "    return torch.cat((a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b811810e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(example_matrix)\n",
    "# print(np.shape(example_matrix))\n",
    "# print(\"---\")\n",
    "# new = delete_column_tensor(example_matrix, 1)\n",
    "# print(new)\n",
    "# print(np.shape(new))\n",
    "# print(\"---\")\n",
    "# new = delete_row_tensor(example_matrix, 1)\n",
    "# print(new)\n",
    "# print(np.shape(new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "65fe76c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(example_vector)\n",
    "# print(np.shape(example_vector))\n",
    "# print(\"---\")\n",
    "# new = delete_row_tensor(example_vector, 1)\n",
    "# print(new)\n",
    "# print(np.shape(new))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7a44cf",
   "metadata": {},
   "source": [
    "## Pruning methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e8f214",
   "metadata": {},
   "source": [
    "The following function prunes a part of the model randomly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5fd8408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('linear1.weight', tensor([[-0.3647,  0.4542, -0.4356],\n",
      "        [ 0.0097,  0.7044,  0.4866],\n",
      "        [ 0.1109, -0.0927,  0.1088],\n",
      "        ...,\n",
      "        [ 0.5325, -0.4551, -0.3039],\n",
      "        [-0.4302, -0.1418,  0.2808],\n",
      "        [ 0.6406, -0.2961,  0.0552]])), ('linear1.bias', tensor([ 5.6580e-01,  2.9055e-01, -7.6713e-01, -3.1754e-01, -1.9565e-01,\n",
      "         5.0677e-02,  5.1462e-02, -4.1435e-01,  2.3143e-01, -5.2321e-01,\n",
      "         2.5009e-01, -3.1832e-01, -4.8635e-01, -5.0145e-01, -3.6713e-01,\n",
      "        -2.6734e-01,  7.8623e-01,  7.4853e-01,  1.0236e-01,  8.8082e-01,\n",
      "         1.5340e-01, -4.3577e-01, -3.3913e-01, -5.9674e-01, -4.3297e-01,\n",
      "        -7.3644e-01, -4.7058e-01, -4.1418e-01, -1.2201e-01, -1.7898e-01,\n",
      "        -7.2384e-01,  5.4838e-04,  2.8393e-01,  1.1887e-01,  5.4077e-01,\n",
      "        -1.8006e-01, -2.5018e-02, -3.4073e-01, -1.1368e-01, -2.8283e-01,\n",
      "         5.4974e-01, -1.4166e-01,  3.3166e-01, -5.8469e-01,  5.7012e-02,\n",
      "        -2.6767e-01,  3.8736e-01,  8.4181e-01, -2.4272e-01,  5.3141e-01,\n",
      "         2.3967e-03,  1.3625e-01, -3.3550e-01,  2.1975e-01, -3.6444e-01,\n",
      "         7.3873e-02, -7.6772e-01, -7.6143e-01, -4.5311e-01,  7.1578e-01,\n",
      "         4.7067e-01,  1.5371e-01, -7.9601e-01, -5.9970e-01,  5.3325e-01,\n",
      "        -4.4428e-01, -5.5113e-01,  2.6503e-01, -5.5351e-01, -1.8345e-01,\n",
      "         6.8588e-01, -1.0565e-01, -2.3687e-01,  5.5699e-01, -2.5287e-01,\n",
      "        -8.3980e-02, -2.7117e-01,  1.5100e-01, -3.6566e-01, -8.4284e-02,\n",
      "        -3.7020e-01, -4.9965e-01,  1.5619e-01,  9.7304e-02, -1.5444e-01,\n",
      "        -2.5198e-01, -3.1559e-01,  2.4842e-01,  1.3810e-01,  1.0239e-01,\n",
      "        -6.0938e-01, -4.8550e-01,  6.0714e-01, -1.7163e-01,  3.9716e-01,\n",
      "        -8.2663e-01, -7.7325e-01,  4.4856e-01,  1.0270e-01,  2.3359e-02,\n",
      "         3.9440e-01, -7.8085e-04, -5.5042e-01, -6.4305e-01, -1.4615e-01,\n",
      "        -5.0617e-01, -4.3187e-01, -6.5382e-01, -8.0944e-01,  8.5088e-01,\n",
      "        -4.1514e-01, -7.2059e-01, -8.9249e-02,  1.4716e-01, -9.1409e-02,\n",
      "         1.5991e-01, -3.1587e-01, -7.2910e-01,  2.5841e-01, -1.5874e-01,\n",
      "        -1.9847e-01,  4.6647e-01, -5.1674e-01, -6.1615e-01, -3.8674e-01,\n",
      "         8.5148e-02,  5.4886e-01,  1.5381e-01, -5.9712e-01,  1.2888e-01,\n",
      "        -2.8023e-01, -1.5841e-01, -4.7383e-01, -1.9967e-01,  1.6954e-01,\n",
      "        -2.2951e-01,  5.2581e-01, -7.7807e-01,  7.2939e-01, -1.3889e-01,\n",
      "        -4.0971e-02,  4.1558e-01,  2.6860e-01, -6.3942e-01,  1.8276e-01,\n",
      "        -6.3662e-01, -7.7534e-01,  4.0544e-02,  1.9765e-01,  1.6535e-03,\n",
      "        -2.9051e-01,  5.8826e-01,  1.2349e-01, -6.0414e-01, -3.2924e-01,\n",
      "        -4.7019e-01,  1.4821e-01,  6.4438e-01, -4.5646e-01,  6.6175e-01,\n",
      "        -5.5232e-01, -7.3775e-01,  2.2489e-01,  9.8045e-01,  1.9362e-01,\n",
      "         5.0179e-01,  2.2673e-01,  2.5831e-01,  6.9030e-01,  2.3059e-01,\n",
      "         7.9197e-01, -1.1315e-01,  2.1999e-01,  6.2983e-01,  3.1423e-01,\n",
      "         5.1037e-02, -5.7310e-01, -6.5169e-01, -7.0638e-01, -3.0746e-01,\n",
      "        -2.2316e-01, -5.5396e-01, -2.7101e-01, -2.6117e-01, -5.8402e-01,\n",
      "         6.6620e-01, -4.4476e-02, -3.2434e-01, -2.7772e-01,  1.5250e-01,\n",
      "         8.1940e-01, -7.3389e-02, -1.3209e-01,  3.5933e-02, -3.5152e-01,\n",
      "         2.5677e-01,  8.9088e-02, -3.4195e-01, -6.0814e-01, -2.2089e-01,\n",
      "         4.1479e-01, -5.0409e-01,  1.9718e-01,  2.0918e-03,  2.4698e-01,\n",
      "         2.6820e-01, -6.7927e-01, -2.6780e-01, -3.7472e-01,  3.4266e-01,\n",
      "        -6.1689e-02, -6.6041e-02,  3.6132e-01, -2.4126e-01,  3.0802e-01,\n",
      "        -7.7993e-01, -4.2640e-02, -1.0966e-01, -6.0465e-01, -4.1379e-01,\n",
      "         2.2434e-02,  5.4738e-02,  4.4989e-01,  2.5082e-01, -6.2680e-02,\n",
      "         4.3781e-01,  3.1156e-01,  3.8063e-01, -8.1456e-01, -1.7054e-01,\n",
      "        -7.5615e-02, -4.4827e-01, -3.7218e-01,  2.6457e-01,  2.7228e-01,\n",
      "         2.1131e-01, -4.9710e-01, -7.8328e-01, -1.2594e-01,  1.0413e-01,\n",
      "        -4.4624e-01, -4.7671e-01,  3.1786e-02, -6.6385e-01,  8.2908e-02,\n",
      "         5.0040e-01,  3.3957e-01,  3.5931e-01, -5.5873e-01, -4.0336e-01,\n",
      "        -5.2768e-01,  2.0219e-01, -2.7830e-01,  1.7026e-01, -7.8506e-01,\n",
      "        -4.3001e-01, -5.4520e-01, -2.1760e-01,  5.0204e-01,  1.6400e-01,\n",
      "        -2.2537e-01, -1.8396e-01,  3.9546e-01, -1.5862e-01, -6.8222e-02,\n",
      "        -5.5122e-01,  4.9842e-02, -7.0198e-02, -6.9021e-02, -1.9660e-01,\n",
      "        -6.5614e-01, -1.2692e-02, -5.5874e-01,  3.8662e-01, -3.3618e-01,\n",
      "         7.8169e-02, -4.7092e-01, -4.9348e-01,  5.2310e-01, -4.6083e-02,\n",
      "        -5.8600e-01,  4.4129e-02,  3.4901e-01, -3.8184e-01, -7.6566e-02,\n",
      "        -4.9308e-01, -9.4691e-02,  3.3324e-02,  2.3596e-02, -1.5274e-01,\n",
      "         2.7065e-01,  3.8332e-01, -3.7504e-02, -7.7412e-01, -3.9524e-01,\n",
      "         7.1161e-01, -5.1989e-01, -8.4754e-01, -2.8098e-01,  6.3751e-02,\n",
      "        -4.7208e-02,  2.0954e-01, -5.9220e-01,  3.1605e-01,  7.4417e-01,\n",
      "        -2.8843e-01, -4.2453e-01, -4.6851e-01,  7.3902e-01, -2.4770e-01,\n",
      "        -2.9880e-01, -7.8490e-01, -5.7495e-01,  6.4505e-01,  5.7126e-01,\n",
      "         3.3282e-02, -7.7908e-01, -3.9697e-01, -1.9720e-01,  8.6806e-01,\n",
      "         2.1629e-01,  7.9779e-02, -2.1747e-01, -3.7438e-01, -1.7818e-01,\n",
      "         2.7282e-02, -2.7550e-01, -1.7290e-01,  5.4735e-01, -2.1771e-01,\n",
      "        -5.1595e-01, -8.2863e-01, -5.1890e-01, -2.3090e-01,  4.5823e-02,\n",
      "        -2.0891e-02, -4.6765e-02, -6.5400e-01, -8.3584e-02,  5.8543e-02,\n",
      "         5.7075e-02,  3.7038e-01,  1.8273e-01, -6.6493e-01,  5.9146e-03,\n",
      "         1.8015e-01, -3.4803e-01, -5.7002e-01,  5.9692e-01,  6.9171e-01,\n",
      "        -5.2004e-01, -6.6167e-02, -2.6004e-02,  5.5497e-01, -5.0196e-01,\n",
      "         1.2916e-01,  1.3107e-02,  1.3677e-01,  5.3407e-01, -1.2990e-01,\n",
      "         4.2778e-03,  7.7809e-02, -8.9109e-01, -2.6457e-01,  1.3176e-01,\n",
      "         1.7578e-01,  5.9683e-02, -4.0642e-01,  3.2780e-01,  2.7924e-01,\n",
      "        -3.8322e-01,  1.4440e-01, -6.4389e-02, -6.7345e-01, -9.5982e-01,\n",
      "         3.4120e-01, -4.4339e-01, -3.7241e-01,  2.7219e-01,  5.3837e-01,\n",
      "         4.3551e-02, -7.0088e-01,  4.4899e-01,  2.5183e-01,  4.9155e-01,\n",
      "        -2.9846e-01, -7.2596e-02,  8.2120e-01,  3.4533e-02, -4.9643e-01,\n",
      "         2.1130e-01, -3.7364e-01, -1.5495e-01,  4.6162e-01, -7.4252e-01,\n",
      "         3.9750e-01, -1.4582e-01, -8.9182e-02,  5.7729e-01, -5.7674e-01,\n",
      "        -7.3679e-02, -8.9086e-01, -1.9479e-01,  3.7843e-01,  6.8335e-01,\n",
      "         4.9878e-01, -7.7539e-02,  2.0239e-01,  5.1344e-01, -4.8599e-01,\n",
      "        -5.4534e-01, -5.8807e-01,  8.1371e-01,  5.9439e-01,  1.6362e-01,\n",
      "         2.2661e-01, -6.3002e-01,  3.9609e-01, -2.0697e-01, -4.9776e-01,\n",
      "        -2.1154e-02, -3.8874e-01, -2.2980e-01, -3.4677e-01,  7.4446e-01,\n",
      "        -1.0316e-01,  7.1833e-01, -7.4309e-01, -5.1476e-01,  6.9213e-02,\n",
      "        -2.5444e-01,  5.0248e-01, -7.5739e-01,  9.7586e-02,  1.4107e-01,\n",
      "         1.4384e-01,  1.7403e-02,  1.6017e-02, -4.8211e-01,  8.2394e-01,\n",
      "        -1.1629e-02, -1.1092e-01, -6.6114e-01,  7.9065e-01, -4.4794e-01,\n",
      "        -2.0110e-01,  1.8591e-01, -3.6666e-01,  2.4047e-01,  2.2370e-01,\n",
      "        -7.1309e-02, -1.4794e-01, -2.0567e-01,  4.5510e-01,  2.7569e-01,\n",
      "        -2.6540e-01,  5.4415e-01,  2.8879e-01,  1.3689e-02, -5.0633e-01,\n",
      "        -3.4899e-01, -4.3339e-01, -2.6942e-01, -6.2549e-01,  4.7045e-01,\n",
      "        -5.4458e-01, -2.8223e-01,  7.4403e-01,  7.9540e-01, -2.1258e-01,\n",
      "         6.0476e-01,  2.1606e-01,  7.2048e-02,  8.6618e-01,  7.5487e-02,\n",
      "         1.9408e-01, -5.4365e-01, -1.1381e-01,  3.8081e-01,  4.0498e-01,\n",
      "        -5.7987e-01, -6.3950e-01, -6.4449e-01, -3.9301e-01, -7.4739e-01,\n",
      "        -2.7891e-01,  1.5489e-01,  1.4161e-01,  4.7514e-01, -2.3069e-01,\n",
      "        -5.8666e-01,  6.4360e-01, -3.4201e-01, -5.6968e-01,  1.7279e-01,\n",
      "         4.7086e-01, -3.6354e-01,  4.7273e-01,  5.4751e-01,  2.2654e-01,\n",
      "        -3.2976e-01, -1.3767e-01,  3.9496e-01, -3.4149e-01, -1.0276e+00,\n",
      "        -4.2942e-01,  2.6467e-01,  1.8500e-01,  3.8211e-01,  1.6242e-01,\n",
      "        -1.0686e-01, -1.1276e-01,  1.3375e-01,  3.7472e-01, -2.4881e-02,\n",
      "         2.6876e-01,  6.7374e-01, -4.9155e-01, -8.2490e-01,  1.4829e-01,\n",
      "        -6.9106e-01, -3.8704e-01,  1.1947e-01,  2.2498e-01,  4.6112e-01,\n",
      "        -9.2929e-02,  5.8460e-01, -5.2256e-01,  3.0838e-02, -1.9051e-01,\n",
      "        -4.0993e-01,  5.7201e-02,  2.1790e-01,  1.5305e-01, -4.5617e-01,\n",
      "        -3.4129e-02, -1.8993e-01, -2.3720e-01, -5.5371e-02,  3.1972e-01,\n",
      "        -2.3440e-01, -1.0954e-01, -2.4433e-01, -5.9393e-02, -7.9695e-03,\n",
      "         4.3481e-02,  4.7899e-01,  4.5974e-01, -7.8359e-01, -4.5711e-01,\n",
      "        -1.4387e-01,  7.8454e-01,  6.2129e-01, -3.0618e-01, -3.3947e-02,\n",
      "         5.4840e-01, -8.7944e-01, -7.0078e-01,  6.6780e-01, -4.7729e-01,\n",
      "         2.3035e-01,  6.9666e-02, -1.8897e-01, -2.8841e-01, -1.2192e-01,\n",
      "         3.3711e-01, -1.4240e-01, -5.6618e-01, -3.4767e-01,  2.6803e-01,\n",
      "        -3.9645e-01, -1.2458e-01,  1.6638e-01,  3.6470e-01,  2.1963e-02,\n",
      "        -8.1026e-02,  8.3694e-01, -8.0312e-01,  1.3057e-01,  5.9188e-01,\n",
      "         9.1342e-02,  5.7692e-01, -3.1698e-01, -2.3174e-01,  3.8406e-01,\n",
      "        -3.5836e-01, -1.5904e-01, -2.2143e-01, -3.8120e-01,  3.0015e-01,\n",
      "         5.3891e-01, -9.9217e-02,  1.4005e-01, -2.2715e-01, -4.4899e-01,\n",
      "         6.4897e-01, -3.4117e-01,  7.3072e-01, -6.7530e-01, -1.6890e-01])), ('linear2.weight', tensor([[-0.2067,  0.0381,  0.0541,  ..., -0.1053,  0.0773, -0.0022],\n",
      "        [ 0.0454, -0.0570, -0.0544,  ...,  0.0199, -0.1168, -0.0555],\n",
      "        [-0.0048, -0.0284, -0.0800,  ..., -0.0789, -0.0413, -0.0859],\n",
      "        ...,\n",
      "        [ 0.0500, -0.0569, -0.0705,  ...,  0.0048, -0.0813, -0.0858],\n",
      "        [ 0.0667, -0.0904, -0.0727,  ...,  0.0317, -0.0615, -0.0056],\n",
      "        [-0.1763,  0.0120,  0.0712,  ..., -0.0230,  0.0433,  0.0013]])), ('linear2.bias', tensor([-0.0271, -0.0239, -0.0302, -0.0114, -0.0249,  0.0093, -0.0515, -0.0817,\n",
      "         0.0342, -0.0339, -0.0481,  0.0432, -0.0191,  0.0025, -0.0540, -0.0058,\n",
      "        -0.0647, -0.0440, -0.0351, -0.0593, -0.0735, -0.0544, -0.0814, -0.0214,\n",
      "        -0.0154, -0.0055, -0.0674,  0.0044, -0.0351, -0.0741,  0.0171, -0.0615,\n",
      "        -0.0459, -0.0020, -0.0305, -0.0228, -0.0305, -0.0376, -0.0454, -0.0744,\n",
      "         0.0535, -0.0635, -0.0144, -0.0232, -0.0254,  0.0227, -0.0344, -0.0436,\n",
      "        -0.0584,  0.0099, -0.0403, -0.0387, -0.0368,  0.0166,  0.0336, -0.0221,\n",
      "         0.0520, -0.0206,  0.0083, -0.0750, -0.0349, -0.0069, -0.0171,  0.0392,\n",
      "         0.0177, -0.0280,  0.0325,  0.0341, -0.0005, -0.0501, -0.0515, -0.0328,\n",
      "        -0.0284, -0.0531,  0.0279, -0.0303,  0.0078, -0.0676, -0.0238, -0.0261,\n",
      "        -0.0792,  0.0161, -0.0640,  0.0077, -0.0182,  0.0292,  0.0060,  0.0367,\n",
      "        -0.0227, -0.0028,  0.0066, -0.0860, -0.0802,  0.0037, -0.0384, -0.0578,\n",
      "        -0.0726,  0.0060, -0.0239, -0.0855, -0.0250, -0.0263,  0.0115, -0.0662,\n",
      "        -0.0285, -0.0276, -0.0946,  0.0428, -0.0400, -0.0256, -0.0032,  0.0145,\n",
      "        -0.0033, -0.0091, -0.0723, -0.0200, -0.0704, -0.0427,  0.0333, -0.0604,\n",
      "         0.0111,  0.0077, -0.0716, -0.0779, -0.0307, -0.0148,  0.0232,  0.0291,\n",
      "        -0.0622, -0.0294,  0.0257,  0.0165, -0.0498, -0.0171, -0.0305,  0.0129,\n",
      "         0.0129,  0.0155, -0.0162,  0.0116, -0.0579,  0.0244, -0.0378,  0.0376,\n",
      "        -0.0052, -0.0232, -0.0540,  0.0339, -0.0018, -0.0475, -0.0338, -0.0417,\n",
      "        -0.0022, -0.0551,  0.0414, -0.0723, -0.0047, -0.0709,  0.0090, -0.0440,\n",
      "        -0.0442, -0.0542,  0.0242, -0.0196, -0.0681, -0.0328, -0.0508, -0.0354,\n",
      "        -0.0399,  0.0588,  0.0258,  0.0199,  0.0177,  0.0257, -0.0361,  0.0115,\n",
      "        -0.0522,  0.0754, -0.0126,  0.0152, -0.0197,  0.0306, -0.0713,  0.0023,\n",
      "        -0.0181, -0.0771,  0.0207, -0.0439,  0.0010,  0.0851, -0.0483, -0.0554,\n",
      "        -0.0075, -0.0417,  0.0246,  0.0064,  0.0121, -0.0648, -0.0229, -0.0409])), ('linear3.weight', tensor([[ 0.1630, -0.0711,  0.0122,  0.3188, -0.0672,  0.1460,  0.1611, -0.0655,\n",
      "          0.1425,  0.1598, -0.0634,  0.1600, -0.0604,  0.1874,  0.2189,  0.1595,\n",
      "         -0.0528,  0.1662,  0.2074, -0.0820,  0.2165, -0.0661, -0.0646,  0.1621,\n",
      "         -0.0484,  0.1861, -0.0662, -0.0878, -0.0545, -0.0589, -0.0734,  0.2158,\n",
      "         -0.0420, -0.0437, -0.0665,  0.1537, -0.0546, -0.0537, -0.0798, -0.0606,\n",
      "          0.0215,  0.1841, -0.0688, -0.0404,  0.1669,  0.1637,  0.1718,  0.1685,\n",
      "         -0.0620,  0.1889,  0.1763, -0.0651, -0.0010, -0.0844,  0.1750,  0.1665,\n",
      "          0.1265,  0.1654,  0.1831,  0.2238, -0.0434, -0.0862,  0.1615,  0.1765,\n",
      "          0.1828,  0.1783,  0.1497,  0.1665,  0.1712,  0.2593, -0.0624,  0.1816,\n",
      "          0.2360,  0.1678,  0.1844, -0.0550,  0.1842,  0.1726, -0.0541, -0.0591,\n",
      "         -0.0587,  0.1768,  0.1599,  0.1645,  0.1677,  0.1748,  0.1488,  0.1809,\n",
      "         -0.0266, -0.0622,  0.1615, -0.0609, -0.0664, -0.0654, -0.0659, -0.0471,\n",
      "         -0.0631,  0.1913,  0.1853, -0.0627,  0.1793,  0.1616,  0.1755, -0.0580,\n",
      "          0.2019,  0.1765, -0.0553,  0.1636, -0.0652, -0.0579,  0.1667,  0.2021,\n",
      "          0.1624, -0.0618, -0.0617, -0.0589, -0.0635,  0.1525,  0.1598, -0.0430,\n",
      "          0.1753, -0.0761,  0.2072, -0.0508, -0.0685, -0.0739,  0.1519,  0.1452,\n",
      "          0.1638, -0.0740,  0.1462,  0.1989, -0.0282, -0.0613, -0.0731,  0.1711,\n",
      "          0.1886, -0.0729, -0.0717,  0.1787,  0.1643, -0.0765,  0.1669,  0.1742,\n",
      "          0.1628, -0.0758,  0.0117,  0.1503,  0.2081,  0.1700,  0.1675,  0.1990,\n",
      "         -0.0656,  0.1644,  0.1855, -0.0559,  0.1582,  0.2026,  0.1768, -0.0492,\n",
      "         -0.0666,  0.1800,  0.2190,  0.1595, -0.0642,  0.1566,  0.1600, -0.0580,\n",
      "         -0.0678,  0.0647,  0.1556, -0.0787,  0.1674,  0.1616, -0.0586,  0.1968,\n",
      "         -0.0578,  0.2105,  0.1688,  0.1554, -0.0259,  0.1645, -0.0830, -0.0669,\n",
      "         -0.0481, -0.0418,  0.1470, -0.0654,  0.1408,  0.1044, -0.0696, -0.0665,\n",
      "         -0.0867,  0.2075,  0.1450,  0.1996,  0.1943, -0.0597, -0.0619,  0.1819]])), ('linear3.bias', tensor([0.1305]))])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict())\n",
    "# print(state_dict.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee0ee2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_nn_once(old_model):\n",
    "    \n",
    "    # Get the relevant info\n",
    "    state_dict             = old_model.state_dict()\n",
    "    state_dict_items = state_dict.items()\n",
    "    \n",
    "    # Get number of layers:\n",
    "    number_of_layers = len(state_dict_items)//2\n",
    "    \n",
    "    # Get number of neurons in each layer (hidden + output, not input) by directly counting it \n",
    "    number_neurons = np.array([0 for i in range(number_of_layers)])\n",
    "    counter = 0\n",
    "    for name, item in state_dict_items:\n",
    "        if \"weight\" in name:\n",
    "            number_neurons[counter] = np.shape(item)[0]\n",
    "            counter += 1\n",
    "    number_neurons_hidden = number_neurons[:-1]\n",
    "    \n",
    "    # Get probabilities based on this:\n",
    "    probabilities_hidden_layers = number_neurons_hidden/np.sum(number_neurons_hidden)\n",
    "    \n",
    "    # Get the hidden layer from which we are going to prune:\n",
    "    layer_index     = np.random.choice(number_of_layers-1, p=probabilities_hidden_layers)\n",
    "    # Get the index of the neuron we are going to delete in this layer (uniform probability)\n",
    "    neuron_index = np.random.choice(number_neurons_hidden[layer_index])\n",
    "    \n",
    "    # Also get layer index: they have increments of two\n",
    "    layer_number = 2*layer_index + 2\n",
    "    # Testing\n",
    "#     print(layer_index)\n",
    "#     print(neuron_index)\n",
    "#     print(layer_number)\n",
    "    \n",
    "    # Copy the state dict of original model\n",
    "    new_state_dict = state_dict.copy()\n",
    "    \n",
    "    # Prune that state dict:\n",
    "    for key in new_state_dict:\n",
    "        # Prune previous (increment -2!) weight matrix by deleting the row:\n",
    "        if  str(layer_number - 2) + \".weight\" in key:\n",
    "            old = new_state_dict[key]\n",
    "            new = delete_row_tensor(old, neuron_index)\n",
    "            new_state_dict[key] = new\n",
    "            \n",
    "        # Prune current weight matrix by deleting the column\n",
    "        if  str(layer_number) + \".weight\" in key:\n",
    "            old = new_state_dict[key]\n",
    "            new = delete_column_tensor(old, neuron_index)\n",
    "            new_state_dict[key] = new\n",
    "            \n",
    "        # Prune the current bias vector by deleting the row:\n",
    "        if  str(layer_number-2) + \".bias\" in key:\n",
    "            old = new_state_dict[key]\n",
    "            new = delete_row_tensor(old, neuron_index)\n",
    "            new_state_dict[key] = new        \n",
    "        \n",
    "    # Instantiate a new model, with the appropriate number of hidden neurons, and save the pruned state dict\n",
    "    new_number_neurons_hidden = number_neurons_hidden\n",
    "    new_number_neurons_hidden[layer_index] -= 1\n",
    "    new_model = NeuralNetwork(new_number_neurons_hidden[0], new_number_neurons_hidden[1]).to(device)\n",
    "    new_model.load_state_dict(new_state_dict)\n",
    "    \n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b82a01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_nn(old_model, number=10):\n",
    "    counter = 0\n",
    "    while counter < number:\n",
    "        new_model = prune_nn_once(old_model)\n",
    "        old_model = new_model\n",
    "        counter +=1\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5bb01a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = prune_nn(previous_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b2312966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, 'Models/NNC2Pv1.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62646508",
   "metadata": {},
   "source": [
    "# Performance after pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7f4426c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors for p: 2.623259e-04  with L1 and 8.344986e-03 with Linfty for NNC2P with 20 neurons pruned\n",
      "Errors for p: 2.649312e-01  with L1 and 1.045513e+00 with Linfty for pruned with 20 neurons pruned\n"
     ]
    }
   ],
   "source": [
    "number = 20\n",
    "new_model = prune_nn(NNC2P, number=number)\n",
    "model = new_model\n",
    "models = [NNC2P, new_model]\n",
    "names = [\"NNC2P\", \"pruned\"]\n",
    "\n",
    "for i in range(len(models)):\n",
    "    # Get model and name\n",
    "    model = models[i]\n",
    "    name = names[i]\n",
    "\n",
    "    # Get predictions\n",
    "    with torch.no_grad():\n",
    "        p_hat= np.array([])\n",
    "        for input_values in test_features:\n",
    "            prediction = model(input_values)\n",
    "            p_hat = np.append(p_hat, prediction[0].item())\n",
    "\n",
    "    # Get labels as np arrays\n",
    "    p = np.array([])\n",
    "    for value in test_labels:\n",
    "        p = np.append(p, value.item())\n",
    "\n",
    "    # Get the errors:\n",
    "    delta_p_L1       = L1_norm(p_hat, p)\n",
    "    delta_p_Linfty = Linfty_norm(p_hat, p)\n",
    "\n",
    "    print(\"Errors for p: %e  with L1 and %e with Linfty for %s with %d neurons pruned\" % (delta_p_L1, delta_p_Linfty, name, number) )"
   ]
  }
 ],
 "metadata": {
  "author": "Thibeau Wouters",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
