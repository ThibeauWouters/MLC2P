======== Pruning iteration 1/100 ========
Pruned 1/100. Performance is 4.862864671672379e-07
Performance dropped too much, retraining the model for 100 epochs.
Training the model for 100 epochs.

 Epoch 0 
 --------------
Train loss: 1.9119185624560942e-07
Test  loss: 1.8618422827037027e-07

 Epoch 1 
 --------------
Train loss: 1.8928979712171668e-07
Test  loss: 1.841858169397395e-07

 Epoch 2 
 --------------
Train loss: 1.8834122786870466e-07
Test  loss: 1.832178582538689e-07

 Epoch 3 
 --------------
Train loss: 1.8770197019790657e-07
Test  loss: 1.8257431404553057e-07

 Epoch 4 
 --------------
Train loss: 1.8739361337480887e-07
Test  loss: 1.8228135709964357e-07

 Epoch 5 
 --------------
Train loss: 1.8705505344058793e-07
Test  loss: 1.8194909563671404e-07

 Epoch 6 
 --------------
Train loss: 1.8676316591097476e-07
Test  loss: 1.816633558470572e-07

 Epoch 7 
 --------------
Train loss: 1.8650820373693477e-07
Test  loss: 1.8141455685074257e-07

 Epoch 8 
 --------------
Train loss: 1.8635093153420712e-07
Test  loss: 1.812681466483569e-07

 Epoch 9 
 --------------
Train loss: 1.8618974887658623e-07
Test  loss: 1.8111865630563958e-07

 Epoch 10 
 --------------
Train loss: 1.8604722115611593e-07
Test  loss: 1.8098729481952064e-07

 Epoch 11 
 --------------
Train loss: 1.8591605906124187e-07
Test  loss: 1.8086649173739306e-07

 Epoch 12 
 --------------
Train loss: 1.8581926546659134e-07
Test  loss: 1.8078472722388037e-07

 Epoch 13 
 --------------
Train loss: 1.8571354681000685e-07
Test  loss: 1.8069263348478492e-07

 Epoch 14 
 --------------
Train loss: 1.8564580734476976e-07
Test  loss: 1.8064037104617667e-07

 Epoch 15 
 --------------
Train loss: 1.8557849757456778e-07
Test  loss: 1.8058591069798248e-07

 Epoch 16 
 --------------
Train loss: 1.8543929282373027e-07
Test  loss: 1.8045466944795298e-07

 Epoch 17 
 --------------
Train loss: 1.8539351890467515e-07
Test  loss: 1.804252326555812e-07

 Epoch 18 
 --------------
Train loss: 1.8533958233746262e-07
Test  loss: 1.8038649877472872e-07

 Epoch 19 
 --------------
Train loss: 1.8525438513421477e-07
Test  loss: 1.8031212757188686e-07

 Epoch 20 
 --------------
Train loss: 1.851744808433864e-07
Test  loss: 1.8024196570480035e-07

 Epoch 21 
 --------------
Train loss: 1.8509649725615418e-07
Test  loss: 1.8016906004742832e-07

 Epoch 22 
 --------------
Train loss: 1.850394252642218e-07
Test  loss: 1.801285460470381e-07

 Epoch 23 
 --------------
Train loss: 1.8496129141851724e-07
Test  loss: 1.8005730943866165e-07

 Epoch 24 
 --------------
Train loss: 1.8492886188852253e-07
Test  loss: 1.8003708998032114e-07

 Epoch 25 
 --------------
Train loss: 1.8483207075377095e-07
Test  loss: 1.7995022996735123e-07

 Epoch 26 
 --------------
Train loss: 1.8479148310461824e-07
Test  loss: 1.7991937762288786e-07

 Epoch 27 
 --------------
Train loss: 1.8476405783900418e-07
Test  loss: 1.7990709035264505e-07

 Epoch 28 
 --------------
Train loss: 1.8467617130397685e-07
Test  loss: 1.798239113880415e-07

 Epoch 29 
 --------------
Train loss: 1.846601723300978e-07
Test  loss: 1.7982741616846195e-07

 Epoch 30 
 --------------
Train loss: 1.846019003593824e-07
Test  loss: 1.797737476838251e-07

 Epoch 31 
 --------------
Train loss: 1.8457072056747847e-07
Test  loss: 1.7975402447602258e-07

 Epoch 32 
 --------------
Train loss: 1.8450885254566174e-07
Test  loss: 1.7969488737186328e-07

 Epoch 33 
 --------------
Train loss: 1.8444983523266955e-07
Test  loss: 1.7964920993913604e-07

 Epoch 34 
 --------------
Train loss: 1.8439576845423744e-07
Test  loss: 1.7960174996353443e-07

 Epoch 35 
 --------------
Train loss: 1.843704859069817e-07
Test  loss: 1.7958741607482586e-07

 Epoch 36 
 --------------
Train loss: 1.844022229249731e-07
Test  loss: 1.79638899504344e-07

 Epoch 37 
 --------------
Train loss: 1.8433780943780675e-07
Test  loss: 1.79578881145584e-07

 Epoch 38 
 --------------
Train loss: 1.842396184102313e-07
Test  loss: 1.794810036964494e-07

 Epoch 39 
 --------------
Train loss: 1.8419444229209603e-07
Test  loss: 1.794460001763102e-07

 Epoch 40 
 --------------
Train loss: 1.8414013720757794e-07
Test  loss: 1.7939782426647442e-07

 Epoch 41 
 --------------
Train loss: 1.8416404086707416e-07
Test  loss: 1.794408455349532e-07

 Epoch 42 
 --------------
Train loss: 1.841600714428182e-07
Test  loss: 1.7944997330768325e-07

 Epoch 43 
 --------------
Train loss: 1.8407773553121841e-07
Test  loss: 1.7937079158863875e-07

 Epoch 44 
 --------------
Train loss: 1.8403075512480882e-07
Test  loss: 1.793256280394869e-07

 Epoch 45 
 --------------
Train loss: 1.8398384293618618e-07
Test  loss: 1.7928566327387575e-07

 Epoch 46 
 --------------
Train loss: 1.839821774709094e-07
Test  loss: 1.7929665121570657e-07

 Epoch 47 
 --------------
Train loss: 1.8392670553026845e-07
Test  loss: 1.7924834006439e-07

 Epoch 48 
 --------------
Train loss: 1.8389285075244287e-07
Test  loss: 1.7922073696602422e-07

 Epoch 49 
 --------------
Train loss: 1.838765704007983e-07
Test  loss: 1.7921501529794348e-07

 Epoch 50 
 --------------
Train loss: 1.8387806802024897e-07
Test  loss: 1.7922690936904602e-07

 Epoch 51 
 --------------
Train loss: 1.8387457385387052e-07
Test  loss: 1.792300197982481e-07

 Epoch 52 
 --------------
Train loss: 1.8379194119120258e-07
Test  loss: 1.7915124082413366e-07

 Epoch 53 
 --------------
Train loss: 1.8375539511765737e-07
Test  loss: 1.7912271151742108e-07

 Epoch 54 
 --------------
Train loss: 1.837020113299559e-07
Test  loss: 1.7907110835691178e-07

 Epoch 55 
 --------------
Train loss: 1.8369301224367973e-07
Test  loss: 1.7907463636050216e-07

 Epoch 56 
 --------------
Train loss: 1.8370136711070018e-07
Test  loss: 1.7909699622100415e-07

 Epoch 57 
 --------------
Train loss: 1.8370346806761972e-07
Test  loss: 1.7910981839031556e-07

 Epoch 58 
 --------------
Train loss: 1.8362134236440397e-07
Test  loss: 1.790253964639969e-07

 Epoch 59 
 --------------
Train loss: 1.8356045659544407e-07
Test  loss: 1.7896643842568744e-07

 Epoch 60 
 --------------
Train loss: 1.8357718773955867e-07
Test  loss: 1.7899906113958937e-07

 Epoch 61 
 --------------
Train loss: 1.8355555601914375e-07
Test  loss: 1.7898324526417848e-07

 Epoch 62 
 --------------
Train loss: 1.8353079561421737e-07
Test  loss: 1.7896205671521554e-07

 Epoch 63 
 --------------
Adapting learning rate to 5e-07
Train loss: 1.83568676813195e-07
Test  loss: 1.790125171958799e-07

 Epoch 64 
 --------------
Train loss: 1.8026395139685292e-07
Test  loss: 1.7492137584331605e-07

 Epoch 65 
 --------------
Train loss: 1.800953335944655e-07
Test  loss: 1.7475299175496078e-07

 Epoch 66 
 --------------
Train loss: 1.7995888116075774e-07
Test  loss: 1.7461592045638229e-07

 Epoch 67 
 --------------
Train loss: 1.7993505282305477e-07
Test  loss: 1.7459584951395915e-07

 Epoch 68 
 --------------
Train loss: 1.7990766039162053e-07
Test  loss: 1.7457389212597465e-07

 Epoch 69 
 --------------
Train loss: 1.7986589380001305e-07
Test  loss: 1.745352783223043e-07

 Epoch 70 
 --------------
Train loss: 1.798098734596465e-07
Test  loss: 1.7448174826864515e-07

 Epoch 71 
 --------------
Train loss: 1.7976911182273626e-07
Test  loss: 1.7444676448706532e-07

 Epoch 72 
 --------------
Train loss: 1.797425140694031e-07
Test  loss: 1.744203814110078e-07

 Epoch 73 
 --------------
Train loss: 1.797223119567093e-07
Test  loss: 1.7440075193014842e-07

 Epoch 74 
 --------------
Train loss: 1.7970242150795456e-07
Test  loss: 1.743867007091878e-07

 Epoch 75 
 --------------
Train loss: 1.7966145344132654e-07
Test  loss: 1.743450562534658e-07

 Epoch 76 
 --------------
Train loss: 1.7963332134200983e-07
Test  loss: 1.743224273174671e-07

 Epoch 77 
 --------------
Train loss: 1.7964706386521812e-07
Test  loss: 1.743453018844574e-07

 Epoch 78 
 --------------
Train loss: 1.795522495299906e-07
Test  loss: 1.7424640342740847e-07

 Epoch 79 
 --------------
Train loss: 1.7955967250458116e-07
Test  loss: 1.7425530597171192e-07

 Epoch 80 
 --------------
Train loss: 1.79553516503006e-07
Test  loss: 1.7425687110099473e-07

 Epoch 81 
 --------------
Adapting learning rate to 2.5e-07
Train loss: 1.7954513610476397e-07
Test  loss: 1.7425421239422917e-07

 Epoch 82 
 --------------
Train loss: 1.7581827035471066e-07
Test  loss: 1.6968824296420496e-07

 Epoch 83 
 --------------
Train loss: 1.7570963005155705e-07
Test  loss: 1.6959139020055415e-07

 Epoch 84 
 --------------
Train loss: 1.7565657719131877e-07
Test  loss: 1.695433469442799e-07

 Epoch 85 
 --------------
Train loss: 1.7561894806448208e-07
Test  loss: 1.6950586395915808e-07

 Epoch 86 
 --------------
Train loss: 1.7557412448496735e-07
Test  loss: 1.6945824803872183e-07

 Epoch 87 
 --------------
Train loss: 1.7556910886042943e-07
Test  loss: 1.69455594774532e-07

 Epoch 88 
 --------------
Train loss: 1.7553982416913527e-07
Test  loss: 1.6942557933817624e-07

 Epoch 89 
 --------------
Train loss: 1.755279080754235e-07
Test  loss: 1.6941320070757431e-07

 Epoch 90 
 --------------
Train loss: 1.7551216583200357e-07
Test  loss: 1.6940219704526925e-07

 Epoch 91 
 --------------
Train loss: 1.7548143427816853e-07
Test  loss: 1.693669473549886e-07

 Epoch 92 
 --------------
Train loss: 1.7547368691381848e-07
Test  loss: 1.6936176858809512e-07

 Epoch 93 
 --------------
Adapting learning rate to 1.25e-07
Train loss: 1.754774859115571e-07
Test  loss: 1.6936752323512025e-07

 Epoch 94 
 --------------
Train loss: 1.7299996788366912e-07
Test  loss: 1.6648484680458185e-07

 Epoch 95 
 --------------
Train loss: 1.7298191464192314e-07
Test  loss: 1.6647563998681006e-07

 Epoch 96 
 --------------
Train loss: 1.729730958295761e-07
Test  loss: 1.6646974469545522e-07

 Epoch 97 
 --------------
Train loss: 1.7296339176624543e-07
Test  loss: 1.6646314497362122e-07

 Epoch 98 
 --------------
Train loss: 1.7295379952599887e-07
Test  loss: 1.6645294285119428e-07

 Epoch 99 
 --------------
Train loss: 1.7295344732488616e-07
Test  loss: 1.6645304095376402e-07
Retrained 1/100. Performance is 1.7746552702252146e-07
======== Pruning iteration 2/100 ========
Pruned 2/100. Performance is 5.336990664982532e-07
Performance dropped too much, retraining the model for 100 epochs.
Training the model for 100 epochs.

 Epoch 0 
 --------------
Train loss: 1.723873710808732e-07
Test  loss: 1.5560557271807698e-07

 Epoch 1 
 --------------
Train loss: 1.6985145190844265e-07
Test  loss: 1.5302990463315693e-07

 Epoch 2 
 --------------
Train loss: 1.689133595846215e-07
Test  loss: 1.5210759677438782e-07

 Epoch 3 
 --------------
Train loss: 1.6837930037709725e-07
Test  loss: 1.5160292005366855e-07

 Epoch 4 
 --------------
Train loss: 1.680069294849318e-07
Test  loss: 1.5126822353751503e-07

 Epoch 5 
 --------------
Train loss: 1.6780171532673193e-07
Test  loss: 1.510939011222972e-07

 Epoch 6 
 --------------
Train loss: 1.676619714203298e-07
Test  loss: 1.509812550736138e-07

 Epoch 7 
 --------------
Train loss: 1.6750764868618262e-07
Test  loss: 1.5085032364745834e-07

 Epoch 8 
 --------------
Train loss: 1.674030143476557e-07
Test  loss: 1.507723785991016e-07

 Epoch 9 
 --------------
Train loss: 1.672829439073098e-07
Test  loss: 1.506738306178246e-07

 Epoch 10 
 --------------
Train loss: 1.6724322616994415e-07
Test  loss: 1.5064827563903125e-07

 Epoch 11 
 --------------
Train loss: 1.6715312712278775e-07
Test  loss: 1.5057827883124925e-07

 Epoch 12 
 --------------
Train loss: 1.6706161285640064e-07
Test  loss: 1.5050414349511161e-07

 Epoch 13 
 --------------
Train loss: 1.669761495989519e-07
Test  loss: 1.5043541485004325e-07

 Epoch 14 
 --------------
Train loss: 1.6693823237332594e-07
Test  loss: 1.504107353427592e-07

 Epoch 15 
 --------------
Train loss: 1.6687584467973693e-07
Test  loss: 1.5036265488798365e-07

 Epoch 16 
 --------------
Train loss: 1.66822968373026e-07
Test  loss: 1.5032095157696263e-07

 Epoch 17 
 --------------
Train loss: 1.667628441239799e-07
Test  loss: 1.5027695324411903e-07

 Epoch 18 
 --------------
Train loss: 1.6673354289054031e-07
Test  loss: 1.5025814237148666e-07

 Epoch 19 
 --------------
Train loss: 1.6666102739719691e-07
Test  loss: 1.5019850334720315e-07

 Epoch 20 
 --------------
Train loss: 1.666021617765523e-07
Test  loss: 1.501519873690554e-07

 Epoch 21 
 --------------
Train loss: 1.6655133985494787e-07
Test  loss: 1.5011196839902195e-07

 Epoch 22 
 --------------
Train loss: 1.6652521152096255e-07
Test  loss: 1.5009593297328354e-07

 Epoch 23 
 --------------
Train loss: 1.6644333759927577e-07
Test  loss: 1.500274422692275e-07

 Epoch 24 
 --------------
Train loss: 1.6646121038306207e-07
Test  loss: 1.500540308947425e-07

 Epoch 25 
 --------------
Train loss: 1.663873408404015e-07
Test  loss: 1.4999015483091477e-07

 Epoch 26 
 --------------
Train loss: 1.6633107923382795e-07
Test  loss: 1.4994339542945215e-07

 Epoch 27 
 --------------
Train loss: 1.6626608058203373e-07
Test  loss: 1.4988926227143208e-07

 Epoch 28 
 --------------
Train loss: 1.6625251648676455e-07
Test  loss: 1.4988594431210626e-07

 Epoch 29 
 --------------
Train loss: 1.6620397548763323e-07
Test  loss: 1.4984425643212117e-07

 Epoch 30 
 --------------
Train loss: 1.661646859929533e-07
Test  loss: 1.4981432741297175e-07

 Epoch 31 
 --------------
Train loss: 1.6611694481554194e-07
Test  loss: 1.4977545942285317e-07

 Epoch 32 
 --------------
Train loss: 1.660875405605111e-07
Test  loss: 1.4975549699994217e-07

 Epoch 33 
 --------------
Train loss: 1.6605204780475446e-07
Test  loss: 1.4973016125082404e-07

 Epoch 34 
 --------------
Train loss: 1.6601794035793205e-07
Test  loss: 1.4970167019537378e-07

 Epoch 35 
 --------------
Train loss: 1.659681917445255e-07
Test  loss: 1.496611533460023e-07

 Epoch 36 
 --------------
Train loss: 1.6594734529320477e-07
Test  loss: 1.4964924718091757e-07

 Epoch 37 
 --------------
Train loss: 1.6593887378206772e-07
Test  loss: 1.4964697418194713e-07

 Epoch 38 
 --------------
Train loss: 1.6590245118521807e-07
Test  loss: 1.4961353641536952e-07

 Epoch 39 
 --------------
Train loss: 1.6587916721988448e-07
Test  loss: 1.4959865122324908e-07

 Epoch 40 
 --------------
Train loss: 1.6583831420433625e-07
Test  loss: 1.495666761276214e-07

 Epoch 41 
 --------------
Train loss: 1.6583071563758266e-07
Test  loss: 1.4956800686576797e-07

 Epoch 42 
 --------------
Train loss: 1.6583211919680708e-07
Test  loss: 1.4957643115294992e-07

 Epoch 43 
 --------------
Train loss: 1.6577975646612232e-07
Test  loss: 1.4952871258973475e-07

 Epoch 44 
 --------------
Train loss: 1.6572673865979937e-07
Test  loss: 1.4948357862572094e-07

 Epoch 45 
 --------------
Train loss: 1.65670988360489e-07
Test  loss: 1.4943491243004698e-07

 Epoch 46 
 --------------
Train loss: 1.656424104993448e-07
Test  loss: 1.494132257548721e-07

 Epoch 47 
 --------------
Train loss: 1.6561212089669653e-07
Test  loss: 1.4938865393567436e-07

 Epoch 48 
 --------------
Train loss: 1.6563366729656082e-07
Test  loss: 1.4941129030910324e-07

 Epoch 49 
 --------------
Train loss: 1.6560567133012683e-07
Test  loss: 1.4939143564238172e-07

 Epoch 50 
 --------------
Train loss: 1.6558416714360647e-07
Test  loss: 1.4937540956096133e-07

 Epoch 51 
 --------------
Train loss: 1.6553686074445295e-07
Test  loss: 1.4933530021238902e-07

 Epoch 52 
 --------------
Train loss: 1.6546669024251058e-07
Test  loss: 1.4927392475956817e-07

 Epoch 53 
 --------------
Train loss: 1.65451522065041e-07
Test  loss: 1.4926235658468016e-07

 Epoch 54 
 --------------
Train loss: 1.6540630270895917e-07
Test  loss: 1.492235689420758e-07

 Epoch 55 
 --------------
Train loss: 1.6538457081054504e-07
Test  loss: 1.4920433284764033e-07

 Epoch 56 
 --------------
Train loss: 1.653636134761882e-07
Test  loss: 1.491887927643981e-07

 Epoch 57 
 --------------
Train loss: 1.65392190565683e-07
Test  loss: 1.4922034861711065e-07

 Epoch 58 
 --------------
Train loss: 1.6537499413544765e-07
Test  loss: 1.4920869546369503e-07

 Epoch 59 
 --------------
Train loss: 1.653049214965563e-07
Test  loss: 1.491471715829234e-07

 Epoch 60 
 --------------
Train loss: 1.6529242523617425e-07
Test  loss: 1.4913573461156762e-07

 Epoch 61 
 --------------
Train loss: 1.652777540577688e-07
Test  loss: 1.4912794592245615e-07

 Epoch 62 
 --------------
Train loss: 1.6523021800196602e-07
Test  loss: 1.490862399696009e-07

 Epoch 63 
 --------------
Train loss: 1.6520357616514048e-07
Test  loss: 1.490640672253071e-07

 Epoch 64 
 --------------
Train loss: 1.6520898585383749e-07
Test  loss: 1.490721322741134e-07

 Epoch 65 
 --------------
Train loss: 1.6517166621667913e-07
Test  loss: 1.4903747083035915e-07

 Epoch 66 
 --------------
Train loss: 1.6515055985450998e-07
Test  loss: 1.4902125811512777e-07

 Epoch 67 
 --------------
Train loss: 1.651424927786138e-07
Test  loss: 1.4901883069796805e-07

 Epoch 68 
 --------------
Train loss: 1.6510978370689599e-07
Test  loss: 1.4899219811471533e-07

 Epoch 69 
 --------------
Train loss: 1.6511640968701612e-07
Test  loss: 1.4899742930683664e-07

 Epoch 70 
 --------------
Adapting learning rate to 5e-07
Train loss: 1.651060600636356e-07
Test  loss: 1.4899439426497024e-07

 Epoch 71 
 --------------
Train loss: 1.633369995985845e-07
Test  loss: 1.478075777668574e-07

 Epoch 72 
 --------------
Train loss: 1.6326306849236972e-07
Test  loss: 1.4772699501871542e-07

 Epoch 73 
 --------------
Train loss: 1.6322981217768985e-07
Test  loss: 1.4769102837265357e-07

 Epoch 74 
 --------------
Train loss: 1.6320374048461872e-07
Test  loss: 1.4766607673941972e-07

 Epoch 75 
 --------------
Train loss: 1.6318392576835095e-07
Test  loss: 1.476438654629382e-07

 Epoch 76 
 --------------
Train loss: 1.6319592263585036e-07
Test  loss: 1.4765340427783058e-07

 Epoch 77 
 --------------
Train loss: 1.6319072630182064e-07
Test  loss: 1.4765004071494124e-07

 Epoch 78 
 --------------
Train loss: 1.6319410853355976e-07
Test  loss: 1.4765165461174588e-07

 Epoch 79 
 --------------
Train loss: 1.631617124786544e-07
Test  loss: 1.476253856878975e-07

 Epoch 80 
 --------------
Train loss: 1.631461316634386e-07
Test  loss: 1.4760965500951176e-07

 Epoch 81 
 --------------
Adapting learning rate to 2.5e-07
Train loss: 1.6312667418958427e-07
Test  loss: 1.4759055512702677e-07

 Epoch 82 
 --------------
Train loss: 1.5682519897382007e-07
Test  loss: 1.4137052521452727e-07

 Epoch 83 
 --------------
Train loss: 1.5682535402419263e-07
Test  loss: 1.4137316476161012e-07

 Epoch 84 
 --------------
Train loss: 1.5681256927422283e-07
Test  loss: 1.4136503409826838e-07

 Epoch 85 
 --------------
Train loss: 1.5681364793493912e-07
Test  loss: 1.413664009679671e-07

 Epoch 86 
 --------------
Train loss: 1.5681519384997954e-07
Test  loss: 1.4136738275414944e-07

 Epoch 87 
 --------------
Train loss: 1.5682191049535277e-07
Test  loss: 1.4137627709770007e-07

 Epoch 88 
 --------------
Train loss: 1.5681878217179702e-07
Test  loss: 1.4137177171193026e-07

 Epoch 89 
 --------------
Train loss: 1.5680165695073355e-07
Test  loss: 1.4136071902104136e-07

 Epoch 90 
 --------------
Train loss: 1.5679228245204513e-07
Test  loss: 1.4134986483377282e-07

 Epoch 91 
 --------------
Train loss: 1.5677831671467855e-07
Test  loss: 1.4133802107953845e-07

 Epoch 92 
 --------------
Adapting learning rate to 1.25e-07
Train loss: 1.5678538107835038e-07
Test  loss: 1.4134540058229811e-07

 Epoch 93 
 --------------
Train loss: 1.548024053398933e-07
Test  loss: 1.39372412669387e-07

 Epoch 94 
 --------------
Train loss: 1.5479662691149088e-07
Test  loss: 1.39371888700872e-07

 Epoch 95 
 --------------
Train loss: 1.5479709898471584e-07
Test  loss: 1.3937536907199285e-07

 Epoch 96 
 --------------
Train loss: 1.5479606547046386e-07
Test  loss: 1.3937553398941584e-07

 Epoch 97 
 --------------
Train loss: 1.547924325578265e-07
Test  loss: 1.3937487257741863e-07

 Epoch 98 
 --------------
Train loss: 1.5479063355030576e-07
Test  loss: 1.3937490366082568e-07

 Epoch 99 
 --------------
Train loss: 1.5478839362685903e-07
Test  loss: 1.393733864193991e-07
Retrained 2/100. Performance is 1.4845147255951188e-07
======== Pruning iteration 3/100 ========
