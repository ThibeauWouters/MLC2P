======== Pruning iteration 1/100 ========
Pruned 1/100. Performance is 6.442766826645999e-07
Performance dropped too much, retraining the model for 100 epochs.
Training the model for 100 epochs.

 Epoch 0 
 --------------
Train loss: 1.9074388664819253e-07
Test  loss: 2.0447778482706528e-07

 Epoch 1 
 --------------
Train loss: 1.84970280938046e-07
Test  loss: 1.9733483359975882e-07

 Epoch 2 
 --------------
Train loss: 1.833390399966106e-07
Test  loss: 1.9521816126714289e-07

 Epoch 3 
 --------------
Train loss: 1.8234469786193585e-07
Test  loss: 1.9397793889292946e-07

 Epoch 4 
 --------------
Train loss: 1.8171485662463737e-07
Test  loss: 1.9317679446133954e-07

 Epoch 5 
 --------------
Train loss: 1.8121559054407043e-07
Test  loss: 1.9254739703968968e-07

 Epoch 6 
 --------------
Train loss: 1.8087715374122126e-07
Test  loss: 1.9210943758327148e-07

 Epoch 7 
 --------------
Train loss: 1.8062738898265705e-07
Test  loss: 1.9177952645042516e-07

 Epoch 8 
 --------------
Train loss: 1.8055365614770834e-07
Test  loss: 1.916369106824547e-07

 Epoch 9 
 --------------
Train loss: 1.8029346783237087e-07
Test  loss: 1.9131494567614826e-07

 Epoch 10 
 --------------
Train loss: 1.8014913018191692e-07
Test  loss: 1.911250078641309e-07

 Epoch 11 
 --------------
Train loss: 1.8010189625954355e-07
Test  loss: 1.910354863635173e-07

 Epoch 12 
 --------------
Train loss: 1.8005006315604532e-07
Test  loss: 1.9094722905577194e-07

 Epoch 13 
 --------------
Train loss: 1.800041309522271e-07
Test  loss: 1.9086560914224618e-07

 Epoch 14 
 --------------
Train loss: 1.7977558654536096e-07
Test  loss: 1.906057050723793e-07

 Epoch 15 
 --------------
Train loss: 1.7974505757791803e-07
Test  loss: 1.9054332011256148e-07

 Epoch 16 
 --------------
Train loss: 1.7970856543740866e-07
Test  loss: 1.9048709349814277e-07

 Epoch 17 
 --------------
Train loss: 1.7966095710733044e-07
Test  loss: 1.9041489051759412e-07

 Epoch 18 
 --------------
Train loss: 1.796623192262814e-07
Test  loss: 1.9039533440083976e-07

 Epoch 19 
 --------------
Train loss: 1.7957498602214628e-07
Test  loss: 1.902851116916407e-07

 Epoch 20 
 --------------
Train loss: 1.7954581569767926e-07
Test  loss: 1.9024318855220432e-07

 Epoch 21 
 --------------
Train loss: 1.7950792047685128e-07
Test  loss: 1.901918164713162e-07

 Epoch 22 
 --------------
Train loss: 1.7950515366180753e-07
Test  loss: 1.9017271131651332e-07

 Epoch 23 
 --------------
Train loss: 1.793771147760026e-07
Test  loss: 1.9003157493597546e-07

 Epoch 24 
 --------------
Train loss: 1.7931827899531072e-07
Test  loss: 1.8996166520373016e-07

 Epoch 25 
 --------------
Train loss: 1.7931252219796078e-07
Test  loss: 1.8994702508358805e-07

 Epoch 26 
 --------------
Train loss: 1.79284270703306e-07
Test  loss: 1.8990793945002982e-07

 Epoch 27 
 --------------
Train loss: 1.7921286706439332e-07
Test  loss: 1.8983067620204713e-07

 Epoch 28 
 --------------
Train loss: 1.7918903219111826e-07
Test  loss: 1.898004160597674e-07

 Epoch 29 
 --------------
Train loss: 1.7917848671089586e-07
Test  loss: 1.897822295027857e-07

 Epoch 30 
 --------------
Train loss: 1.7915842851010665e-07
Test  loss: 1.8975508288272554e-07

 Epoch 31 
 --------------
Train loss: 1.7908620059898796e-07
Test  loss: 1.8967435953565595e-07

 Epoch 32 
 --------------
Train loss: 1.7902366982411877e-07
Test  loss: 1.8960796154170166e-07

 Epoch 33 
 --------------
Train loss: 1.7894494833399223e-07
Test  loss: 1.895270390270061e-07

 Epoch 34 
 --------------
Train loss: 1.7896478617842604e-07
Test  loss: 1.895430964642461e-07

 Epoch 35 
 --------------
Train loss: 1.7895494216020324e-07
Test  loss: 1.8952913773869687e-07

 Epoch 36 
 --------------
Train loss: 1.788836887996581e-07
Test  loss: 1.8945168825700912e-07

 Epoch 37 
 --------------
Train loss: 1.7884819894220527e-07
Test  loss: 1.894239727544147e-07

 Epoch 38 
 --------------
Train loss: 1.788190228594999e-07
Test  loss: 1.8939072521692624e-07

 Epoch 39 
 --------------
Train loss: 1.787762196101994e-07
Test  loss: 1.8934158592010577e-07

 Epoch 40 
 --------------
Train loss: 1.7874220129669993e-07
Test  loss: 1.893109954038302e-07

 Epoch 41 
 --------------
Train loss: 1.787075483250078e-07
Test  loss: 1.8926918742679956e-07

 Epoch 42 
 --------------
Train loss: 1.7868399941392e-07
Test  loss: 1.8924765626230183e-07

 Epoch 43 
 --------------
Train loss: 1.786058611813246e-07
Test  loss: 1.8917068099411177e-07

 Epoch 44 
 --------------
Train loss: 1.7856533439157828e-07
Test  loss: 1.8912975415250135e-07

 Epoch 45 
 --------------
Train loss: 1.7854784550479507e-07
Test  loss: 1.8910757485044293e-07

 Epoch 46 
 --------------
Train loss: 1.7855376681978895e-07
Test  loss: 1.891175061550679e-07

 Epoch 47 
 --------------
Train loss: 1.78465700093966e-07
Test  loss: 1.8902776573691844e-07

 Epoch 48 
 --------------
Train loss: 1.7844044353836352e-07
Test  loss: 1.8900479870289303e-07

 Epoch 49 
 --------------
Train loss: 1.7839226351412663e-07
Test  loss: 1.8895501388480745e-07

 Epoch 50 
 --------------
Train loss: 1.784606910788966e-07
Test  loss: 1.890222528730576e-07

 Epoch 51 
 --------------
Train loss: 1.7833497956729615e-07
Test  loss: 1.8890048825408058e-07

 Epoch 52 
 --------------
Train loss: 1.783254632314879e-07
Test  loss: 1.88890366470655e-07

 Epoch 53 
 --------------
Train loss: 1.7833282378489912e-07
Test  loss: 1.8889836112635565e-07

 Epoch 54 
 --------------
Train loss: 1.782634847472764e-07
Test  loss: 1.8882708282750847e-07

 Epoch 55 
 --------------
Train loss: 1.782294288148023e-07
Test  loss: 1.8879443863841714e-07

 Epoch 56 
 --------------
Train loss: 1.7825505514252882e-07
Test  loss: 1.8881934602163733e-07

 Epoch 57 
 --------------
Train loss: 1.7818875669064483e-07
Test  loss: 1.8875531781256255e-07

 Epoch 58 
 --------------
Train loss: 1.7822119839081552e-07
Test  loss: 1.887896448982874e-07

 Epoch 59 
 --------------
Adapting learning rate to 5e-07
Train loss: 1.7821885680433526e-07
Test  loss: 1.8878446885551943e-07

 Epoch 60 
 --------------
Train loss: 1.5975201633295911e-07
Test  loss: 1.6947789331950913e-07

 Epoch 61 
 --------------
Train loss: 1.6000342665947186e-07
Test  loss: 1.6971485470222227e-07

 Epoch 62 
 --------------
Train loss: 1.6006206046910164e-07
Test  loss: 1.6977389971391375e-07

 Epoch 63 
 --------------
Train loss: 1.6011836201386132e-07
Test  loss: 1.6982379039832675e-07

 Epoch 64 
 --------------
Train loss: 1.6012040520223536e-07
Test  loss: 1.698239959846734e-07

 Epoch 65 
 --------------
Train loss: 1.6008526510660204e-07
Test  loss: 1.69784691166842e-07

 Epoch 66 
 --------------
Train loss: 1.6008454058322741e-07
Test  loss: 1.6978269448500191e-07

 Epoch 67 
 --------------
Train loss: 1.601155880763372e-07
Test  loss: 1.698089564680055e-07

 Epoch 68 
 --------------
Train loss: 1.6010272723860908e-07
Test  loss: 1.6979495024619306e-07

 Epoch 69 
 --------------
Train loss: 1.6006678910471805e-07
Test  loss: 1.697555976880622e-07

 Epoch 70 
 --------------
Adapting learning rate to 2.5e-07
Train loss: 1.6010191134796514e-07
Test  loss: 1.6978962201561356e-07

 Epoch 71 
 --------------
Train loss: 1.540829295187507e-07
Test  loss: 1.6364117483433687e-07

 Epoch 72 
 --------------
