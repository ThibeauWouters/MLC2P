{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bb9f224",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "import random\n",
    "import csv\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from pysr import PySRRegressor  # Miles Cranmer's PySR\n",
    "import torch  # PyTorch -- note that this should be loaded AFTER PySR\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import ToTensor \n",
    "import matplotlib.cm as cm\n",
    "# Own scripts:\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import physics\n",
    "import data\n",
    "import nnc2p\n",
    "# from nnc2p import NeuralNetwork # our own architecture\n",
    "# Get dirs\n",
    "import os\n",
    "cwd = os.getcwd()# \"Code\" folder\n",
    "master_dir = os.path.abspath(os.path.join(cwd, \"..\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3393c80",
   "metadata": {},
   "source": [
    "Get the folder for the eos tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efbc8d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eos_tables_folder = os.path.join(master_dir, \"eos_tables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fb3c8c",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ab265e",
   "metadata": {},
   "source": [
    "We are going to explore symbolic regression as a way to gain insight into C2P aspects. We will use PySR, the Github repo can be found [here](https://github.com/MilesCranmer/PySR)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d06e8c",
   "metadata": {},
   "source": [
    "## PySR demo from Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10de7bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training data\n",
    "\n",
    "X = 2 * np.random.randn(100, 5)\n",
    "y = 2.5382 * np.cos(X[:, 3]) + X[:, 0] ** 2 - 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f8e64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PySRRegressor(\n",
    "    niterations=40,  # < Increase me for better results\n",
    "    binary_operators=[\"+\", \"*\"],\n",
    "    unary_operators=[\n",
    "        \"cos\",\n",
    "        \"exp\",\n",
    "        \"sin\",\n",
    "        \"inv(x) = 1/x\",\n",
    "        # ^ Custom operator (julia syntax)\n",
    "    ],\n",
    "    extra_sympy_mappings={\"inv\": lambda x: 1 / x},\n",
    "    # ^ Define operator for SymPy as well\n",
    "    loss=\"loss(prediction, target) = (prediction - target)^2\",\n",
    "    # ^ Custom loss function (julia syntax)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2c807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e76e8b2",
   "metadata": {},
   "source": [
    "## Read in EOS tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf08ad4a",
   "metadata": {},
   "source": [
    "Read in an EOS table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d5e6fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our downloaded EOS tables here\n",
    "first_table_filename      = \"LS180_234r_136t_50y_analmu_20091212_SVNr26.h5\"\n",
    "second_table_filename     = \"GShen_NL3EOS_rho280_temp180_ye52_version_1.1_20120817.h5\"\n",
    "third_table_filename      = \"SLy4_0000_rho391_temp163_ye66.h5\"\n",
    "# Then specify which we are going to use here -- let's try the SLy4\n",
    "eos_table_filename = third_table_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d8f465",
   "metadata": {},
   "source": [
    "Read in the SLy4 EOS table using our py script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d74b0643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For ye 0.005, log temp -3.0, log rho 3.0239960056064277, we have log p: 17.99956975587081.\n"
     ]
    }
   ],
   "source": [
    "eos_table = physics.read_eos_table(eos_table_filename)\n",
    "# Small test to see the output of the EOS table\n",
    "test_ye = eos_table[\"ye\"][()][0]\n",
    "test_temp = eos_table[\"logtemp\"][()][0]\n",
    "test_rho = eos_table[\"logrho\"][()][0]\n",
    "test_press = eos_table[\"logpress\"][()][0, 0, 0]\n",
    "print(f\"For ye {test_ye}, log temp {test_temp}, log rho {test_rho}, we have log p: {test_press}.\")\n",
    "eos_table.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb1e315",
   "metadata": {},
   "source": [
    "# PySR explorations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f8432f",
   "metadata": {},
   "source": [
    "## Analytic Gamma law"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02569bd1",
   "metadata": {},
   "source": [
    "### Import training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc90fcc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rho</th>\n",
       "      <th>eps</th>\n",
       "      <th>v</th>\n",
       "      <th>p</th>\n",
       "      <th>D</th>\n",
       "      <th>S</th>\n",
       "      <th>tau</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.961337</td>\n",
       "      <td>0.236087</td>\n",
       "      <td>0.319649</td>\n",
       "      <td>1.253046</td>\n",
       "      <td>8.402148</td>\n",
       "      <td>3.949742</td>\n",
       "      <td>2.701290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.979841</td>\n",
       "      <td>0.299793</td>\n",
       "      <td>0.409997</td>\n",
       "      <td>1.195142</td>\n",
       "      <td>6.556218</td>\n",
       "      <td>4.419662</td>\n",
       "      <td>3.028383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.789420</td>\n",
       "      <td>1.948681</td>\n",
       "      <td>0.423389</td>\n",
       "      <td>2.324672</td>\n",
       "      <td>1.975190</td>\n",
       "      <td>3.921111</td>\n",
       "      <td>4.961391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.306846</td>\n",
       "      <td>0.241474</td>\n",
       "      <td>0.293585</td>\n",
       "      <td>1.498240</td>\n",
       "      <td>9.735878</td>\n",
       "      <td>4.193450</td>\n",
       "      <td>3.049464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.010703</td>\n",
       "      <td>0.463988</td>\n",
       "      <td>0.528883</td>\n",
       "      <td>3.096566</td>\n",
       "      <td>11.795413</td>\n",
       "      <td>13.034884</td>\n",
       "      <td>9.754071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>7.702782</td>\n",
       "      <td>0.973514</td>\n",
       "      <td>0.611309</td>\n",
       "      <td>4.999177</td>\n",
       "      <td>9.733204</td>\n",
       "      <td>19.717146</td>\n",
       "      <td>17.521607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>5.652622</td>\n",
       "      <td>0.787668</td>\n",
       "      <td>0.080313</td>\n",
       "      <td>2.968260</td>\n",
       "      <td>5.670941</td>\n",
       "      <td>1.056769</td>\n",
       "      <td>4.518943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>2.695031</td>\n",
       "      <td>1.121314</td>\n",
       "      <td>0.292665</td>\n",
       "      <td>2.014650</td>\n",
       "      <td>2.818436</td>\n",
       "      <td>2.474755</td>\n",
       "      <td>3.622844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>2.015569</td>\n",
       "      <td>0.735307</td>\n",
       "      <td>0.683622</td>\n",
       "      <td>0.988041</td>\n",
       "      <td>2.761673</td>\n",
       "      <td>5.756956</td>\n",
       "      <td>4.671540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>7.907945</td>\n",
       "      <td>0.085229</td>\n",
       "      <td>0.361200</td>\n",
       "      <td>0.449324</td>\n",
       "      <td>8.480475</td>\n",
       "      <td>3.751535</td>\n",
       "      <td>1.456509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           rho       eps         v         p          D          S        tau\n",
       "0     7.961337  0.236087  0.319649  1.253046   8.402148   3.949742   2.701290\n",
       "1     5.979841  0.299793  0.409997  1.195142   6.556218   4.419662   3.028383\n",
       "2     1.789420  1.948681  0.423389  2.324672   1.975190   3.921111   4.961391\n",
       "3     9.306846  0.241474  0.293585  1.498240   9.735878   4.193450   3.049464\n",
       "4    10.010703  0.463988  0.528883  3.096566  11.795413  13.034884   9.754071\n",
       "..         ...       ...       ...       ...        ...        ...        ...\n",
       "195   7.702782  0.973514  0.611309  4.999177   9.733204  19.717146  17.521607\n",
       "196   5.652622  0.787668  0.080313  2.968260   5.670941   1.056769   4.518943\n",
       "197   2.695031  1.121314  0.292665  2.014650   2.818436   2.474755   3.622844\n",
       "198   2.015569  0.735307  0.683622  0.988041   2.761673   5.756956   4.671540\n",
       "199   7.907945  0.085229  0.361200  0.449324   8.480475   3.751535   1.456509\n",
       "\n",
       "[200 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = physics.generate_data_as_df(200)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dce712",
   "metadata": {},
   "source": [
    "### Can PySR learn the analytic $\\Gamma$-law EOS?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfc7cb72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 2)\n",
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "X = np.dstack((df[\"rho\"], df[\"eps\"]))[0]\n",
    "print(X.shape)\n",
    "# Output\n",
    "y = df[\"p\"]\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b063566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below is the standard set-up shown on PySR github repo\n",
    "model = PySRRegressor(\n",
    "    niterations=40,  # < Increase me for better results\n",
    "    binary_operators=[\"+\", \"*\"],\n",
    "    unary_operators=[\n",
    "        \"cos\",\n",
    "        \"exp\",\n",
    "        \"sin\",\n",
    "        \"inv(x) = 1/x\",\n",
    "        # ^ Custom operator (julia syntax)\n",
    "    ],\n",
    "    extra_sympy_mappings={\"inv\": lambda x: 1 / x},\n",
    "    # ^ Define operator for SymPy as well\n",
    "    loss=\"loss(prediction, target) = (prediction - target)^2\",\n",
    "    # ^ Custom loss function (julia syntax)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e861f76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\lib\\site-packages\\pysr\\sr.py:1259: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda3\\lib\\site-packages\\pysr\\julia_helpers.py:151: UserWarning: `torch` was loaded before the Julia instance started. This may cause a segfault when running `PySRRegressor.fit`. To avoid this, please run `pysr.julia_helpers.init_julia()` *before* importing `torch`. For updates, see https://github.com/pytorch/pytorch/issues/78829\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PySRRegressor.equations_ = [\n",
       "\t   pick      score                                           equation  \\\n",
       "\t0         0.000000                                                 x0   \n",
       "\t1         0.420195                                            exp(x1)   \n",
       "\t2         0.175832                                          (x0 * x1)   \n",
       "\t3         1.535634                                     (x0 * sin(x1))   \n",
       "\t4  >>>>  30.287430                            ((x0 * 0.6666667) * x1)   \n",
       "\t5         0.039924  (((x1 * 0.25803784) * (x0 * 2.7054994)) * 0.95...   \n",
       "\t\n",
       "\t           loss  complexity  \n",
       "\t0  9.241160e+00           1  \n",
       "\t1  6.070693e+00           2  \n",
       "\t2  5.091847e+00           3  \n",
       "\t3  1.096372e+00           4  \n",
       "\t4  7.696519e-14           5  \n",
       "\t5  6.560545e-14           9  \n",
       "]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5877a2",
   "metadata": {},
   "source": [
    "We can then print the analytic expression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96481a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.6666667 x_{0} x_{1}$"
      ],
      "text/plain": [
       "0.6666667*x0*x1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.sympy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0d2353",
   "metadata": {},
   "source": [
    "### Can PySR learn the simple C2P?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d81dcf69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rho</th>\n",
       "      <th>eps</th>\n",
       "      <th>v</th>\n",
       "      <th>p</th>\n",
       "      <th>D</th>\n",
       "      <th>S</th>\n",
       "      <th>tau</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.528004</td>\n",
       "      <td>0.288118</td>\n",
       "      <td>0.459442</td>\n",
       "      <td>0.293497</td>\n",
       "      <td>1.720322</td>\n",
       "      <td>1.317179</td>\n",
       "      <td>0.853093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.632820</td>\n",
       "      <td>1.100745</td>\n",
       "      <td>0.423803</td>\n",
       "      <td>4.133531</td>\n",
       "      <td>6.218926</td>\n",
       "      <td>8.248147</td>\n",
       "      <td>9.109778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.455899</td>\n",
       "      <td>0.645595</td>\n",
       "      <td>0.539136</td>\n",
       "      <td>1.917803</td>\n",
       "      <td>5.290667</td>\n",
       "      <td>7.030875</td>\n",
       "      <td>5.832534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.804941</td>\n",
       "      <td>0.006145</td>\n",
       "      <td>0.236600</td>\n",
       "      <td>0.007394</td>\n",
       "      <td>1.857686</td>\n",
       "      <td>0.457005</td>\n",
       "      <td>0.066474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.432881</td>\n",
       "      <td>0.162764</td>\n",
       "      <td>0.113164</td>\n",
       "      <td>0.589519</td>\n",
       "      <td>5.468005</td>\n",
       "      <td>0.791726</td>\n",
       "      <td>0.938749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1.225224</td>\n",
       "      <td>1.221148</td>\n",
       "      <td>0.273365</td>\n",
       "      <td>0.997454</td>\n",
       "      <td>1.273741</td>\n",
       "      <td>1.098710</td>\n",
       "      <td>1.748013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.886651</td>\n",
       "      <td>1.475485</td>\n",
       "      <td>0.005496</td>\n",
       "      <td>0.872160</td>\n",
       "      <td>0.886664</td>\n",
       "      <td>0.016857</td>\n",
       "      <td>1.308319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>2.382949</td>\n",
       "      <td>1.593343</td>\n",
       "      <td>0.122966</td>\n",
       "      <td>2.531237</td>\n",
       "      <td>2.401172</td>\n",
       "      <td>1.087605</td>\n",
       "      <td>3.912371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>9.317872</td>\n",
       "      <td>1.219796</td>\n",
       "      <td>0.292129</td>\n",
       "      <td>7.577268</td>\n",
       "      <td>9.742867</td>\n",
       "      <td>9.026161</td>\n",
       "      <td>13.577712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>2.272659</td>\n",
       "      <td>0.713480</td>\n",
       "      <td>0.715505</td>\n",
       "      <td>1.080998</td>\n",
       "      <td>3.253127</td>\n",
       "      <td>7.293779</td>\n",
       "      <td>5.859764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          rho       eps         v         p         D         S        tau\n",
       "0    1.528004  0.288118  0.459442  0.293497  1.720322  1.317179   0.853093\n",
       "1    5.632820  1.100745  0.423803  4.133531  6.218926  8.248147   9.109778\n",
       "2    4.455899  0.645595  0.539136  1.917803  5.290667  7.030875   5.832534\n",
       "3    1.804941  0.006145  0.236600  0.007394  1.857686  0.457005   0.066474\n",
       "4    5.432881  0.162764  0.113164  0.589519  5.468005  0.791726   0.938749\n",
       "..        ...       ...       ...       ...       ...       ...        ...\n",
       "995  1.225224  1.221148  0.273365  0.997454  1.273741  1.098710   1.748013\n",
       "996  0.886651  1.475485  0.005496  0.872160  0.886664  0.016857   1.308319\n",
       "997  2.382949  1.593343  0.122966  2.531237  2.401172  1.087605   3.912371\n",
       "998  9.317872  1.219796  0.292129  7.577268  9.742867  9.026161  13.577712\n",
       "999  2.272659  0.713480  0.715505  1.080998  3.253127  7.293779   5.859764\n",
       "\n",
       "[1000 rows x 7 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = physics.generate_data_as_df(1000)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d2f8c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 3)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "X = np.dstack((df[\"D\"], df[\"S\"], df[\"tau\"]))[0]\n",
    "print(X.shape)\n",
    "# Output\n",
    "y = df[\"p\"]\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1360c08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PySRRegressor(\n",
    "    niterations=200,\n",
    "    # ^ number of iterations\n",
    "    populations = 15,\n",
    "    # ^ number of populations to run, default value 15\n",
    "    population_size = 30,\n",
    "    early_stop_condition=(\n",
    "        \"stop_if(loss, complexity) = loss < 1e-3 && complexity < 15\"\n",
    "        # ^ stop early if we find a \"good\" and \"simple\" equation\n",
    "    ),\n",
    "    # ^ population size, default 33\n",
    "    binary_operators=[\"+\", \"*\", \"-\", \"^\"],\n",
    "    unary_operators=[\n",
    "        \"exp\",\n",
    "        \"log\",\n",
    "        \"sqrt\",\n",
    "        \"neg\",\n",
    "        \"inv(x) = 1/x\"\n",
    "        # ^ Custom operator (julia syntax)\n",
    "    ],\n",
    "    extra_sympy_mappings={\"inv\": lambda x: 1 / x},\n",
    "    # ^ Define operator for SymPy as well\n",
    "    loss=\"loss(prediction, target) = (prediction - target)^2\",\n",
    "    # ^ Custom loss function (julia syntax)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c4a60004",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\lib\\site-packages\\pysr\\sr.py:1259: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PySRRegressor.equations_ = [\n",
       "\t    pick     score                                           equation  \\\n",
       "\t0         0.000000                                           3.490505   \n",
       "\t1         0.609810                                           sqrt(x2)   \n",
       "\t2         0.833614                                  (x2 ^ 0.68019384)   \n",
       "\t3         0.293849                            (x2 - (x1 * 0.6666658))   \n",
       "\t4         0.773863            ((x2 ^ 0.8975117) + (x1 * -0.40171713))   \n",
       "\t5         0.025583  ((x2 ^ 0.8989676) + ((x1 + 0.38503948) * -0.39...   \n",
       "\t6         0.282104  ((x2 - (x1 - (2.1141105 ^ log(x1)))) * 0.7067767)   \n",
       "\t7         0.069874  ((x2 - (x1 + (0.3394276 - (sqrt(x1) ^ 1.500181...   \n",
       "\t8         0.046445  ((x2 - ((x1 * 0.8953143) + (sqrt(x1 * x0) * -0...   \n",
       "\t9   >>>>  0.342677  ((x2 - ((x1 * 0.8808253) + (0.73212016 - sqrt(...   \n",
       "\t10        0.042481  ((x2 - ((x1 * 0.8737067) + (0.87068933 - sqrt(...   \n",
       "\t11        0.011066  ((x2 - ((x1 * 0.87068933) + (sqrt(0.87068933) ...   \n",
       "\t12        0.036880  ((x2 - (x1 + ((x0 ^ 0.3162221) - sqrt(((x1 - -...   \n",
       "\t13        0.020655  ((x2 - ((x1 * 0.8808253) + (0.8808253 - sqrt((...   \n",
       "\t\n",
       "\t        loss  complexity  \n",
       "\t0   9.549363           1  \n",
       "\t1   5.189640           2  \n",
       "\t2   2.254775           3  \n",
       "\t3   1.252765           5  \n",
       "\t4   0.266502           7  \n",
       "\t5   0.253209           9  \n",
       "\t6   0.190969          10  \n",
       "\t7   0.166062          12  \n",
       "\t8   0.151332          14  \n",
       "\t9   0.107425          15  \n",
       "\t10  0.098675          17  \n",
       "\t11  0.097589          18  \n",
       "\t12  0.094056          19  \n",
       "\t13  0.092133          20  \n",
       "]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3672dd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complexity</th>\n",
       "      <th>loss</th>\n",
       "      <th>score</th>\n",
       "      <th>equation</th>\n",
       "      <th>sympy_format</th>\n",
       "      <th>lambda_format</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>9.549363</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.490504</td>\n",
       "      <td>3.49050400000000</td>\n",
       "      <td>PySRFunction(X=&gt;3.49050400000000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5.189640</td>\n",
       "      <td>0.609810</td>\n",
       "      <td>sqrt(x2)</td>\n",
       "      <td>sqrt(x2)</td>\n",
       "      <td>PySRFunction(X=&gt;sqrt(x2))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2.254775</td>\n",
       "      <td>0.833614</td>\n",
       "      <td>(x2 ^ 0.68021053)</td>\n",
       "      <td>x2**0.68021053</td>\n",
       "      <td>PySRFunction(X=&gt;x2**0.68021053)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1.252765</td>\n",
       "      <td>0.293849</td>\n",
       "      <td>(x2 + (x1 * -0.66666174))</td>\n",
       "      <td>-0.66666174*x1 + x2</td>\n",
       "      <td>PySRFunction(X=&gt;-0.66666174*x1 + x2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>1.121657</td>\n",
       "      <td>0.110545</td>\n",
       "      <td>abs(x2 + (x1 * -0.6738634))</td>\n",
       "      <td>Abs(0.6738634*x1 - x2)</td>\n",
       "      <td>PySRFunction(X=&gt;Abs(0.6738634*x1 - x2))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>0.398951</td>\n",
       "      <td>1.033723</td>\n",
       "      <td>(((x2 * 1.7942535) - x1) * 0.42594182)</td>\n",
       "      <td>-0.42594182*x1 + 0.76424760133137*x2</td>\n",
       "      <td>PySRFunction(X=&gt;-0.42594182*x1 + 0.76424760133...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>0.376517</td>\n",
       "      <td>0.057876</td>\n",
       "      <td>abs(((x2 * 1.7730448) - x1) * 0.43487522)</td>\n",
       "      <td>Abs(0.43487522*x1 - 0.771053247469856*x2)</td>\n",
       "      <td>PySRFunction(X=&gt;Abs(0.43487522*x1 - 0.77105324...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>0.321599</td>\n",
       "      <td>0.157660</td>\n",
       "      <td>((((x2 - -0.56282926) * 1.7466879) - x1) * 0.4...</td>\n",
       "      <td>-0.4176508*x1 + 0.72950559878532*x2 + 0.410587...</td>\n",
       "      <td>PySRFunction(X=&gt;-0.4176508*x1 + 0.729505598785...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>0.286597</td>\n",
       "      <td>0.115226</td>\n",
       "      <td>(((x2 * 1.7467062) - abs(x1 + -1.2373165)) * 0...</td>\n",
       "      <td>0.72950538161706*x2 - 0.4176463*Abs(x1 - 1.237...</td>\n",
       "      <td>PySRFunction(X=&gt;0.72950538161706*x2 - 0.417646...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>0.171904</td>\n",
       "      <td>0.511139</td>\n",
       "      <td>(((x1 ^ 0.66303796) + ((x1 - x2) * -0.7327512)...</td>\n",
       "      <td>x1**0.66303796 - 0.7327512*x1 + 0.7327512*x2 -...</td>\n",
       "      <td>PySRFunction(X=&gt;x1**0.66303796 - 0.7327512*x1 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12</td>\n",
       "      <td>0.165470</td>\n",
       "      <td>0.038151</td>\n",
       "      <td>abs(((x1 ^ 0.66598684) + ((x1 - x2) * -0.73920...</td>\n",
       "      <td>Abs(x1**0.66598684 - 0.7392043*x1 + 0.7392043*...</td>\n",
       "      <td>PySRFunction(X=&gt;Abs(x1**0.66598684 - 0.7392043...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>0.159934</td>\n",
       "      <td>0.034023</td>\n",
       "      <td>((((x1 - -0.76880467) ^ 0.6760533) + ((x1 - x2...</td>\n",
       "      <td>-0.73738474*x1 + 0.73738474*x2 + (x1 + 0.76880...</td>\n",
       "      <td>PySRFunction(X=&gt;-0.73738474*x1 + 0.73738474*x2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14</td>\n",
       "      <td>0.156823</td>\n",
       "      <td>0.019648</td>\n",
       "      <td>abs((((x1 + 0.7549633) ^ 0.6760533) + ((x1 - x...</td>\n",
       "      <td>Abs(0.73738474*x1 - 0.73738474*x2 - (x1 + 0.75...</td>\n",
       "      <td>PySRFunction(X=&gt;Abs(0.73738474*x1 - 0.73738474...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15</td>\n",
       "      <td>0.145126</td>\n",
       "      <td>0.077517</td>\n",
       "      <td>((((x1 + 0.47303814) ^ 0.6604226) + ((x1 - x2)...</td>\n",
       "      <td>-0.95266294**x0 - 0.7210607*x1 + 0.7210607*x2 ...</td>\n",
       "      <td>PySRFunction(X=&gt;-0.95266294**x0 - 0.7210607*x1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16</td>\n",
       "      <td>0.142561</td>\n",
       "      <td>0.017830</td>\n",
       "      <td>abs((((x1 + 0.47303814) ^ 0.6604226) + ((x1 - ...</td>\n",
       "      <td>Abs(0.95266294**x0 + 0.7210607*x1 - 0.7210607*...</td>\n",
       "      <td>PySRFunction(X=&gt;Abs(0.95266294**x0 + 0.7210607...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>17</td>\n",
       "      <td>0.130425</td>\n",
       "      <td>0.088972</td>\n",
       "      <td>((((x1 + exp(neg(x2))) ^ 0.65931267) + ((x1 - ...</td>\n",
       "      <td>-0.9220804**x0 - 0.73266983*x1 + 0.73266983*x2...</td>\n",
       "      <td>PySRFunction(X=&gt;-0.9220804**x0 - 0.73266983*x1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18</td>\n",
       "      <td>0.126397</td>\n",
       "      <td>0.031372</td>\n",
       "      <td>((((x1 + sqrt(exp(neg(x2)))) ^ 0.65931267) + (...</td>\n",
       "      <td>-0.9220804**x0 - 0.73266983*x1 + 0.73266983*x2...</td>\n",
       "      <td>PySRFunction(X=&gt;-0.9220804**x0 - 0.73266983*x1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>19</td>\n",
       "      <td>0.126017</td>\n",
       "      <td>0.003005</td>\n",
       "      <td>abs((((x1 + sqrt(exp(neg(x2)))) ^ 0.65931267) ...</td>\n",
       "      <td>Abs(0.9220804**x0 + 0.73266983*x1 - 0.73266983...</td>\n",
       "      <td>PySRFunction(X=&gt;Abs(0.9220804**x0 + 0.73266983...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20</td>\n",
       "      <td>0.122662</td>\n",
       "      <td>0.026984</td>\n",
       "      <td>((((x1 + sqrt(exp(neg(x2)))) ^ 0.6627494) + ((...</td>\n",
       "      <td>-0.9220804**(x0 - 1.2818602) - 0.7328811*x1 + ...</td>\n",
       "      <td>PySRFunction(X=&gt;-0.9220804**(x0 - 1.2818602) -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    complexity      loss     score  \\\n",
       "0            1  9.549363  0.000000   \n",
       "1            2  5.189640  0.609810   \n",
       "2            3  2.254775  0.833614   \n",
       "3            5  1.252765  0.293849   \n",
       "4            6  1.121657  0.110545   \n",
       "5            7  0.398951  1.033723   \n",
       "6            8  0.376517  0.057876   \n",
       "7            9  0.321599  0.157660   \n",
       "8           10  0.286597  0.115226   \n",
       "9           11  0.171904  0.511139   \n",
       "10          12  0.165470  0.038151   \n",
       "11          13  0.159934  0.034023   \n",
       "12          14  0.156823  0.019648   \n",
       "13          15  0.145126  0.077517   \n",
       "14          16  0.142561  0.017830   \n",
       "15          17  0.130425  0.088972   \n",
       "16          18  0.126397  0.031372   \n",
       "17          19  0.126017  0.003005   \n",
       "18          20  0.122662  0.026984   \n",
       "\n",
       "                                             equation  \\\n",
       "0                                            3.490504   \n",
       "1                                            sqrt(x2)   \n",
       "2                                   (x2 ^ 0.68021053)   \n",
       "3                           (x2 + (x1 * -0.66666174))   \n",
       "4                         abs(x2 + (x1 * -0.6738634))   \n",
       "5              (((x2 * 1.7942535) - x1) * 0.42594182)   \n",
       "6           abs(((x2 * 1.7730448) - x1) * 0.43487522)   \n",
       "7   ((((x2 - -0.56282926) * 1.7466879) - x1) * 0.4...   \n",
       "8   (((x2 * 1.7467062) - abs(x1 + -1.2373165)) * 0...   \n",
       "9   (((x1 ^ 0.66303796) + ((x1 - x2) * -0.7327512)...   \n",
       "10  abs(((x1 ^ 0.66598684) + ((x1 - x2) * -0.73920...   \n",
       "11  ((((x1 - -0.76880467) ^ 0.6760533) + ((x1 - x2...   \n",
       "12  abs((((x1 + 0.7549633) ^ 0.6760533) + ((x1 - x...   \n",
       "13  ((((x1 + 0.47303814) ^ 0.6604226) + ((x1 - x2)...   \n",
       "14  abs((((x1 + 0.47303814) ^ 0.6604226) + ((x1 - ...   \n",
       "15  ((((x1 + exp(neg(x2))) ^ 0.65931267) + ((x1 - ...   \n",
       "16  ((((x1 + sqrt(exp(neg(x2)))) ^ 0.65931267) + (...   \n",
       "17  abs((((x1 + sqrt(exp(neg(x2)))) ^ 0.65931267) ...   \n",
       "18  ((((x1 + sqrt(exp(neg(x2)))) ^ 0.6627494) + ((...   \n",
       "\n",
       "                                         sympy_format  \\\n",
       "0                                    3.49050400000000   \n",
       "1                                            sqrt(x2)   \n",
       "2                                      x2**0.68021053   \n",
       "3                                 -0.66666174*x1 + x2   \n",
       "4                              Abs(0.6738634*x1 - x2)   \n",
       "5                -0.42594182*x1 + 0.76424760133137*x2   \n",
       "6           Abs(0.43487522*x1 - 0.771053247469856*x2)   \n",
       "7   -0.4176508*x1 + 0.72950559878532*x2 + 0.410587...   \n",
       "8   0.72950538161706*x2 - 0.4176463*Abs(x1 - 1.237...   \n",
       "9   x1**0.66303796 - 0.7327512*x1 + 0.7327512*x2 -...   \n",
       "10  Abs(x1**0.66598684 - 0.7392043*x1 + 0.7392043*...   \n",
       "11  -0.73738474*x1 + 0.73738474*x2 + (x1 + 0.76880...   \n",
       "12  Abs(0.73738474*x1 - 0.73738474*x2 - (x1 + 0.75...   \n",
       "13  -0.95266294**x0 - 0.7210607*x1 + 0.7210607*x2 ...   \n",
       "14  Abs(0.95266294**x0 + 0.7210607*x1 - 0.7210607*...   \n",
       "15  -0.9220804**x0 - 0.73266983*x1 + 0.73266983*x2...   \n",
       "16  -0.9220804**x0 - 0.73266983*x1 + 0.73266983*x2...   \n",
       "17  Abs(0.9220804**x0 + 0.73266983*x1 - 0.73266983...   \n",
       "18  -0.9220804**(x0 - 1.2818602) - 0.7328811*x1 + ...   \n",
       "\n",
       "                                        lambda_format  \n",
       "0                   PySRFunction(X=>3.49050400000000)  \n",
       "1                           PySRFunction(X=>sqrt(x2))  \n",
       "2                     PySRFunction(X=>x2**0.68021053)  \n",
       "3                PySRFunction(X=>-0.66666174*x1 + x2)  \n",
       "4             PySRFunction(X=>Abs(0.6738634*x1 - x2))  \n",
       "5   PySRFunction(X=>-0.42594182*x1 + 0.76424760133...  \n",
       "6   PySRFunction(X=>Abs(0.43487522*x1 - 0.77105324...  \n",
       "7   PySRFunction(X=>-0.4176508*x1 + 0.729505598785...  \n",
       "8   PySRFunction(X=>0.72950538161706*x2 - 0.417646...  \n",
       "9   PySRFunction(X=>x1**0.66303796 - 0.7327512*x1 ...  \n",
       "10  PySRFunction(X=>Abs(x1**0.66598684 - 0.7392043...  \n",
       "11  PySRFunction(X=>-0.73738474*x1 + 0.73738474*x2...  \n",
       "12  PySRFunction(X=>Abs(0.73738474*x1 - 0.73738474...  \n",
       "13  PySRFunction(X=>-0.95266294**x0 - 0.7210607*x1...  \n",
       "14  PySRFunction(X=>Abs(0.95266294**x0 + 0.7210607...  \n",
       "15  PySRFunction(X=>-0.9220804**x0 - 0.73266983*x1...  \n",
       "16  PySRFunction(X=>-0.9220804**x0 - 0.73266983*x1...  \n",
       "17  PySRFunction(X=>Abs(0.9220804**x0 + 0.73266983...  \n",
       "18  PySRFunction(X=>-0.9220804**(x0 - 1.2818602) -...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.equations_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80d4f8a",
   "metadata": {},
   "source": [
    "We can then print the analytic expression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "070522ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle x_{1}^{0.66303796} - 0.7327512 x_{1} + 0.7327512 x_{2} - 0.5902447$"
      ],
      "text/plain": [
       "x1**0.66303796 - 0.7327512*x1 + 0.7327512*x2 - 0.5902447"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.sympy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "23bbf53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(y, pred):\n",
    "\n",
    "    return np.mean((y-pred)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893d484f",
   "metadata": {},
   "source": [
    "Test if the model generalizes well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "85b320b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18144073842679312\n"
     ]
    }
   ],
   "source": [
    "test_df = physics.generate_data_as_df(10000)\n",
    "test_X = np.dstack((test_df[\"D\"], test_df[\"S\"], test_df[\"tau\"]))[0]\n",
    "true_values = test_df[\"p\"]\n",
    "predictions = model.predict(test_X)\n",
    "loss = mse_loss(true_values, predictions)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de55394e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "efa62044",
   "metadata": {},
   "source": [
    "# __TODO__ Tabulated EOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "511ae7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to  D:\\Coding\\master-thesis-AI\\Data/SLy4_training_data.csv\n",
      "Saving to  D:\\Coding\\master-thesis-AI\\Data/SLy4_test_data.csv\n"
     ]
    }
   ],
   "source": [
    "# dat = physics.generate_tabular_data(eos_table, number_of_points = 100000, save_name = \"SLy4_training_data\")\n",
    "# dat = physics.generate_tabular_data(eos_table, number_of_points = 20000, save_name = \"SLy4_test_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a121af",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f929937d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rho</th>\n",
       "      <th>eps</th>\n",
       "      <th>v</th>\n",
       "      <th>temp</th>\n",
       "      <th>ye</th>\n",
       "      <th>p</th>\n",
       "      <th>D</th>\n",
       "      <th>S</th>\n",
       "      <th>tau</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.590663</td>\n",
       "      <td>19.381445</td>\n",
       "      <td>0.683568</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.045</td>\n",
       "      <td>31.985334</td>\n",
       "      <td>18.620245</td>\n",
       "      <td>580.748110</td>\n",
       "      <td>655.358209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.457329</td>\n",
       "      <td>28.786040</td>\n",
       "      <td>0.041886</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>0.545</td>\n",
       "      <td>34.766248</td>\n",
       "      <td>6.463001</td>\n",
       "      <td>13.269992</td>\n",
       "      <td>186.431092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.323996</td>\n",
       "      <td>19.654200</td>\n",
       "      <td>0.558550</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.535</td>\n",
       "      <td>30.418591</td>\n",
       "      <td>13.652070</td>\n",
       "      <td>310.329455</td>\n",
       "      <td>393.570454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.723996</td>\n",
       "      <td>19.246855</td>\n",
       "      <td>0.009527</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>0.095</td>\n",
       "      <td>26.341137</td>\n",
       "      <td>8.724392</td>\n",
       "      <td>2.749496</td>\n",
       "      <td>167.935288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.523996</td>\n",
       "      <td>29.186040</td>\n",
       "      <td>0.334705</td>\n",
       "      <td>2.033333</td>\n",
       "      <td>0.095</td>\n",
       "      <td>34.232914</td>\n",
       "      <td>5.862105</td>\n",
       "      <td>103.365923</td>\n",
       "      <td>195.482542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>3.323996</td>\n",
       "      <td>25.652376</td>\n",
       "      <td>0.577186</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.435</td>\n",
       "      <td>28.498601</td>\n",
       "      <td>4.070468</td>\n",
       "      <td>125.881369</td>\n",
       "      <td>157.178893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>9.757329</td>\n",
       "      <td>19.124371</td>\n",
       "      <td>0.376611</td>\n",
       "      <td>-2.900000</td>\n",
       "      <td>0.295</td>\n",
       "      <td>27.371010</td>\n",
       "      <td>10.532847</td>\n",
       "      <td>140.768515</td>\n",
       "      <td>238.842241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>9.590663</td>\n",
       "      <td>19.114310</td>\n",
       "      <td>0.266570</td>\n",
       "      <td>-0.833333</td>\n",
       "      <td>0.305</td>\n",
       "      <td>27.176186</td>\n",
       "      <td>9.950723</td>\n",
       "      <td>90.427775</td>\n",
       "      <td>207.064143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>14.690663</td>\n",
       "      <td>20.976110</td>\n",
       "      <td>0.476948</td>\n",
       "      <td>2.233333</td>\n",
       "      <td>0.485</td>\n",
       "      <td>35.391058</td>\n",
       "      <td>16.714229</td>\n",
       "      <td>326.155098</td>\n",
       "      <td>461.688397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>7.590663</td>\n",
       "      <td>19.036140</td>\n",
       "      <td>0.589693</td>\n",
       "      <td>-2.133333</td>\n",
       "      <td>0.455</td>\n",
       "      <td>24.684220</td>\n",
       "      <td>9.398714</td>\n",
       "      <td>224.588620</td>\n",
       "      <td>275.127114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             rho        eps         v      temp     ye          p          D  \\\n",
       "0      13.590663  19.381445  0.683568 -0.333333  0.045  31.985334  18.620245   \n",
       "1       6.457329  28.786040  0.041886  2.166667  0.545  34.766248   6.463001   \n",
       "2      11.323996  19.654200  0.558550  0.866667  0.535  30.418591  13.652070   \n",
       "3       8.723996  19.246855  0.009527 -0.300000  0.095  26.341137   8.724392   \n",
       "4       5.523996  29.186040  0.334705  2.033333  0.095  34.232914   5.862105   \n",
       "...          ...        ...       ...       ...    ...        ...        ...   \n",
       "99995   3.323996  25.652376  0.577186  0.600000  0.435  28.498601   4.070468   \n",
       "99996   9.757329  19.124371  0.376611 -2.900000  0.295  27.371010  10.532847   \n",
       "99997   9.590663  19.114310  0.266570 -0.833333  0.305  27.176186   9.950723   \n",
       "99998  14.690663  20.976110  0.476948  2.233333  0.485  35.391058  16.714229   \n",
       "99999   7.590663  19.036140  0.589693 -2.133333  0.455  24.684220   9.398714   \n",
       "\n",
       "                S         tau  \n",
       "0      580.748110  655.358209  \n",
       "1       13.269992  186.431092  \n",
       "2      310.329455  393.570454  \n",
       "3        2.749496  167.935288  \n",
       "4      103.365923  195.482542  \n",
       "...           ...         ...  \n",
       "99995  125.881369  157.178893  \n",
       "99996  140.768515  238.842241  \n",
       "99997   90.427775  207.064143  \n",
       "99998  326.155098  461.688397  \n",
       "99999  224.588620  275.127114  \n",
       "\n",
       "[100000 rows x 9 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(master_dir, \"Data/SLy4_training_data.csv\"))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451d20ee",
   "metadata": {},
   "source": [
    "For comparison, this was the table we trained on for the ideal gas EOS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "74c3ad69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rho</th>\n",
       "      <th>eps</th>\n",
       "      <th>v</th>\n",
       "      <th>p</th>\n",
       "      <th>D</th>\n",
       "      <th>S</th>\n",
       "      <th>tau</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.662984</td>\n",
       "      <td>0.084146</td>\n",
       "      <td>0.218802</td>\n",
       "      <td>0.037192</td>\n",
       "      <td>0.679448</td>\n",
       "      <td>0.173724</td>\n",
       "      <td>0.077335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.565808</td>\n",
       "      <td>0.205945</td>\n",
       "      <td>0.657351</td>\n",
       "      <td>1.176059</td>\n",
       "      <td>11.366755</td>\n",
       "      <td>13.318537</td>\n",
       "      <td>7.718100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.387112</td>\n",
       "      <td>1.598809</td>\n",
       "      <td>0.021593</td>\n",
       "      <td>4.676103</td>\n",
       "      <td>4.388135</td>\n",
       "      <td>0.347321</td>\n",
       "      <td>7.020631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.337054</td>\n",
       "      <td>0.530803</td>\n",
       "      <td>0.351307</td>\n",
       "      <td>1.888615</td>\n",
       "      <td>5.700396</td>\n",
       "      <td>4.031171</td>\n",
       "      <td>3.885760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.133895</td>\n",
       "      <td>0.786717</td>\n",
       "      <td>0.079475</td>\n",
       "      <td>0.594703</td>\n",
       "      <td>1.137493</td>\n",
       "      <td>0.209600</td>\n",
       "      <td>0.905115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79995</th>\n",
       "      <td>8.101834</td>\n",
       "      <td>0.428605</td>\n",
       "      <td>0.616897</td>\n",
       "      <td>2.314990</td>\n",
       "      <td>10.294002</td>\n",
       "      <td>13.832316</td>\n",
       "      <td>9.813427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79996</th>\n",
       "      <td>7.841014</td>\n",
       "      <td>1.125480</td>\n",
       "      <td>0.209087</td>\n",
       "      <td>5.883268</td>\n",
       "      <td>8.018242</td>\n",
       "      <td>4.930289</td>\n",
       "      <td>9.678536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79997</th>\n",
       "      <td>4.628822</td>\n",
       "      <td>0.194190</td>\n",
       "      <td>0.237759</td>\n",
       "      <td>0.599248</td>\n",
       "      <td>4.765476</td>\n",
       "      <td>1.544018</td>\n",
       "      <td>1.129323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79998</th>\n",
       "      <td>9.913117</td>\n",
       "      <td>1.152242</td>\n",
       "      <td>0.477216</td>\n",
       "      <td>7.614874</td>\n",
       "      <td>11.280468</td>\n",
       "      <td>17.889657</td>\n",
       "      <td>18.592193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79999</th>\n",
       "      <td>9.717025</td>\n",
       "      <td>0.001552</td>\n",
       "      <td>0.163383</td>\n",
       "      <td>0.010052</td>\n",
       "      <td>9.849373</td>\n",
       "      <td>1.635352</td>\n",
       "      <td>0.149919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80000 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            rho       eps         v         p          D          S        tau\n",
       "0      0.662984  0.084146  0.218802  0.037192   0.679448   0.173724   0.077335\n",
       "1      8.565808  0.205945  0.657351  1.176059  11.366755  13.318537   7.718100\n",
       "2      4.387112  1.598809  0.021593  4.676103   4.388135   0.347321   7.020631\n",
       "3      5.337054  0.530803  0.351307  1.888615   5.700396   4.031171   3.885760\n",
       "4      1.133895  0.786717  0.079475  0.594703   1.137493   0.209600   0.905115\n",
       "...         ...       ...       ...       ...        ...        ...        ...\n",
       "79995  8.101834  0.428605  0.616897  2.314990  10.294002  13.832316   9.813427\n",
       "79996  7.841014  1.125480  0.209087  5.883268   8.018242   4.930289   9.678536\n",
       "79997  4.628822  0.194190  0.237759  0.599248   4.765476   1.544018   1.129323\n",
       "79998  9.913117  1.152242  0.477216  7.614874  11.280468  17.889657  18.592193\n",
       "79999  9.717025  0.001552  0.163383  0.010052   9.849373   1.635352   0.149919\n",
       "\n",
       "[80000 rows x 7 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_df = pd.read_csv(os.path.join(master_dir, \"Data/ideal_gas_c2p_training_data.csv\"))\n",
    "old_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd2f127",
   "metadata": {},
   "source": [
    "# Define and train architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714ed67a",
   "metadata": {},
   "source": [
    "## Define architecture and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "118ed574",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNC2P(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements a two-layered neural network for the C2P conversion, using tabulated SLy4 EOS.\n",
    "    \"\"\"\n",
    "    def __init__(self, h1: int = 600, h2: int = 200, reg: bool = False) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the neural network class.\n",
    "        :param h1: Size (number of neurons) of the first hidden layer.\n",
    "        :param h2: Size (number of neurons) of the second hidden layer.\n",
    "        \"\"\"\n",
    "        # Call the super constructor first\n",
    "        super(NNC2P, self).__init__()\n",
    "        \n",
    "        # For convenience, save the sizes of the hidden layers as fields as well\n",
    "        self.h1 = h1\n",
    "        self.h2 = h2\n",
    "        \n",
    "        # Initialize empty mean and std:\n",
    "        self.mean = torch.Tensor([0, 0, 0])\n",
    "        self.std = torch.Tensor([1, 1, 1])\n",
    "\n",
    "        # Add field to specify whether or not we do regularization\n",
    "        self.regularization = reg\n",
    "\n",
    "        # Define the layers:\n",
    "        self.linear1 = nn.Linear(3, h1)\n",
    "        self.linear2 = nn.Linear(h1, h2)\n",
    "        self.linear3 = nn.Linear(h2, 1)\n",
    "        \n",
    "    def normalize(x):\n",
    "        \n",
    "        return (x-self.mean)/self.std\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Computes a forward step given the input x.\n",
    "        :param x: Input for the neural network.\n",
    "        :return: x: Output neural network\n",
    "        \"\"\"\n",
    "        x = self.normalize(x)\n",
    "\n",
    "        x = self.linear1(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        x = self.linear2(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        x = self.linear3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6d6047",
   "metadata": {},
   "source": [
    "Get the training data as DataSet and DataLoader objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bf69d945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data as pandas dataframes\n",
    "train_df = pd.read_csv(os.path.join(master_dir, \"Data/SLy4_training_data.csv\"))\n",
    "test_df = pd.read_csv(os.path.join(master_dir, \"Data/SLy4_test_data.csv\"))\n",
    "# Convert to PyTorch Datasets as we defined them\n",
    "train_dataset = data.CustomDataset(train_df)\n",
    "test_dataset = data.CustomDataset(test_df)\n",
    "# Then create dataloaders, with batch size 32, from datasets\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d3047b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 10.6174, 171.6808, 283.8405])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader.dataset.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7492c2b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 18.6202, 580.7481, 655.3582])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = train_dataset.features\n",
    "test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "547c4171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.8245, 2.6370, 2.5105]), tensor([31.9853]))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fce59893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 10.6174, 171.6808, 283.8405])\n",
      "tensor([  4.3864, 155.1245, 147.9844])\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.mean)\n",
    "print(train_dataset.std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12e532a",
   "metadata": {},
   "source": [
    "Create a new instance of the NNC2P:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "be7a388c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NNC2P()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1e3745",
   "metadata": {},
   "source": [
    "Create a trainer object from it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "df92e917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the learning rate to 1e-3\n",
    "trainer = nnc2p.Trainer(model, 0.1, train_dataloader=train_dataloader, test_dataloader=test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7e30e2",
   "metadata": {},
   "source": [
    "## Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "53ce8669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model for 500 epochs.\n",
      "\n",
      " Epoch 0 \n",
      " --------------\n",
      "Train loss: 2.84E+01\n",
      "Test  loss: 2.86E+01\n",
      "\n",
      " Epoch 1 \n",
      " --------------\n",
      "Train loss: 2.92E+01\n",
      "Test  loss: 2.94E+01\n",
      "\n",
      " Epoch 2 \n",
      " --------------\n",
      "Train loss: 2.94E+01\n",
      "Test  loss: 2.96E+01\n",
      "\n",
      " Epoch 3 \n",
      " --------------\n",
      "Train loss: 2.93E+01\n",
      "Test  loss: 2.95E+01\n",
      "\n",
      " Epoch 4 \n",
      " --------------\n",
      "Train loss: 2.93E+01\n",
      "Test  loss: 2.95E+01\n",
      "\n",
      " Epoch 5 \n",
      " --------------\n",
      "Train loss: 2.93E+01\n",
      "Test  loss: 2.95E+01\n",
      "\n",
      " Epoch 6 \n",
      " --------------\n",
      "Train loss: 2.93E+01\n",
      "Test  loss: 2.95E+01\n",
      "\n",
      " Epoch 7 \n",
      " --------------\n",
      "Train loss: 2.93E+01\n",
      "Test  loss: 2.95E+01\n",
      "\n",
      " Epoch 8 \n",
      " --------------\n",
      "Train loss: 2.93E+01\n",
      "Test  loss: 2.95E+01\n",
      "\n",
      " Epoch 9 \n",
      " --------------\n",
      "Train loss: 2.93E+01\n",
      "Test  loss: 2.95E+01\n",
      "\n",
      " Epoch 10 \n",
      " --------------\n",
      "Adapting learning rate to 0.05\n",
      "Train loss: 2.93E+01\n",
      "Test  loss: 2.95E+01\n",
      "\n",
      " Epoch 11 \n",
      " --------------\n",
      "Train loss: 2.26E+01\n",
      "Test  loss: 2.26E+01\n",
      "\n",
      " Epoch 12 \n",
      " --------------\n",
      "Train loss: 2.26E+01\n",
      "Test  loss: 2.26E+01\n",
      "\n",
      " Epoch 13 \n",
      " --------------\n",
      "Train loss: 2.26E+01\n",
      "Test  loss: 2.26E+01\n",
      "\n",
      " Epoch 14 \n",
      " --------------\n",
      "Train loss: 2.26E+01\n",
      "Test  loss: 2.26E+01\n",
      "\n",
      " Epoch 15 \n",
      " --------------\n",
      "Train loss: 2.26E+01\n",
      "Test  loss: 2.26E+01\n",
      "\n",
      " Epoch 16 \n",
      " --------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [80]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Coding\\master-thesis-AI\\Code\\nnc2p.py:376\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, adaptation_threshold, adaptation_multiplier, number_of_epochs, log_file, csv_file)\u001b[0m\n\u001b[0;32m    374\u001b[0m write_to_txt(log_file, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_counter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m --------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    375\u001b[0m \u001b[38;5;66;03m# Train the network\u001b[39;00m\n\u001b[1;32m--> 376\u001b[0m \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;66;03m# Test on the training data\u001b[39;00m\n\u001b[0;32m    378\u001b[0m average_train_loss \u001b[38;5;241m=\u001b[39m test_loop(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_dataloader, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn)\n",
      "File \u001b[1;32mD:\\Coding\\master-thesis-AI\\Code\\nnc2p.py:258\u001b[0m, in \u001b[0;36mtrain_loop\u001b[1;34m(dataloader, model, loss_fn, optimizer, report_progress)\u001b[0m\n\u001b[0;32m    256\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m    257\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m--> 258\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;66;03m# If we want to report progress during training (not recommended - obstructs view)\u001b[39;00m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m report_progress:\n",
      "File \u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\optim\\optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[1;32m--> 140\u001b[0m     out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\optim\\optimizer.py:23\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     22\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 23\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     25\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\optim\\adam.py:234\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[0;32m    231\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`requires_grad` is not supported for `step` in differentiable mode\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    232\u001b[0m             state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m--> 234\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m         \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[43m         \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[43m         \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[43m         \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[43m         \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[43m         \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[43m         \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[43m         \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[43m         \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[43m         \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[43m         \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m         \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\optim\\adam.py:300\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    298\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 300\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    303\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    304\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    305\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    306\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    307\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    308\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    309\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\optim\\adam.py:363\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    360\u001b[0m     param \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mview_as_real(param)\n\u001b[0;32m    362\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[1;32m--> 363\u001b[0m \u001b[43mexp_avg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39madd_(grad, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1)\n\u001b[0;32m    364\u001b[0m exp_avg_sq\u001b[38;5;241m.\u001b[39mmul_(beta2)\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad\u001b[38;5;241m.\u001b[39mconj(), value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbef171",
   "metadata": {},
   "source": [
    "__TODO__ do hyperparameter search over learning rate?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb04008",
   "metadata": {},
   "source": [
    "__TODO__ is the normalization done correctly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8337841e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55f36b5d",
   "metadata": {},
   "source": [
    "# Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "abb635c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We successfully loaded the EOS table. We have 391 rho, 163 temp, 66 ye points.\n",
      "We have 4206378 data points.\n"
     ]
    }
   ],
   "source": [
    "# Open the HDF5 file\n",
    "with h5py.File(eos_table_filename, 'r') as file:\n",
    "    eos_table = file\n",
    "    Abar = file[\"Abar\"][()]\n",
    "    Albar = file[\"Albar\"][()]\n",
    "    Xa = file[\"Xa\"][()]\n",
    "    Xh = file[\"Xh\"][()]\n",
    "    Xn = file[\"Xn\"][()]\n",
    "    Xp = file[\"Xp\"][()]\n",
    "    Zbar = file[\"Zbar\"][()]\n",
    "    cs2 = file[\"cs2\"][()]\n",
    "    dedt = file[\"dedt\"][()]\n",
    "    dpderho = file[\"dpderho\"][()]\n",
    "    dpdrhoe = file[\"dpdrhoe\"][()]\n",
    "    energy_shift = file[\"energy_shift\"][()]\n",
    "    entropy = file[\"entropy\"][()]\n",
    "    gamma = file[\"gamma\"][()]\n",
    "    logenergy = file[\"logenergy\"][()]\n",
    "    logpress = file[\"logpress\"][()]\n",
    "    logrho = file[\"logrho\"][()]\n",
    "    logtemp = file[\"logtemp\"][()]\n",
    "    mu_e = file[\"mu_e\"][()]\n",
    "    mu_n = file[\"mu_n\"][()]\n",
    "    muhat = file[\"muhat\"][()]\n",
    "    munu = file[\"munu\"][()]\n",
    "    pointsrho = file[\"pointsrho\"][()]\n",
    "    pointstemp = file[\"pointstemp\"][()]\n",
    "    pointsye = file[\"pointsye\"][()]\n",
    "    u = file[\"u\"][()] ## these don't exist???\n",
    "    r = file[\"r\"][()]\n",
    "    ye = file[\"ye\"][()]\n",
    "# Print message\n",
    "print(f\"We successfully loaded the EOS table. We have {pointsrho[0]} rho, {pointstemp[0]} temp, {pointsye[0]} ye points.\")\n",
    "print(f\"We have {pointsrho[0]*pointstemp[0]*pointsye[0]} data points.\")"
   ]
  }
 ],
 "metadata": {
  "author": "Thibeau Wouters",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
