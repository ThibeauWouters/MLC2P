{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af563537",
   "metadata": {},
   "source": [
    "%%latex\n",
    "\\tableofcontents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bb9f224",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "import random\n",
    "import csv\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn # pytorch neural networks\n",
    "from torch.utils.data import Dataset, DataLoader # pytorch dataset structures\n",
    "from torchvision.transforms import ToTensor # pytorch transformer\n",
    "# from torch.utils.data import DataLoader\n",
    "# from torchvision import datasets\n",
    "# from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fb3c8c",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8efeafb",
   "metadata": {},
   "source": [
    "The conserved variables are $(D, S_i, \\tau)$ and they are related to primitive variables, $w = (\\rho, v^i, \\epsilon, p)$, defined in the local rest frame of the fluid through (in units of light speed $c = 1$). The P2C is explicitly given:\n",
    "\\begin{equation}\n",
    "D = \\rho W \\, , \\quad S_i = \\rho h W^2 v_i \\, , \\quad \\tau = \\rho h W^2 - p - D \\, ,\n",
    "\\end{equation}\n",
    "where we used\n",
    "\\begin{equation}\n",
    "W = (1 - v^2)^{-1/2} \\, , \\quad h = 1 + \\epsilon + \\frac{p}{\\rho} \\, .\n",
    "\\end{equation}\n",
    "\n",
    "Our first goal is to reproduce the results from [this paper](https://www.mdpi.com/2073-8994/13/11/2157). We first focus on what they call __NNEOS__ networks. These are networks which are trained to infer information on the equation of state (EOS). In its simplest form, the EOS is the thermodynamical relation connecting the pressure to the fluid's rest-mass density and internal energy $p = \\bar{p}(\\rho, \\epsilon)$. We consider an __analytical $\\Gamma$-law EOS__ as a benchmark:\n",
    "\\begin{equation}\n",
    "    p(\\rho, \\varepsilon) = (\\Gamma - 1)\\rho\\epsilon \\, ,\n",
    "\\end{equation}\n",
    "and we fix $\\Gamma = 5/3$ in order to fully mimic the situation of the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca72213",
   "metadata": {},
   "source": [
    "# Generating training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db09163",
   "metadata": {},
   "source": [
    "We generate training data for the NNEOS networks as follows. We create a training set by randomly sampling the EOS on a uniform distribution over $\\rho \\in (0, 10.1)$ and $\\epsilon \\in (0, 2.02)$. Below, we first focus on the implementation of __NNEOSB__ as called in the paper, meaning we also make the derivatives of the EOS part of the output. So we compute three quantities:\n",
    "\\begin{itemize}\n",
    "\\item $p$, using the EOS defined above\n",
    "\\item $\\chi := \\partial p/\\partial\\rho$, inferred from the EOS\n",
    "\\item $\\kappa := \\partial p/\\partial \\epsilon$, inferred from the EOS\n",
    "\\end{itemize}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ebd9592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the three functions determining the output\n",
    "def eos(rho, eps, Gamma = 5/3):\n",
    "    \"\"\"Computes the analytical gamma law EOS from rho and epsilon\"\"\"\n",
    "    return (Gamma - 1) * rho * eps\n",
    "\n",
    "def chi(rho, eps, Gamma = 5/3):\n",
    "    \"\"\"Computes dp/drho from EOS\"\"\"\n",
    "    return (Gamma - 1) * eps\n",
    "\n",
    "def kappa(rho, eps, Gamma = 5/3):\n",
    "    \"\"\"Computes dp/deps from EOS\"\"\"\n",
    "    return (Gamma - 1) * rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40409d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ranges of parameters to be sampled (see paper Section 2.1)\n",
    "rho_min = 0\n",
    "rho_max = 10.1\n",
    "eps_min = 0\n",
    "eps_max = 2.02"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1751eb",
   "metadata": {},
   "source": [
    "Note: the code in comment below was used to generate the data. It has now been saved separately in a folder called \"data\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af4df2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number_of_datapoints = 10000 # 80 000 for train, 10 000 for test\n",
    "# data = []\n",
    "\n",
    "# for i in range(number_of_datapoints):\n",
    "#     rho = random.uniform(rho_min, rho_max)\n",
    "#     eps = random.uniform(eps_min, eps_max)\n",
    "    \n",
    "#     new_row = [rho, eps, eos(rho, eps), chi(rho, eps), kappa(rho, eps)]\n",
    "    \n",
    "#     data.append(new_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "663bea84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# header = ['rho', 'eps', 'p', 'chi', 'kappa']\n",
    "\n",
    "# with open('NNEOS_data_test.csv', 'w', newline = '') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     # write header\n",
    "#     writer.writerow(header)\n",
    "#     # write data\n",
    "#     writer.writerows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ea690aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training data has 80000 instances\n",
      "The test data has 10000 instances\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rho</th>\n",
       "      <th>eps</th>\n",
       "      <th>p</th>\n",
       "      <th>chi</th>\n",
       "      <th>kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.770794</td>\n",
       "      <td>0.809768</td>\n",
       "      <td>5.274717</td>\n",
       "      <td>0.539845</td>\n",
       "      <td>6.513863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.093352</td>\n",
       "      <td>0.575342</td>\n",
       "      <td>3.871421</td>\n",
       "      <td>0.383561</td>\n",
       "      <td>6.728901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.685186</td>\n",
       "      <td>1.647820</td>\n",
       "      <td>1.851255</td>\n",
       "      <td>1.098547</td>\n",
       "      <td>1.123457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.167718</td>\n",
       "      <td>0.408377</td>\n",
       "      <td>0.317913</td>\n",
       "      <td>0.272251</td>\n",
       "      <td>0.778479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.750848</td>\n",
       "      <td>1.069954</td>\n",
       "      <td>5.528700</td>\n",
       "      <td>0.713303</td>\n",
       "      <td>5.167232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79995</th>\n",
       "      <td>3.985951</td>\n",
       "      <td>1.642317</td>\n",
       "      <td>4.364131</td>\n",
       "      <td>1.094878</td>\n",
       "      <td>2.657301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79996</th>\n",
       "      <td>6.948815</td>\n",
       "      <td>0.809021</td>\n",
       "      <td>3.747824</td>\n",
       "      <td>0.539347</td>\n",
       "      <td>4.632543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79997</th>\n",
       "      <td>8.423227</td>\n",
       "      <td>1.125142</td>\n",
       "      <td>6.318217</td>\n",
       "      <td>0.750095</td>\n",
       "      <td>5.615485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79998</th>\n",
       "      <td>4.748173</td>\n",
       "      <td>0.774870</td>\n",
       "      <td>2.452810</td>\n",
       "      <td>0.516580</td>\n",
       "      <td>3.165449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79999</th>\n",
       "      <td>2.927483</td>\n",
       "      <td>0.616751</td>\n",
       "      <td>1.203686</td>\n",
       "      <td>0.411167</td>\n",
       "      <td>1.951655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             rho       eps         p       chi     kappa\n",
       "0       9.770794  0.809768  5.274717  0.539845  6.513863\n",
       "1      10.093352  0.575342  3.871421  0.383561  6.728901\n",
       "2       1.685186  1.647820  1.851255  1.098547  1.123457\n",
       "3       1.167718  0.408377  0.317913  0.272251  0.778479\n",
       "4       7.750848  1.069954  5.528700  0.713303  5.167232\n",
       "...          ...       ...       ...       ...       ...\n",
       "79995   3.985951  1.642317  4.364131  1.094878  2.657301\n",
       "79996   6.948815  0.809021  3.747824  0.539347  4.632543\n",
       "79997   8.423227  1.125142  6.318217  0.750095  5.615485\n",
       "79998   4.748173  0.774870  2.452810  0.516580  3.165449\n",
       "79999   2.927483  0.616751  1.203686  0.411167  1.951655\n",
       "\n",
       "[80000 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data\n",
    "data_train = pd.read_csv(\"data/NNEOS_data_train.csv\")\n",
    "data_test = pd.read_csv(\"data/NNEOS_data_test.csv\")\n",
    "print(\"The training data has \" + str(len(data_train)) + \" instances\")\n",
    "print(\"The test data has \" + str(len(data_test)) + \" instances\")\n",
    "data_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01f30d9",
   "metadata": {},
   "source": [
    "In case we want to visualize the datapoints (not useful, nothing significant happening)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55cf2dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rho = data_train['rho']\n",
    "# eps = data_train['eps']\n",
    "\n",
    "# plt.figure(figsize = (12,10))\n",
    "# plt.plot(rho, eps, 'o', color = 'black', alpha = 0.005)\n",
    "# plt.grid()\n",
    "# plt.xlabel(r'$\\rho$')\n",
    "# plt.ylabel(r'$\\epsilon$')\n",
    "# plt.title('Training data')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f8ccb7",
   "metadata": {},
   "source": [
    "# Getting data into PyTorch's DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46c8cfc",
   "metadata": {},
   "source": [
    "Below: all_data is of the type $(\\rho, \\epsilon, p, \\chi, \\kappa)$ as generated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13501f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    \"\"\"See PyTorch tutorial: the following three methods HAVE to be implemented\"\"\"\n",
    "    \n",
    "    def __init__(self, all_data, transform=None, target_transform=None):\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        \n",
    "        # Separate features (rho and eps) from the labels (p, chi, kappa)\n",
    "        # (see above to get how data is organized)\n",
    "        features = []\n",
    "        labels = []\n",
    "        \n",
    "        for i in range(len(all_data)):\n",
    "            # Separate the features\n",
    "            new_feature = [all_data['rho'][i], all_data['eps'][i]]\n",
    "            features.append(torch.tensor(new_feature, dtype = torch.float32))\n",
    "            # Separate the labels\n",
    "            new_label = [all_data['p'][i], all_data['chi'][i], all_data['kappa'][i]]\n",
    "            labels.append(torch.tensor(new_label, dtype = torch.float32))\n",
    "            \n",
    "        # Save as instance variables to the dataloader\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    # TODO: I don't understand transform and target_transform --- but this is not used now!\n",
    "    def __getitem__(self, idx):\n",
    "        feature = self.features[idx]\n",
    "        if self.transform:\n",
    "            feature = transform(feature)\n",
    "        label = self.labels[idx]\n",
    "        if self.target_transform:\n",
    "            feature = target_transform(label)\n",
    "            \n",
    "        return feature, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6faa7ab8",
   "metadata": {},
   "source": [
    "Note that the following cell may be confusing. \"data_train\" refers to the data that was generatd above, see the pandas table. \"training_data\" is defined similarly as in the PyTorch tutorial, see [this page](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html) and this is an instance of the class CustomDataset defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c141bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make training and test data, as in the tutorial\n",
    "training_data = CustomDataset(data_train)\n",
    "test_data = CustomDataset(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6801365f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([9.7708, 0.8098]), tensor([10.0934,  0.5753])]\n",
      "[tensor([5.2747, 0.5398, 6.5139]), tensor([3.8714, 0.3836, 6.7289])]\n",
      "80000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# Check if this is done correctly\n",
    "print(training_data.features[:2])\n",
    "print(training_data.labels[:2])\n",
    "print(training_data.__len__())\n",
    "print(test_data.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fcf1d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now call DataLoader on the above CustomDataset instances:\n",
    "train_dataloader = DataLoader(training_data, batch_size=32)\n",
    "test_dataloader = DataLoader(test_data, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1411ed07",
   "metadata": {},
   "source": [
    "# Building the neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb3639f",
   "metadata": {},
   "source": [
    "We will follow [this part of the PyTorch tutorial](https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html). For more information, see the [documentation page of torch.nn](https://pytorch.org/docs/stable/nn.html). We take the parameters of NNEOSB in the paper, see Table 1. __To do:__ check other activation functions and architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1115de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters of the model here. Will first of all put two hidden layers\n",
    "device = \"cpu\"\n",
    "size_HL_1 = 400\n",
    "size_HL_2 = 600\n",
    "\n",
    "# Implement neural network\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        #self.flatten = nn.Flatten()\n",
    "        self.stack = nn.Sequential(\n",
    "            nn.Linear(2, size_HL_1),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(size_HL_1, size_HL_2),\n",
    "            nn.Sigmoid(),#nn.ReLU(),\n",
    "            nn.Linear(size_HL_2, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # No flatten needed, as our input and output are 1D?\n",
    "        #x = self.flatten(x) \n",
    "        logits = self.stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac35c30",
   "metadata": {},
   "source": [
    "# Training the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a386e1",
   "metadata": {},
   "source": [
    "Now we generate an instance of the above neural network in `model` (note: running this cell will create a 'fresh' model!).\n",
    "\n",
    "Save hyperparameters and loss function - note that we follow the paper. I think that their loss function agrees with [MSELoss](https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html#torch.nn.MSELoss). The paper uses the [Adam optimizer](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam). More details on optimizers can be found [here](https://pytorch.org/docs/stable/optim.html). Required argument `params` can be filled in by calling `model` which contains the neural network. For simplicity we will train for 10 epochs here. __Question:__ how many epochs should be used? What size for the batches,..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3b3e7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (stack): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=400, bias=True)\n",
      "    (1): Sigmoid()\n",
      "    (2): Linear(in_features=400, out_features=600, bias=True)\n",
      "    (3): Sigmoid()\n",
      "    (4): Linear(in_features=600, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)\n",
    "\n",
    "# Save hyperparameters, loss function and optimizer here (see paper for details)\n",
    "# learning_rate = 6e-4\n",
    "learning_rate = 4.6875e-6\n",
    "batch_size = 32\n",
    "epochs = 200\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "### not sure how this works\n",
    "# Adaptive learning rate:  \n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e8dc1d",
   "metadata": {},
   "source": [
    "The train and test loops are implemented below (copy pasted from [this part of the tutorial](https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html#full-implementation)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5157ea7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer, report_progress = False):\n",
    "    \"\"\"The training loop of the algorithm\"\"\"\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # If we want to report progress during training (not recommended - obstructs view)\n",
    "        if report_progress:\n",
    "            if batch % 100 == 0:\n",
    "                loss, current = loss.item(), batch * len(X)\n",
    "                print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    \"\"\"The testing loop of the algorithm\"\"\"\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss = 0\n",
    "\n",
    "    # Predict and compute losses\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            \n",
    "    average_test_loss = test_loss/num_batches\n",
    "    return average_test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c124df68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subset_train_dataloader(data_train, size = 10000):\n",
    "    \"\"\"Creates a 'subset' of dataloader for computing loss on training data.\n",
    "        This way we can 'test' on training data too - to check the claim of the paper about overfitting. \"\"\"\n",
    "    \n",
    "    # Get random ids to sample\n",
    "    random_ids =  np.random.choice(len(data_train), size, replace=False)\n",
    "    \n",
    "    # the following is a pandas dataframe\n",
    "    sampled_train_data = data_train.iloc[random_ids] \n",
    "    # relabel the indices\n",
    "    sampled_train_data.index = [i for i in range(len(sampled_train_data))]\n",
    "    new_dataset = CustomDataset(sampled_train_data)\n",
    "    \n",
    "    # Make it a dataloader and return it\n",
    "    new_dataloader = DataLoader(new_dataset, batch_size=32)\n",
    "    \n",
    "    return new_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009cdcab",
   "metadata": {},
   "source": [
    "continue with NNEOSBv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da41aee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('NNEOSBv1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "598fb7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are you sure you want to restart? Press y >> y\n",
      "Training the model . . .\n",
      "\n",
      " Epoch 1 \n",
      " --------------\n",
      "Average loss of: 3.9656275366807545e-08 for train data\n",
      "\n",
      " Epoch 2 \n",
      " --------------\n",
      "Average loss of: 3.716019254323629e-08 for train data\n",
      "\n",
      " Epoch 3 \n",
      " --------------\n",
      "Average loss of: 3.605011615034167e-08 for train data\n",
      "\n",
      " Epoch 4 \n",
      " --------------\n",
      "Average loss of: 3.869103654999537e-08 for train data\n",
      "\n",
      " Epoch 5 \n",
      " --------------\n",
      "Average loss of: 3.802104947104466e-08 for train data\n",
      "\n",
      " Epoch 6 \n",
      " --------------\n",
      "Average loss of: 3.487937339733266e-08 for train data\n",
      "\n",
      " Epoch 7 \n",
      " --------------\n",
      "Average loss of: 3.417244890182027e-08 for train data\n",
      "\n",
      " Epoch 8 \n",
      " --------------\n",
      "Average loss of: 3.8948198015706376e-08 for train data\n",
      "\n",
      " Epoch 9 \n",
      " --------------\n",
      "Average loss of: 3.611024425447031e-08 for train data\n",
      "\n",
      " Epoch 10 \n",
      " --------------\n",
      "Average loss of: 3.756165950089083e-08 for train data\n",
      "\n",
      " Epoch 11 \n",
      " --------------\n",
      "Average loss of: 3.804749886253245e-08 for train data\n",
      "\n",
      " Epoch 12 \n",
      " --------------\n",
      "Average loss of: 3.7600973157941954e-08 for train data\n",
      "\n",
      " Epoch 13 \n",
      " --------------\n",
      "Average loss of: 3.710415834572001e-08 for train data\n",
      "\n",
      " Epoch 14 \n",
      " --------------\n",
      "Average loss of: 3.7186421669313614e-08 for train data\n",
      "\n",
      " Epoch 15 \n",
      " --------------\n",
      "Average loss of: 3.511040774127833e-08 for train data\n",
      "\n",
      " Epoch 16 \n",
      " --------------\n",
      "Average loss of: 3.587256612028535e-08 for train data\n",
      "\n",
      " Epoch 17 \n",
      " --------------\n",
      "Average loss of: 3.210988081176723e-08 for train data\n",
      "\n",
      " Epoch 18 \n",
      " --------------\n",
      "Average loss of: 3.1800146578475666e-08 for train data\n",
      "\n",
      " Epoch 19 \n",
      " --------------\n",
      "Average loss of: 3.410315440480728e-08 for train data\n",
      "\n",
      " Epoch 20 \n",
      " --------------\n",
      "Average loss of: 3.274497183732988e-08 for train data\n",
      "\n",
      " Epoch 21 \n",
      " --------------\n",
      "Average loss of: 3.533321528862826e-08 for train data\n",
      "\n",
      " Epoch 22 \n",
      " --------------\n",
      "Average loss of: 3.837813405658735e-08 for train data\n",
      "\n",
      " Epoch 23 \n",
      " --------------\n",
      "Average loss of: 3.322278134529921e-08 for train data\n",
      "\n",
      " Epoch 24 \n",
      " --------------\n",
      "Average loss of: 3.2989946689235476e-08 for train data\n",
      "\n",
      " Epoch 25 \n",
      " --------------\n",
      "Average loss of: 3.4498897035521075e-08 for train data\n",
      "\n",
      " Epoch 26 \n",
      " --------------\n",
      "Average loss of: 3.373054959376224e-08 for train data\n",
      "\n",
      " Epoch 27 \n",
      " --------------\n",
      "Average loss of: 3.646424172194738e-08 for train data\n",
      "\n",
      " Epoch 28 \n",
      " --------------\n",
      "Average loss of: 3.243444333984538e-08 for train data\n",
      "\n",
      " Epoch 29 \n",
      " --------------\n",
      "Average loss of: 3.5955106518656704e-08 for train data\n",
      "\n",
      " Epoch 30 \n",
      " --------------\n",
      "Average loss of: 3.471433224229131e-08 for train data\n",
      "\n",
      " Epoch 31 \n",
      " --------------\n",
      "Average loss of: 3.2624217758247445e-08 for train data\n",
      "\n",
      " Epoch 32 \n",
      " --------------\n",
      "Average loss of: 3.3159731426445716e-08 for train data\n",
      "\n",
      " Epoch 33 \n",
      " --------------\n",
      "Average loss of: 3.133581688344136e-08 for train data\n",
      "\n",
      " Epoch 34 \n",
      " --------------\n",
      "Average loss of: 3.2883910214639965e-08 for train data\n",
      "\n",
      " Epoch 35 \n",
      " --------------\n",
      "Average loss of: 3.137121819116974e-08 for train data\n",
      "\n",
      " Epoch 36 \n",
      " --------------\n",
      "Average loss of: 3.4862964857204325e-08 for train data\n",
      "\n",
      " Epoch 37 \n",
      " --------------\n",
      "Average loss of: 2.8229605992525552e-08 for train data\n",
      "\n",
      " Epoch 38 \n",
      " --------------\n",
      "Average loss of: 3.1416802356650004e-08 for train data\n",
      "\n",
      " Epoch 39 \n",
      " --------------\n",
      "Average loss of: 3.214741090439689e-08 for train data\n",
      "\n",
      " Epoch 40 \n",
      " --------------\n",
      "Average loss of: 3.151867600425789e-08 for train data\n",
      "\n",
      " Epoch 41 \n",
      " --------------\n",
      "Average loss of: 3.076069082661646e-08 for train data\n",
      "\n",
      " Epoch 42 \n",
      " --------------\n",
      "Average loss of: 3.0987181661223406e-08 for train data\n",
      "\n",
      " Epoch 43 \n",
      " --------------\n",
      "Average loss of: 3.1727118979598125e-08 for train data\n",
      "\n",
      " Epoch 44 \n",
      " --------------\n",
      "Average loss of: 2.927234164540717e-08 for train data\n",
      "\n",
      " Epoch 45 \n",
      " --------------\n",
      "Average loss of: 2.850116378617179e-08 for train data\n",
      "\n",
      " Epoch 46 \n",
      " --------------\n",
      "Average loss of: 2.9115289456616863e-08 for train data\n",
      "\n",
      " Epoch 47 \n",
      " --------------\n",
      "Average loss of: 2.823471736568911e-08 for train data\n",
      "\n",
      " Epoch 48 \n",
      " --------------\n",
      "Average loss of: 2.8568788936237985e-08 for train data\n",
      "\n",
      " Epoch 49 \n",
      " --------------\n",
      "Average loss of: 2.85102714911773e-08 for train data\n",
      "\n",
      " Epoch 50 \n",
      " --------------\n",
      "Average loss of: 2.85499862331445e-08 for train data\n",
      "\n",
      " Epoch 51 \n",
      " --------------\n",
      "Average loss of: 2.6542487392926167e-08 for train data\n",
      "\n",
      " Epoch 52 \n",
      " --------------\n",
      "Average loss of: 2.852271720053213e-08 for train data\n",
      "\n",
      " Epoch 53 \n",
      " --------------\n",
      "Average loss of: 2.685605900249886e-08 for train data\n",
      "\n",
      " Epoch 54 \n",
      " --------------\n",
      "Average loss of: 2.6848865324825437e-08 for train data\n",
      "\n",
      " Epoch 55 \n",
      " --------------\n",
      "Average loss of: 2.894451507014951e-08 for train data\n",
      "\n",
      " Epoch 56 \n",
      " --------------\n",
      "Average loss of: 2.8696734950688568e-08 for train data\n",
      "\n",
      " Epoch 57 \n",
      " --------------\n",
      "Average loss of: 2.9144240423905963e-08 for train data\n",
      "\n",
      " Epoch 58 \n",
      " --------------\n",
      "Average loss of: 2.604699807207158e-08 for train data\n",
      "\n",
      " Epoch 59 \n",
      " --------------\n",
      "Average loss of: 2.6580363784335324e-08 for train data\n",
      "\n",
      " Epoch 60 \n",
      " --------------\n",
      "Average loss of: 2.8261188638147483e-08 for train data\n",
      "\n",
      " Epoch 61 \n",
      " --------------\n",
      "Average loss of: 2.8461491007087883e-08 for train data\n",
      "\n",
      " Epoch 62 \n",
      " --------------\n",
      "Average loss of: 2.6075002036855867e-08 for train data\n",
      "\n",
      " Epoch 63 \n",
      " --------------\n",
      "Average loss of: 2.7555899100335023e-08 for train data\n",
      "\n",
      " Epoch 64 \n",
      " --------------\n",
      "Average loss of: 2.4245537403113083e-08 for train data\n",
      "\n",
      " Epoch 65 \n",
      " --------------\n",
      "Average loss of: 2.64057220845826e-08 for train data\n",
      "\n",
      " Epoch 66 \n",
      " --------------\n",
      "Average loss of: 2.5773773224284177e-08 for train data\n",
      "\n",
      " Epoch 67 \n",
      " --------------\n",
      "Average loss of: 2.6858814744885012e-08 for train data\n",
      "\n",
      " Epoch 68 \n",
      " --------------\n",
      "Average loss of: 2.40518719204564e-08 for train data\n",
      "\n",
      " Epoch 69 \n",
      " --------------\n",
      "Average loss of: 2.448724737641337e-08 for train data\n",
      "\n",
      " Epoch 70 \n",
      " --------------\n",
      "Average loss of: 2.5458800656554758e-08 for train data\n",
      "\n",
      " Epoch 71 \n",
      " --------------\n",
      "Average loss of: 2.662722840514557e-08 for train data\n",
      "\n",
      " Epoch 72 \n",
      " --------------\n",
      "Average loss of: 2.6049230824925322e-08 for train data\n",
      "\n",
      " Epoch 73 \n",
      " --------------\n",
      "Average loss of: 2.7272617203991943e-08 for train data\n",
      "\n",
      " Epoch 74 \n",
      " --------------\n",
      "Average loss of: 2.859144890456641e-08 for train data\n",
      "\n",
      " Epoch 75 \n",
      " --------------\n",
      "Average loss of: 2.4215464067739817e-08 for train data\n",
      "\n",
      " Epoch 76 \n",
      " --------------\n",
      "Average loss of: 2.4441993000376992e-08 for train data\n",
      "\n",
      " Epoch 77 \n",
      " --------------\n",
      "Average loss of: 2.4986604299991664e-08 for train data\n",
      "\n",
      " Epoch 78 \n",
      " --------------\n",
      "Average loss of: 2.4487391088221888e-08 for train data\n",
      "\n",
      " Epoch 79 \n",
      " --------------\n",
      "Average loss of: 2.277483091857905e-08 for train data\n",
      "\n",
      " Epoch 80 \n",
      " --------------\n",
      "Average loss of: 2.4838377735848506e-08 for train data\n",
      "\n",
      " Epoch 81 \n",
      " --------------\n",
      "Average loss of: 2.2422933116236677e-08 for train data\n",
      "\n",
      " Epoch 82 \n",
      " --------------\n",
      "Average loss of: 2.4840709428373047e-08 for train data\n",
      "\n",
      " Epoch 83 \n",
      " --------------\n",
      "Average loss of: 2.672523824110441e-08 for train data\n",
      "\n",
      " Epoch 84 \n",
      " --------------\n",
      "Average loss of: 2.3676443961944757e-08 for train data\n",
      "\n",
      " Epoch 85 \n",
      " --------------\n",
      "Average loss of: 2.3550350245007273e-08 for train data\n",
      "\n",
      " Epoch 86 \n",
      " --------------\n",
      "Average loss of: 2.4110217717233994e-08 for train data\n",
      "\n",
      " Epoch 87 \n",
      " --------------\n",
      "Average loss of: 2.281514604929455e-08 for train data\n",
      "\n",
      " Epoch 88 \n",
      " --------------\n",
      "Average loss of: 2.3572611262317932e-08 for train data\n",
      "\n",
      " Epoch 89 \n",
      " --------------\n",
      "Average loss of: 2.561007488150818e-08 for train data\n",
      "\n",
      " Epoch 90 \n",
      " --------------\n",
      "Average loss of: 2.4343603741975095e-08 for train data\n",
      "\n",
      " Epoch 91 \n",
      " --------------\n",
      "Average loss of: 2.2956524340690103e-08 for train data\n",
      "\n",
      " Epoch 92 \n",
      " --------------\n",
      "Average loss of: 2.2325116341322448e-08 for train data\n",
      "\n",
      " Epoch 93 \n",
      " --------------\n",
      "Average loss of: 2.352275113351268e-08 for train data\n",
      "\n",
      " Epoch 94 \n",
      " --------------\n",
      "Average loss of: 2.305670661566144e-08 for train data\n",
      "\n",
      " Epoch 95 \n",
      " --------------\n",
      "Average loss of: 2.2042823418880365e-08 for train data\n",
      "\n",
      " Epoch 96 \n",
      " --------------\n",
      "Average loss of: 2.3145481898845705e-08 for train data\n",
      "\n",
      " Epoch 97 \n",
      " --------------\n",
      "Average loss of: 2.3301973706643424e-08 for train data\n",
      "\n",
      " Epoch 98 \n",
      " --------------\n",
      "Average loss of: 2.337100169621552e-08 for train data\n",
      "\n",
      " Epoch 99 \n",
      " --------------\n",
      "Average loss of: 2.1640068355643382e-08 for train data\n",
      "\n",
      " Epoch 100 \n",
      " --------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of: 2.4113521814733678e-08 for train data\n",
      "\n",
      " Epoch 101 \n",
      " --------------\n",
      "Average loss of: 2.5146560386706363e-08 for train data\n",
      "\n",
      " Epoch 102 \n",
      " --------------\n",
      "Average loss of: 2.094976783602227e-08 for train data\n",
      "\n",
      " Epoch 103 \n",
      " --------------\n",
      "Average loss of: 2.0629460298340357e-08 for train data\n",
      "\n",
      " Epoch 104 \n",
      " --------------\n",
      "Average loss of: 2.4196617001127442e-08 for train data\n",
      "\n",
      " Epoch 105 \n",
      " --------------\n",
      "Average loss of: 2.192571642172442e-08 for train data\n",
      "\n",
      " Epoch 106 \n",
      " --------------\n",
      "Average loss of: 2.2183948780898086e-08 for train data\n",
      "\n",
      " Epoch 107 \n",
      " --------------\n",
      "Average loss of: 2.136465272356079e-08 for train data\n",
      "\n",
      " Epoch 108 \n",
      " --------------\n",
      "Average loss of: 2.105262002356295e-08 for train data\n",
      "\n",
      " Epoch 109 \n",
      " --------------\n",
      "Average loss of: 2.261402906183597e-08 for train data\n",
      "\n",
      " Epoch 110 \n",
      " --------------\n",
      "Average loss of: 2.1230688616447732e-08 for train data\n",
      "\n",
      " Epoch 111 \n",
      " --------------\n",
      "Average loss of: 2.236114529324232e-08 for train data\n",
      "\n",
      " Epoch 112 \n",
      " --------------\n",
      "Average loss of: 2.0900970536133127e-08 for train data\n",
      "\n",
      " Epoch 113 \n",
      " --------------\n",
      "Average loss of: 2.2561442062118466e-08 for train data\n",
      "\n",
      " Epoch 114 \n",
      " --------------\n",
      "Average loss of: 2.2520775926412893e-08 for train data\n",
      "\n",
      " Epoch 115 \n",
      " --------------\n",
      "Average loss of: 2.065608349187296e-08 for train data\n",
      "\n",
      " Epoch 116 \n",
      " --------------\n",
      "Average loss of: 2.1398720344844247e-08 for train data\n",
      "\n",
      " Epoch 117 \n",
      " --------------\n",
      "Average loss of: 2.2929078560572213e-08 for train data\n",
      "\n",
      " Epoch 118 \n",
      " --------------\n",
      "Average loss of: 2.3302839453592174e-08 for train data\n",
      "\n",
      " Epoch 119 \n",
      " --------------\n",
      "Average loss of: 2.5711605766024462e-08 for train data\n",
      "\n",
      " Epoch 120 \n",
      " --------------\n",
      "Average loss of: 2.0563829676352536e-08 for train data\n",
      "\n",
      " Epoch 121 \n",
      " --------------\n",
      "Average loss of: 2.3243066714473227e-08 for train data\n",
      "\n",
      " Epoch 122 \n",
      " --------------\n",
      "Average loss of: 2.0699608944905282e-08 for train data\n",
      "\n",
      " Epoch 123 \n",
      " --------------\n",
      "Average loss of: 2.2524418005596394e-08 for train data\n",
      "\n",
      " Epoch 124 \n",
      " --------------\n",
      "Average loss of: 2.1414034118522567e-08 for train data\n",
      "\n",
      " Epoch 125 \n",
      " --------------\n",
      "Average loss of: 2.1803329862193688e-08 for train data\n",
      "\n",
      " Epoch 126 \n",
      " --------------\n",
      "Average loss of: 2.306037215921348e-08 for train data\n",
      "\n",
      " Epoch 127 \n",
      " --------------\n",
      "Average loss of: 2.052748999251678e-08 for train data\n",
      "\n",
      " Epoch 128 \n",
      " --------------\n",
      "Average loss of: 2.252601659905847e-08 for train data\n",
      "\n",
      " Epoch 129 \n",
      " --------------\n",
      "Average loss of: 2.1239227240284826e-08 for train data\n",
      "\n",
      " Epoch 130 \n",
      " --------------\n",
      "Average loss of: 2.0332748979708826e-08 for train data\n",
      "\n",
      " Epoch 131 \n",
      " --------------\n",
      "Average loss of: 2.1940679191831484e-08 for train data\n",
      "\n",
      " Epoch 132 \n",
      " --------------\n",
      "Average loss of: 1.995270434071235e-08 for train data\n",
      "\n",
      " Epoch 133 \n",
      " --------------\n",
      "Average loss of: 2.0067068807490844e-08 for train data\n",
      "\n",
      " Epoch 134 \n",
      " --------------\n",
      "Adapting learning rate to 4.21875e-06\n",
      "Average loss of: 2.0767464780161985e-08 for train data\n",
      "\n",
      " Epoch 135 \n",
      " --------------\n",
      "Average loss of: 2.0728052921224056e-08 for train data\n",
      "\n",
      " Epoch 136 \n",
      " --------------\n",
      "Average loss of: 1.8683102099837274e-08 for train data\n",
      "\n",
      " Epoch 137 \n",
      " --------------\n",
      "Average loss of: 2.0060848664169593e-08 for train data\n",
      "\n",
      " Epoch 138 \n",
      " --------------\n",
      "Average loss of: 1.851899518080006e-08 for train data\n",
      "\n",
      " Epoch 139 \n",
      " --------------\n",
      "Average loss of: 2.085253944951597e-08 for train data\n",
      "\n",
      " Epoch 140 \n",
      " --------------\n",
      "Average loss of: 2.0984559353931722e-08 for train data\n",
      "\n",
      " Epoch 141 \n",
      " --------------\n",
      "Average loss of: 2.125548222486363e-08 for train data\n",
      "\n",
      " Epoch 142 \n",
      " --------------\n",
      "Average loss of: 1.97036386298098e-08 for train data\n",
      "\n",
      " Epoch 143 \n",
      " --------------\n",
      "Average loss of: 2.0035366087524405e-08 for train data\n",
      "\n",
      " Epoch 144 \n",
      " --------------\n",
      "Average loss of: 1.8834248481013244e-08 for train data\n",
      "\n",
      " Epoch 145 \n",
      " --------------\n",
      "Average loss of: 1.8873680413350984e-08 for train data\n",
      "\n",
      " Epoch 146 \n",
      " --------------\n",
      "Average loss of: 1.9938520006493986e-08 for train data\n",
      "\n",
      " Epoch 147 \n",
      " --------------\n",
      "Average loss of: 1.901866052220637e-08 for train data\n",
      "\n",
      " Epoch 148 \n",
      " --------------\n",
      "Average loss of: 2.026511635816091e-08 for train data\n",
      "\n",
      " Epoch 149 \n",
      " --------------\n",
      "Average loss of: 1.9039122877481246e-08 for train data\n",
      "\n",
      " Epoch 150 \n",
      " --------------\n",
      "Average loss of: 1.7351085170705976e-08 for train data\n",
      "\n",
      " Epoch 151 \n",
      " --------------\n",
      "Average loss of: 1.9473223692413608e-08 for train data\n",
      "\n",
      " Epoch 152 \n",
      " --------------\n",
      "Average loss of: 1.8900701215702015e-08 for train data\n",
      "\n",
      " Epoch 153 \n",
      " --------------\n",
      "Average loss of: 1.8441214331945725e-08 for train data\n",
      "\n",
      " Epoch 154 \n",
      " --------------\n",
      "Average loss of: 1.836047869509742e-08 for train data\n",
      "\n",
      " Epoch 155 \n",
      " --------------\n",
      "Average loss of: 1.7416910654215106e-08 for train data\n",
      "\n",
      " Epoch 156 \n",
      " --------------\n",
      "Average loss of: 1.7952485357012827e-08 for train data\n",
      "\n",
      " Epoch 157 \n",
      " --------------\n",
      "Average loss of: 1.751544282705128e-08 for train data\n",
      "\n",
      " Epoch 158 \n",
      " --------------\n",
      "Average loss of: 1.7332085842503683e-08 for train data\n",
      "\n",
      " Epoch 159 \n",
      " --------------\n",
      "Average loss of: 1.8427248745005377e-08 for train data\n",
      "\n",
      " Epoch 160 \n",
      " --------------\n",
      "Average loss of: 1.9020149716490763e-08 for train data\n",
      "\n",
      " Epoch 161 \n",
      " --------------\n",
      "Average loss of: 1.7659883665467928e-08 for train data\n",
      "\n",
      " Epoch 162 \n",
      " --------------\n",
      "Average loss of: 2.1020089319837567e-08 for train data\n",
      "\n",
      " Epoch 163 \n",
      " --------------\n",
      "Average loss of: 1.796696507440243e-08 for train data\n",
      "\n",
      " Epoch 164 \n",
      " --------------\n",
      "Average loss of: 1.769769929185255e-08 for train data\n",
      "\n",
      " Epoch 165 \n",
      " --------------\n",
      "Average loss of: 1.8690176777209428e-08 for train data\n",
      "\n",
      " Epoch 166 \n",
      " --------------\n",
      "Average loss of: 1.829210694452173e-08 for train data\n",
      "\n",
      " Epoch 167 \n",
      " --------------\n",
      "Average loss of: 1.854306248060384e-08 for train data\n",
      "\n",
      " Epoch 168 \n",
      " --------------\n",
      "Average loss of: 1.950000353167561e-08 for train data\n",
      "\n",
      " Epoch 169 \n",
      " --------------\n",
      "Average loss of: 1.7778413569854324e-08 for train data\n",
      "\n",
      " Epoch 170 \n",
      " --------------\n",
      "Average loss of: 1.6845578221661867e-08 for train data\n",
      "\n",
      " Epoch 171 \n",
      " --------------\n",
      "Average loss of: 1.900248635760731e-08 for train data\n",
      "\n",
      " Epoch 172 \n",
      " --------------\n",
      "Average loss of: 1.703475856930046e-08 for train data\n",
      "\n",
      " Epoch 173 \n",
      " --------------\n",
      "Average loss of: 1.745092205777728e-08 for train data\n",
      "\n",
      " Epoch 174 \n",
      " --------------\n",
      "Average loss of: 1.9531199050687046e-08 for train data\n",
      "\n",
      " Epoch 175 \n",
      " --------------\n",
      "Average loss of: 1.625457582944685e-08 for train data\n",
      "\n",
      " Epoch 176 \n",
      " --------------\n",
      "Average loss of: 1.827222562535355e-08 for train data\n",
      "\n",
      " Epoch 177 \n",
      " --------------\n",
      "Average loss of: 1.8469707978152865e-08 for train data\n",
      "\n",
      " Epoch 178 \n",
      " --------------\n",
      "Average loss of: 2.100681660854403e-08 for train data\n",
      "\n",
      " Epoch 179 \n",
      " --------------\n",
      "Average loss of: 1.825709856493989e-08 for train data\n",
      "\n",
      " Epoch 180 \n",
      " --------------\n",
      "Average loss of: 1.8102942349990157e-08 for train data\n",
      "\n",
      " Epoch 181 \n",
      " --------------\n",
      "Average loss of: 1.6437446915133364e-08 for train data\n",
      "\n",
      " Epoch 182 \n",
      " --------------\n",
      "Average loss of: 1.7624167465857017e-08 for train data\n",
      "\n",
      " Epoch 183 \n",
      " --------------\n",
      "Average loss of: 1.7508332226692854e-08 for train data\n",
      "\n",
      " Epoch 184 \n",
      " --------------\n",
      "Average loss of: 1.8030641831560295e-08 for train data\n",
      "\n",
      " Epoch 185 \n",
      " --------------\n",
      "Average loss of: 1.7319891897679268e-08 for train data\n",
      "\n",
      " Epoch 186 \n",
      " --------------\n",
      "Average loss of: 1.7357603842712138e-08 for train data\n",
      "\n",
      " Epoch 187 \n",
      " --------------\n",
      "Average loss of: 1.7023809565438577e-08 for train data\n",
      "\n",
      " Epoch 188 \n",
      " --------------\n",
      "Average loss of: 1.796971604815013e-08 for train data\n",
      "\n",
      " Epoch 189 \n",
      " --------------\n",
      "Average loss of: 1.8232820392283385e-08 for train data\n",
      "\n",
      " Epoch 190 \n",
      " --------------\n",
      "Average loss of: 1.7822572820480396e-08 for train data\n",
      "\n",
      " Epoch 191 \n",
      " --------------\n",
      "Average loss of: 1.6852466964699e-08 for train data\n",
      "\n",
      " Epoch 192 \n",
      " --------------\n",
      "Average loss of: 1.769570750350665e-08 for train data\n",
      "\n",
      " Epoch 193 \n",
      " --------------\n",
      "Average loss of: 1.718251275447417e-08 for train data\n",
      "\n",
      " Epoch 194 \n",
      " --------------\n",
      "Average loss of: 1.7708177202191707e-08 for train data\n",
      "\n",
      " Epoch 195 \n",
      " --------------\n",
      "Average loss of: 1.8179436577342925e-08 for train data\n",
      "\n",
      " Epoch 196 \n",
      " --------------\n",
      "Adapting learning rate to 3.796875e-06\n",
      "Average loss of: 1.8517390494944795e-08 for train data\n",
      "\n",
      " Epoch 197 \n",
      " --------------\n",
      "Average loss of: 1.900607153945697e-08 for train data\n",
      "\n",
      " Epoch 198 \n",
      " --------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of: 1.844973889674135e-08 for train data\n",
      "\n",
      " Epoch 199 \n",
      " --------------\n",
      "Average loss of: 1.5591153183554336e-08 for train data\n",
      "\n",
      " Epoch 200 \n",
      " --------------\n",
      "Average loss of: 1.6758489047309143e-08 for train data\n",
      "\n",
      " Epoch 201 \n",
      " --------------\n",
      "Average loss of: 1.5947463701740836e-08 for train data\n",
      "\n",
      " Epoch 202 \n",
      " --------------\n",
      "Average loss of: 1.589696324737233e-08 for train data\n",
      "\n",
      " Epoch 203 \n",
      " --------------\n",
      "Average loss of: 1.747598792976801e-08 for train data\n",
      "\n",
      " Epoch 204 \n",
      " --------------\n",
      "Average loss of: 1.6678891585567004e-08 for train data\n",
      "\n",
      " Epoch 205 \n",
      " --------------\n",
      "Average loss of: 1.6519428012230628e-08 for train data\n",
      "\n",
      " Epoch 206 \n",
      " --------------\n",
      "Average loss of: 1.7154041369480138e-08 for train data\n",
      "\n",
      " Epoch 207 \n",
      " --------------\n",
      "Average loss of: 1.703549449038669e-08 for train data\n",
      "\n",
      " Epoch 208 \n",
      " --------------\n",
      "Average loss of: 1.6844158705400144e-08 for train data\n",
      "\n",
      " Epoch 209 \n",
      " --------------\n",
      "Average loss of: 1.6701002123319847e-08 for train data\n",
      "\n",
      " Epoch 210 \n",
      " --------------\n",
      "Average loss of: 1.537543044959355e-08 for train data\n",
      "\n",
      " Epoch 211 \n",
      " --------------\n",
      "Average loss of: 1.569023027797086e-08 for train data\n",
      "\n",
      " Epoch 212 \n",
      " --------------\n",
      "Average loss of: 1.6031628476287114e-08 for train data\n",
      "\n",
      " Epoch 213 \n",
      " --------------\n",
      "Average loss of: 1.6147126155155623e-08 for train data\n",
      "\n",
      " Epoch 214 \n",
      " --------------\n",
      "Average loss of: 1.514381461835789e-08 for train data\n",
      "\n",
      " Epoch 215 \n",
      " --------------\n",
      "Average loss of: 1.5388845944790353e-08 for train data\n",
      "\n",
      " Epoch 216 \n",
      " --------------\n",
      "Average loss of: 1.7123805344224005e-08 for train data\n",
      "\n",
      " Epoch 217 \n",
      " --------------\n",
      "Average loss of: 1.6557145775825317e-08 for train data\n",
      "\n",
      " Epoch 218 \n",
      " --------------\n",
      "Average loss of: 1.6177929208554336e-08 for train data\n",
      "\n",
      " Epoch 219 \n",
      " --------------\n",
      "Average loss of: 1.4907728257389536e-08 for train data\n",
      "\n",
      " Epoch 220 \n",
      " --------------\n",
      "Average loss of: 1.4674044716997695e-08 for train data\n",
      "\n",
      " Epoch 221 \n",
      " --------------\n",
      "Average loss of: 1.5479410420836644e-08 for train data\n",
      "\n",
      " Epoch 222 \n",
      " --------------\n",
      "Average loss of: 1.4910836132723972e-08 for train data\n",
      "\n",
      " Epoch 223 \n",
      " --------------\n",
      "Average loss of: 1.5801835514915033e-08 for train data\n",
      "\n",
      " Epoch 224 \n",
      " --------------\n",
      "Average loss of: 1.53029285998443e-08 for train data\n",
      "\n",
      " Epoch 225 \n",
      " --------------\n",
      "Average loss of: 1.6048359567063337e-08 for train data\n",
      "\n",
      " Epoch 226 \n",
      " --------------\n",
      "Average loss of: 1.5853687298697543e-08 for train data\n",
      "\n",
      " Epoch 227 \n",
      " --------------\n",
      "Average loss of: 1.4155368800439678e-08 for train data\n",
      "\n",
      " Epoch 228 \n",
      " --------------\n",
      "Average loss of: 1.5660119614984103e-08 for train data\n",
      "\n",
      " Epoch 229 \n",
      " --------------\n",
      "Average loss of: 1.6376609924026498e-08 for train data\n",
      "\n",
      " Epoch 230 \n",
      " --------------\n",
      "Average loss of: 1.4813735625465507e-08 for train data\n",
      "\n",
      " Epoch 231 \n",
      " --------------\n",
      "Average loss of: 1.5030884458991322e-08 for train data\n",
      "\n",
      " Epoch 232 \n",
      " --------------\n",
      "Average loss of: 1.676006838460906e-08 for train data\n",
      "\n",
      " Epoch 233 \n",
      " --------------\n",
      "Average loss of: 1.5255790882614595e-08 for train data\n",
      "\n",
      " Epoch 234 \n",
      " --------------\n",
      "Average loss of: 1.4057086578887878e-08 for train data\n",
      "\n",
      " Epoch 235 \n",
      " --------------\n",
      "Average loss of: 1.5049632432700843e-08 for train data\n",
      "\n",
      " Epoch 236 \n",
      " --------------\n",
      "Average loss of: 1.458426894906336e-08 for train data\n",
      "\n",
      " Epoch 237 \n",
      " --------------\n",
      "Average loss of: 1.4692760181390712e-08 for train data\n",
      "\n",
      " Epoch 238 \n",
      " --------------\n",
      "Average loss of: 1.5421000371586346e-08 for train data\n",
      "\n",
      " Epoch 239 \n",
      " --------------\n",
      "Average loss of: 1.54420819021438e-08 for train data\n",
      "\n",
      " Epoch 240 \n",
      " --------------\n",
      "Average loss of: 1.4278305884452641e-08 for train data\n",
      "\n",
      " Epoch 241 \n",
      " --------------\n",
      "Average loss of: 1.6284880268561158e-08 for train data\n",
      "\n",
      " Epoch 242 \n",
      " --------------\n",
      "Average loss of: 1.4110007980618026e-08 for train data\n",
      "\n",
      " Epoch 243 \n",
      " --------------\n",
      "Average loss of: 1.4428435549630743e-08 for train data\n",
      "\n",
      " Epoch 244 \n",
      " --------------\n",
      "Average loss of: 1.477765795568238e-08 for train data\n",
      "\n",
      " Epoch 245 \n",
      " --------------\n",
      "Average loss of: 1.4798109027118641e-08 for train data\n",
      "\n",
      " Epoch 246 \n",
      " --------------\n",
      "Average loss of: 1.4625710778087529e-08 for train data\n",
      "\n",
      " Epoch 247 \n",
      " --------------\n",
      "Average loss of: 1.4258346123239271e-08 for train data\n",
      "\n",
      " Epoch 248 \n",
      " --------------\n",
      "Average loss of: 1.5144945635540536e-08 for train data\n",
      "\n",
      " Epoch 249 \n",
      " --------------\n",
      "Average loss of: 1.644012906356643e-08 for train data\n",
      "\n",
      " Epoch 250 \n",
      " --------------\n",
      "Average loss of: 1.4931360230587173e-08 for train data\n",
      "\n",
      " Epoch 251 \n",
      " --------------\n",
      "Average loss of: 1.526338022107295e-08 for train data\n",
      "\n",
      " Epoch 252 \n",
      " --------------\n",
      "Average loss of: 1.4902732421198937e-08 for train data\n",
      "\n",
      " Epoch 253 \n",
      " --------------\n",
      "Average loss of: 1.579725743897752e-08 for train data\n",
      "\n",
      " Epoch 254 \n",
      " --------------\n",
      "Average loss of: 1.6046368299422678e-08 for train data\n",
      "\n",
      " Epoch 255 \n",
      " --------------\n",
      "Average loss of: 1.3845588458486316e-08 for train data\n",
      "\n",
      " Epoch 256 \n",
      " --------------\n",
      "Average loss of: 1.458594237368552e-08 for train data\n",
      "\n",
      " Epoch 257 \n",
      " --------------\n",
      "Average loss of: 1.5730043809214428e-08 for train data\n",
      "\n",
      " Epoch 258 \n",
      " --------------\n",
      "Average loss of: 1.5238876883836527e-08 for train data\n",
      "\n",
      " Epoch 259 \n",
      " --------------\n",
      "Average loss of: 1.3904996142086614e-08 for train data\n",
      "\n",
      " Epoch 260 \n",
      " --------------\n",
      "Average loss of: 1.4148846164263383e-08 for train data\n",
      "\n",
      " Epoch 261 \n",
      " --------------\n",
      "Average loss of: 1.4950317496589096e-08 for train data\n",
      "\n",
      " Epoch 262 \n",
      " --------------\n",
      "Average loss of: 1.5269772804376266e-08 for train data\n",
      "\n",
      " Epoch 263 \n",
      " --------------\n",
      "Average loss of: 1.5440002509043066e-08 for train data\n",
      "\n",
      " Epoch 264 \n",
      " --------------\n",
      "Average loss of: 1.4695798854005626e-08 for train data\n",
      "\n",
      " Epoch 265 \n",
      " --------------\n",
      "Average loss of: 1.561745091077347e-08 for train data\n",
      "\n",
      " Epoch 266 \n",
      " --------------\n",
      "Average loss of: 1.4377443343787766e-08 for train data\n",
      "\n",
      " Epoch 267 \n",
      " --------------\n",
      "Average loss of: 1.3709935778059424e-08 for train data\n",
      "\n",
      " Epoch 268 \n",
      " --------------\n",
      "Adapting learning rate to 3.4171875e-06\n",
      "Average loss of: 1.5425981128607225e-08 for train data\n",
      "\n",
      " Epoch 269 \n",
      " --------------\n",
      "Average loss of: 1.3663480837348747e-08 for train data\n",
      "\n",
      " Epoch 270 \n",
      " --------------\n",
      "Average loss of: 1.481852299937069e-08 for train data\n",
      "\n",
      " Epoch 271 \n",
      " --------------\n",
      "Average loss of: 1.4515318026704368e-08 for train data\n",
      "\n",
      " Epoch 272 \n",
      " --------------\n",
      "Average loss of: 1.5028832830688508e-08 for train data\n",
      "\n",
      " Epoch 273 \n",
      " --------------\n",
      "Average loss of: 1.3548998647202812e-08 for train data\n",
      "\n",
      " Epoch 274 \n",
      " --------------\n",
      "Average loss of: 1.3549849781772098e-08 for train data\n",
      "\n",
      " Epoch 275 \n",
      " --------------\n",
      "Average loss of: 1.2831937470703458e-08 for train data\n",
      "\n",
      " Epoch 276 \n",
      " --------------\n",
      "Average loss of: 1.2886662422288328e-08 for train data\n",
      "\n",
      " Epoch 277 \n",
      " --------------\n",
      "Average loss of: 1.3548161564580922e-08 for train data\n",
      "\n",
      " Epoch 278 \n",
      " --------------\n",
      "Average loss of: 1.3134104957333757e-08 for train data\n",
      "\n",
      " Epoch 279 \n",
      " --------------\n",
      "Average loss of: 1.3572830398117005e-08 for train data\n",
      "\n",
      " Epoch 280 \n",
      " --------------\n",
      "Average loss of: 1.4104440265355108e-08 for train data\n",
      "\n",
      " Epoch 281 \n",
      " --------------\n",
      "Average loss of: 1.4001873944991008e-08 for train data\n",
      "\n",
      " Epoch 282 \n",
      " --------------\n",
      "Average loss of: 1.3583604852218373e-08 for train data\n",
      "\n",
      " Epoch 283 \n",
      " --------------\n",
      "Average loss of: 1.3170343737858247e-08 for train data\n",
      "\n",
      " Epoch 284 \n",
      " --------------\n",
      "Average loss of: 1.2593763321503845e-08 for train data\n",
      "\n",
      " Epoch 285 \n",
      " --------------\n",
      "Average loss of: 1.4119965997279908e-08 for train data\n",
      "\n",
      " Epoch 286 \n",
      " --------------\n",
      "Average loss of: 1.3399046576563007e-08 for train data\n",
      "\n",
      " Epoch 287 \n",
      " --------------\n",
      "Average loss of: 1.3002022938600056e-08 for train data\n",
      "\n",
      " Epoch 288 \n",
      " --------------\n",
      "Average loss of: 1.3579290971052704e-08 for train data\n",
      "\n",
      " Epoch 289 \n",
      " --------------\n",
      "Average loss of: 1.305385013005581e-08 for train data\n",
      "\n",
      " Epoch 290 \n",
      " --------------\n",
      "Average loss of: 1.3323238262730044e-08 for train data\n",
      "\n",
      " Epoch 291 \n",
      " --------------\n",
      "Average loss of: 1.2407190982101317e-08 for train data\n",
      "\n",
      " Epoch 292 \n",
      " --------------\n",
      "Average loss of: 1.2649126284564104e-08 for train data\n",
      "\n",
      " Epoch 293 \n",
      " --------------\n",
      "Average loss of: 1.2502652268119673e-08 for train data\n",
      "\n",
      " Epoch 294 \n",
      " --------------\n",
      "Average loss of: 1.439781003118008e-08 for train data\n",
      "\n",
      " Epoch 295 \n",
      " --------------\n",
      "Average loss of: 1.31039716273527e-08 for train data\n",
      "\n",
      " Epoch 296 \n",
      " --------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of: 1.3724014546739226e-08 for train data\n",
      "\n",
      " Epoch 297 \n",
      " --------------\n",
      "Average loss of: 1.332018992514485e-08 for train data\n",
      "\n",
      " Epoch 298 \n",
      " --------------\n",
      "Average loss of: 1.3337239808127055e-08 for train data\n",
      "\n",
      " Epoch 299 \n",
      " --------------\n",
      "Average loss of: 1.3836114518926588e-08 for train data\n",
      "\n",
      " Epoch 300 \n",
      " --------------\n",
      "Average loss of: 1.3670450469887579e-08 for train data\n",
      "\n",
      " Epoch 301 \n",
      " --------------\n",
      "Average loss of: 1.3039874953342394e-08 for train data\n",
      "\n",
      " Epoch 302 \n",
      " --------------\n",
      "Average loss of: 1.3890083014910426e-08 for train data\n",
      "\n",
      " Epoch 303 \n",
      " --------------\n",
      "Average loss of: 1.3945222462054223e-08 for train data\n",
      "\n",
      " Epoch 304 \n",
      " --------------\n",
      "Average loss of: 1.3649813705314908e-08 for train data\n",
      "\n",
      " Epoch 305 \n",
      " --------------\n",
      "Average loss of: 1.3077651562304426e-08 for train data\n",
      "\n",
      " Epoch 306 \n",
      " --------------\n",
      "Average loss of: 1.2036814478761472e-08 for train data\n",
      "\n",
      " Epoch 307 \n",
      " --------------\n",
      "Average loss of: 1.2904518034910445e-08 for train data\n",
      "\n",
      " Epoch 308 \n",
      " --------------\n",
      "Average loss of: 1.2342287132678241e-08 for train data\n",
      "\n",
      " Epoch 309 \n",
      " --------------\n",
      "Average loss of: 1.2845482821557907e-08 for train data\n",
      "\n",
      " Epoch 310 \n",
      " --------------\n",
      "Average loss of: 1.3470098520444183e-08 for train data\n",
      "\n",
      " Epoch 311 \n",
      " --------------\n",
      "Average loss of: 1.3790089929036563e-08 for train data\n",
      "\n",
      " Epoch 312 \n",
      " --------------\n",
      "Average loss of: 1.2622005711116468e-08 for train data\n",
      "\n",
      " Epoch 313 \n",
      " --------------\n",
      "Average loss of: 1.353432201242843e-08 for train data\n",
      "\n",
      " Epoch 314 \n",
      " --------------\n",
      "Average loss of: 1.2254808672278028e-08 for train data\n",
      "\n",
      " Epoch 315 \n",
      " --------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [104]\u001b[0m, in \u001b[0;36m<cell line: 28>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     39\u001b[0m train_loop(train_dataloader, model, loss_fn, optimizer)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Test on the training data\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m average_train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtest_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m train_losses\u001b[38;5;241m.\u001b[39mappend(average_train_loss)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Test on SUBSET of the training data\u001b[39;00m\n",
      "Input \u001b[1;32mIn [101]\u001b[0m, in \u001b[0;36mtest_loop\u001b[1;34m(dataloader, model, loss_fn)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m X, y \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m---> 29\u001b[0m         pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m         test_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss_fn(pred, y)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     32\u001b[0m average_test_loss \u001b[38;5;241m=\u001b[39m test_loss\u001b[38;5;241m/\u001b[39mnum_batches\n",
      "File \u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36mNeuralNetwork.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;66;03m# No flatten needed, as our input and output are 1D?\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m#x = self.flatten(x) \u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m logits\n",
      "File \u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 204\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\activation.py:294\u001b[0m, in \u001b[0;36mSigmoid.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msigmoid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Restart training by changing this parameter:\n",
    "restart = True\n",
    "abort = False\n",
    "update_lr = True\n",
    "batch_size = 32\n",
    "max_number_epochs = 400\n",
    "adaptation_threshold = 0.9995\n",
    "adaptation_multiplier = 0.9\n",
    "\n",
    "# Initialize the loss function\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Initialize lists in case we start a new training loop\n",
    "if restart:\n",
    "    confirmation = input(\"Are you sure you want to restart? Press y >> \")\n",
    "    if confirmation == \"y\":\n",
    "        test_losses = []\n",
    "        train_losses = []\n",
    "        train_losses_subset = []\n",
    "        adaptation_indices = []\n",
    "        counter = -5 # we skip the very first few iterations before changing learning rate\n",
    "    else:\n",
    "        print(\"Aborting training.\")\n",
    "        abort = True\n",
    "\n",
    "# Acutal training loop is done:\n",
    "if abort is False:\n",
    "    epoch_counter = len(train_losses) + 1\n",
    "\n",
    "    print(\"Training the model . . .\")\n",
    "    if restart is False:\n",
    "        print(\"(Continued)\")\n",
    "        \n",
    "    # Training: \n",
    "    while epoch_counter < max_number_epochs:\n",
    "        print(f\"\\n Epoch {epoch_counter} \\n --------------\")\n",
    "        # Train \n",
    "        train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "        # Test on the training data\n",
    "        average_train_loss = test_loop(train_dataloader, model, loss_fn)\n",
    "        train_losses.append(average_train_loss)\n",
    "        # Test on SUBSET of the training data\n",
    "        train_subset_dataloader = get_subset_train_dataloader(data_train)\n",
    "        average_train_loss = test_loop(train_subset_dataloader, model, loss_fn)\n",
    "        train_losses_subset.append(average_train_loss)\n",
    "        # Test on testing data\n",
    "        average_test_loss = test_loop(test_dataloader, model, loss_fn)\n",
    "        test_losses.append(average_test_loss)\n",
    "\n",
    "        # Update the learning rate - see Appendix B of the paper\n",
    "        # only check if update needed after 10 new epochs\n",
    "        if counter >= 10 and update_lr is True:\n",
    "            current = np.min(train_losses[-5:])\n",
    "            previous = np.min(train_losses[-10:-5])\n",
    "\n",
    "            # If we did not improve the test loss sufficiently, going to adapt LR\n",
    "            if current/previous >= adaptation_threshold:\n",
    "                # Reset counter (note: will increment later, so set to -1 st it becomes 0)\n",
    "                counter = -1\n",
    "                learning_rate = adaptation_multiplier*learning_rate\n",
    "                print(f\"Adapting learning rate to {learning_rate}\")\n",
    "                # Change optimizer\n",
    "                optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "                # Add the epoch time for plotting later on\n",
    "                adaptation_indices.append(epoch_counter)\n",
    "\n",
    "        # Report progress:\n",
    "#         print(f\"Average loss of: {average_test_loss} for test data\")\n",
    "        print(f\"Average loss of: {average_train_loss} for train data\")\n",
    "        \n",
    "        # Another epoch passed - increment counter\n",
    "        counter += 1\n",
    "        epoch_counter += 1\n",
    "\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84490a1",
   "metadata": {},
   "source": [
    "## Results of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9f2fef5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x1200 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot it\n",
    "plt.figure()\n",
    "lw = 1\n",
    "ms = 2\n",
    "epochs = [i for i in range(200, 200+314)]\n",
    "plt.plot(epochs, train_losses, 'o--', color = 'red', label = 'Train set', lw = lw, ms = ms)\n",
    "plt.plot(epochs, test_losses, 'o--', color = 'blue', label = \"Test set\", lw = lw, ms = ms)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel(\"Epoch\")\n",
    "# xt_step = 20\n",
    "# xt = [i*xt_step for i in range(len(train_losses)//xt_step+2)]\n",
    "# plt.xticks(xt)\n",
    "plt.ylabel(r'$L$')\n",
    "plt.axhline(0, color = 'black', alpha = 0.7)\n",
    "plt.title(\"Loss\")\n",
    "# Plot when we adapted learning rate\n",
    "for t in adaptation_indices:\n",
    "    plt.axvline(t+200, linestyle = \"--\", color = 'black', alpha = 0.5, lw = 1)\n",
    "plt.yscale('log')\n",
    "# plt.ylim(10**(-9))\n",
    "plt.savefig(\"Plots/NNEOSBv1_part2.pdf\", bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ddedbf",
   "metadata": {},
   "source": [
    "## Estimate the performance of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "901cff69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L1_norm(predictions, y):\n",
    "    \"\"\"Here, predictions and y are arrays for one specific quantity, eg pressure. See table 1\"\"\"\n",
    "    return sum(abs(predictions - y))/len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "995db234",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Linfty_norm(predictions, y):\n",
    "    \"\"\"Here, predictions and y are arrays for one specific quantity, eg pressure. See table 1\"\"\"\n",
    "    return max(abs(predictions - y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b543e0",
   "metadata": {},
   "source": [
    "Get rho, chi and kappa back out of custom dataset objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4c636bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([7.2904, 0.7552]),\n",
       " tensor([5.5853, 0.9099]),\n",
       " tensor([5.5768, 1.4810]),\n",
       " tensor([3.9533, 0.8353])]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get features and labels\n",
    "test_features = test_data.features\n",
    "test_labels = test_data.labels\n",
    "test_features[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7f4426c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    p_hat= np.array([])\n",
    "    chi_hat = np.array([])\n",
    "    kappa_hat = np.array([])\n",
    "    for input_values in test_features:\n",
    "        prediction = model(input_values)\n",
    "        \n",
    "        p_hat = np.append(p_hat, prediction[0].item())\n",
    "        chi_hat = np.append(chi_hat, prediction[1].item())\n",
    "        kappa_hat = np.append(kappa_hat, prediction[2].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "dec026d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get features as np arrays\n",
    "rho = np.array([])\n",
    "eps = np.array([])\n",
    "for value in test_features:\n",
    "    rho = np.append(rho, value[0].item())\n",
    "    eps = np.append(eps, value[1].item())\n",
    "\n",
    "\n",
    "# Get labels as np arrays\n",
    "p = np.array([])\n",
    "chi = np.array([])\n",
    "kappa = np.array([])\n",
    "for value in test_labels:\n",
    "    p = np.append(p, value[0].item())\n",
    "    chi = np.append(chi, value[1].item())\n",
    "    kappa = np.append(kappa, value[2].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d51daabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6703102588653564\n",
      "3.6704049110412598\n"
     ]
    }
   ],
   "source": [
    "print(p[0])\n",
    "print(p_hat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "54311489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the errors:\n",
    "delta_p_L1 = L1_norm(p_hat, p)\n",
    "delta_chi_L1 = L1_norm(chi_hat, chi)\n",
    "delta_kappa_L1 = L1_norm(kappa_hat, kappa)\n",
    "\n",
    "delta_p_Linfty = Linfty_norm(p_hat, p)\n",
    "delta_chi_Linfty = Linfty_norm(chi_hat, chi)\n",
    "delta_kappa_Linfty = Linfty_norm(kappa_hat, kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3ca5d3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors for p: 9.858099e-05  with L1 and 3.545761e-03 with Linfty\n",
      "Errors for chi: 6.180509e-05  with L1 and 7.337332e-04 with Linfty\n",
      "Errors for kappa: 7.404387e-05  with L1 and 9.305319e-04 with Linfty\n"
     ]
    }
   ],
   "source": [
    "print(\"Errors for p: %e  with L1 and %e with Linfty\" % (delta_p_L1, delta_p_Linfty) )\n",
    "print(\"Errors for chi: %e  with L1 and %e with Linfty\" % (delta_chi_L1, delta_chi_Linfty) )\n",
    "print(\"Errors for kappa: %e  with L1 and %e with Linfty\" % (delta_kappa_L1, delta_kappa_Linfty) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ad8552",
   "metadata": {},
   "source": [
    "## Save the neural network if desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0f463535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, 'NNEOSBv1_part2.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98d9586",
   "metadata": {},
   "source": [
    "Testing the loading of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e74a0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = torch.load('NNEOSBv0.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a961528",
   "metadata": {},
   "source": [
    "# Archive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09059b71",
   "metadata": {},
   "source": [
    "The following plots the difference between the train and test loss. However, I put it in the archive of this notebook, as the differences are usually very small and hence unimportant for practical aspects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3695326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the difference (need np.array)\n",
    "test_losses_as_array = np.array(test_losses)\n",
    "train_losses_as_array = np.array(train_losses)\n",
    "difference = test_losses_as_array - train_losses_as_array\n",
    "\n",
    "# Plot it\n",
    "plt.figure()\n",
    "plt.plot(difference[20:], 'o--', color = 'red', label = \"Difference\", lw = 1, ms = 1.5)\n",
    "plt.grid()\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(r'$L_{test} - L_{train}$')\n",
    "plt.axhline(0, color = 'black', alpha = 0.7)\n",
    "plt.title(\"Difference in losses\")\n",
    "# Plot when we adapted learning rate\n",
    "# for t in adaptation_indices:\n",
    "#     plt.axvline(t, color = 'black', alpha = 0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a60718",
   "metadata": {},
   "source": [
    "## Line search to find the optimal learning rate parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95591978",
   "metadata": {},
   "source": [
    "For now, we are __not__ using a self-adaptive algorithm, but rather, we are going to do a line search to find the optimal value for the learning rate using a log scale as recommended by the book of Goodfellow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a2ebe9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model with lr 0.001 . . .\n",
      "\n",
      " Epoch 1 \n",
      " --------------\n",
      "\n",
      " Epoch 2 \n",
      " --------------\n",
      "\n",
      " Epoch 3 \n",
      " --------------\n",
      "\n",
      " Epoch 4 \n",
      " --------------\n",
      "\n",
      " Epoch 5 \n",
      " --------------\n",
      "\n",
      " Epoch 6 \n",
      " --------------\n",
      "\n",
      " Epoch 7 \n",
      " --------------\n",
      "\n",
      " Epoch 8 \n",
      " --------------\n",
      "\n",
      " Epoch 9 \n",
      " --------------\n",
      "\n",
      " Epoch 10 \n",
      " --------------\n",
      "\n",
      " Epoch 11 \n",
      " --------------\n",
      "\n",
      " Epoch 12 \n",
      " --------------\n",
      "\n",
      " Epoch 13 \n",
      " --------------\n",
      "\n",
      " Epoch 14 \n",
      " --------------\n",
      "\n",
      " Epoch 15 \n",
      " --------------\n",
      "\n",
      " Epoch 16 \n",
      " --------------\n",
      "\n",
      " Epoch 17 \n",
      " --------------\n",
      "\n",
      " Epoch 18 \n",
      " --------------\n",
      "\n",
      " Epoch 19 \n",
      " --------------\n",
      "\n",
      " Epoch 20 \n",
      " --------------\n",
      "\n",
      " Epoch 21 \n",
      " --------------\n",
      "\n",
      " Epoch 22 \n",
      " --------------\n",
      "\n",
      " Epoch 23 \n",
      " --------------\n",
      "\n",
      " Epoch 24 \n",
      " --------------\n",
      "\n",
      " Epoch 25 \n",
      " --------------\n",
      "\n",
      " Epoch 26 \n",
      " --------------\n",
      "\n",
      " Epoch 27 \n",
      " --------------\n",
      "\n",
      " Epoch 28 \n",
      " --------------\n",
      "\n",
      " Epoch 29 \n",
      " --------------\n",
      "\n",
      " Epoch 30 \n",
      " --------------\n",
      "\n",
      " Epoch 31 \n",
      " --------------\n",
      "\n",
      " Epoch 32 \n",
      " --------------\n",
      "\n",
      " Epoch 33 \n",
      " --------------\n",
      "\n",
      " Epoch 34 \n",
      " --------------\n",
      "\n",
      " Epoch 35 \n",
      " --------------\n",
      "\n",
      " Epoch 36 \n",
      " --------------\n",
      "\n",
      " Epoch 37 \n",
      " --------------\n",
      "\n",
      " Epoch 38 \n",
      " --------------\n",
      "\n",
      " Epoch 39 \n",
      " --------------\n",
      "\n",
      " Epoch 40 \n",
      " --------------\n",
      "\n",
      " Epoch 41 \n",
      " --------------\n",
      "\n",
      " Epoch 42 \n",
      " --------------\n",
      "\n",
      " Epoch 43 \n",
      " --------------\n",
      "\n",
      " Epoch 44 \n",
      " --------------\n",
      "\n",
      " Epoch 45 \n",
      " --------------\n",
      "\n",
      " Epoch 46 \n",
      " --------------\n",
      "\n",
      " Epoch 47 \n",
      " --------------\n",
      "\n",
      " Epoch 48 \n",
      " --------------\n",
      "\n",
      " Epoch 49 \n",
      " --------------\n",
      "\n",
      " Epoch 50 \n",
      " --------------\n",
      "\n",
      " Epoch 51 \n",
      " --------------\n",
      "\n",
      " Epoch 52 \n",
      " --------------\n",
      "\n",
      " Epoch 53 \n",
      " --------------\n",
      "\n",
      " Epoch 54 \n",
      " --------------\n",
      "\n",
      " Epoch 55 \n",
      " --------------\n",
      "\n",
      " Epoch 56 \n",
      " --------------\n",
      "\n",
      " Epoch 57 \n",
      " --------------\n",
      "\n",
      " Epoch 58 \n",
      " --------------\n",
      "\n",
      " Epoch 59 \n",
      " --------------\n",
      "\n",
      " Epoch 60 \n",
      " --------------\n",
      "\n",
      " Epoch 61 \n",
      " --------------\n",
      "\n",
      " Epoch 62 \n",
      " --------------\n",
      "\n",
      " Epoch 63 \n",
      " --------------\n",
      "\n",
      " Epoch 64 \n",
      " --------------\n",
      "\n",
      " Epoch 65 \n",
      " --------------\n",
      "\n",
      " Epoch 66 \n",
      " --------------\n",
      "\n",
      " Epoch 67 \n",
      " --------------\n",
      "\n",
      " Epoch 68 \n",
      " --------------\n",
      "\n",
      " Epoch 69 \n",
      " --------------\n",
      "\n",
      " Epoch 70 \n",
      " --------------\n",
      "\n",
      " Epoch 71 \n",
      " --------------\n",
      "\n",
      " Epoch 72 \n",
      " --------------\n",
      "\n",
      " Epoch 73 \n",
      " --------------\n",
      "\n",
      " Epoch 74 \n",
      " --------------\n",
      "\n",
      " Epoch 75 \n",
      " --------------\n",
      "\n",
      " Epoch 76 \n",
      " --------------\n",
      "\n",
      " Epoch 77 \n",
      " --------------\n",
      "\n",
      " Epoch 78 \n",
      " --------------\n",
      "\n",
      " Epoch 79 \n",
      " --------------\n",
      "\n",
      " Epoch 80 \n",
      " --------------\n",
      "\n",
      " Epoch 81 \n",
      " --------------\n",
      "\n",
      " Epoch 82 \n",
      " --------------\n",
      "\n",
      " Epoch 83 \n",
      " --------------\n",
      "\n",
      " Epoch 84 \n",
      " --------------\n",
      "\n",
      " Epoch 85 \n",
      " --------------\n",
      "\n",
      " Epoch 86 \n",
      " --------------\n",
      "\n",
      " Epoch 87 \n",
      " --------------\n",
      "\n",
      " Epoch 88 \n",
      " --------------\n",
      "\n",
      " Epoch 89 \n",
      " --------------\n",
      "\n",
      " Epoch 90 \n",
      " --------------\n",
      "\n",
      " Epoch 91 \n",
      " --------------\n",
      "\n",
      " Epoch 92 \n",
      " --------------\n",
      "\n",
      " Epoch 93 \n",
      " --------------\n",
      "\n",
      " Epoch 94 \n",
      " --------------\n",
      "\n",
      " Epoch 95 \n",
      " --------------\n",
      "\n",
      " Epoch 96 \n",
      " --------------\n",
      "\n",
      " Epoch 97 \n",
      " --------------\n",
      "\n",
      " Epoch 98 \n",
      " --------------\n",
      "\n",
      " Epoch 99 \n",
      " --------------\n",
      "\n",
      " Epoch 100 \n",
      " --------------\n",
      "Finished a run\n",
      "Done!\n",
      "Training the model with lr 0.0001 . . .\n",
      "\n",
      " Epoch 1 \n",
      " --------------\n",
      "\n",
      " Epoch 2 \n",
      " --------------\n",
      "\n",
      " Epoch 3 \n",
      " --------------\n",
      "\n",
      " Epoch 4 \n",
      " --------------\n",
      "\n",
      " Epoch 5 \n",
      " --------------\n",
      "\n",
      " Epoch 6 \n",
      " --------------\n",
      "\n",
      " Epoch 7 \n",
      " --------------\n",
      "\n",
      " Epoch 8 \n",
      " --------------\n",
      "\n",
      " Epoch 9 \n",
      " --------------\n",
      "\n",
      " Epoch 10 \n",
      " --------------\n",
      "\n",
      " Epoch 11 \n",
      " --------------\n",
      "\n",
      " Epoch 12 \n",
      " --------------\n",
      "\n",
      " Epoch 13 \n",
      " --------------\n",
      "\n",
      " Epoch 14 \n",
      " --------------\n",
      "\n",
      " Epoch 15 \n",
      " --------------\n",
      "\n",
      " Epoch 16 \n",
      " --------------\n",
      "\n",
      " Epoch 17 \n",
      " --------------\n",
      "\n",
      " Epoch 18 \n",
      " --------------\n",
      "\n",
      " Epoch 19 \n",
      " --------------\n",
      "\n",
      " Epoch 20 \n",
      " --------------\n",
      "\n",
      " Epoch 21 \n",
      " --------------\n",
      "\n",
      " Epoch 22 \n",
      " --------------\n",
      "\n",
      " Epoch 23 \n",
      " --------------\n",
      "\n",
      " Epoch 24 \n",
      " --------------\n",
      "\n",
      " Epoch 25 \n",
      " --------------\n",
      "\n",
      " Epoch 26 \n",
      " --------------\n",
      "\n",
      " Epoch 27 \n",
      " --------------\n",
      "\n",
      " Epoch 28 \n",
      " --------------\n",
      "\n",
      " Epoch 29 \n",
      " --------------\n",
      "\n",
      " Epoch 30 \n",
      " --------------\n",
      "\n",
      " Epoch 31 \n",
      " --------------\n",
      "\n",
      " Epoch 32 \n",
      " --------------\n",
      "\n",
      " Epoch 33 \n",
      " --------------\n",
      "\n",
      " Epoch 34 \n",
      " --------------\n",
      "\n",
      " Epoch 35 \n",
      " --------------\n",
      "\n",
      " Epoch 36 \n",
      " --------------\n",
      "\n",
      " Epoch 37 \n",
      " --------------\n",
      "\n",
      " Epoch 38 \n",
      " --------------\n",
      "\n",
      " Epoch 39 \n",
      " --------------\n",
      "\n",
      " Epoch 40 \n",
      " --------------\n",
      "\n",
      " Epoch 41 \n",
      " --------------\n",
      "\n",
      " Epoch 42 \n",
      " --------------\n",
      "\n",
      " Epoch 43 \n",
      " --------------\n",
      "\n",
      " Epoch 44 \n",
      " --------------\n",
      "\n",
      " Epoch 45 \n",
      " --------------\n",
      "\n",
      " Epoch 46 \n",
      " --------------\n",
      "\n",
      " Epoch 47 \n",
      " --------------\n",
      "\n",
      " Epoch 48 \n",
      " --------------\n",
      "\n",
      " Epoch 49 \n",
      " --------------\n",
      "\n",
      " Epoch 50 \n",
      " --------------\n",
      "\n",
      " Epoch 51 \n",
      " --------------\n",
      "\n",
      " Epoch 52 \n",
      " --------------\n",
      "\n",
      " Epoch 53 \n",
      " --------------\n",
      "\n",
      " Epoch 54 \n",
      " --------------\n",
      "\n",
      " Epoch 55 \n",
      " --------------\n",
      "\n",
      " Epoch 56 \n",
      " --------------\n",
      "\n",
      " Epoch 57 \n",
      " --------------\n",
      "\n",
      " Epoch 58 \n",
      " --------------\n",
      "\n",
      " Epoch 59 \n",
      " --------------\n",
      "\n",
      " Epoch 60 \n",
      " --------------\n",
      "\n",
      " Epoch 61 \n",
      " --------------\n",
      "\n",
      " Epoch 62 \n",
      " --------------\n",
      "\n",
      " Epoch 63 \n",
      " --------------\n",
      "\n",
      " Epoch 64 \n",
      " --------------\n",
      "\n",
      " Epoch 65 \n",
      " --------------\n",
      "\n",
      " Epoch 66 \n",
      " --------------\n",
      "\n",
      " Epoch 67 \n",
      " --------------\n",
      "\n",
      " Epoch 68 \n",
      " --------------\n",
      "\n",
      " Epoch 69 \n",
      " --------------\n",
      "\n",
      " Epoch 70 \n",
      " --------------\n",
      "\n",
      " Epoch 71 \n",
      " --------------\n",
      "\n",
      " Epoch 72 \n",
      " --------------\n",
      "\n",
      " Epoch 73 \n",
      " --------------\n",
      "\n",
      " Epoch 74 \n",
      " --------------\n",
      "\n",
      " Epoch 75 \n",
      " --------------\n",
      "\n",
      " Epoch 76 \n",
      " --------------\n",
      "\n",
      " Epoch 77 \n",
      " --------------\n",
      "\n",
      " Epoch 78 \n",
      " --------------\n",
      "\n",
      " Epoch 79 \n",
      " --------------\n",
      "\n",
      " Epoch 80 \n",
      " --------------\n",
      "\n",
      " Epoch 81 \n",
      " --------------\n",
      "\n",
      " Epoch 82 \n",
      " --------------\n",
      "\n",
      " Epoch 83 \n",
      " --------------\n",
      "\n",
      " Epoch 84 \n",
      " --------------\n",
      "\n",
      " Epoch 85 \n",
      " --------------\n",
      "\n",
      " Epoch 86 \n",
      " --------------\n",
      "\n",
      " Epoch 87 \n",
      " --------------\n",
      "\n",
      " Epoch 88 \n",
      " --------------\n",
      "\n",
      " Epoch 89 \n",
      " --------------\n",
      "\n",
      " Epoch 90 \n",
      " --------------\n",
      "\n",
      " Epoch 91 \n",
      " --------------\n",
      "\n",
      " Epoch 92 \n",
      " --------------\n",
      "\n",
      " Epoch 93 \n",
      " --------------\n",
      "\n",
      " Epoch 94 \n",
      " --------------\n",
      "\n",
      " Epoch 95 \n",
      " --------------\n",
      "\n",
      " Epoch 96 \n",
      " --------------\n",
      "\n",
      " Epoch 97 \n",
      " --------------\n",
      "\n",
      " Epoch 98 \n",
      " --------------\n",
      "\n",
      " Epoch 99 \n",
      " --------------\n",
      "\n",
      " Epoch 100 \n",
      " --------------\n",
      "Finished a run\n",
      "Done!\n",
      "Training the model with lr 1e-05 . . .\n",
      "\n",
      " Epoch 1 \n",
      " --------------\n",
      "\n",
      " Epoch 2 \n",
      " --------------\n",
      "\n",
      " Epoch 3 \n",
      " --------------\n",
      "\n",
      " Epoch 4 \n",
      " --------------\n",
      "\n",
      " Epoch 5 \n",
      " --------------\n",
      "\n",
      " Epoch 6 \n",
      " --------------\n",
      "\n",
      " Epoch 7 \n",
      " --------------\n",
      "\n",
      " Epoch 8 \n",
      " --------------\n",
      "\n",
      " Epoch 9 \n",
      " --------------\n",
      "\n",
      " Epoch 10 \n",
      " --------------\n",
      "\n",
      " Epoch 11 \n",
      " --------------\n",
      "\n",
      " Epoch 12 \n",
      " --------------\n",
      "\n",
      " Epoch 13 \n",
      " --------------\n",
      "\n",
      " Epoch 14 \n",
      " --------------\n",
      "\n",
      " Epoch 15 \n",
      " --------------\n",
      "\n",
      " Epoch 16 \n",
      " --------------\n",
      "\n",
      " Epoch 17 \n",
      " --------------\n",
      "\n",
      " Epoch 18 \n",
      " --------------\n",
      "\n",
      " Epoch 19 \n",
      " --------------\n",
      "\n",
      " Epoch 20 \n",
      " --------------\n",
      "\n",
      " Epoch 21 \n",
      " --------------\n",
      "\n",
      " Epoch 22 \n",
      " --------------\n",
      "\n",
      " Epoch 23 \n",
      " --------------\n",
      "\n",
      " Epoch 24 \n",
      " --------------\n",
      "\n",
      " Epoch 25 \n",
      " --------------\n",
      "\n",
      " Epoch 26 \n",
      " --------------\n",
      "\n",
      " Epoch 27 \n",
      " --------------\n",
      "\n",
      " Epoch 28 \n",
      " --------------\n",
      "\n",
      " Epoch 29 \n",
      " --------------\n",
      "\n",
      " Epoch 30 \n",
      " --------------\n",
      "\n",
      " Epoch 31 \n",
      " --------------\n",
      "\n",
      " Epoch 32 \n",
      " --------------\n",
      "\n",
      " Epoch 33 \n",
      " --------------\n",
      "\n",
      " Epoch 34 \n",
      " --------------\n",
      "\n",
      " Epoch 35 \n",
      " --------------\n",
      "\n",
      " Epoch 36 \n",
      " --------------\n",
      "\n",
      " Epoch 37 \n",
      " --------------\n",
      "\n",
      " Epoch 38 \n",
      " --------------\n",
      "\n",
      " Epoch 39 \n",
      " --------------\n",
      "\n",
      " Epoch 40 \n",
      " --------------\n",
      "\n",
      " Epoch 41 \n",
      " --------------\n",
      "\n",
      " Epoch 42 \n",
      " --------------\n",
      "\n",
      " Epoch 43 \n",
      " --------------\n",
      "\n",
      " Epoch 44 \n",
      " --------------\n",
      "\n",
      " Epoch 45 \n",
      " --------------\n",
      "\n",
      " Epoch 46 \n",
      " --------------\n",
      "\n",
      " Epoch 47 \n",
      " --------------\n",
      "\n",
      " Epoch 48 \n",
      " --------------\n",
      "\n",
      " Epoch 49 \n",
      " --------------\n",
      "\n",
      " Epoch 50 \n",
      " --------------\n",
      "\n",
      " Epoch 51 \n",
      " --------------\n",
      "\n",
      " Epoch 52 \n",
      " --------------\n",
      "\n",
      " Epoch 53 \n",
      " --------------\n",
      "\n",
      " Epoch 54 \n",
      " --------------\n",
      "\n",
      " Epoch 55 \n",
      " --------------\n",
      "\n",
      " Epoch 56 \n",
      " --------------\n",
      "\n",
      " Epoch 57 \n",
      " --------------\n",
      "\n",
      " Epoch 58 \n",
      " --------------\n",
      "\n",
      " Epoch 59 \n",
      " --------------\n",
      "\n",
      " Epoch 60 \n",
      " --------------\n",
      "\n",
      " Epoch 61 \n",
      " --------------\n",
      "\n",
      " Epoch 62 \n",
      " --------------\n",
      "\n",
      " Epoch 63 \n",
      " --------------\n",
      "\n",
      " Epoch 64 \n",
      " --------------\n",
      "\n",
      " Epoch 65 \n",
      " --------------\n",
      "\n",
      " Epoch 66 \n",
      " --------------\n",
      "\n",
      " Epoch 67 \n",
      " --------------\n",
      "\n",
      " Epoch 68 \n",
      " --------------\n",
      "\n",
      " Epoch 69 \n",
      " --------------\n",
      "\n",
      " Epoch 70 \n",
      " --------------\n",
      "\n",
      " Epoch 71 \n",
      " --------------\n",
      "\n",
      " Epoch 72 \n",
      " --------------\n",
      "\n",
      " Epoch 73 \n",
      " --------------\n",
      "\n",
      " Epoch 74 \n",
      " --------------\n",
      "\n",
      " Epoch 75 \n",
      " --------------\n",
      "\n",
      " Epoch 76 \n",
      " --------------\n",
      "\n",
      " Epoch 77 \n",
      " --------------\n",
      "\n",
      " Epoch 78 \n",
      " --------------\n",
      "\n",
      " Epoch 79 \n",
      " --------------\n",
      "\n",
      " Epoch 80 \n",
      " --------------\n",
      "\n",
      " Epoch 81 \n",
      " --------------\n",
      "\n",
      " Epoch 82 \n",
      " --------------\n",
      "\n",
      " Epoch 83 \n",
      " --------------\n",
      "\n",
      " Epoch 84 \n",
      " --------------\n",
      "\n",
      " Epoch 85 \n",
      " --------------\n",
      "\n",
      " Epoch 86 \n",
      " --------------\n",
      "\n",
      " Epoch 87 \n",
      " --------------\n",
      "\n",
      " Epoch 88 \n",
      " --------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 89 \n",
      " --------------\n",
      "\n",
      " Epoch 90 \n",
      " --------------\n",
      "\n",
      " Epoch 91 \n",
      " --------------\n",
      "\n",
      " Epoch 92 \n",
      " --------------\n",
      "\n",
      " Epoch 93 \n",
      " --------------\n",
      "\n",
      " Epoch 94 \n",
      " --------------\n",
      "\n",
      " Epoch 95 \n",
      " --------------\n",
      "\n",
      " Epoch 96 \n",
      " --------------\n",
      "\n",
      " Epoch 97 \n",
      " --------------\n",
      "\n",
      " Epoch 98 \n",
      " --------------\n",
      "\n",
      " Epoch 99 \n",
      " --------------\n",
      "\n",
      " Epoch 100 \n",
      " --------------\n",
      "Finished a run\n",
      "Done!\n",
      "Training the model with lr 1e-06 . . .\n",
      "\n",
      " Epoch 1 \n",
      " --------------\n",
      "\n",
      " Epoch 2 \n",
      " --------------\n",
      "\n",
      " Epoch 3 \n",
      " --------------\n",
      "\n",
      " Epoch 4 \n",
      " --------------\n",
      "\n",
      " Epoch 5 \n",
      " --------------\n",
      "\n",
      " Epoch 6 \n",
      " --------------\n",
      "\n",
      " Epoch 7 \n",
      " --------------\n",
      "\n",
      " Epoch 8 \n",
      " --------------\n",
      "\n",
      " Epoch 9 \n",
      " --------------\n",
      "\n",
      " Epoch 10 \n",
      " --------------\n",
      "\n",
      " Epoch 11 \n",
      " --------------\n",
      "\n",
      " Epoch 12 \n",
      " --------------\n",
      "\n",
      " Epoch 13 \n",
      " --------------\n",
      "\n",
      " Epoch 14 \n",
      " --------------\n",
      "\n",
      " Epoch 15 \n",
      " --------------\n",
      "\n",
      " Epoch 16 \n",
      " --------------\n",
      "\n",
      " Epoch 17 \n",
      " --------------\n",
      "\n",
      " Epoch 18 \n",
      " --------------\n",
      "\n",
      " Epoch 19 \n",
      " --------------\n",
      "\n",
      " Epoch 20 \n",
      " --------------\n",
      "\n",
      " Epoch 21 \n",
      " --------------\n",
      "\n",
      " Epoch 22 \n",
      " --------------\n",
      "\n",
      " Epoch 23 \n",
      " --------------\n",
      "\n",
      " Epoch 24 \n",
      " --------------\n",
      "\n",
      " Epoch 25 \n",
      " --------------\n",
      "\n",
      " Epoch 26 \n",
      " --------------\n",
      "\n",
      " Epoch 27 \n",
      " --------------\n",
      "\n",
      " Epoch 28 \n",
      " --------------\n",
      "\n",
      " Epoch 29 \n",
      " --------------\n",
      "\n",
      " Epoch 30 \n",
      " --------------\n",
      "\n",
      " Epoch 31 \n",
      " --------------\n",
      "\n",
      " Epoch 32 \n",
      " --------------\n",
      "\n",
      " Epoch 33 \n",
      " --------------\n",
      "\n",
      " Epoch 34 \n",
      " --------------\n",
      "\n",
      " Epoch 35 \n",
      " --------------\n",
      "\n",
      " Epoch 36 \n",
      " --------------\n",
      "\n",
      " Epoch 37 \n",
      " --------------\n",
      "\n",
      " Epoch 38 \n",
      " --------------\n",
      "\n",
      " Epoch 39 \n",
      " --------------\n",
      "\n",
      " Epoch 40 \n",
      " --------------\n",
      "\n",
      " Epoch 41 \n",
      " --------------\n",
      "\n",
      " Epoch 42 \n",
      " --------------\n",
      "\n",
      " Epoch 43 \n",
      " --------------\n",
      "\n",
      " Epoch 44 \n",
      " --------------\n",
      "\n",
      " Epoch 45 \n",
      " --------------\n",
      "\n",
      " Epoch 46 \n",
      " --------------\n",
      "\n",
      " Epoch 47 \n",
      " --------------\n",
      "\n",
      " Epoch 48 \n",
      " --------------\n",
      "\n",
      " Epoch 49 \n",
      " --------------\n",
      "\n",
      " Epoch 50 \n",
      " --------------\n",
      "\n",
      " Epoch 51 \n",
      " --------------\n",
      "\n",
      " Epoch 52 \n",
      " --------------\n",
      "\n",
      " Epoch 53 \n",
      " --------------\n",
      "\n",
      " Epoch 54 \n",
      " --------------\n",
      "\n",
      " Epoch 55 \n",
      " --------------\n",
      "\n",
      " Epoch 56 \n",
      " --------------\n",
      "\n",
      " Epoch 57 \n",
      " --------------\n",
      "\n",
      " Epoch 58 \n",
      " --------------\n",
      "\n",
      " Epoch 59 \n",
      " --------------\n",
      "\n",
      " Epoch 60 \n",
      " --------------\n",
      "\n",
      " Epoch 61 \n",
      " --------------\n",
      "\n",
      " Epoch 62 \n",
      " --------------\n",
      "\n",
      " Epoch 63 \n",
      " --------------\n",
      "\n",
      " Epoch 64 \n",
      " --------------\n",
      "\n",
      " Epoch 65 \n",
      " --------------\n",
      "\n",
      " Epoch 66 \n",
      " --------------\n",
      "\n",
      " Epoch 67 \n",
      " --------------\n",
      "\n",
      " Epoch 68 \n",
      " --------------\n",
      "\n",
      " Epoch 69 \n",
      " --------------\n",
      "\n",
      " Epoch 70 \n",
      " --------------\n",
      "\n",
      " Epoch 71 \n",
      " --------------\n",
      "\n",
      " Epoch 72 \n",
      " --------------\n",
      "\n",
      " Epoch 73 \n",
      " --------------\n",
      "\n",
      " Epoch 74 \n",
      " --------------\n",
      "\n",
      " Epoch 75 \n",
      " --------------\n",
      "\n",
      " Epoch 76 \n",
      " --------------\n",
      "\n",
      " Epoch 77 \n",
      " --------------\n",
      "\n",
      " Epoch 78 \n",
      " --------------\n",
      "\n",
      " Epoch 79 \n",
      " --------------\n",
      "\n",
      " Epoch 80 \n",
      " --------------\n",
      "\n",
      " Epoch 81 \n",
      " --------------\n",
      "\n",
      " Epoch 82 \n",
      " --------------\n",
      "\n",
      " Epoch 83 \n",
      " --------------\n",
      "\n",
      " Epoch 84 \n",
      " --------------\n",
      "\n",
      " Epoch 85 \n",
      " --------------\n",
      "\n",
      " Epoch 86 \n",
      " --------------\n",
      "\n",
      " Epoch 87 \n",
      " --------------\n",
      "\n",
      " Epoch 88 \n",
      " --------------\n",
      "\n",
      " Epoch 89 \n",
      " --------------\n",
      "\n",
      " Epoch 90 \n",
      " --------------\n",
      "\n",
      " Epoch 91 \n",
      " --------------\n",
      "\n",
      " Epoch 92 \n",
      " --------------\n",
      "\n",
      " Epoch 93 \n",
      " --------------\n",
      "\n",
      " Epoch 94 \n",
      " --------------\n",
      "\n",
      " Epoch 95 \n",
      " --------------\n",
      "\n",
      " Epoch 96 \n",
      " --------------\n",
      "\n",
      " Epoch 97 \n",
      " --------------\n",
      "\n",
      " Epoch 98 \n",
      " --------------\n",
      "\n",
      " Epoch 99 \n",
      " --------------\n",
      "\n",
      " Epoch 100 \n",
      " --------------\n",
      "Finished a run\n",
      "Done!\n",
      "Training the model with lr 1e-07 . . .\n",
      "\n",
      " Epoch 1 \n",
      " --------------\n",
      "\n",
      " Epoch 2 \n",
      " --------------\n",
      "\n",
      " Epoch 3 \n",
      " --------------\n",
      "\n",
      " Epoch 4 \n",
      " --------------\n",
      "\n",
      " Epoch 5 \n",
      " --------------\n",
      "\n",
      " Epoch 6 \n",
      " --------------\n",
      "\n",
      " Epoch 7 \n",
      " --------------\n",
      "\n",
      " Epoch 8 \n",
      " --------------\n",
      "\n",
      " Epoch 9 \n",
      " --------------\n",
      "\n",
      " Epoch 10 \n",
      " --------------\n",
      "\n",
      " Epoch 11 \n",
      " --------------\n",
      "\n",
      " Epoch 12 \n",
      " --------------\n",
      "\n",
      " Epoch 13 \n",
      " --------------\n",
      "\n",
      " Epoch 14 \n",
      " --------------\n",
      "\n",
      " Epoch 15 \n",
      " --------------\n",
      "\n",
      " Epoch 16 \n",
      " --------------\n",
      "\n",
      " Epoch 17 \n",
      " --------------\n",
      "\n",
      " Epoch 18 \n",
      " --------------\n",
      "\n",
      " Epoch 19 \n",
      " --------------\n",
      "\n",
      " Epoch 20 \n",
      " --------------\n",
      "\n",
      " Epoch 21 \n",
      " --------------\n",
      "\n",
      " Epoch 22 \n",
      " --------------\n",
      "\n",
      " Epoch 23 \n",
      " --------------\n",
      "\n",
      " Epoch 24 \n",
      " --------------\n",
      "\n",
      " Epoch 25 \n",
      " --------------\n",
      "\n",
      " Epoch 26 \n",
      " --------------\n",
      "\n",
      " Epoch 27 \n",
      " --------------\n",
      "\n",
      " Epoch 28 \n",
      " --------------\n",
      "\n",
      " Epoch 29 \n",
      " --------------\n",
      "\n",
      " Epoch 30 \n",
      " --------------\n",
      "\n",
      " Epoch 31 \n",
      " --------------\n",
      "\n",
      " Epoch 32 \n",
      " --------------\n",
      "\n",
      " Epoch 33 \n",
      " --------------\n",
      "\n",
      " Epoch 34 \n",
      " --------------\n",
      "\n",
      " Epoch 35 \n",
      " --------------\n",
      "\n",
      " Epoch 36 \n",
      " --------------\n",
      "\n",
      " Epoch 37 \n",
      " --------------\n",
      "\n",
      " Epoch 38 \n",
      " --------------\n",
      "\n",
      " Epoch 39 \n",
      " --------------\n",
      "\n",
      " Epoch 40 \n",
      " --------------\n",
      "\n",
      " Epoch 41 \n",
      " --------------\n",
      "\n",
      " Epoch 42 \n",
      " --------------\n",
      "\n",
      " Epoch 43 \n",
      " --------------\n",
      "\n",
      " Epoch 44 \n",
      " --------------\n",
      "\n",
      " Epoch 45 \n",
      " --------------\n",
      "\n",
      " Epoch 46 \n",
      " --------------\n",
      "\n",
      " Epoch 47 \n",
      " --------------\n",
      "\n",
      " Epoch 48 \n",
      " --------------\n",
      "\n",
      " Epoch 49 \n",
      " --------------\n",
      "\n",
      " Epoch 50 \n",
      " --------------\n",
      "\n",
      " Epoch 51 \n",
      " --------------\n",
      "\n",
      " Epoch 52 \n",
      " --------------\n",
      "\n",
      " Epoch 53 \n",
      " --------------\n",
      "\n",
      " Epoch 54 \n",
      " --------------\n",
      "\n",
      " Epoch 55 \n",
      " --------------\n",
      "\n",
      " Epoch 56 \n",
      " --------------\n",
      "\n",
      " Epoch 57 \n",
      " --------------\n",
      "\n",
      " Epoch 58 \n",
      " --------------\n",
      "\n",
      " Epoch 59 \n",
      " --------------\n",
      "\n",
      " Epoch 60 \n",
      " --------------\n",
      "\n",
      " Epoch 61 \n",
      " --------------\n",
      "\n",
      " Epoch 62 \n",
      " --------------\n",
      "\n",
      " Epoch 63 \n",
      " --------------\n",
      "\n",
      " Epoch 64 \n",
      " --------------\n",
      "\n",
      " Epoch 65 \n",
      " --------------\n",
      "\n",
      " Epoch 66 \n",
      " --------------\n",
      "\n",
      " Epoch 67 \n",
      " --------------\n",
      "\n",
      " Epoch 68 \n",
      " --------------\n",
      "\n",
      " Epoch 69 \n",
      " --------------\n",
      "\n",
      " Epoch 70 \n",
      " --------------\n",
      "\n",
      " Epoch 71 \n",
      " --------------\n",
      "\n",
      " Epoch 72 \n",
      " --------------\n",
      "\n",
      " Epoch 73 \n",
      " --------------\n",
      "\n",
      " Epoch 74 \n",
      " --------------\n",
      "\n",
      " Epoch 75 \n",
      " --------------\n",
      "\n",
      " Epoch 76 \n",
      " --------------\n",
      "\n",
      " Epoch 77 \n",
      " --------------\n",
      "\n",
      " Epoch 78 \n",
      " --------------\n",
      "\n",
      " Epoch 79 \n",
      " --------------\n",
      "\n",
      " Epoch 80 \n",
      " --------------\n",
      "\n",
      " Epoch 81 \n",
      " --------------\n",
      "\n",
      " Epoch 82 \n",
      " --------------\n",
      "\n",
      " Epoch 83 \n",
      " --------------\n",
      "\n",
      " Epoch 84 \n",
      " --------------\n",
      "\n",
      " Epoch 85 \n",
      " --------------\n",
      "\n",
      " Epoch 86 \n",
      " --------------\n",
      "\n",
      " Epoch 87 \n",
      " --------------\n",
      "\n",
      " Epoch 88 \n",
      " --------------\n",
      "\n",
      " Epoch 89 \n",
      " --------------\n",
      "\n",
      " Epoch 90 \n",
      " --------------\n",
      "\n",
      " Epoch 91 \n",
      " --------------\n",
      "\n",
      " Epoch 92 \n",
      " --------------\n",
      "\n",
      " Epoch 93 \n",
      " --------------\n",
      "\n",
      " Epoch 94 \n",
      " --------------\n",
      "\n",
      " Epoch 95 \n",
      " --------------\n",
      "\n",
      " Epoch 96 \n",
      " --------------\n",
      "\n",
      " Epoch 97 \n",
      " --------------\n",
      "\n",
      " Epoch 98 \n",
      " --------------\n",
      "\n",
      " Epoch 99 \n",
      " --------------\n",
      "\n",
      " Epoch 100 \n",
      " --------------\n",
      "Finished a run\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "lr_list = [10**(-3), 10**(-4), 10**(-5), 10**(-6), 10**(-7)]\n",
    "all_train_losses = []\n",
    "all_test_losses = []\n",
    "\n",
    "# Hyperparameters:\n",
    "batch_size = 32\n",
    "max_number_epochs = 100\n",
    "\n",
    "for learning_rate in lr_list:\n",
    "    ## Do a run: for one single learning rate\n",
    "    \n",
    "    # Make a new model, empty train and test loss arrays again\n",
    "    model = NeuralNetwork().to(device)\n",
    "    test_losses = []\n",
    "    train_losses = []\n",
    "    \n",
    "    # Initialize the loss function\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # ----- Train the model -----\n",
    "    print(f\"Training the model with lr {learning_rate} . . .\")\n",
    "    for t in range(max_number_epochs):\n",
    "        print(f\"\\n Epoch {t+1} \\n --------------\")\n",
    "        # Train \n",
    "        train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "        # Test on the training data\n",
    "        average_train_loss = test_loop(train_dataloader, model, loss_fn)\n",
    "        train_losses.append(average_train_loss)\n",
    "        # Test on testing data\n",
    "        average_test_loss = test_loop(test_dataloader, model, loss_fn)\n",
    "        test_losses.append(average_test_loss)\n",
    "        \n",
    "    # ----- Train the model -----\n",
    "    print('Finished a run')\n",
    "    all_test_losses.append(test_losses)\n",
    "    all_train_losses.append(train_losses)\n",
    "\n",
    "    print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "author": "Thibeau Wouters",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
