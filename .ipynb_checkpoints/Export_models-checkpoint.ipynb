{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af563537",
   "metadata": {},
   "source": [
    "%%latex\n",
    "\\tableofcontents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bb9f224",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "import random\n",
    "import csv\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.cm as cm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcceeebc",
   "metadata": {},
   "source": [
    "# Export the NNC2P model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d04d5a",
   "metadata": {},
   "source": [
    "This is the model architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40ee3cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters of the model here. Will first of all put two hidden layers\n",
    "# total of 800 neurons for the one in the paper\n",
    "device = \"cpu\"\n",
    "size_HL_1 = 600\n",
    "size_HL_2 = 200\n",
    "\n",
    "# Implement neural network\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        #self.flatten = nn.Flatten()\n",
    "        self.stack = nn.Sequential(\n",
    "            nn.Linear(3, size_HL_1),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(size_HL_1, size_HL_2),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(size_HL_2, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # No flatten needed, as our input and output are 1D?\n",
    "        #x = self.flatten(x) \n",
    "        logits = self.stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9071780a",
   "metadata": {},
   "source": [
    "We import NNC2Pv0, which was on par with the models in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e1c29f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "NNC2P = torch.load('Models/NNC2Pv0t2.pth')\n",
    "model = NNC2P"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2c9074",
   "metadata": {},
   "source": [
    "In case we want to view the variables, uncomment the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05d1fee6-36b8-4ef9-a84d-cec0dcc9456c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NNC2P.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fcb86b-ad79-4733-8911-d26de50082b3",
   "metadata": {},
   "source": [
    "## Save the matrices as a CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad316e9b",
   "metadata": {},
   "source": [
    "Note that converting from Torch tensor to Numpy array does __not__ cause loss of information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b75e32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.3647063672542572021484375\n",
      "---\n",
      "-0.3647063672542572021484375\n"
     ]
    }
   ],
   "source": [
    "test_exact = NNC2P.state_dict()[\"stack.0.weight\"]\n",
    "test_exact_value = test_exact[0][0].item()\n",
    "print('%.25f' % test_exact_value)\n",
    "print(\"---\")\n",
    "test_exact_np = test_exact.numpy()\n",
    "test_exact_value_np = test_exact_np[0][0]\n",
    "print('%.25f' % test_exact_value_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80676c3",
   "metadata": {},
   "source": [
    "### Saving and loading as CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba9ed1f",
   "metadata": {},
   "source": [
    "Save the values: ([refresher on Pickle](https://tech.qvread.com/python/python-list-read-write-csv/))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f210e996-8996-4aef-a7e4-e759f410fcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# State dict contains all the variables\n",
    "state_dict = NNC2P.state_dict().items()\n",
    "# Names to save the files:\n",
    "file_names            = [\"weight0\", \"bias0\", \"weight2\", \"bias2\", \"weight4\", \"bias4\"]\n",
    "save_names         = [\"Models/paramvals/\" + name + \".csv\" for name in file_names]\n",
    "flat_save_names = [\"Models/paramvals/\" + name + \"_flat.csv\" for name in file_names]\n",
    "no_comma_flat_save_names = [\"Models/paramvals/\" + name + \"_flat_no_comma.csv\" for name in file_names]\n",
    "\n",
    "# Save each one:\n",
    "counter = 0\n",
    "for param_name, item in state_dict:\n",
    "    # Get appropriate names\n",
    "    name                   = file_names[counter]\n",
    "    save_name         = save_names[counter]\n",
    "    flat_save_name = flat_save_names[counter]\n",
    "    no_comma_flat_save_name = no_comma_flat_save_names[counter]\n",
    "    # Get the matrix and flatten it as well\n",
    "    matrix_np   = item.numpy() \n",
    "    flat_matrix_np   = matrix_np.flatten()\n",
    "    # The following save txt is only important for stuff done within this noteboo!\n",
    "    np.savetxt(no_comma_flat_save_name, flat_matrix_np, delimiter=\",\", fmt=\"%0.35f\")\n",
    "    \n",
    "    np.savetxt(save_name, matrix_np, delimiter=\",\", fmt=\"%0.35f\")\n",
    "    # Note: due to weird Fortran stuff, have to append a 0 at the start of the file\n",
    "    flat_matrix_np   = np.insert(flat_matrix_np, 0, 0)\n",
    "    np.savetxt(flat_save_name, flat_matrix_np, delimiter=\",\", newline=',\\n', fmt=\"%0.35f\")\n",
    "    \n",
    "    \n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88386f6f-a165-4d9a-9c2d-4c14fccbfe72",
   "metadata": {},
   "source": [
    "Read the files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9180ced9",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight0 = np.loadtxt('Models/paramvals/weight0.csv', delimiter=\",\")\n",
    "bias0      = np.loadtxt('Models/paramvals/bias0.csv', delimiter=\",\")\n",
    "s = np.shape(bias0)[0]\n",
    "bias0 = np.reshape(bias0, (s, 1))\n",
    "weight2 = np.loadtxt('Models/paramvals/weight2.csv', delimiter=\",\")\n",
    "bias2      = np.loadtxt('Models/paramvals/bias2.csv', delimiter=\",\")\n",
    "s = np.shape(bias2)[0]\n",
    "bias2 = np.reshape(bias2, (s, 1))\n",
    "weight4 = np.loadtxt('Models/paramvals/weight4.csv', delimiter=\",\")\n",
    "s = np.shape(weight4)[0]\n",
    "weight4 = np.reshape(weight4, (1, s))\n",
    "bias4      = np.loadtxt('Models/paramvals/bias4.csv', delimiter=\",\")\n",
    "bias4 = np.reshape(bias4, (1, 1))\n",
    "\n",
    "weights_and_biases = [weight0, bias0, weight2, bias2, weight4, bias4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088e1425",
   "metadata": {},
   "source": [
    "Same for flat: __NOTE__ for numpy (here), we load \"no_comma\" files since otherwise there's an error. For Fortran, we use the files __WITHOUT__ \"no comma\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a79742bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight0_flat = np.loadtxt('Models/paramvals/weight0_flat_no_comma.csv', delimiter=\",\")\n",
    "# bias0_flat      = np.loadtxt('Models/paramvals/bias0_flat_no_comma.csv', delimiter=\",\")\n",
    "# weight2_flat = np.loadtxt('Models/paramvals/weight2_flat_no_comma.csv', delimiter=\",\")\n",
    "# bias2_flat      = np.loadtxt('Models/paramvals/bias2_flat_no_comma.csv', delimiter=\",\")\n",
    "# weight4_flat = np.loadtxt('Models/paramvals/weight4_flat_no_comma.csv', delimiter=\",\")\n",
    "# bias4_flat      = np.loadtxt('Models/paramvals/bias4_flat_no_comma.csv', delimiter=\",\")\n",
    "\n",
    "# weights_and_biases_flat = [weight0_flat, bias0_flat, weight2_flat, bias2_flat, weight4_flat, bias4_flat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a2157cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.3647063672542572021484375\n"
     ]
    }
   ],
   "source": [
    "print('%.25f' % weight0[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3e7a63e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1800,)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(weight0_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ad63b8",
   "metadata": {},
   "source": [
    "(Below: old pickle version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "60288975",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   reload pickled data from file\n",
    "# test_name = save_names[0]\n",
    "# with open(test_name, 'rb') as f:\n",
    "#     test_load = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "788d1c48-f316-4c85-b069-e7d62cd6c9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the loaded versions in the appropriate variables\n",
    "# with open('Models/paramvals/weight0.csv', 'rb') as f:\n",
    "#     weight0 = pickle.load(f)\n",
    "    \n",
    "# with open('Models/paramvals/bias0.csv', 'rb') as f:\n",
    "#     bias0 = pickle.load(f)\n",
    "#     s = np.shape(bias0)[0]\n",
    "#     bias0 = np.reshape(bias0, (s, 1))\n",
    "    \n",
    "# with open('Models/paramvals/weight2.csv', 'rb') as f:\n",
    "#     weight2 = pickle.load(f)\n",
    "    \n",
    "# with open('Models/paramvals/bias2.csv', 'rb') as f:\n",
    "#     bias2 = pickle.load(f)\n",
    "#     s = np.shape(bias2)[0]\n",
    "#     bias2 = np.reshape(bias2, (s, 1))\n",
    "    \n",
    "# with open('Models/paramvals/weight4.csv', 'rb') as f:\n",
    "#     weight4 = pickle.load(f)\n",
    "    \n",
    "# with open('Models/paramvals/bias4.csv', 'rb') as f:\n",
    "#     bias4 = pickle.load(f)\n",
    "#     s = np.shape(bias4)[0]\n",
    "#     bias4 = np.reshape(bias4, (s, 1))\n",
    "\n",
    "# # Gather together in a list of all variables\n",
    "# weights_and_biases = [weight0, bias0, weight2, bias2, weight4, bias4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5b9a2b",
   "metadata": {},
   "source": [
    "Same for flattened arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4abc8dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('Models/paramvals/bias0_flat.csv', 'r') as file:\n",
    "#     csvreader = csv.reader(file)\n",
    "# #     for row in csvreader:\n",
    "# #         print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5b4c157b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the loaded versions in the appropriate variables\n",
    "# with open('Models/paramvals/weight0_flat.csv', 'rb') as f:\n",
    "#     weight0_flat = pickle.load(f)\n",
    "    \n",
    "# # with open('Models/paramvals/bias0_flat.csv', 'rb') as f:\n",
    "# #     bias0_flat = pickle.load(f)\n",
    "\n",
    "    \n",
    "# with open('Models/paramvals/weight2_flat.csv', 'rb') as f:\n",
    "#     weight2_flat = pickle.load(f)\n",
    "    \n",
    "# with open('Models/paramvals/bias2_flat.csv', 'rb') as f:\n",
    "#     bias2_flat = pickle.load(f)\n",
    "    \n",
    "# with open('Models/paramvals/weight4_flat.csv', 'rb') as f:\n",
    "#     weight4_flat = pickle.load(f)\n",
    "    \n",
    "# with open('Models/paramvals/bias4_flat.csv', 'rb') as f:\n",
    "#     bias4_flat = pickle.load(f)\n",
    "\n",
    "# # Gather together in a list of all variables\n",
    "# weights_and_biases_flat = [weight0_flat, bias0_flat, weight2_flat, bias2_flat, weight4_flat, bias4_flat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "85e7dfa7-7137-4a5f-9c90-b79ab3516a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the file:  weight0\n",
      "The shape is equal to  (600, 3)\n",
      "For the file:  bias0\n",
      "The shape is equal to  (600, 1)\n",
      "For the file:  weight2\n",
      "The shape is equal to  (200, 600)\n",
      "For the file:  bias2\n",
      "The shape is equal to  (200, 1)\n",
      "For the file:  weight4\n",
      "The shape is equal to  (1, 200)\n",
      "For the file:  bias4\n",
      "The shape is equal to  (1, 1)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape for each parameter:\n",
    "for i in range(len(weights_and_biases)):\n",
    "    print(\"For the file: \", file_names[i])\n",
    "    # Read the values\n",
    "    shape = np.shape(weights_and_biases[i])\n",
    "    print(\"The shape is equal to \", shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b07bec3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the file:  Models/paramvals/weight0_flat.csv\n",
      "The shape is equal to  (1800,)\n",
      "For the file:  Models/paramvals/bias0_flat.csv\n",
      "The shape is equal to  (600,)\n",
      "For the file:  Models/paramvals/weight2_flat.csv\n",
      "The shape is equal to  (120000,)\n",
      "For the file:  Models/paramvals/bias2_flat.csv\n",
      "The shape is equal to  (200,)\n",
      "For the file:  Models/paramvals/weight4_flat.csv\n",
      "The shape is equal to  (200,)\n",
      "For the file:  Models/paramvals/bias4_flat.csv\n",
      "The shape is equal to  ()\n"
     ]
    }
   ],
   "source": [
    "# Same for their flattened versions:\n",
    "for i in range(len(weights_and_biases_flat)):\n",
    "    print(\"For the file: \", flat_save_names[i])\n",
    "    # Read the values\n",
    "    shape = np.shape(weights_and_biases_flat[i])\n",
    "    print(\"The shape is equal to \", shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afd58f4",
   "metadata": {},
   "source": [
    "##### Play around with some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b8c6a77e-6221-4158-8dc5-2de8cdddbce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read the example file\n",
    "# print(example)\n",
    "# print(np.shape(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8cf45633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_load_value = test_load[0][0]\n",
    "# print('%.25f' % test_load_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a77502-f96b-4221-9878-4e50854bcfe2",
   "metadata": {},
   "source": [
    "### Predicting using the values in the arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9709a2-c540-4130-ac6b-3ada2552bc0b",
   "metadata": {},
   "source": [
    "When we are going to implement this in the Gmunu code, we can no longer use any of the built-in tools of PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1e65ebe8-1c4f-4c4f-aced-77fadcd57267",
   "metadata": {},
   "outputs": [],
   "source": [
    "## One specific test case for the data\n",
    "rho,eps,v,p,D,S,tau = 9.83632270803203,1.962038705851822,0.2660655147967911,12.866163917605371,10.204131145455385,12.026584842282125,22.131296926293793"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acabd1c-7014-4bae-9615-389bd9c251d5",
   "metadata": {},
   "source": [
    "This is how the PyTorch implementation works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1ffbcdea-ab47-41ce-a968-d53be5534c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact:\n",
      "12.866163917605371\n",
      "Pytorch prediction:\n",
      "12.866371154785156\n"
     ]
    }
   ],
   "source": [
    "input_test = torch.tensor([D, S, tau])\n",
    "exact_result = p\n",
    "print(\"Exact:\")\n",
    "print(exact_result)\n",
    "# print(input_test)\n",
    "with torch.no_grad():\n",
    "    pred = model(input_test).item()\n",
    "\n",
    "print(\"Pytorch prediction:\")\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28e00da-5bd8-419c-806b-4b6ecf3f2dbf",
   "metadata": {},
   "source": [
    "Now, we have to try and get the same output, but by defining all intermediate steps ourselves!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "194e0737-14b7-49b7-b3af-89221678facc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def compute_prediction(x):\n",
    "    \"\"\"Input is a np. array of size 1x3\"\"\"\n",
    "    x = np.matmul(weight0, x) + bias0\n",
    "    x = sigmoid(x)\n",
    "    x = np.matmul(weight2, x) + bias2\n",
    "    x = sigmoid(x)\n",
    "    x = np.matmul(weight4, x) + bias4\n",
    "    return x[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5745fb74-6f68-4556-a8e0-c80628e93b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3)\n",
      "(3, 1)\n"
     ]
    }
   ],
   "source": [
    "input_test = np.array([[D, S, tau]])\n",
    "print(np.shape(input_test))\n",
    "input_test = np.transpose(input_test)\n",
    "print(np.shape(input_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c422a5de-4b83-4f5f-b1e0-c6023c8cd65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.866371869133928\n",
      "12.866371154785156\n"
     ]
    }
   ],
   "source": [
    "our_prediction = compute_prediction(input_test)\n",
    "print(our_prediction)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fbe512-19ff-4157-9a33-68899241991d",
   "metadata": {},
   "source": [
    "Now we compute rho and eps from this (see appendix A of central paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "aee97e55-2be0-4bc1-8c31-62ad7b4db25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our calculations:\n",
      "9.836326155512264 1.9620391642983483\n",
      "Exact results:\n",
      "9.83632270803203 1.962038705851822\n"
     ]
    }
   ],
   "source": [
    "v_star = S/(tau + D + our_prediction)\n",
    "W_star = 1/np.sqrt(1-v_star**2)\n",
    "\n",
    "rho_star = D/W_star\n",
    "eps_star = (tau + D*(1 - W_star) + our_prediction*(1 - W_star**2))/(D*W_star)\n",
    "print(\"Our calculations:\")\n",
    "print(rho_star, eps_star)\n",
    "print(\"Exact results:\")\n",
    "print(rho, eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aff9646-60ef-402e-a56c-3eccee7478e2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Now save it into an hdf5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ba57a7f2-8af2-4ba6-a242-d19fbfbe034b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Open an HDF5 file for writing\n",
    "# with h5py.File(\"NNC2Pv0_params.h5\", \"w\") as f:\n",
    "#     # Save the weights and biases of the network to the HDF5 file\n",
    "#     f.create_dataset(\"NNC2Pv0_params\", data=NNC2P.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929bc14b",
   "metadata": {},
   "source": [
    "## More advanced: using Torch script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a983a5e9",
   "metadata": {},
   "source": [
    "There exist two ways of converting a PyTorch model to Torch Script. The first is known as tracing, a mechanism in which the structure of the model is captured by evaluating it once using example inputs, and recording the flow of those inputs through the model. This is suitable for models that make limited use of control flow. The second approach is to add explicit annotations to your model that inform the Torch Script compiler that it may directly parse and compile your model code, subject to the constraints imposed by the Torch Script language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa4c899e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 0.5000])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = torch.tensor([1, 1, 0.5])\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71837a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  original_name=NeuralNetwork\n",
       "  (stack): Sequential(\n",
       "    original_name=Sequential\n",
       "    (0): Linear(original_name=Linear)\n",
       "    (1): Sigmoid(original_name=Sigmoid)\n",
       "    (2): Linear(original_name=Linear)\n",
       "    (3): Sigmoid(original_name=Sigmoid)\n",
       "    (4): Linear(original_name=Linear)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traced_script_module = torch.jit.trace(model, example)\n",
    "traced_script_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28fafa57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0595], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = traced_script_module(torch.tensor([1,1,0.5]))\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8866ef33",
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_script_module.save(\"traced_NNC2P_model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7817ec-e463-4ed5-baf0-1b887b960d0b",
   "metadata": {},
   "source": [
    "__To do: finish it__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498cc2eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "author": "Thibeau Wouters",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
